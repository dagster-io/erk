{"type":"queue-operation","operation":"dequeue","timestamp":"2026-02-22T14:36:49.318Z","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0"}
{"parentUuid":null,"isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":"<command-message>erk:plan-implement is running…</command-message>\n<command-name>/erk:plan-implement</command-name>\n<command-args>7853</command-args>"},"uuid":"18919d47-54ba-40b8-ba83-39b4a718f547","timestamp":"2026-02-22T14:36:49.355Z"}
{"parentUuid":"18919d47-54ba-40b8-ba83-39b4a718f547","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":[{"type":"text","text":"# /erk:plan-implement\n\nImplement a plan - either from a GitHub issue, a markdown file, an existing `.impl/` folder, or by saving the current plan first.\n\nThis is the primary implementation workflow - it orchestrates:\n\n1. Setting up the `.impl/` folder (from issue, file, existing folder, or fresh plan)\n2. Executing the implementation\n3. Running CI and submitting the PR\n\n## Prerequisites\n\n- Must be in a git repository managed by erk\n- GitHub CLI (`gh`) must be authenticated\n- One of:\n  - An issue number, URL, or file path argument\n  - An existing `.impl/` folder\n  - A plan in `~/.claude/plans/` (from plan mode)\n\n## Usage\n\n```bash\n/erk:plan-implement                    # Use .impl/ or save current plan\n/erk:plan-implement 2521               # Fetch and implement issue #2521\n/erk:plan-implement https://github.com/owner/repo/issues/2521  # URL form\n/erk:plan-implement ./my-plan.md       # Implement from local markdown file\n```\n\n---\n\n## Agent Instructions\n\n### Step 0: Parse Arguments\n\nExtract optional argument from `7853`:\n\n- **If numeric** (e.g., `2521`): Store as `ISSUE_ARG`\n- **If GitHub URL** (e.g., `https://github.com/owner/repo/issues/2521`): Extract number from path, store as `ISSUE_ARG`\n- **If path to file** (anything else non-empty): Store as `FILE_ARG`\n- **If empty**: Proceed to check `.impl/` folder\n\nStore either `ISSUE_ARG` (issue number) or `FILE_ARG` (file path), or neither if empty.\n\n### Step 1: Determine Implementation Source\n\nFollow this priority order:\n\n#### 1a. If ISSUE_ARG is provided\n\nFirst, check if `.impl/` already exists and is valid:\n\n```bash\nerk exec impl-init --json\n```\n\nIf this succeeds with `\"valid\": true`:\n\n- If `has_issue_tracking: false`: **Skip directly to Step 2d** (file-based plan, no remote to sync with).\n- If `has_issue_tracking: true`: **Still call `setup-impl-from-issue`** to ensure the local branch is synced with remote (see below). The command is idempotent — if already on the plan branch it just pulls the latest.\n\nOtherwise, set up from the specified issue:\n\n```bash\nerk exec setup-impl-from-issue <ISSUE_ARG>\n```\n\nThis command:\n\n- For draft-PR plans: checks out the plan branch and syncs with remote via pull-rebase\n- For issue-based plans: creates a feature branch from current branch (stacked) or trunk\n- Checks out the branch in the current worktree\n- Creates `.impl/` folder with the plan content\n- Saves issue reference for PR linking\n\nIf this fails, display the error and stop.\n\nThen run impl-init:\n\n```bash\nerk exec impl-init --json\n```\n\n#### 1a-file. If FILE_ARG is provided\n\nSet up from the specified markdown file:\n\n1. **Verify the file exists** using the Read tool\n2. **Extract the title** from the first `# ` heading in the file\n3. **Generate branch name** from the title (slugify: lowercase, replace spaces with hyphens, remove special chars)\n4. **Create a feature branch** (use devrun agent for gt commands):\n   ```bash\n   gt create <branch-name>\n   ```\n5. **Create `.impl/` folder** and copy the plan:\n   ```bash\n   mkdir -p .impl && cp <FILE_ARG> .impl/plan.md\n   ```\n\nThis is a local-only plan (no GitHub issue tracking).\n\nThen run impl-init:\n\n```bash\nerk exec impl-init --json\n```\n\nNote: `has_issue_tracking` will be `false` for file-based plans.\n\n#### 1b. If .impl/ already exists\n\nCheck if implementation is already set up:\n\n```bash\nerk exec impl-init --json\n```\n\nIf this succeeds with `\"valid\": true`:\n\n- If `has_issue_tracking: false`: **Skip directly to Step 2d** (file-based plan, no remote to sync with).\n- If `has_issue_tracking: true`: **Call `setup-impl-from-issue <issue_number>`** to sync the local branch with remote, then proceed to Step 2d. The `issue_number` is available in `.impl/issue.json`.\n\nIf it fails or returns `\"valid\": false`, continue to Step 2.\n\n#### 1c. Fall back to saving current plan\n\nIf neither argument nor valid `.impl/` exists, save the current plan from plan mode (Step 2).\n\n### Step 2: Save Plan to GitHub\n\nSave the current plan to GitHub and capture the issue number:\n\n```bash\nerk exec plan-save --format json --session-id=\"${CLAUDE_SESSION_ID}\"\n```\n\nParse the JSON output to get:\n\n- `issue_number`: The created issue number\n- `title`: The issue title (for branch naming)\n\nIf this fails, display the error and stop.\n\n### Step 2b: Create Branch and Setup .impl/\n\nNow set up the implementation environment using the saved issue:\n\n```bash\nerk exec setup-impl-from-issue <issue-number>\n```\n\nThis command:\n\n- Creates a feature branch from current branch (stacked) or trunk\n- Checks out the new branch in the current worktree\n- Creates `.impl/` folder with the plan content\n- Saves issue reference for PR linking\n\nIf this fails, display the error and stop.\n\n### Step 2c: Re-run Implementation Initialization\n\nRun impl-init again now that .impl/ is set up:\n\n```bash\nerk exec impl-init --json\n```\n\nUse the returned `phases` for TodoWrite entries. If validation fails, display error and stop.\n\n### Step 2d: Clean Up Plan Staging Directory (All Paths)\n\n**All setup paths converge here before Step 3.** If `.erk/impl-context/` exists in git tracking (from draft-PR plan save), remove it:\n\n```bash\nif [ -d .erk/impl-context/ ]; then\n  git rm -rf .erk/impl-context/\n  git commit -m \"Remove .erk/impl-context/ before implementation\"\n  git push origin \"$(git branch --show-current)\"\nfi\n```\n\nThis directory contains plan content committed during plan-save. It is idempotent — safe to run even when the directory doesn't exist.\n\n### Step 3: Read Plan and Load Context\n\nRead `.impl/plan.md` to understand:\n\n- Overall goal and context\n- Context & Understanding sections (API quirks, architectural insights, pitfalls)\n- Implementation phases and dependencies\n- Success criteria\n\n**Context Consumption**: Plans contain expensive discoveries. Ignoring `[CRITICAL:]` tags, \"Related Context:\" subsections, or \"DO NOT\" items causes repeated mistakes.\n\n### Step 4: Load Related Documentation\n\nIf plan contains \"Related Documentation\" section, load listed skills via Skill tool and read listed docs.\n\n### Step 5: Create TodoWrite Entries\n\nCreate todo entries for each phase from impl-init output.\n\n### Step 6: Signal GitHub Started\n\n```bash\nerk exec impl-signal started --session-id=\"${CLAUDE_SESSION_ID}\" 2>/dev/null || true\n```\n\nThis also deletes the Claude plan file (from `~/.claude/plans/`) since:\n\n- The content has been saved to GitHub issue\n- The content has been snapshotted to `.erk/scratch/`\n- Keeping it could cause confusion if the user tries to re-save\n\n### Step 7: Execute Each Phase Sequentially\n\nFor each phase:\n\n1. **Mark phase as in_progress** (in TodoWrite)\n2. **Read task requirements** carefully\n3. **Implement code AND tests together**:\n   - Load `dignified-python-313` skill for coding standards\n   - Load `fake-driven-testing` skill for test patterns\n   - Follow project AGENTS.md standards\n4. **Mark phase as completed** (in TodoWrite)\n5. **Report progress**: changes made, what's next\n\n**Important:** `.impl/plan.md` is immutable - NEVER edit during implementation\n\n### Step 8: Report Progress\n\nAfter each phase: report changes made and what's next.\n\n### Step 9: Final Verification\n\nConfirm all tasks executed, success criteria met, note deviations, summarize changes.\n\n### Step 10: Signal GitHub Ended\n\n```bash\nerk exec impl-signal ended --session-id=\"${CLAUDE_SESSION_ID}\" 2>/dev/null || true\n```\n\n### Step 10b: Upload Session for Async Learn\n\nUpload the current session to enable async learn:\n\n```bash\n# Capture session info\neval \"$(erk exec capture-session-info)\"\n\n# Get issue number from .impl/issue.json (jq extracts issue_number field)\nISSUE_NUMBER=$(jq -r '.issue_number // empty' .impl/issue.json 2>/dev/null || echo \"\")\n\n# Upload if we have both session and issue tracking\nif [ -n \"$SESSION_ID\" ] && [ -n \"$SESSION_FILE\" ] && [ -n \"$ISSUE_NUMBER\" ]; then\n  erk exec upload-session \\\n    --session-file \"$SESSION_FILE\" \\\n    --session-id \"$SESSION_ID\" \\\n    --source local \\\n    --issue-number \"$ISSUE_NUMBER\" || true\nfi\n```\n\nThis enables `erk learn --async` to work for locally-implemented PRs by uploading the session to a gist.\n\n### Step 11: Verify .impl/ Preserved\n\n**CRITICAL GUARDRAIL**: Verify the .impl/ folder was NOT deleted.\n\n```bash\nerk exec impl-verify\n```\n\nIf this fails, you have violated instructions. The .impl/ folder must be preserved for user review.\n\n### Step 12: Run CI Iteratively\n\n1. If `.erk/prompt-hooks/post-plan-implement-ci.md` exists: follow its instructions\n2. Otherwise: check CLAUDE.md/AGENTS.md for CI commands\n\n**Note:** `.worker-impl/` and `.erk/impl-context/` cleanup is handled by the workflow before implementation begins. For local execution, Step 2d handles `.erk/impl-context/` cleanup.\n\n**CRITICAL**: Never delete `.impl/` - leave for user review (no auto-commit).\n\n### Step 13: Submit PR\n\nPush the branch and create or update the PR using the Graphite-aware submit pipeline:\n\n```bash\nerk pr submit\n```\n\nThis handles pushing commits, creating/updating the PR, generating the PR description, and enhancing with Graphite stack metadata when available.\n\nAfter successful submission, signal lifecycle transition:\n\n```bash\nerk exec impl-signal submitted 2>/dev/null || true\n```\n\nThen validate PR rules:\n\n```bash\nerk pr check\n```\n\nIf checks fail, display output and warn user.\n\n### Step 14: Output Format\n\n- **Start**: \"Setting up implementation...\" or \"Fetching plan from issue #X...\"\n- **After setup**: \"Implementation environment ready, reading plan...\"\n- **Each phase**: \"Phase X: [brief description]\" with code changes\n- **End**: \"Plan execution complete. [Summary]\"\n\n---\n\n## Related Commands\n\n- `/erk:plan-save` - Save plan only, don't implement (for defer-to-later workflow)\n- `/erk:replan` - Re-plan an existing issue with current codebase state\n"}]},"isMeta":true,"uuid":"9ba2d9d4-0382-4b1d-bc53-2633490fda77","timestamp":"2026-02-22T14:36:49.355Z"}
{"parentUuid":"9ba2d9d4-0382-4b1d-bc53-2633490fda77","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01HtBEihe4V6ynSVPVby3t1P","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll implement plan #7853. Let me start by setting up the implementation environment."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11839,"cache_read_input_tokens":16522,"cache_creation":{"ephemeral_5m_input_tokens":11839,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGyu2KzLXsPkBRFNppi","type":"assistant","uuid":"4496f5d1-a61b-4bce-a9c4-a907f735320e","timestamp":"2026-02-22T14:36:52.913Z"}
{"parentUuid":"4496f5d1-a61b-4bce-a9c4-a907f735320e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01HtBEihe4V6ynSVPVby3t1P","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012QZfHdGHBNe58EvMHxhebM","name":"Bash","input":{"command":"erk exec impl-init --json 2>&1","description":"Check if .impl/ already exists"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":11839,"cache_read_input_tokens":16522,"cache_creation":{"ephemeral_5m_input_tokens":11839,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGyu2KzLXsPkBRFNppi","type":"assistant","uuid":"fd0589b3-b614-4810-bd37-28eaa5af288c","timestamp":"2026-02-22T14:36:53.591Z"}
{"parentUuid":"fd0589b3-b614-4810-bd37-28eaa5af288c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012QZfHdGHBNe58EvMHxhebM","type":"tool_result","content":"{\"valid\": true, \"impl_type\": \"impl\", \"has_issue_tracking\": true, \"related_docs\": {\"skills\": [], \"docs\": []}, \"issue_number\": 7853}","is_error":false}]},"uuid":"50bacc11-e2c1-4e20-b1d9-2ea1e51bf057","timestamp":"2026-02-22T14:36:54.639Z","toolUseResult":{"stdout":"{\"valid\": true, \"impl_type\": \"impl\", \"has_issue_tracking\": true, \"related_docs\": {\"skills\": [], \"docs\": []}, \"issue_number\": 7853}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"50bacc11-e2c1-4e20-b1d9-2ea1e51bf057","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01WuDoNrrtmNGhPkSfNDbftA","type":"message","role":"assistant","content":[{"type":"text","text":"The `.impl/` folder exists and is valid with issue tracking. Let me sync with remote and read the plan."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":164,"cache_read_input_tokens":28361,"cache_creation":{"ephemeral_5m_input_tokens":164,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGzDdWyuP2ZL7MtYF9W","type":"assistant","uuid":"ee7e81a3-e859-4cb0-a792-91f02392524c","timestamp":"2026-02-22T14:36:57.400Z"}
{"parentUuid":"ee7e81a3-e859-4cb0-a792-91f02392524c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01WuDoNrrtmNGhPkSfNDbftA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VBWx6kPhV9g1ARQdLbFTkh","name":"Bash","input":{"command":"erk exec setup-impl-from-issue 7853 2>&1","description":"Sync local branch with remote"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":164,"cache_read_input_tokens":28361,"cache_creation":{"ephemeral_5m_input_tokens":164,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGzDdWyuP2ZL7MtYF9W","type":"assistant","uuid":"97971f9d-dc8e-4de0-8e75-82e1a5bc4bbc","timestamp":"2026-02-22T14:36:57.870Z"}
{"parentUuid":"97971f9d-dc8e-4de0-8e75-82e1a5bc4bbc","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VBWx6kPhV9g1ARQdLbFTkh","type":"tool_result","content":"Found existing .impl/ for plan #7853, skipping branch setup\n{\"success\": true, \"impl_path\": \"/home/runner/work/erk/erk/.impl\", \"issue_number\": 7853, \"issue_url\": \"https://github.com/dagster-io/erk/pull/7853\", \"branch\": \"planned/plan-llm-generated-bran-02-22-0933\", \"plan_title\": \"\", \"no_impl\": false}","is_error":false}]},"uuid":"5683337e-f354-4fb1-b5d6-72eb2fb0553c","timestamp":"2026-02-22T14:36:58.882Z","toolUseResult":{"stdout":"Found existing .impl/ for plan #7853, skipping branch setup\n{\"success\": true, \"impl_path\": \"/home/runner/work/erk/erk/.impl\", \"issue_number\": 7853, \"issue_url\": \"https://github.com/dagster-io/erk/pull/7853\", \"branch\": \"planned/plan-llm-generated-bran-02-22-0933\", \"plan_title\": \"\", \"no_impl\": false}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"5683337e-f354-4fb1-b5d6-72eb2fb0553c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01TLFQxDjUSdFF3VYDJRemZK","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014LsEx77qgXYsPWyJtY9Vzj","name":"Bash","input":{"command":"erk exec impl-init --json 2>&1","description":"Re-run impl-init after sync"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":237,"cache_read_input_tokens":28525,"cache_creation":{"ephemeral_5m_input_tokens":237,"ephemeral_1h_input_tokens":0},"output_tokens":19,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGzXkgKyLas7tD2d19R","type":"assistant","uuid":"185006ee-0519-4045-bb33-68654e514d2d","timestamp":"2026-02-22T14:37:01.260Z"}
{"parentUuid":"185006ee-0519-4045-bb33-68654e514d2d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014LsEx77qgXYsPWyJtY9Vzj","type":"tool_result","content":"{\"valid\": true, \"impl_type\": \"impl\", \"has_issue_tracking\": true, \"related_docs\": {\"skills\": [], \"docs\": []}, \"issue_number\": 7853}","is_error":false}]},"uuid":"bb7537f2-d00c-4618-92df-2c1fe111e923","timestamp":"2026-02-22T14:37:02.255Z","toolUseResult":{"stdout":"{\"valid\": true, \"impl_type\": \"impl\", \"has_issue_tracking\": true, \"related_docs\": {\"skills\": [], \"docs\": []}, \"issue_number\": 7853}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"bb7537f2-d00c-4618-92df-2c1fe111e923","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_019n4CJPRdEAGd4boCwsKkBc","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me clean up any plan staging directory and read the plan:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":143,"cache_read_input_tokens":28762,"cache_creation":{"ephemeral_5m_input_tokens":143,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGznBbgZjmvTpT5UyxF","type":"assistant","uuid":"c7d7dc84-7598-4c97-aec0-e9331ed77adc","timestamp":"2026-02-22T14:37:04.622Z"}
{"parentUuid":"c7d7dc84-7598-4c97-aec0-e9331ed77adc","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_019n4CJPRdEAGd4boCwsKkBc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019BbRaY3SeGvEZvotsH4EmA","name":"Bash","input":{"command":"if [ -d .erk/impl-context/ ]; then git rm -rf .erk/impl-context/ && git commit -m \"Remove .erk/impl-context/ before implementation\" && git push origin \"$(git branch --show-current)\"; else echo \"No impl-context to clean up\"; fi","description":"Clean up plan staging directory"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":143,"cache_read_input_tokens":28762,"cache_creation":{"ephemeral_5m_input_tokens":143,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPGznBbgZjmvTpT5UyxF","type":"assistant","uuid":"0f81a982-be8f-42e0-ae78-23619f7cc648","timestamp":"2026-02-22T14:37:05.722Z"}
{"parentUuid":"0f81a982-be8f-42e0-ae78-23619f7cc648","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019BbRaY3SeGvEZvotsH4EmA","type":"tool_result","content":"No impl-context to clean up","is_error":false}]},"uuid":"c1e103c2-d8c1-4138-886d-1011b9af6ef7","timestamp":"2026-02-22T14:37:07.083Z","toolUseResult":{"stdout":"No impl-context to clean up","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"c1e103c2-d8c1-4138-886d-1011b9af6ef7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","message":{"model":"claude-opus-4-6","id":"msg_01TGsbSvQjL1rLX61RFCym4C","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PAqEatFyvTq3SnVJBzw9BU","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/.impl/plan.md"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":28905,"cache_creation":{"ephemeral_5m_input_tokens":280,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH18qoyB6WaZaaw1mQo","type":"assistant","uuid":"c94af156-ae01-406d-8729-946a564f3518","timestamp":"2026-02-22T14:37:09.316Z"}
{"parentUuid":"c94af156-ae01-406d-8729-946a564f3518","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PAqEatFyvTq3SnVJBzw9BU","type":"tool_result","content":"     1→# Plan: LLM-Generated Branch Name Slugs\n     2→\n     3→## Context\n     4→\n     5→Current branch names use `sanitize_worktree_name()` which mindlessly truncates raw plan/issue titles to 31 characters, producing ugly slugs like `add-discriminated-union-validat`. This plan adds a haiku inference call to distill titles into meaningful 2-4 word slugs before they enter the branch naming pipeline. The structural format (prefixes, timestamps) stays the same.\n     6→\n     7→**Before:** `P7843-add-objective-context-mark-02-22-1430`\n     8→**After:** `P7843-objective-marker-fallback-02-22-1430`\n     9→\n    10→## Implementation\n    11→\n    12→### 1. Create `src/erk/core/branch_slug_generator.py`\n    13→\n    14→Follow the `CommitMessageGenerator` pattern from `src/erk/core/commit_message_generator.py`.\n    15→\n    16→**Types:**\n    17→- `BranchSlugResult` — frozen dataclass with `success: bool`, `slug: str | None`, `error_message: str | None`\n    18→- `BranchSlugGenerator` — concrete class taking `PromptExecutor`, with `generate(title: str) -> BranchSlugResult`\n    19→- `generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str` — convenience function that returns the LLM slug on success, or the raw title on failure (so `sanitize_worktree_name` handles it downstream)\n    20→\n    21→**System prompt** (inline constant):\n    22→```\n    23→You are a branch name slug generator. Given a title, return ONLY a concise\n    24→2-4 word slug using lowercase letters and hyphens. No explanation.\n    25→\n    26→Rules:\n    27→- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n    28→- Capture the distinctive essence, not generic words\n    29→- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n    30→- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n    31→- Never exceed 30 characters total\n    32→- Output ONLY the slug, nothing else\n    33→```\n    34→\n    35→**Post-processing:** Strip quotes/backticks, run through `sanitize_worktree_name` as safety net, validate 2+ words and max 30 chars.\n    36→\n    37→### 2. Create `tests/core/test_branch_slug_generator.py`\n    38→\n    39→Unit tests using `FakePromptExecutor` (from `erk_shared.core.fakes`):\n    40→- Successful slug generation\n    41→- Strips quotes/backticks from LLM output\n    42→- Falls back on executor failure\n    43→- Rejects single-word output\n    44→- Rejects too-long output\n    45→- `generate_slug_or_fallback` returns slug on success, raw title on failure\n    46→\n    47→### 3. Integrate at 5 call sites\n    48→\n    49→Each call site already has access to `PromptExecutor` via `require_prompt_executor(ctx)`. The pattern at each site:\n    50→\n    51→```python\n    52→executor = require_prompt_executor(ctx)\n    53→slug = generate_slug_or_fallback(executor, title)\n    54→branch_name = generate_*_branch_name(slug, ...)\n    55→```\n    56→\n    57→**Call sites:**\n    58→\n    59→| File | Function | Branch type |\n    60→|------|----------|-------------|\n    61→| `src/erk/cli/commands/exec/scripts/plan_save.py` ~L140 | `save_plan_as_draft_pr` | `planned/` |\n    62→| `src/erk/cli/commands/submit.py` | `_validate_issue_for_submit` | `P{issue}-` |\n    63→| `src/erk/cli/commands/one_shot_dispatch.py` ~L60 | `generate_branch_name` | `P{issue}-` or `oneshot-` |\n    64→| `src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py` | `setup_impl_from_issue` | `P{issue}-` |\n    65→| `src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py` | migration flow | `planned/` |\n    66→\n    67→**For `one_shot_dispatch.py`:** Add `prompt_executor: PromptExecutor | None` parameter to `generate_branch_name()`. When `None` (dry-run), skip inference and use raw prompt as before.\n    68→\n    69→### Key files\n    70→\n    71→- `src/erk/core/commit_message_generator.py` — pattern to follow\n    72→- `packages/erk-shared/src/erk_shared/naming.py` — `sanitize_worktree_name()`, `generate_issue_branch_name()`, `generate_draft_pr_branch_name()`\n    73→- `packages/erk-shared/src/erk_shared/context/helpers.py` — `require_prompt_executor()`\n    74→- `packages/erk-shared/src/erk_shared/core/fakes.py` — `FakePromptExecutor` with queue-based `prompt_results`\n    75→\n    76→### Design notes\n    77→\n    78→- **Model:** Hardcode `\"haiku\"` — always fast/cheap, no reason to vary\n    79→- **Fallback:** If LLM fails or is unavailable, raw title passes through to `sanitize_worktree_name()` — identical to current behavior\n    80→- **Existing tests:** Won't break — default `FakePromptExecutor` returns empty prompt results, which causes fallback to raw title (same as before)\n    81→- **Latency:** ~200-500ms per call, negligible vs. git/GitHub operations already in these flows\n    82→\n    83→## Verification\n    84→\n    85→1. Run unit tests: `pytest tests/core/test_branch_slug_generator.py`\n    86→2. Run affected call-site tests: `pytest tests/unit/cli/commands/exec/scripts/ tests/commands/`\n    87→3. Run full CI: `make fast-ci`\n    88→4. Manual test: `erk plan save` on a plan with a long title, verify the branch name has a meaningful slug\n    89→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"26fed1a0-7e82-43a0-8ddf-5716e0d41e6b","timestamp":"2026-02-22T14:37:09.334Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/.impl/plan.md","content":"# Plan: LLM-Generated Branch Name Slugs\n\n## Context\n\nCurrent branch names use `sanitize_worktree_name()` which mindlessly truncates raw plan/issue titles to 31 characters, producing ugly slugs like `add-discriminated-union-validat`. This plan adds a haiku inference call to distill titles into meaningful 2-4 word slugs before they enter the branch naming pipeline. The structural format (prefixes, timestamps) stays the same.\n\n**Before:** `P7843-add-objective-context-mark-02-22-1430`\n**After:** `P7843-objective-marker-fallback-02-22-1430`\n\n## Implementation\n\n### 1. Create `src/erk/core/branch_slug_generator.py`\n\nFollow the `CommitMessageGenerator` pattern from `src/erk/core/commit_message_generator.py`.\n\n**Types:**\n- `BranchSlugResult` — frozen dataclass with `success: bool`, `slug: str | None`, `error_message: str | None`\n- `BranchSlugGenerator` — concrete class taking `PromptExecutor`, with `generate(title: str) -> BranchSlugResult`\n- `generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str` — convenience function that returns the LLM slug on success, or the raw title on failure (so `sanitize_worktree_name` handles it downstream)\n\n**System prompt** (inline constant):\n```\nYou are a branch name slug generator. Given a title, return ONLY a concise\n2-4 word slug using lowercase letters and hyphens. No explanation.\n\nRules:\n- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n- Capture the distinctive essence, not generic words\n- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n- Never exceed 30 characters total\n- Output ONLY the slug, nothing else\n```\n\n**Post-processing:** Strip quotes/backticks, run through `sanitize_worktree_name` as safety net, validate 2+ words and max 30 chars.\n\n### 2. Create `tests/core/test_branch_slug_generator.py`\n\nUnit tests using `FakePromptExecutor` (from `erk_shared.core.fakes`):\n- Successful slug generation\n- Strips quotes/backticks from LLM output\n- Falls back on executor failure\n- Rejects single-word output\n- Rejects too-long output\n- `generate_slug_or_fallback` returns slug on success, raw title on failure\n\n### 3. Integrate at 5 call sites\n\nEach call site already has access to `PromptExecutor` via `require_prompt_executor(ctx)`. The pattern at each site:\n\n```python\nexecutor = require_prompt_executor(ctx)\nslug = generate_slug_or_fallback(executor, title)\nbranch_name = generate_*_branch_name(slug, ...)\n```\n\n**Call sites:**\n\n| File | Function | Branch type |\n|------|----------|-------------|\n| `src/erk/cli/commands/exec/scripts/plan_save.py` ~L140 | `save_plan_as_draft_pr` | `planned/` |\n| `src/erk/cli/commands/submit.py` | `_validate_issue_for_submit` | `P{issue}-` |\n| `src/erk/cli/commands/one_shot_dispatch.py` ~L60 | `generate_branch_name` | `P{issue}-` or `oneshot-` |\n| `src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py` | `setup_impl_from_issue` | `P{issue}-` |\n| `src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py` | migration flow | `planned/` |\n\n**For `one_shot_dispatch.py`:** Add `prompt_executor: PromptExecutor | None` parameter to `generate_branch_name()`. When `None` (dry-run), skip inference and use raw prompt as before.\n\n### Key files\n\n- `src/erk/core/commit_message_generator.py` — pattern to follow\n- `packages/erk-shared/src/erk_shared/naming.py` — `sanitize_worktree_name()`, `generate_issue_branch_name()`, `generate_draft_pr_branch_name()`\n- `packages/erk-shared/src/erk_shared/context/helpers.py` — `require_prompt_executor()`\n- `packages/erk-shared/src/erk_shared/core/fakes.py` — `FakePromptExecutor` with queue-based `prompt_results`\n\n### Design notes\n\n- **Model:** Hardcode `\"haiku\"` — always fast/cheap, no reason to vary\n- **Fallback:** If LLM fails or is unavailable, raw title passes through to `sanitize_worktree_name()` — identical to current behavior\n- **Existing tests:** Won't break — default `FakePromptExecutor` returns empty prompt results, which causes fallback to raw title (same as before)\n- **Latency:** ~200-500ms per call, negligible vs. git/GitHub operations already in these flows\n\n## Verification\n\n1. Run unit tests: `pytest tests/core/test_branch_slug_generator.py`\n2. Run affected call-site tests: `pytest tests/unit/cli/commands/exec/scripts/ tests/commands/`\n3. Run full CI: `make fast-ci`\n4. Manual test: `erk plan save` on a plan with a long title, verify the branch name has a meaningful slug\n","numLines":89,"startLine":1,"totalLines":89}}}
{"parentUuid":"26fed1a0-7e82-43a0-8ddf-5716e0d41e6b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01T3UpKTCBwQCZ7iaUmWzp2h","type":"message","role":"assistant","content":[{"type":"text","text":"Good, I have a clear plan. Let me load the relevant documentation and set up the todos."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1873,"cache_read_input_tokens":29185,"cache_creation":{"ephemeral_5m_input_tokens":1873,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH1JSX39HMWBhV9EWW7","type":"assistant","uuid":"f23137c4-98e4-4cf4-9c3c-c4a051d67ce2","timestamp":"2026-02-22T14:37:11.966Z"}
{"parentUuid":"f23137c4-98e4-4cf4-9c3c-c4a051d67ce2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01T3UpKTCBwQCZ7iaUmWzp2h","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WFZkLsKgbd2wLyPZ3QgfEw","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1873,"cache_read_input_tokens":29185,"cache_creation":{"ephemeral_5m_input_tokens":1873,"ephemeral_1h_input_tokens":0},"output_tokens":241,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH1JSX39HMWBhV9EWW7","type":"assistant","uuid":"c64ae503-007e-46af-a6aa-ffe129cf5e61","timestamp":"2026-02-22T14:37:14.242Z"}
{"parentUuid":"c64ae503-007e-46af-a6aa-ffe129cf5e61","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WFZkLsKgbd2wLyPZ3QgfEw","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"db3ea6f9-f113-4178-8d4d-a2c9cd30e4d6","timestamp":"2026-02-22T14:37:14.254Z","toolUseResult":{"oldTodos":[],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]}}
{"parentUuid":"db3ea6f9-f113-4178-8d4d-a2c9cd30e4d6","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01JoPBhxVaTpB3Udojw6eY4Z","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012oGMEzr4hWQK2NqLSagrpq","name":"Bash","input":{"command":"erk exec impl-signal started --session-id \"${CLAUDE_SESSION_ID}\" 2>/dev/null || true","description":"Signal implementation started"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":276,"cache_read_input_tokens":31058,"cache_creation":{"ephemeral_5m_input_tokens":276,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH1fX33JzK7qEHzstwu","type":"assistant","uuid":"60baadde-606e-4a8a-a1fe-7f94c3c81965","timestamp":"2026-02-22T14:37:16.900Z"}
{"parentUuid":"60baadde-606e-4a8a-a1fe-7f94c3c81965","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012oGMEzr4hWQK2NqLSagrpq","type":"tool_result","content":"{\n  \"success\": false,\n  \"event\": \"started\",\n  \"error_type\": \"session-id-required\",\n  \"message\": \"Session ID required for impl-signal started. Ensure ${CLAUDE_SESSION_ID} is available in the command context.\"\n}","is_error":false}]},"uuid":"ca4464a0-d6c3-48f6-b0c2-2c0bf94a4501","timestamp":"2026-02-22T14:37:17.906Z","toolUseResult":{"stdout":"{\n  \"success\": false,\n  \"event\": \"started\",\n  \"error_type\": \"session-id-required\",\n  \"message\": \"Session ID required for impl-signal started. Ensure ${CLAUDE_SESSION_ID} is available in the command context.\"\n}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"ca4464a0-d6c3-48f6-b0c2-2c0bf94a4501","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01DJRbFqu91TXUNuGR8vZA6N","type":"message","role":"assistant","content":[{"type":"text","text":"Let me load the necessary skills and read the key reference files:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":171,"cache_read_input_tokens":31334,"cache_creation":{"ephemeral_5m_input_tokens":171,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH1w5fXr9R2fCaQajyK","type":"assistant","uuid":"42be0961-183c-4319-8b15-00382017868f","timestamp":"2026-02-22T14:37:20.467Z"}
{"parentUuid":"42be0961-183c-4319-8b15-00382017868f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01DJRbFqu91TXUNuGR8vZA6N","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HwjeppxtqBdbbU22WQmiFt","name":"Skill","input":{"skill":"dignified-python"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":171,"cache_read_input_tokens":31334,"cache_creation":{"ephemeral_5m_input_tokens":171,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH1w5fXr9R2fCaQajyK","type":"assistant","uuid":"184098fe-a14e-48d2-8492-5c470fb85790","timestamp":"2026-02-22T14:37:20.798Z"}
{"parentUuid":"184098fe-a14e-48d2-8492-5c470fb85790","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"toolu_01HwjeppxtqBdbbU22WQmiFt","content":"Launching skill: dignified-python"}]},"uuid":"839efbf3-b97c-4ade-922b-333e5b55e7fc","timestamp":"2026-02-22T14:37:20.829Z","toolUseResult":{"success":true,"commandName":"dignified-python"}}
{"parentUuid":"839efbf3-b97c-4ade-922b-333e5b55e7fc","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /home/runner/work/erk/erk/.claude/skills/dignified-python\n\n# Dignified Python Coding Standards\n\n## Core Knowledge (ALWAYS Loaded)\n\n@dignified-python-core.md\n\n## Version Detection\n\n**Identify the project's minimum Python version** by checking (in order):\n\n1. `pyproject.toml` - Look for `requires-python` field (e.g., `requires-python = \">=3.12\"`)\n2. `setup.py` or `setup.cfg` - Look for `python_requires`\n3. `.python-version` file - Contains version like `3.12` or `3.12.0`\n4. Default to Python 3.12 if no version specifier found\n\n**Once identified, load the appropriate version-specific file:**\n\n- Python 3.10: Load `versions/python-3.10.md`\n- Python 3.11: Load `versions/python-3.11.md`\n- Python 3.12: Load `versions/python-3.12.md`\n- Python 3.13: Load `versions/python-3.13.md`\n\n## Conditional Loading (Load Based on Task Patterns)\n\nCore files above cover 80%+ of Python code patterns. Only load these additional files when you detect specific patterns:\n\nPattern detection examples:\n\n- If task mentions \"click\" or \"CLI\" -> Load `cli-patterns.md`\n- If task mentions \"subprocess\" -> Load `subprocess.md`\n\n## When to Read Each Reference Document\n\nThe `references/` directory contains detailed guidance for specialized topics. Load these on-demand when you encounter relevant patterns:\n\n### `references/exception-handling.md`\n\n**Read when**:\n\n- Writing try/except blocks\n- Wrapping third-party APIs that may raise\n- Seeing or writing `from e` or `from None`\n- Unsure if LBYL alternative exists\n\n### `references/interfaces.md`\n\n**Read when**:\n\n- Creating ABC or Protocol classes\n- Writing @abstractmethod decorators\n- Designing gateway layer interfaces\n- Choosing between ABC and Protocol\n\n### `references/typing-advanced.md`\n\n**Read when**:\n\n- Using typing.cast()\n- Creating Literal type aliases\n- Narrowing types in conditional blocks\n\n### `references/module-design.md`\n\n**Read when**:\n\n- Creating new Python modules\n- Adding module-level code (beyond simple constants)\n- Using @cache decorator at module level\n- Seeing Path() or computation at module level\n- Considering inline imports\n\n### `references/api-design.md`\n\n**Read when**:\n\n- Adding default parameter values to functions\n- Defining functions with 5 or more parameters\n- Using ThreadPoolExecutor.submit()\n- Reviewing function signatures\n\n### `references/checklists.md`\n\n**Read when**:\n\n- Final review before committing Python code\n- Unsure if you've followed all rules\n- Need a quick lookup of requirements\n\n## How to Use This Skill\n\n1. **Core knowledge** is loaded automatically (LBYL, pathlib, basic imports, anti-patterns)\n2. **Version detection** happens once - identify the minimum Python version and load the appropriate version file\n3. **Reference documents** are loaded on-demand based on the triggers above\n4. **Additional patterns** may require extra loading (CLI patterns, subprocess)\n5. **Each file is self-contained** with complete guidance for its domain\n"}]},"isMeta":true,"uuid":"d5ecd35c-5d9e-40eb-9495-56d16b0581d0","timestamp":"2026-02-22T14:37:20.828Z","sourceToolUseID":"toolu_01HwjeppxtqBdbbU22WQmiFt"}
{"parentUuid":"d5ecd35c-5d9e-40eb-9495-56d16b0581d0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01B6iUeM1Pw4N5QGcxNTQ3BW","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nNow let me read the core dignified-python standards and detect the Python version:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":889,"cache_read_input_tokens":31505,"cache_creation":{"ephemeral_5m_input_tokens":889,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH29byumQkcvCvF9sjb","type":"assistant","uuid":"77f093e8-00b8-49c6-a45c-ac04e076cac7","timestamp":"2026-02-22T14:37:23.177Z"}
{"parentUuid":"77f093e8-00b8-49c6-a45c-ac04e076cac7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01B6iUeM1Pw4N5QGcxNTQ3BW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017jEfoacDMXhD7x4fcX2zKf","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/.claude/skills/dignified-python/dignified-python-core.md"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":889,"cache_read_input_tokens":31505,"cache_creation":{"ephemeral_5m_input_tokens":889,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH29byumQkcvCvF9sjb","type":"assistant","uuid":"42c589ae-c089-4b5d-bc0f-019a17e1a9e1","timestamp":"2026-02-22T14:37:23.841Z"}
{"parentUuid":"42c589ae-c089-4b5d-bc0f-019a17e1a9e1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01B6iUeM1Pw4N5QGcxNTQ3BW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FtvZSE7YfxebmMPmYcTUB3","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/pyproject.toml","limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":889,"cache_read_input_tokens":31505,"cache_creation":{"ephemeral_5m_input_tokens":889,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH29byumQkcvCvF9sjb","type":"assistant","uuid":"8dd0abe1-cb5e-4607-8ca1-3619d7afd731","timestamp":"2026-02-22T14:37:24.515Z"}
{"parentUuid":"8dd0abe1-cb5e-4607-8ca1-3619d7afd731","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017jEfoacDMXhD7x4fcX2zKf","type":"tool_result","content":"     1→---\n     2→---\n     3→\n     4→# Dignified Python - Core Standards\n     5→\n     6→This document contains the core Python coding standards that apply to 80%+ of Python code. These principles are loaded with every skill invocation.\n     7→\n     8→For conditional loading of specialized patterns:\n     9→\n    10→- CLI development -> Load `cli-patterns.md`\n    11→- Subprocess operations -> Load `subprocess.md`\n    12→\n    13→For detailed reference material, see the \"When to Read Each Reference\" section in SKILL.md.\n    14→\n    15→---\n    16→\n    17→## The Cornerstone: LBYL Over EAFP\n    18→\n    19→**Look Before You Leap: Check conditions proactively, NEVER use exceptions for control flow.**\n    20→\n    21→This is the single most important rule in dignified Python. Every pattern below flows from this principle.\n    22→\n    23→```python\n    24→# CORRECT: Check first\n    25→if key in mapping:\n    26→    value = mapping[key]\n    27→    process(value)\n    28→\n    29→# WRONG: Exception as control flow\n    30→try:\n    31→    value = mapping[key]\n    32→    process(value)\n    33→except KeyError:\n    34→    pass\n    35→```\n    36→\n    37→---\n    38→\n    39→## Exception Handling Basics\n    40→\n    41→### Core Principle\n    42→\n    43→**ALWAYS use LBYL, NEVER EAFP for control flow**\n    44→\n    45→LBYL means checking conditions before acting. EAFP (Easier to Ask for Forgiveness than Permission) means trying operations and catching exceptions. In dignified Python, we strongly prefer LBYL.\n    46→\n    47→### Dictionary Access Patterns\n    48→\n    49→```python\n    50→# CORRECT: Membership testing\n    51→if key in mapping:\n    52→    value = mapping[key]\n    53→    process(value)\n    54→else:\n    55→    handle_missing()\n    56→\n    57→# ALSO CORRECT: .get() with default\n    58→value = mapping.get(key, default_value)\n    59→process(value)\n    60→\n    61→# CORRECT: Check before nested access\n    62→if \"config\" in data and \"timeout\" in data[\"config\"]:\n    63→    timeout = data[\"config\"][\"timeout\"]\n    64→\n    65→# WRONG: KeyError as control flow\n    66→try:\n    67→    value = mapping[key]\n    68→except KeyError:\n    69→    handle_missing()\n    70→```\n    71→\n    72→### When Exceptions ARE Acceptable\n    73→\n    74→Exceptions are ONLY acceptable at:\n    75→\n    76→1. **Error boundaries** (CLI/API level)\n    77→2. **Third-party API compatibility** (when no alternative exists)\n    78→3. **Adding context before re-raising**\n    79→\n    80→**Default: Let exceptions bubble up**\n    81→\n    82→For detailed exception handling patterns including B904 chaining, third-party API examples, and anti-patterns, see `references/exception-handling.md`.\n    83→\n    84→### Assert for Type Narrowing\n    85→\n    86→`assert` is acceptable when used **solely to narrow types** after a guard check has already established the invariant:\n    87→\n    88→```python\n    89→# CORRECT: assert for type narrowing after guard check\n    90→if not result.is_valid:\n    91→    return None\n    92→# is_valid guarantees metadata is not None, assert narrows the type\n    93→assert result.metadata is not None\n    94→process(result.metadata)\n    95→\n    96→# WRONG: assert as control flow (no prior guard)\n    97→assert result.metadata is not None  # This IS control flow\n    98→process(result.metadata)\n    99→```\n   100→\n   101→The key distinction: if removing the assert would cause a runtime error, it's control flow (WRONG). If removing it would only lose type information, it's type narrowing (ACCEPTABLE).\n   102→\n   103→---\n   104→\n   105→## Path Operations\n   106→\n   107→### The Golden Rule\n   108→\n   109→**ALWAYS check `.exists()` BEFORE `.resolve()` or `.is_relative_to()`**\n   110→\n   111→### Why This Matters\n   112→\n   113→- `.resolve()` raises `OSError` for non-existent paths\n   114→- `.is_relative_to()` raises `ValueError` for invalid comparisons\n   115→- Checking `.exists()` first avoids exceptions entirely (LBYL!)\n   116→\n   117→### Correct Patterns\n   118→\n   119→```python\n   120→from pathlib import Path\n   121→\n   122→# CORRECT: Check exists first\n   123→for wt_path in worktree_paths:\n   124→    if wt_path.exists():\n   125→        wt_path_resolved = wt_path.resolve()\n   126→        if current_dir.is_relative_to(wt_path_resolved):\n   127→            current_worktree = wt_path_resolved\n   128→            break\n   129→\n   130→# WRONG: Using exceptions for path validation\n   131→try:\n   132→    wt_path_resolved = wt_path.resolve()\n   133→    if current_dir.is_relative_to(wt_path_resolved):\n   134→        current_worktree = wt_path_resolved\n   135→except (OSError, ValueError):\n   136→    continue\n   137→```\n   138→\n   139→### Pathlib Best Practices\n   140→\n   141→**Always Use Pathlib (Never os.path)**\n   142→\n   143→```python\n   144→# CORRECT: Use pathlib.Path\n   145→from pathlib import Path\n   146→\n   147→config_file = Path.home() / \".config\" / \"app.yml\"\n   148→if config_file.exists():\n   149→    content = config_file.read_text(encoding=\"utf-8\")\n   150→\n   151→# WRONG: Use os.path\n   152→import os.path\n   153→config_file = os.path.join(os.path.expanduser(\"~\"), \".config\", \"app.yml\")\n   154→```\n   155→\n   156→**Always Specify Encoding**\n   157→\n   158→```python\n   159→# CORRECT: Always specify encoding\n   160→content = path.read_text(encoding=\"utf-8\")\n   161→path.write_text(data, encoding=\"utf-8\")\n   162→\n   163→# WRONG: Default encoding\n   164→content = path.read_text()  # Platform-dependent!\n   165→```\n   166→\n   167→---\n   168→\n   169→## Import Organization\n   170→\n   171→### Core Rules\n   172→\n   173→1. **Default: ALWAYS place imports at module level**\n   174→2. **Use absolute imports only** (no relative imports)\n   175→3. **Inline imports only for specific exceptions** (circular deps, TYPE_CHECKING, conditional features)\n   176→\n   177→```python\n   178→# CORRECT: Module-level imports\n   179→import json\n   180→import click\n   181→from pathlib import Path\n   182→from erk.config import load_config\n   183→\n   184→def my_function() -> None:\n   185→    data = json.loads(content)\n   186→\n   187→# CORRECT: Absolute import\n   188→from erk.config import load_config\n   189→\n   190→# WRONG: Relative import\n   191→from .config import load_config\n   192→\n   193→# WRONG: Inline imports without justification\n   194→def my_function() -> None:\n   195→    import json  # NEVER do this\n   196→```\n   197→\n   198→For detailed inline import patterns and when they're legitimate, see `references/module-design.md`.\n   199→\n   200→### No Import Aliases\n   201→\n   202→**Rule:** Imports must use canonical names. The `as` keyword for aliasing is prohibited by default.\n   203→\n   204→**Rationale:** Import aliases obscure the canonical name, make grep-based discovery harder, and invite cargo-culting. When reading code, aliases force you to scroll up to find the real import, breaking flow. When searching for usage of a symbol, aliases fragment results across different names.\n   205→\n   206→**The only acceptable exception:** Resolving genuine name collisions between two different modules that export identically-named symbols.\n   207→\n   208→```python\n   209→# WRONG: Gratuitous aliasing\n   210→from erk.helpers import require_issues as require_github_issues\n   211→\n   212→# CORRECT: Use canonical name\n   213→from erk.helpers import require_issues\n   214→\n   215→# CORRECT (rare exception): Resolving genuine collision\n   216→from datetime import datetime as dt\n   217→from pandas import datetime as pd_datetime\n   218→```\n   219→\n   220→**Note:** This rule is complementary to the \"No Re-Exports\" rule. Re-exports use `import X as X` for explicit re-export syntax at package boundaries. This rule targets gratuitous renaming aliases.\n   221→\n   222→---\n   223→\n   224→## Performance Guidelines\n   225→\n   226→### Properties Must Be O(1)\n   227→\n   228→```python\n   229→# WRONG: Property doing I/O\n   230→@property\n   231→def size(self) -> int:\n   232→    return self._fetch_from_db()\n   233→\n   234→# CORRECT: Explicit method name\n   235→def fetch_size_from_db(self) -> int:\n   236→    return self._fetch_from_db()\n   237→\n   238→# CORRECT: O(1) property\n   239→@property\n   240→def size(self) -> int:\n   241→    return self._cached_size\n   242→```\n   243→\n   244→### Magic Methods Must Be O(1)\n   245→\n   246→```python\n   247→# WRONG: __len__ doing iteration\n   248→def __len__(self) -> int:\n   249→    return sum(1 for _ in self._items)\n   250→\n   251→# CORRECT: O(1) __len__\n   252→def __len__(self) -> int:\n   253→    return self._count\n   254→```\n   255→\n   256→---\n   257→\n   258→## Anti-Patterns\n   259→\n   260→### No Backwards Compatibility Preservation (Default)\n   261→\n   262→```python\n   263→# WRONG: Keeping old API unnecessarily\n   264→def process_data(data: dict, legacy_format: bool = False) -> Result:\n   265→    if legacy_format:\n   266→        return legacy_process(data)\n   267→    return new_process(data)\n   268→\n   269→# CORRECT: Break and migrate immediately\n   270→def process_data(data: dict) -> Result:\n   271→    return new_process(data)\n   272→```\n   273→\n   274→### No Re-Exports: One Canonical Import Path\n   275→\n   276→**Core Principle:** Every symbol has exactly one import path. Never re-export.\n   277→\n   278→```python\n   279→# WRONG: __all__ exports create duplicate import paths\n   280→# myapp/__init__.py\n   281→from myapp.core import Process\n   282→__all__ = [\"Process\"]\n   283→\n   284→# CORRECT: Empty __init__.py, import from canonical location\n   285→# from myapp.core import Process\n   286→```\n   287→\n   288→**When re-exports ARE required** (plugin entry points): Use explicit `import X as X` syntax:\n   289→\n   290→```python\n   291→# CORRECT: Explicit re-export syntax for required entry points\n   292→from myapp.core.feature import my_function as my_function\n   293→```\n   294→\n   295→### Declare Variables Close to Use\n   296→\n   297→```python\n   298→# WRONG: Variable declared far from use\n   299→def process_data(ctx, items):\n   300→    result_path = compute_result_path(ctx)  # Declared here...\n   301→    # 20+ lines of other logic...\n   302→    save_to_path(transformed, result_path)  # ...used here\n   303→\n   304→# CORRECT: Inline at use site\n   305→def process_data(ctx, items):\n   306→    validate_items(items)\n   307→    transformed = transform_items(items)\n   308→    save_to_path(transformed, compute_result_path(ctx))\n   309→```\n   310→\n   311→### Don't Destructure Objects Into Single-Use Locals\n   312→\n   313→```python\n   314→# WRONG: Unnecessary field extraction\n   315→result = fetch_user(user_id)\n   316→name = result.name      # only used once below\n   317→email = result.email    # only used once below\n   318→send_notification(name, email, role)\n   319→\n   320→# CORRECT: Access fields directly\n   321→user = fetch_user(user_id)\n   322→send_notification(user.name, user.email, user.role)\n   323→```\n   324→\n   325→### Indentation Depth Limit\n   326→\n   327→**Maximum indentation: 4 levels**\n   328→\n   329→```python\n   330→# WRONG: Too deeply nested (5 levels)\n   331→def process_items(items):\n   332→    for item in items:\n   333→        if item.valid:\n   334→            for child in item.children:\n   335→                if child.enabled:\n   336→                    for grandchild in child.descendants:\n   337→                        pass  # 5 levels deep!\n   338→\n   339→# CORRECT: Extract helper functions\n   340→def process_items(items):\n   341→    for item in items:\n   342→        if item.valid:\n   343→            process_children(item.children)\n   344→\n   345→def process_children(children):\n   346→    for child in children:\n   347→        if child.enabled:\n   348→            process_descendants(child.descendants)\n   349→```\n   350→\n   351→---\n   352→\n   353→## Lightweight `__init__` Pattern\n   354→\n   355→Class `__init__` methods should be lightweight and cheap - just data assignment. Heavy I/O operations belong in static factory methods.\n   356→\n   357→### Why\n   358→\n   359→- **Testability**: Tests can construct objects directly without I/O setup\n   360→- **Predictability**: Instantiation has no side effects\n   361→- **Explicit dependencies**: Heavy operations are visible at call sites\n   362→- **Flexibility**: Multiple construction paths (from file, from dict, for testing)\n   363→\n   364→### Correct Pattern\n   365→\n   366→```python\n   367→class Registry:\n   368→    def __init__(self, items: list[Item], default: str | None) -> None:\n   369→        \"\"\"Lightweight - just assigns data.\"\"\"\n   370→        self._items = {item.name: item for item in items}\n   371→        self._default = default\n   372→\n   373→    @classmethod\n   374→    def from_config_path(cls, path: Path) -> \"Registry\":\n   375→        \"\"\"Heavy I/O happens here, not in __init__.\"\"\"\n   376→        data = tomllib.loads(path.read_text())\n   377→        items = [Item.from_dict(d) for d in data.get(\"items\", [])]\n   378→        return cls(items=items, default=data.get(\"default\"))\n   379→```\n   380→\n   381→### Anti-pattern\n   382→\n   383→```python\n   384→# WRONG: __init__ does heavy I/O\n   385→class Registry:\n   386→    def __init__(self, config_path: Path) -> None:\n   387→        data = tomllib.loads(config_path.read_text())  # Heavy I/O\n   388→        self._items = ...\n   389→```\n   390→\n   391→### When This Applies\n   392→\n   393→- Any class backed by file storage (TOML, JSON, etc.)\n   394→- Any class that calls subprocess on construction\n   395→- Any class that makes network requests on construction\n   396→- Any class where tests need to verify behavior without I/O\n   397→\n   398→---\n   399→\n   400→## No Invalid Object Construction\n   401→\n   402→**Never construct objects with invalid states.** Validate at the construction boundary — factory methods, reader functions, parse functions — so that if an object exists, all its fields are valid. Don't allow invalid objects to exist and then guard at every callsite.\n   403→\n   404→### Why\n   405→\n   406→- **Eliminates defensive guards**: Every callsite can trust the object's fields without conversion or None checks\n   407→- **Single validation point**: Validation logic lives in one place, not scattered across N callsites\n   408→- **Type system works for you**: Once constructed, the type tells the full story — `int` means it's numeric, not \"might be numeric\"\n   409→- **Bugs are caught early**: Invalid data is rejected at parse/read time, not at use time\n   410→\n   411→### Correct Pattern\n   412→\n   413→```python\n   414→@dataclass(frozen=True)\n   415→class PlanRef:\n   416→    plan_id: int          # Always valid — numeric guaranteed\n   417→    url: str\n   418→    provider: str\n   419→\n   420→def read_plan_ref(folder: Path) -> PlanRef | None:\n   421→    \"\"\"Validate at the boundary. Return None if invalid.\"\"\"\n   422→    data = json.loads(path.read_text())\n   423→    raw_id = data.get(\"plan_id\")\n   424→    if not isinstance(raw_id, int):\n   425→        return None  # Don't construct with invalid state\n   426→    return PlanRef(plan_id=raw_id, url=data[\"url\"], provider=data[\"provider\"])\n   427→```\n   428→\n   429→### Anti-pattern\n   430→\n   431→```python\n   432→@dataclass(frozen=True)\n   433→class PlanRef:\n   434→    plan_id: str          # Could be \"42\" or \"PROJ-123\" — caller must check\n   435→\n   436→    @property\n   437→    def numeric_plan_id(self) -> int | None:\n   438→        \"\"\"Every callsite must use this instead of plan_id.\"\"\"\n   439→        if self.plan_id.isdigit():\n   440→            return int(self.plan_id)\n   441→        return None\n   442→\n   443→# Result: N callsites with defensive guards\n   444→issue = plan_ref.numeric_plan_id\n   445→if issue is None:\n   446→    log.warning(\"Non-numeric plan_id\")\n   447→    return\n   448→```\n   449→\n   450→### When This Applies\n   451→\n   452→- Dataclasses read from JSON/TOML/YAML (validate during parsing)\n   453→- Objects constructed from user input (validate before construction)\n   454→- Any case where a field's type is broader than the valid domain (e.g., `str` when only digits are valid → use `int`)\n   455→- Factory methods that transform external data into domain objects\n   456→\n   457→### Decision: Return None vs Raise\n   458→\n   459→- **Return `None`**: When invalid data is expected/normal (e.g., missing optional file, legacy format)\n   460→- **Raise exception**: When invalid data indicates a programming error or corrupt state\n   461→\n   462→---\n   463→\n   464→## Backwards Compatibility Philosophy\n   465→\n   466→**Default stance: NO backwards compatibility preservation**\n   467→\n   468→Only preserve backwards compatibility when:\n   469→\n   470→- Code is clearly part of public API\n   471→- User explicitly requests it\n   472→- Migration cost is prohibitively high (rare)\n   473→\n   474→Benefits:\n   475→\n   476→- Cleaner, maintainable codebase\n   477→- Faster iteration\n   478→- No legacy code accumulation\n   479→- Simpler mental models\n   480→\n   481→---\n   482→\n   483→## See Also\n   484→\n   485→For detailed guidance on specialized topics:\n   486→\n   487→- **Exception chaining (B904)**: `references/exception-handling.md`\n   488→- **ABC vs Protocol**: `references/interfaces.md`\n   489→- **typing.cast() assertions**: `references/typing-advanced.md`\n   490→- **Import-time side effects, @cache**: `references/module-design.md`\n   491→- **Default parameters, keyword-only args**: `references/api-design.md`\n   492→- **All decision checklists**: `references/checklists.md`\n   493→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e2f94e51-a931-45e0-a1a4-878f0ce67f64","timestamp":"2026-02-22T14:37:24.566Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/.claude/skills/dignified-python/dignified-python-core.md","content":"---\n---\n\n# Dignified Python - Core Standards\n\nThis document contains the core Python coding standards that apply to 80%+ of Python code. These principles are loaded with every skill invocation.\n\nFor conditional loading of specialized patterns:\n\n- CLI development -> Load `cli-patterns.md`\n- Subprocess operations -> Load `subprocess.md`\n\nFor detailed reference material, see the \"When to Read Each Reference\" section in SKILL.md.\n\n---\n\n## The Cornerstone: LBYL Over EAFP\n\n**Look Before You Leap: Check conditions proactively, NEVER use exceptions for control flow.**\n\nThis is the single most important rule in dignified Python. Every pattern below flows from this principle.\n\n```python\n# CORRECT: Check first\nif key in mapping:\n    value = mapping[key]\n    process(value)\n\n# WRONG: Exception as control flow\ntry:\n    value = mapping[key]\n    process(value)\nexcept KeyError:\n    pass\n```\n\n---\n\n## Exception Handling Basics\n\n### Core Principle\n\n**ALWAYS use LBYL, NEVER EAFP for control flow**\n\nLBYL means checking conditions before acting. EAFP (Easier to Ask for Forgiveness than Permission) means trying operations and catching exceptions. In dignified Python, we strongly prefer LBYL.\n\n### Dictionary Access Patterns\n\n```python\n# CORRECT: Membership testing\nif key in mapping:\n    value = mapping[key]\n    process(value)\nelse:\n    handle_missing()\n\n# ALSO CORRECT: .get() with default\nvalue = mapping.get(key, default_value)\nprocess(value)\n\n# CORRECT: Check before nested access\nif \"config\" in data and \"timeout\" in data[\"config\"]:\n    timeout = data[\"config\"][\"timeout\"]\n\n# WRONG: KeyError as control flow\ntry:\n    value = mapping[key]\nexcept KeyError:\n    handle_missing()\n```\n\n### When Exceptions ARE Acceptable\n\nExceptions are ONLY acceptable at:\n\n1. **Error boundaries** (CLI/API level)\n2. **Third-party API compatibility** (when no alternative exists)\n3. **Adding context before re-raising**\n\n**Default: Let exceptions bubble up**\n\nFor detailed exception handling patterns including B904 chaining, third-party API examples, and anti-patterns, see `references/exception-handling.md`.\n\n### Assert for Type Narrowing\n\n`assert` is acceptable when used **solely to narrow types** after a guard check has already established the invariant:\n\n```python\n# CORRECT: assert for type narrowing after guard check\nif not result.is_valid:\n    return None\n# is_valid guarantees metadata is not None, assert narrows the type\nassert result.metadata is not None\nprocess(result.metadata)\n\n# WRONG: assert as control flow (no prior guard)\nassert result.metadata is not None  # This IS control flow\nprocess(result.metadata)\n```\n\nThe key distinction: if removing the assert would cause a runtime error, it's control flow (WRONG). If removing it would only lose type information, it's type narrowing (ACCEPTABLE).\n\n---\n\n## Path Operations\n\n### The Golden Rule\n\n**ALWAYS check `.exists()` BEFORE `.resolve()` or `.is_relative_to()`**\n\n### Why This Matters\n\n- `.resolve()` raises `OSError` for non-existent paths\n- `.is_relative_to()` raises `ValueError` for invalid comparisons\n- Checking `.exists()` first avoids exceptions entirely (LBYL!)\n\n### Correct Patterns\n\n```python\nfrom pathlib import Path\n\n# CORRECT: Check exists first\nfor wt_path in worktree_paths:\n    if wt_path.exists():\n        wt_path_resolved = wt_path.resolve()\n        if current_dir.is_relative_to(wt_path_resolved):\n            current_worktree = wt_path_resolved\n            break\n\n# WRONG: Using exceptions for path validation\ntry:\n    wt_path_resolved = wt_path.resolve()\n    if current_dir.is_relative_to(wt_path_resolved):\n        current_worktree = wt_path_resolved\nexcept (OSError, ValueError):\n    continue\n```\n\n### Pathlib Best Practices\n\n**Always Use Pathlib (Never os.path)**\n\n```python\n# CORRECT: Use pathlib.Path\nfrom pathlib import Path\n\nconfig_file = Path.home() / \".config\" / \"app.yml\"\nif config_file.exists():\n    content = config_file.read_text(encoding=\"utf-8\")\n\n# WRONG: Use os.path\nimport os.path\nconfig_file = os.path.join(os.path.expanduser(\"~\"), \".config\", \"app.yml\")\n```\n\n**Always Specify Encoding**\n\n```python\n# CORRECT: Always specify encoding\ncontent = path.read_text(encoding=\"utf-8\")\npath.write_text(data, encoding=\"utf-8\")\n\n# WRONG: Default encoding\ncontent = path.read_text()  # Platform-dependent!\n```\n\n---\n\n## Import Organization\n\n### Core Rules\n\n1. **Default: ALWAYS place imports at module level**\n2. **Use absolute imports only** (no relative imports)\n3. **Inline imports only for specific exceptions** (circular deps, TYPE_CHECKING, conditional features)\n\n```python\n# CORRECT: Module-level imports\nimport json\nimport click\nfrom pathlib import Path\nfrom erk.config import load_config\n\ndef my_function() -> None:\n    data = json.loads(content)\n\n# CORRECT: Absolute import\nfrom erk.config import load_config\n\n# WRONG: Relative import\nfrom .config import load_config\n\n# WRONG: Inline imports without justification\ndef my_function() -> None:\n    import json  # NEVER do this\n```\n\nFor detailed inline import patterns and when they're legitimate, see `references/module-design.md`.\n\n### No Import Aliases\n\n**Rule:** Imports must use canonical names. The `as` keyword for aliasing is prohibited by default.\n\n**Rationale:** Import aliases obscure the canonical name, make grep-based discovery harder, and invite cargo-culting. When reading code, aliases force you to scroll up to find the real import, breaking flow. When searching for usage of a symbol, aliases fragment results across different names.\n\n**The only acceptable exception:** Resolving genuine name collisions between two different modules that export identically-named symbols.\n\n```python\n# WRONG: Gratuitous aliasing\nfrom erk.helpers import require_issues as require_github_issues\n\n# CORRECT: Use canonical name\nfrom erk.helpers import require_issues\n\n# CORRECT (rare exception): Resolving genuine collision\nfrom datetime import datetime as dt\nfrom pandas import datetime as pd_datetime\n```\n\n**Note:** This rule is complementary to the \"No Re-Exports\" rule. Re-exports use `import X as X` for explicit re-export syntax at package boundaries. This rule targets gratuitous renaming aliases.\n\n---\n\n## Performance Guidelines\n\n### Properties Must Be O(1)\n\n```python\n# WRONG: Property doing I/O\n@property\ndef size(self) -> int:\n    return self._fetch_from_db()\n\n# CORRECT: Explicit method name\ndef fetch_size_from_db(self) -> int:\n    return self._fetch_from_db()\n\n# CORRECT: O(1) property\n@property\ndef size(self) -> int:\n    return self._cached_size\n```\n\n### Magic Methods Must Be O(1)\n\n```python\n# WRONG: __len__ doing iteration\ndef __len__(self) -> int:\n    return sum(1 for _ in self._items)\n\n# CORRECT: O(1) __len__\ndef __len__(self) -> int:\n    return self._count\n```\n\n---\n\n## Anti-Patterns\n\n### No Backwards Compatibility Preservation (Default)\n\n```python\n# WRONG: Keeping old API unnecessarily\ndef process_data(data: dict, legacy_format: bool = False) -> Result:\n    if legacy_format:\n        return legacy_process(data)\n    return new_process(data)\n\n# CORRECT: Break and migrate immediately\ndef process_data(data: dict) -> Result:\n    return new_process(data)\n```\n\n### No Re-Exports: One Canonical Import Path\n\n**Core Principle:** Every symbol has exactly one import path. Never re-export.\n\n```python\n# WRONG: __all__ exports create duplicate import paths\n# myapp/__init__.py\nfrom myapp.core import Process\n__all__ = [\"Process\"]\n\n# CORRECT: Empty __init__.py, import from canonical location\n# from myapp.core import Process\n```\n\n**When re-exports ARE required** (plugin entry points): Use explicit `import X as X` syntax:\n\n```python\n# CORRECT: Explicit re-export syntax for required entry points\nfrom myapp.core.feature import my_function as my_function\n```\n\n### Declare Variables Close to Use\n\n```python\n# WRONG: Variable declared far from use\ndef process_data(ctx, items):\n    result_path = compute_result_path(ctx)  # Declared here...\n    # 20+ lines of other logic...\n    save_to_path(transformed, result_path)  # ...used here\n\n# CORRECT: Inline at use site\ndef process_data(ctx, items):\n    validate_items(items)\n    transformed = transform_items(items)\n    save_to_path(transformed, compute_result_path(ctx))\n```\n\n### Don't Destructure Objects Into Single-Use Locals\n\n```python\n# WRONG: Unnecessary field extraction\nresult = fetch_user(user_id)\nname = result.name      # only used once below\nemail = result.email    # only used once below\nsend_notification(name, email, role)\n\n# CORRECT: Access fields directly\nuser = fetch_user(user_id)\nsend_notification(user.name, user.email, user.role)\n```\n\n### Indentation Depth Limit\n\n**Maximum indentation: 4 levels**\n\n```python\n# WRONG: Too deeply nested (5 levels)\ndef process_items(items):\n    for item in items:\n        if item.valid:\n            for child in item.children:\n                if child.enabled:\n                    for grandchild in child.descendants:\n                        pass  # 5 levels deep!\n\n# CORRECT: Extract helper functions\ndef process_items(items):\n    for item in items:\n        if item.valid:\n            process_children(item.children)\n\ndef process_children(children):\n    for child in children:\n        if child.enabled:\n            process_descendants(child.descendants)\n```\n\n---\n\n## Lightweight `__init__` Pattern\n\nClass `__init__` methods should be lightweight and cheap - just data assignment. Heavy I/O operations belong in static factory methods.\n\n### Why\n\n- **Testability**: Tests can construct objects directly without I/O setup\n- **Predictability**: Instantiation has no side effects\n- **Explicit dependencies**: Heavy operations are visible at call sites\n- **Flexibility**: Multiple construction paths (from file, from dict, for testing)\n\n### Correct Pattern\n\n```python\nclass Registry:\n    def __init__(self, items: list[Item], default: str | None) -> None:\n        \"\"\"Lightweight - just assigns data.\"\"\"\n        self._items = {item.name: item for item in items}\n        self._default = default\n\n    @classmethod\n    def from_config_path(cls, path: Path) -> \"Registry\":\n        \"\"\"Heavy I/O happens here, not in __init__.\"\"\"\n        data = tomllib.loads(path.read_text())\n        items = [Item.from_dict(d) for d in data.get(\"items\", [])]\n        return cls(items=items, default=data.get(\"default\"))\n```\n\n### Anti-pattern\n\n```python\n# WRONG: __init__ does heavy I/O\nclass Registry:\n    def __init__(self, config_path: Path) -> None:\n        data = tomllib.loads(config_path.read_text())  # Heavy I/O\n        self._items = ...\n```\n\n### When This Applies\n\n- Any class backed by file storage (TOML, JSON, etc.)\n- Any class that calls subprocess on construction\n- Any class that makes network requests on construction\n- Any class where tests need to verify behavior without I/O\n\n---\n\n## No Invalid Object Construction\n\n**Never construct objects with invalid states.** Validate at the construction boundary — factory methods, reader functions, parse functions — so that if an object exists, all its fields are valid. Don't allow invalid objects to exist and then guard at every callsite.\n\n### Why\n\n- **Eliminates defensive guards**: Every callsite can trust the object's fields without conversion or None checks\n- **Single validation point**: Validation logic lives in one place, not scattered across N callsites\n- **Type system works for you**: Once constructed, the type tells the full story — `int` means it's numeric, not \"might be numeric\"\n- **Bugs are caught early**: Invalid data is rejected at parse/read time, not at use time\n\n### Correct Pattern\n\n```python\n@dataclass(frozen=True)\nclass PlanRef:\n    plan_id: int          # Always valid — numeric guaranteed\n    url: str\n    provider: str\n\ndef read_plan_ref(folder: Path) -> PlanRef | None:\n    \"\"\"Validate at the boundary. Return None if invalid.\"\"\"\n    data = json.loads(path.read_text())\n    raw_id = data.get(\"plan_id\")\n    if not isinstance(raw_id, int):\n        return None  # Don't construct with invalid state\n    return PlanRef(plan_id=raw_id, url=data[\"url\"], provider=data[\"provider\"])\n```\n\n### Anti-pattern\n\n```python\n@dataclass(frozen=True)\nclass PlanRef:\n    plan_id: str          # Could be \"42\" or \"PROJ-123\" — caller must check\n\n    @property\n    def numeric_plan_id(self) -> int | None:\n        \"\"\"Every callsite must use this instead of plan_id.\"\"\"\n        if self.plan_id.isdigit():\n            return int(self.plan_id)\n        return None\n\n# Result: N callsites with defensive guards\nissue = plan_ref.numeric_plan_id\nif issue is None:\n    log.warning(\"Non-numeric plan_id\")\n    return\n```\n\n### When This Applies\n\n- Dataclasses read from JSON/TOML/YAML (validate during parsing)\n- Objects constructed from user input (validate before construction)\n- Any case where a field's type is broader than the valid domain (e.g., `str` when only digits are valid → use `int`)\n- Factory methods that transform external data into domain objects\n\n### Decision: Return None vs Raise\n\n- **Return `None`**: When invalid data is expected/normal (e.g., missing optional file, legacy format)\n- **Raise exception**: When invalid data indicates a programming error or corrupt state\n\n---\n\n## Backwards Compatibility Philosophy\n\n**Default stance: NO backwards compatibility preservation**\n\nOnly preserve backwards compatibility when:\n\n- Code is clearly part of public API\n- User explicitly requests it\n- Migration cost is prohibitively high (rare)\n\nBenefits:\n\n- Cleaner, maintainable codebase\n- Faster iteration\n- No legacy code accumulation\n- Simpler mental models\n\n---\n\n## See Also\n\nFor detailed guidance on specialized topics:\n\n- **Exception chaining (B904)**: `references/exception-handling.md`\n- **ABC vs Protocol**: `references/interfaces.md`\n- **typing.cast() assertions**: `references/typing-advanced.md`\n- **Import-time side effects, @cache**: `references/module-design.md`\n- **Default parameters, keyword-only args**: `references/api-design.md`\n- **All decision checklists**: `references/checklists.md`\n","numLines":493,"startLine":1,"totalLines":493}}}
{"parentUuid":"e2f94e51-a931-45e0-a1a4-878f0ce67f64","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FtvZSE7YfxebmMPmYcTUB3","type":"tool_result","content":"     1→[tool.uv.workspace]\n     2→members = [\"packages/*\"]\n     3→\n     4→[tool.uv.sources]\n     5→erk-dev = { workspace = true }\n     6→erk-shared = { workspace = true }\n     7→erk-statusline = { workspace = true }\n     8→\n     9→[project]\n    10→name = \"erk\"\n    11→version = \"0.8.0\"\n    12→description = \"Add your description here\"\n    13→readme = \"README.md\"\n    14→authors = [\n    15→    { name = \"Dagster Labs\", email = \"hello@dagsterlabs.com\" }\n    16→]\n    17→requires-python = \">=3.11\"\n    18→dependencies = [\n    19→    \"click>=8.1.7\",\n    20→    \"erk-shared\",\n    21→    \"erk-statusline\",\n    22→    \"packaging>=21.0\",\n    23→    \"pathspec>=0.12.0\",\n    24→    \"pydantic>=2.0\",\n    25→    \"pyyaml>=6.0\",\n    26→    \"python-frontmatter>=1.0.0\",\n    27→    \"rich>=13.0\",\n    28→    \"tomlkit>=0.12.0\",\n    29→    \"tomli>=2.0\",\n    30→    \"tomli-w>=1.0\",\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"360beb0e-448f-42f9-afa4-952e79fd79ea","timestamp":"2026-02-22T14:37:24.566Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/pyproject.toml","content":"[tool.uv.workspace]\nmembers = [\"packages/*\"]\n\n[tool.uv.sources]\nerk-dev = { workspace = true }\nerk-shared = { workspace = true }\nerk-statusline = { workspace = true }\n\n[project]\nname = \"erk\"\nversion = \"0.8.0\"\ndescription = \"Add your description here\"\nreadme = \"README.md\"\nauthors = [\n    { name = \"Dagster Labs\", email = \"hello@dagsterlabs.com\" }\n]\nrequires-python = \">=3.11\"\ndependencies = [\n    \"click>=8.1.7\",\n    \"erk-shared\",\n    \"erk-statusline\",\n    \"packaging>=21.0\",\n    \"pathspec>=0.12.0\",\n    \"pydantic>=2.0\",\n    \"pyyaml>=6.0\",\n    \"python-frontmatter>=1.0.0\",\n    \"rich>=13.0\",\n    \"tomlkit>=0.12.0\",\n    \"tomli>=2.0\",\n    \"tomli-w>=1.0\",","numLines":30,"startLine":1,"totalLines":127}}}
{"parentUuid":"360beb0e-448f-42f9-afa4-952e79fd79ea","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjyLpXDaDn83C9ChT845tb","type":"message","role":"assistant","content":[{"type":"text","text":"Python 3.11+. Let me read the version-specific file and the key reference files from the plan:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6332,"cache_read_input_tokens":32394,"cache_creation":{"ephemeral_5m_input_tokens":6332,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2Rbu9HVacXtHnYbNM","type":"assistant","uuid":"b642cc82-2674-4f19-9a4b-e4c273841ddf","timestamp":"2026-02-22T14:37:27.352Z"}
{"parentUuid":"b642cc82-2674-4f19-9a4b-e4c273841ddf","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjyLpXDaDn83C9ChT845tb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01R7tYE9eocpfUFeWWVHVeir","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/.claude/skills/dignified-python/versions/python-3.11.md"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6332,"cache_read_input_tokens":32394,"cache_creation":{"ephemeral_5m_input_tokens":6332,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2Rbu9HVacXtHnYbNM","type":"assistant","uuid":"cb29fbad-71fc-43c6-af1b-c3b6506c72b3","timestamp":"2026-02-22T14:37:28.255Z"}
{"parentUuid":"cb29fbad-71fc-43c6-af1b-c3b6506c72b3","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjyLpXDaDn83C9ChT845tb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JJYK1K7txKjwmWdRRW9WME","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/core/commit_message_generator.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6332,"cache_read_input_tokens":32394,"cache_creation":{"ephemeral_5m_input_tokens":6332,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2Rbu9HVacXtHnYbNM","type":"assistant","uuid":"b1ec7111-e277-4289-8cf2-775c95e089bd","timestamp":"2026-02-22T14:37:28.769Z"}
{"parentUuid":"b1ec7111-e277-4289-8cf2-775c95e089bd","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjyLpXDaDn83C9ChT845tb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013y6SDaCEVZu2WUCQtRx6GS","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/naming.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6332,"cache_read_input_tokens":32394,"cache_creation":{"ephemeral_5m_input_tokens":6332,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2Rbu9HVacXtHnYbNM","type":"assistant","uuid":"c6b6a1ea-ff93-4049-abbe-c4e78016fed4","timestamp":"2026-02-22T14:37:29.427Z"}
{"parentUuid":"c6b6a1ea-ff93-4049-abbe-c4e78016fed4","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjyLpXDaDn83C9ChT845tb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Af87i38cyzn8JqmaoJmjNE","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/helpers.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6332,"cache_read_input_tokens":32394,"cache_creation":{"ephemeral_5m_input_tokens":6332,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2Rbu9HVacXtHnYbNM","type":"assistant","uuid":"312a9813-89ea-4824-9442-98404ef5c092","timestamp":"2026-02-22T14:37:30.056Z"}
{"parentUuid":"312a9813-89ea-4824-9442-98404ef5c092","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01R7tYE9eocpfUFeWWVHVeir","type":"tool_result","content":"     1→---\n     2→---\n     3→\n     4→# Type Annotations - Python 3.11\n     5→\n     6→This document provides complete, canonical type annotation guidance for Python 3.11.\n     7→\n     8→## Overview\n     9→\n    10→Python 3.11 builds on 3.10's type syntax with the addition of the `Self` type (PEP 673), making method chaining and builder patterns significantly cleaner. All modern syntax from 3.10 continues to work.\n    11→\n    12→**What's new in 3.11:**\n    13→\n    14→- `Self` type for self-returning methods (PEP 673)\n    15→- Variadic generics with TypeVarTuple (PEP 646)\n    16→- Significantly improved error messages\n    17→\n    18→**Available from 3.10:**\n    19→\n    20→- Built-in generic types: `list[T]`, `dict[K, V]`, etc. (PEP 585)\n    21→- Union types with `|` operator (PEP 604)\n    22→- Optional with `X | None`\n    23→\n    24→**What you need from typing module:**\n    25→\n    26→- `Self` for self-returning methods (NEW)\n    27→- `TypeVar` for generic functions/classes\n    28→- `Generic` for generic classes\n    29→- `Protocol` for structural typing (rare - prefer ABC)\n    30→- `TYPE_CHECKING` for conditional imports\n    31→- `Any` (use sparingly)\n    32→\n    33→## Complete Type Annotation Syntax for Python 3.11\n    34→\n    35→### Basic Collection Types\n    36→\n    37→✅ **PREFERRED** - Use built-in generic types:\n    38→\n    39→```python\n    40→names: list[str] = []\n    41→mapping: dict[str, int] = {}\n    42→unique_ids: set[str] = set()\n    43→coordinates: tuple[int, int] = (0, 0)\n    44→```\n    45→\n    46→❌ **WRONG** - Don't use typing module equivalents:\n    47→\n    48→```python\n    49→from typing import List, Dict, Set, Tuple  # Don't do this\n    50→names: List[str] = []\n    51→```\n    52→\n    53→### Union Types\n    54→\n    55→✅ **PREFERRED** - Use `|` operator:\n    56→\n    57→```python\n    58→def process(value: str | int) -> str:\n    59→    return str(value)\n    60→\n    61→def find_config(name: str) -> dict[str, str] | dict[str, int]:\n    62→    ...\n    63→\n    64→# Multiple unions\n    65→def parse(input: str | int | float) -> str:\n    66→    return str(input)\n    67→```\n    68→\n    69→❌ **WRONG** - Don't use `typing.Union`:\n    70→\n    71→```python\n    72→from typing import Union\n    73→def process(value: Union[str, int]) -> str:  # Don't do this\n    74→    ...\n    75→```\n    76→\n    77→### Optional Types\n    78→\n    79→✅ **PREFERRED** - Use `X | None`:\n    80→\n    81→```python\n    82→def find_user(id: str) -> User | None:\n    83→    \"\"\"Returns user or None if not found.\"\"\"\n    84→    if id in users:\n    85→        return users[id]\n    86→    return None\n    87→```\n    88→\n    89→❌ **WRONG** - Don't use `typing.Optional`:\n    90→\n    91→```python\n    92→from typing import Optional\n    93→def find_user(id: str) -> Optional[User]:  # Don't do this\n    94→    ...\n    95→```\n    96→\n    97→### Self Type for Self-Returning Methods (NEW in 3.11)\n    98→\n    99→✅ **PREFERRED** - Use Self for methods that return the instance:\n   100→\n   101→```python\n   102→from typing import Self\n   103→\n   104→class Builder:\n   105→    def set_name(self, name: str) -> Self:\n   106→        self.name = name\n   107→        return self\n   108→\n   109→    def set_value(self, value: int) -> Self:\n   110→        self.value = value\n   111→        return self\n   112→\n   113→# Usage with type safety\n   114→builder = Builder().set_name(\"app\").set_value(42)\n   115→```\n   116→\n   117→❌ **WRONG** - Don't use bound TypeVar anymore:\n   118→\n   119→```python\n   120→from typing import TypeVar\n   121→\n   122→T = TypeVar(\"T\", bound=\"Builder\")\n   123→\n   124→class Builder:\n   125→    def set_name(self: T, name: str) -> T:  # Don't do this\n   126→        ...\n   127→```\n   128→\n   129→**When to use Self:**\n   130→\n   131→- Methods that return `self`\n   132→- Builder pattern methods\n   133→- Fluent interfaces with method chaining\n   134→- Factory classmethods\n   135→\n   136→**Self in classmethod:**\n   137→\n   138→```python\n   139→from typing import Self\n   140→\n   141→class Config:\n   142→    def __init__(self, data: dict[str, str]) -> None:\n   143→        self.data = data\n   144→\n   145→    @classmethod\n   146→    def from_file(cls, path: str) -> Self:\n   147→        \"\"\"Load config from file.\"\"\"\n   148→        import json\n   149→        with open(path, encoding=\"utf-8\") as f:\n   150→            data = json.load(f)\n   151→        return cls(data)\n   152→```\n   153→\n   154→### Generic Functions with TypeVar\n   155→\n   156→✅ **PREFERRED** - Use TypeVar for generic functions:\n   157→\n   158→```python\n   159→from typing import TypeVar\n   160→\n   161→T = TypeVar(\"T\")\n   162→\n   163→def first(items: list[T]) -> T | None:\n   164→    \"\"\"Return first item or None if empty.\"\"\"\n   165→    if not items:\n   166→        return None\n   167→    return items[0]\n   168→\n   169→def identity(value: T) -> T:\n   170→    return value\n   171→```\n   172→\n   173→**Note**: Python 3.12 introduces better syntax (PEP 695) for this pattern.\n   174→\n   175→### Generic Classes\n   176→\n   177→✅ **PREFERRED** - Use Generic with TypeVar:\n   178→\n   179→```python\n   180→from typing import Generic, TypeVar\n   181→\n   182→T = TypeVar(\"T\")\n   183→\n   184→class Stack(Generic[T]):\n   185→    \"\"\"A generic stack data structure.\"\"\"\n   186→\n   187→    def __init__(self) -> None:\n   188→        self._items: list[T] = []\n   189→\n   190→    def push(self, item: T) -> Self:  # Can combine with Self!\n   191→        self._items.append(item)\n   192→        return self\n   193→\n   194→    def pop(self) -> T | None:\n   195→        if not self._items:\n   196→            return None\n   197→        return self._items.pop()\n   198→\n   199→# Usage\n   200→int_stack = Stack[int]()\n   201→int_stack.push(42).push(43)  # Method chaining works!\n   202→```\n   203→\n   204→**Note**: Python 3.12 introduces cleaner syntax for generic classes.\n   205→\n   206→### Constrained and Bounded TypeVars\n   207→\n   208→✅ **Use TypeVar constraints when needed**:\n   209→\n   210→```python\n   211→from typing import TypeVar\n   212→\n   213→# Constrained to specific types\n   214→Numeric = TypeVar(\"Numeric\", int, float)\n   215→\n   216→def add(a: Numeric, b: Numeric) -> Numeric:\n   217→    return a + b\n   218→\n   219→# Bounded to base class\n   220→T = TypeVar(\"T\", bound=BaseClass)\n   221→\n   222→def process(obj: T) -> T:\n   223→    return obj\n   224→```\n   225→\n   226→### Callable Types\n   227→\n   228→✅ **PREFERRED** - Use `collections.abc.Callable`:\n   229→\n   230→```python\n   231→from collections.abc import Callable\n   232→\n   233→# Function that takes int, returns str\n   234→processor: Callable[[int], str] = str\n   235→\n   236→# Function with no args, returns None\n   237→callback: Callable[[], None] = lambda: None\n   238→\n   239→# Function with multiple args\n   240→validator: Callable[[str, int], bool] = lambda s, i: len(s) > i\n   241→```\n   242→\n   243→### Type Aliases\n   244→\n   245→✅ **Use simple assignment for type aliases**:\n   246→\n   247→```python\n   248→# Simple alias\n   249→UserId = str\n   250→Config = dict[str, str | int | bool]\n   251→\n   252→# Complex nested type\n   253→JsonValue = dict[str, \"JsonValue\"] | list[\"JsonValue\"] | str | int | float | bool | None\n   254→\n   255→def load_config() -> Config:\n   256→    return {\"host\": \"localhost\", \"port\": 8080}\n   257→```\n   258→\n   259→**Note**: Python 3.12 introduces `type` statement for better alias support.\n   260→\n   261→### When from **future** import annotations is Needed\n   262→\n   263→Use `from __future__ import annotations` when you encounter:\n   264→\n   265→**Forward references** (class referencing itself):\n   266→\n   267→```python\n   268→from __future__ import annotations\n   269→\n   270→class Node:\n   271→    def __init__(self, value: int, parent: Node | None = None):\n   272→        self.value = value\n   273→        self.parent = parent\n   274→```\n   275→\n   276→**Circular type imports**:\n   277→\n   278→```python\n   279→# a.py\n   280→from __future__ import annotations\n   281→from typing import TYPE_CHECKING\n   282→\n   283→if TYPE_CHECKING:\n   284→    from b import B\n   285→\n   286→class A:\n   287→    def method(self) -> B:\n   288→        ...\n   289→```\n   290→\n   291→**Complex recursive types**:\n   292→\n   293→```python\n   294→from __future__ import annotations\n   295→\n   296→JsonValue = dict[str, JsonValue] | list[JsonValue] | str | int | float | bool | None\n   297→```\n   298→\n   299→### Interfaces: ABC vs Protocol\n   300→\n   301→✅ **PREFERRED** - Use ABC for interfaces:\n   302→\n   303→```python\n   304→from abc import ABC, abstractmethod\n   305→\n   306→class Repository(ABC):\n   307→    @abstractmethod\n   308→    def get(self, id: str) -> User | None:\n   309→        \"\"\"Get user by ID.\"\"\"\n   310→\n   311→    @abstractmethod\n   312→    def save(self, user: User) -> None:\n   313→        \"\"\"Save user.\"\"\"\n   314→```\n   315→\n   316→🟡 **VALID** - Use Protocol only for structural typing:\n   317→\n   318→```python\n   319→from typing import Protocol\n   320→\n   321→class Drawable(Protocol):\n   322→    def draw(self) -> None: ...\n   323→\n   324→# Any object with draw() method matches\n   325→def render(obj: Drawable) -> None:\n   326→    obj.draw()\n   327→```\n   328→\n   329→**Dignified Python prefers ABC** because it makes inheritance and intent explicit.\n   330→\n   331→## Complete Examples\n   332→\n   333→### Builder Pattern with Self\n   334→\n   335→```python\n   336→from typing import Self\n   337→\n   338→class QueryBuilder:\n   339→    \"\"\"SQL query builder with fluent interface.\"\"\"\n   340→\n   341→    def __init__(self) -> None:\n   342→        self._select: list[str] = [\"*\"]\n   343→        self._from: str | None = None\n   344→        self._where: list[str] = []\n   345→        self._limit: int | None = None\n   346→\n   347→    def select(self, *columns: str) -> Self:\n   348→        \"\"\"Specify columns to select.\"\"\"\n   349→        self._select = list(columns)\n   350→        return self\n   351→\n   352→    def from_table(self, table: str) -> Self:\n   353→        \"\"\"Specify table to query.\"\"\"\n   354→        self._from = table\n   355→        return self\n   356→\n   357→    def where(self, condition: str) -> Self:\n   358→        \"\"\"Add WHERE condition.\"\"\"\n   359→        self._where.append(condition)\n   360→        return self\n   361→\n   362→    def limit(self, n: int) -> Self:\n   363→        \"\"\"Set LIMIT.\"\"\"\n   364→        self._limit = n\n   365→        return self\n   366→\n   367→    def build(self) -> str:\n   368→        \"\"\"Build final SQL query.\"\"\"\n   369→        if not self._from:\n   370→            raise ValueError(\"FROM table not specified\")\n   371→\n   372→        parts = [f\"SELECT {', '.join(self._select)}\"]\n   373→        parts.append(f\"FROM {self._from}\")\n   374→\n   375→        if self._where:\n   376→            parts.append(f\"WHERE {' AND '.join(self._where)}\")\n   377→\n   378→        if self._limit:\n   379→            parts.append(f\"LIMIT {self._limit}\")\n   380→\n   381→        return \" \".join(parts)\n   382→\n   383→# Usage with type-safe method chaining\n   384→query = (\n   385→    QueryBuilder()\n   386→    .select(\"id\", \"name\", \"email\")\n   387→    .from_table(\"users\")\n   388→    .where(\"active = true\")\n   389→    .where(\"age > 18\")\n   390→    .limit(10)\n   391→    .build()\n   392→)\n   393→```\n   394→\n   395→### Factory Methods with Self\n   396→\n   397→```python\n   398→from typing import Self\n   399→from pathlib import Path\n   400→import json\n   401→\n   402→class Config:\n   403→    \"\"\"Application configuration with multiple factory methods.\"\"\"\n   404→\n   405→    def __init__(self, data: dict[str, str | int]) -> None:\n   406→        self.data = data\n   407→\n   408→    @classmethod\n   409→    def from_json(cls, path: Path) -> Self:\n   410→        \"\"\"Load configuration from JSON file.\"\"\"\n   411→        if not path.exists():\n   412→            raise FileNotFoundError(f\"Config not found: {path}\")\n   413→\n   414→        with path.open(encoding=\"utf-8\") as f:\n   415→            data = json.load(f)\n   416→        return cls(data)\n   417→\n   418→    @classmethod\n   419→    def from_env(cls) -> Self:\n   420→        \"\"\"Load configuration from environment variables.\"\"\"\n   421→        import os\n   422→        data = {\n   423→            k.lower(): v\n   424→            for k, v in os.environ.items()\n   425→            if k.startswith(\"APP_\")\n   426→        }\n   427→        return cls(data)\n   428→\n   429→    @classmethod\n   430→    def default(cls) -> Self:\n   431→        \"\"\"Create default configuration.\"\"\"\n   432→        return cls({\"host\": \"localhost\", \"port\": 8080})\n   433→\n   434→    def with_override(self, key: str, value: str | int) -> Self:\n   435→        \"\"\"Return new config with overridden value.\"\"\"\n   436→        new_data = self.data.copy()\n   437→        new_data[key] = value\n   438→        return type(self)(new_data)\n   439→\n   440→# All factory methods return correct type\n   441→config = Config.from_json(Path(\"config.json\"))\n   442→dev_config = config.with_override(\"debug\", True)\n   443→```\n   444→\n   445→## Type Checking Rules\n   446→\n   447→### What to Type\n   448→\n   449→✅ **MUST type**:\n   450→\n   451→- All public function parameters (except `self`, `cls`)\n   452→- All public function return values\n   453→- All class attributes (public and private)\n   454→- Module-level constants\n   455→\n   456→🟡 **SHOULD type**:\n   457→\n   458→- Internal function signatures\n   459→- Complex local variables\n   460→\n   461→🟢 **MAY skip**:\n   462→\n   463→- Simple local variables where type is obvious (`count = 0`)\n   464→- Lambda parameters in short inline lambdas\n   465→- Loop variables in short comprehensions\n   466→\n   467→### Running Type Checker\n   468→\n   469→```bash\n   470→uv run ty check\n   471→```\n   472→\n   473→All code should pass type checking without errors.\n   474→\n   475→### Type Checking Configuration\n   476→\n   477→Configure ty in `pyproject.toml`:\n   478→\n   479→```toml\n   480→[tool.ty.environment]\n   481→python-version = \"3.11\"\n   482→```\n   483→\n   484→## Common Patterns\n   485→\n   486→### Checking for None\n   487→\n   488→✅ **CORRECT** - Check before use:\n   489→\n   490→```python\n   491→def process_user(user: User | None) -> str:\n   492→    if user is None:\n   493→        return \"No user\"\n   494→    return user.name\n   495→```\n   496→\n   497→### Dict.get() with Type Safety\n   498→\n   499→✅ **CORRECT** - Handle None case:\n   500→\n   501→```python\n   502→def get_port(config: dict[str, int]) -> int:\n   503→    port = config.get(\"port\")\n   504→    if port is None:\n   505→        return 8080\n   506→    return port\n   507→```\n   508→\n   509→### List Operations\n   510→\n   511→✅ **CORRECT** - Check before accessing:\n   512→\n   513→```python\n   514→def first_or_default(items: list[str], default: str) -> str:\n   515→    if not items:\n   516→        return default\n   517→    return items[0]\n   518→```\n   519→\n   520→## Migration from Python 3.10\n   521→\n   522→If upgrading from Python 3.10:\n   523→\n   524→1. **Replace bound TypeVar with Self** for self-returning methods:\n   525→   - Old: `T = TypeVar(\"T\", bound=\"ClassName\")`\n   526→   - New: `from typing import Self` and use `-> Self`\n   527→\n   528→2. **Enjoy improved error messages** (no code changes needed)\n   529→\n   530→3. **All existing 3.10 syntax continues to work**\n   531→\n   532→## References\n   533→\n   534→- [PEP 673: Self Type](https://peps.python.org/pep-0673/)\n   535→- [PEP 646: Variadic Generics](https://peps.python.org/pep-0646/)\n   536→- [Python 3.11 What's New](https://docs.python.org/3.11/whatsnew/3.11.html)\n   537→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ea2f6749-65ed-4c16-b2e2-bc47e13f0092","timestamp":"2026-02-22T14:37:30.067Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/.claude/skills/dignified-python/versions/python-3.11.md","content":"---\n---\n\n# Type Annotations - Python 3.11\n\nThis document provides complete, canonical type annotation guidance for Python 3.11.\n\n## Overview\n\nPython 3.11 builds on 3.10's type syntax with the addition of the `Self` type (PEP 673), making method chaining and builder patterns significantly cleaner. All modern syntax from 3.10 continues to work.\n\n**What's new in 3.11:**\n\n- `Self` type for self-returning methods (PEP 673)\n- Variadic generics with TypeVarTuple (PEP 646)\n- Significantly improved error messages\n\n**Available from 3.10:**\n\n- Built-in generic types: `list[T]`, `dict[K, V]`, etc. (PEP 585)\n- Union types with `|` operator (PEP 604)\n- Optional with `X | None`\n\n**What you need from typing module:**\n\n- `Self` for self-returning methods (NEW)\n- `TypeVar` for generic functions/classes\n- `Generic` for generic classes\n- `Protocol` for structural typing (rare - prefer ABC)\n- `TYPE_CHECKING` for conditional imports\n- `Any` (use sparingly)\n\n## Complete Type Annotation Syntax for Python 3.11\n\n### Basic Collection Types\n\n✅ **PREFERRED** - Use built-in generic types:\n\n```python\nnames: list[str] = []\nmapping: dict[str, int] = {}\nunique_ids: set[str] = set()\ncoordinates: tuple[int, int] = (0, 0)\n```\n\n❌ **WRONG** - Don't use typing module equivalents:\n\n```python\nfrom typing import List, Dict, Set, Tuple  # Don't do this\nnames: List[str] = []\n```\n\n### Union Types\n\n✅ **PREFERRED** - Use `|` operator:\n\n```python\ndef process(value: str | int) -> str:\n    return str(value)\n\ndef find_config(name: str) -> dict[str, str] | dict[str, int]:\n    ...\n\n# Multiple unions\ndef parse(input: str | int | float) -> str:\n    return str(input)\n```\n\n❌ **WRONG** - Don't use `typing.Union`:\n\n```python\nfrom typing import Union\ndef process(value: Union[str, int]) -> str:  # Don't do this\n    ...\n```\n\n### Optional Types\n\n✅ **PREFERRED** - Use `X | None`:\n\n```python\ndef find_user(id: str) -> User | None:\n    \"\"\"Returns user or None if not found.\"\"\"\n    if id in users:\n        return users[id]\n    return None\n```\n\n❌ **WRONG** - Don't use `typing.Optional`:\n\n```python\nfrom typing import Optional\ndef find_user(id: str) -> Optional[User]:  # Don't do this\n    ...\n```\n\n### Self Type for Self-Returning Methods (NEW in 3.11)\n\n✅ **PREFERRED** - Use Self for methods that return the instance:\n\n```python\nfrom typing import Self\n\nclass Builder:\n    def set_name(self, name: str) -> Self:\n        self.name = name\n        return self\n\n    def set_value(self, value: int) -> Self:\n        self.value = value\n        return self\n\n# Usage with type safety\nbuilder = Builder().set_name(\"app\").set_value(42)\n```\n\n❌ **WRONG** - Don't use bound TypeVar anymore:\n\n```python\nfrom typing import TypeVar\n\nT = TypeVar(\"T\", bound=\"Builder\")\n\nclass Builder:\n    def set_name(self: T, name: str) -> T:  # Don't do this\n        ...\n```\n\n**When to use Self:**\n\n- Methods that return `self`\n- Builder pattern methods\n- Fluent interfaces with method chaining\n- Factory classmethods\n\n**Self in classmethod:**\n\n```python\nfrom typing import Self\n\nclass Config:\n    def __init__(self, data: dict[str, str]) -> None:\n        self.data = data\n\n    @classmethod\n    def from_file(cls, path: str) -> Self:\n        \"\"\"Load config from file.\"\"\"\n        import json\n        with open(path, encoding=\"utf-8\") as f:\n            data = json.load(f)\n        return cls(data)\n```\n\n### Generic Functions with TypeVar\n\n✅ **PREFERRED** - Use TypeVar for generic functions:\n\n```python\nfrom typing import TypeVar\n\nT = TypeVar(\"T\")\n\ndef first(items: list[T]) -> T | None:\n    \"\"\"Return first item or None if empty.\"\"\"\n    if not items:\n        return None\n    return items[0]\n\ndef identity(value: T) -> T:\n    return value\n```\n\n**Note**: Python 3.12 introduces better syntax (PEP 695) for this pattern.\n\n### Generic Classes\n\n✅ **PREFERRED** - Use Generic with TypeVar:\n\n```python\nfrom typing import Generic, TypeVar\n\nT = TypeVar(\"T\")\n\nclass Stack(Generic[T]):\n    \"\"\"A generic stack data structure.\"\"\"\n\n    def __init__(self) -> None:\n        self._items: list[T] = []\n\n    def push(self, item: T) -> Self:  # Can combine with Self!\n        self._items.append(item)\n        return self\n\n    def pop(self) -> T | None:\n        if not self._items:\n            return None\n        return self._items.pop()\n\n# Usage\nint_stack = Stack[int]()\nint_stack.push(42).push(43)  # Method chaining works!\n```\n\n**Note**: Python 3.12 introduces cleaner syntax for generic classes.\n\n### Constrained and Bounded TypeVars\n\n✅ **Use TypeVar constraints when needed**:\n\n```python\nfrom typing import TypeVar\n\n# Constrained to specific types\nNumeric = TypeVar(\"Numeric\", int, float)\n\ndef add(a: Numeric, b: Numeric) -> Numeric:\n    return a + b\n\n# Bounded to base class\nT = TypeVar(\"T\", bound=BaseClass)\n\ndef process(obj: T) -> T:\n    return obj\n```\n\n### Callable Types\n\n✅ **PREFERRED** - Use `collections.abc.Callable`:\n\n```python\nfrom collections.abc import Callable\n\n# Function that takes int, returns str\nprocessor: Callable[[int], str] = str\n\n# Function with no args, returns None\ncallback: Callable[[], None] = lambda: None\n\n# Function with multiple args\nvalidator: Callable[[str, int], bool] = lambda s, i: len(s) > i\n```\n\n### Type Aliases\n\n✅ **Use simple assignment for type aliases**:\n\n```python\n# Simple alias\nUserId = str\nConfig = dict[str, str | int | bool]\n\n# Complex nested type\nJsonValue = dict[str, \"JsonValue\"] | list[\"JsonValue\"] | str | int | float | bool | None\n\ndef load_config() -> Config:\n    return {\"host\": \"localhost\", \"port\": 8080}\n```\n\n**Note**: Python 3.12 introduces `type` statement for better alias support.\n\n### When from **future** import annotations is Needed\n\nUse `from __future__ import annotations` when you encounter:\n\n**Forward references** (class referencing itself):\n\n```python\nfrom __future__ import annotations\n\nclass Node:\n    def __init__(self, value: int, parent: Node | None = None):\n        self.value = value\n        self.parent = parent\n```\n\n**Circular type imports**:\n\n```python\n# a.py\nfrom __future__ import annotations\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from b import B\n\nclass A:\n    def method(self) -> B:\n        ...\n```\n\n**Complex recursive types**:\n\n```python\nfrom __future__ import annotations\n\nJsonValue = dict[str, JsonValue] | list[JsonValue] | str | int | float | bool | None\n```\n\n### Interfaces: ABC vs Protocol\n\n✅ **PREFERRED** - Use ABC for interfaces:\n\n```python\nfrom abc import ABC, abstractmethod\n\nclass Repository(ABC):\n    @abstractmethod\n    def get(self, id: str) -> User | None:\n        \"\"\"Get user by ID.\"\"\"\n\n    @abstractmethod\n    def save(self, user: User) -> None:\n        \"\"\"Save user.\"\"\"\n```\n\n🟡 **VALID** - Use Protocol only for structural typing:\n\n```python\nfrom typing import Protocol\n\nclass Drawable(Protocol):\n    def draw(self) -> None: ...\n\n# Any object with draw() method matches\ndef render(obj: Drawable) -> None:\n    obj.draw()\n```\n\n**Dignified Python prefers ABC** because it makes inheritance and intent explicit.\n\n## Complete Examples\n\n### Builder Pattern with Self\n\n```python\nfrom typing import Self\n\nclass QueryBuilder:\n    \"\"\"SQL query builder with fluent interface.\"\"\"\n\n    def __init__(self) -> None:\n        self._select: list[str] = [\"*\"]\n        self._from: str | None = None\n        self._where: list[str] = []\n        self._limit: int | None = None\n\n    def select(self, *columns: str) -> Self:\n        \"\"\"Specify columns to select.\"\"\"\n        self._select = list(columns)\n        return self\n\n    def from_table(self, table: str) -> Self:\n        \"\"\"Specify table to query.\"\"\"\n        self._from = table\n        return self\n\n    def where(self, condition: str) -> Self:\n        \"\"\"Add WHERE condition.\"\"\"\n        self._where.append(condition)\n        return self\n\n    def limit(self, n: int) -> Self:\n        \"\"\"Set LIMIT.\"\"\"\n        self._limit = n\n        return self\n\n    def build(self) -> str:\n        \"\"\"Build final SQL query.\"\"\"\n        if not self._from:\n            raise ValueError(\"FROM table not specified\")\n\n        parts = [f\"SELECT {', '.join(self._select)}\"]\n        parts.append(f\"FROM {self._from}\")\n\n        if self._where:\n            parts.append(f\"WHERE {' AND '.join(self._where)}\")\n\n        if self._limit:\n            parts.append(f\"LIMIT {self._limit}\")\n\n        return \" \".join(parts)\n\n# Usage with type-safe method chaining\nquery = (\n    QueryBuilder()\n    .select(\"id\", \"name\", \"email\")\n    .from_table(\"users\")\n    .where(\"active = true\")\n    .where(\"age > 18\")\n    .limit(10)\n    .build()\n)\n```\n\n### Factory Methods with Self\n\n```python\nfrom typing import Self\nfrom pathlib import Path\nimport json\n\nclass Config:\n    \"\"\"Application configuration with multiple factory methods.\"\"\"\n\n    def __init__(self, data: dict[str, str | int]) -> None:\n        self.data = data\n\n    @classmethod\n    def from_json(cls, path: Path) -> Self:\n        \"\"\"Load configuration from JSON file.\"\"\"\n        if not path.exists():\n            raise FileNotFoundError(f\"Config not found: {path}\")\n\n        with path.open(encoding=\"utf-8\") as f:\n            data = json.load(f)\n        return cls(data)\n\n    @classmethod\n    def from_env(cls) -> Self:\n        \"\"\"Load configuration from environment variables.\"\"\"\n        import os\n        data = {\n            k.lower(): v\n            for k, v in os.environ.items()\n            if k.startswith(\"APP_\")\n        }\n        return cls(data)\n\n    @classmethod\n    def default(cls) -> Self:\n        \"\"\"Create default configuration.\"\"\"\n        return cls({\"host\": \"localhost\", \"port\": 8080})\n\n    def with_override(self, key: str, value: str | int) -> Self:\n        \"\"\"Return new config with overridden value.\"\"\"\n        new_data = self.data.copy()\n        new_data[key] = value\n        return type(self)(new_data)\n\n# All factory methods return correct type\nconfig = Config.from_json(Path(\"config.json\"))\ndev_config = config.with_override(\"debug\", True)\n```\n\n## Type Checking Rules\n\n### What to Type\n\n✅ **MUST type**:\n\n- All public function parameters (except `self`, `cls`)\n- All public function return values\n- All class attributes (public and private)\n- Module-level constants\n\n🟡 **SHOULD type**:\n\n- Internal function signatures\n- Complex local variables\n\n🟢 **MAY skip**:\n\n- Simple local variables where type is obvious (`count = 0`)\n- Lambda parameters in short inline lambdas\n- Loop variables in short comprehensions\n\n### Running Type Checker\n\n```bash\nuv run ty check\n```\n\nAll code should pass type checking without errors.\n\n### Type Checking Configuration\n\nConfigure ty in `pyproject.toml`:\n\n```toml\n[tool.ty.environment]\npython-version = \"3.11\"\n```\n\n## Common Patterns\n\n### Checking for None\n\n✅ **CORRECT** - Check before use:\n\n```python\ndef process_user(user: User | None) -> str:\n    if user is None:\n        return \"No user\"\n    return user.name\n```\n\n### Dict.get() with Type Safety\n\n✅ **CORRECT** - Handle None case:\n\n```python\ndef get_port(config: dict[str, int]) -> int:\n    port = config.get(\"port\")\n    if port is None:\n        return 8080\n    return port\n```\n\n### List Operations\n\n✅ **CORRECT** - Check before accessing:\n\n```python\ndef first_or_default(items: list[str], default: str) -> str:\n    if not items:\n        return default\n    return items[0]\n```\n\n## Migration from Python 3.10\n\nIf upgrading from Python 3.10:\n\n1. **Replace bound TypeVar with Self** for self-returning methods:\n   - Old: `T = TypeVar(\"T\", bound=\"ClassName\")`\n   - New: `from typing import Self` and use `-> Self`\n\n2. **Enjoy improved error messages** (no code changes needed)\n\n3. **All existing 3.10 syntax continues to work**\n\n## References\n\n- [PEP 673: Self Type](https://peps.python.org/pep-0673/)\n- [PEP 646: Variadic Generics](https://peps.python.org/pep-0646/)\n- [Python 3.11 What's New](https://docs.python.org/3.11/whatsnew/3.11.html)\n","numLines":537,"startLine":1,"totalLines":537}}}
{"parentUuid":"ea2f6749-65ed-4c16-b2e2-bc47e13f0092","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JJYK1K7txKjwmWdRRW9WME","type":"tool_result","content":"     1→\"\"\"Commit message generation via Claude CLI.\n     2→\n     3→This module provides commit message generation for PR submissions,\n     4→using Claude CLI to analyze diffs and generate descriptive messages.\n     5→\n     6→The commit message prompt is loaded from the shared prompt file at:\n     7→packages/erk-shared/src/erk_shared/gateway/gt/commit_message_prompt.md\n     8→\"\"\"\n     9→\n    10→from __future__ import annotations\n    11→\n    12→from collections.abc import Generator\n    13→from dataclasses import dataclass\n    14→from pathlib import Path\n    15→from typing import TYPE_CHECKING\n    16→\n    17→from erk.core.prompt_executor import PromptExecutor\n    18→from erk_shared.gateway.gt.events import CompletionEvent, ProgressEvent\n    19→from erk_shared.gateway.gt.prompts import get_commit_message_prompt\n    20→\n    21→if TYPE_CHECKING:\n    22→    from erk.core.plan_context_provider import PlanContext\n    23→\n    24→# Feature flag: Use --system-prompt to replace Claude Code's default system prompt\n    25→# When True: More deterministic, no Claude Code behaviors (passes system prompt separately)\n    26→# When False: Legacy behavior (system prompt concatenated with user prompt)\n    27→USE_SYSTEM_PROMPT_REPLACEMENT = True\n    28→\n    29→\n    30→@dataclass(frozen=True)\n    31→class CommitMessageRequest:\n    32→    \"\"\"Request for generating a commit message.\n    33→\n    34→    Attributes:\n    35→        diff_file: Path to the file containing the diff content\n    36→        repo_root: Path to the repository root directory\n    37→        current_branch: Name of the current branch\n    38→        parent_branch: Name of the parent branch\n    39→        commit_messages: Optional list of existing commit messages for context\n    40→        plan_context: Optional plan context from linked erk-plan issue\n    41→    \"\"\"\n    42→\n    43→    diff_file: Path\n    44→    repo_root: Path\n    45→    current_branch: str\n    46→    parent_branch: str\n    47→    commit_messages: list[str] | None\n    48→    plan_context: PlanContext | None\n    49→\n    50→\n    51→@dataclass(frozen=True)\n    52→class CommitMessageResult:\n    53→    \"\"\"Result of commit message generation.\n    54→\n    55→    Attributes:\n    56→        success: Whether generation succeeded\n    57→        title: PR title (first line of commit message) if successful\n    58→        body: PR body (remaining lines) if successful\n    59→        error_message: Error description if generation failed\n    60→    \"\"\"\n    61→\n    62→    success: bool\n    63→    title: str | None\n    64→    body: str | None\n    65→    error_message: str | None\n    66→\n    67→\n    68→class CommitMessageGenerator:\n    69→    \"\"\"Generates commit messages via Claude CLI.\n    70→\n    71→    This is a concrete class (not ABC) that uses PromptExecutor for\n    72→    testability. In tests, inject FakePromptExecutor with simulated_prompt_output.\n    73→    \"\"\"\n    74→\n    75→    def __init__(self, executor: PromptExecutor, model: str = \"haiku\") -> None:\n    76→        \"\"\"Initialize generator with executor.\n    77→\n    78→        Args:\n    79→            executor: Prompt executor for prompt execution\n    80→            model: Model to use for generation (default \"haiku\" for speed/cost)\n    81→        \"\"\"\n    82→        self._executor = executor\n    83→        self._model = model\n    84→\n    85→    def generate(\n    86→        self, request: CommitMessageRequest\n    87→    ) -> Generator[ProgressEvent | CompletionEvent[CommitMessageResult]]:\n    88→        \"\"\"Generate commit message from diff with progress updates.\n    89→\n    90→        Reads the diff file, sends it to Claude with the commit message prompt,\n    91→        and parses the response into title and body.\n    92→\n    93→        Args:\n    94→            request: CommitMessageRequest with diff file and context\n    95→\n    96→        Yields:\n    97→            ProgressEvent for status updates\n    98→            CompletionEvent with CommitMessageResult on completion\n    99→        \"\"\"\n   100→        # LBYL: Check diff file exists\n   101→        yield ProgressEvent(\"Reading diff file...\")\n   102→        if not request.diff_file.exists():\n   103→            yield CompletionEvent(\n   104→                CommitMessageResult(\n   105→                    success=False,\n   106→                    title=None,\n   107→                    body=None,\n   108→                    error_message=f\"Diff file not found: {request.diff_file}\",\n   109→                )\n   110→            )\n   111→            return\n   112→\n   113→        # Read diff content\n   114→        diff_content = request.diff_file.read_text(encoding=\"utf-8\")\n   115→        if not diff_content.strip():\n   116→            yield CompletionEvent(\n   117→                CommitMessageResult(\n   118→                    success=False,\n   119→                    title=None,\n   120→                    body=None,\n   121→                    error_message=\"Diff file is empty\",\n   122→                )\n   123→            )\n   124→            return\n   125→\n   126→        diff_size = len(diff_content)\n   127→        yield ProgressEvent(f\"Diff loaded ({diff_size:,} chars)\", style=\"success\")\n   128→\n   129→        # Build prompt with context\n   130→        yield ProgressEvent(\"Analyzing changes with Claude...\")\n   131→\n   132→        # Execute prompt via Claude CLI\n   133→        if USE_SYSTEM_PROMPT_REPLACEMENT:\n   134→            # Use --system-prompt flag for more deterministic behavior\n   135→            user_prompt = self._build_user_prompt(\n   136→                diff_content=diff_content,\n   137→                current_branch=request.current_branch,\n   138→                parent_branch=request.parent_branch,\n   139→                commit_messages=request.commit_messages,\n   140→                plan_context=request.plan_context,\n   141→            )\n   142→            result = self._executor.execute_prompt(\n   143→                user_prompt,\n   144→                model=self._model,\n   145→                tools=None,\n   146→                cwd=request.repo_root,\n   147→                system_prompt=get_commit_message_prompt(request.repo_root),\n   148→                dangerous=False,\n   149→            )\n   150→        else:\n   151→            # Legacy: system prompt concatenated with user prompt\n   152→            prompt = self._build_prompt(\n   153→                diff_content=diff_content,\n   154→                current_branch=request.current_branch,\n   155→                parent_branch=request.parent_branch,\n   156→                repo_root=request.repo_root,\n   157→                commit_messages=request.commit_messages,\n   158→                plan_context=request.plan_context,\n   159→            )\n   160→            result = self._executor.execute_prompt(\n   161→                prompt,\n   162→                model=self._model,\n   163→                tools=None,\n   164→                cwd=request.repo_root,\n   165→                system_prompt=None,\n   166→                dangerous=False,\n   167→            )\n   168→\n   169→        if not result.success:\n   170→            yield CompletionEvent(\n   171→                CommitMessageResult(\n   172→                    success=False,\n   173→                    title=None,\n   174→                    body=None,\n   175→                    error_message=result.error or \"Claude CLI execution failed\",\n   176→                )\n   177→            )\n   178→            return\n   179→\n   180→        # Parse output into title and body\n   181→        title, body = self._parse_output(result.output)\n   182→\n   183→        yield ProgressEvent(\"PR description generated\", style=\"success\")\n   184→        yield CompletionEvent(\n   185→            CommitMessageResult(\n   186→                success=True,\n   187→                title=title,\n   188→                body=body,\n   189→                error_message=None,\n   190→            )\n   191→        )\n   192→\n   193→    def _build_context_section(\n   194→        self,\n   195→        *,\n   196→        current_branch: str,\n   197→        parent_branch: str,\n   198→        commit_messages: list[str] | None,\n   199→        plan_context: PlanContext | None,\n   200→    ) -> str:\n   201→        \"\"\"Build the context section with branch info, commit messages, and plan context.\"\"\"\n   202→        context_section = f\"\"\"## Context\n   203→\n   204→- Current branch: {current_branch}\n   205→- Parent branch: {parent_branch}\"\"\"\n   206→\n   207→        # Add plan context section if present (highest priority context)\n   208→        if plan_context is not None:\n   209→            context_section += f\"\"\"\n   210→\n   211→## Implementation Plan (Issue #{plan_context.plan_id})\n   212→\n   213→The following plan describes the intent and rationale for these changes:\n   214→\n   215→{plan_context.plan_content}\"\"\"\n   216→\n   217→            if plan_context.objective_summary is not None:\n   218→                context_section += f\"\"\"\n   219→\n   220→### Parent Objective\n   221→\n   222→{plan_context.objective_summary}\"\"\"\n   223→\n   224→            context_section += \"\"\"\n   225→\n   226→Use this plan as the primary source of truth for understanding WHY changes were made.\"\"\"\n   227→\n   228→        # Add commit messages section if present\n   229→        if commit_messages:\n   230→            messages_text = \"\\n\\n---\\n\\n\".join(commit_messages)\n   231→            context_section += f\"\"\"\n   232→\n   233→## Developer's Commit Messages\n   234→\n   235→The following commit messages were written by the developer during implementation:\n   236→\n   237→{messages_text}\n   238→\n   239→Use these commit messages as additional context. They describe the developer's intent\n   240→and may contain details not visible in the diff alone.\"\"\"\n   241→\n   242→        return context_section\n   243→\n   244→    def _build_user_prompt(\n   245→        self,\n   246→        *,\n   247→        diff_content: str,\n   248→        current_branch: str,\n   249→        parent_branch: str,\n   250→        commit_messages: list[str] | None,\n   251→        plan_context: PlanContext | None,\n   252→    ) -> str:\n   253→        \"\"\"Build user prompt with context and diff only (no system prompt).\n   254→\n   255→        Used when system prompt is passed separately via --system-prompt flag.\n   256→        \"\"\"\n   257→        context_section = self._build_context_section(\n   258→            current_branch=current_branch,\n   259→            parent_branch=parent_branch,\n   260→            commit_messages=commit_messages,\n   261→            plan_context=plan_context,\n   262→        )\n   263→\n   264→        return f\"\"\"{context_section}\n   265→\n   266→## Diff\n   267→\n   268→```diff\n   269→{diff_content}\n   270→```\n   271→\n   272→Generate a commit message for this diff:\"\"\"\n   273→\n   274→    def _build_prompt(\n   275→        self,\n   276→        *,\n   277→        diff_content: str,\n   278→        current_branch: str,\n   279→        parent_branch: str,\n   280→        repo_root: Path,\n   281→        commit_messages: list[str] | None,\n   282→        plan_context: PlanContext | None,\n   283→    ) -> str:\n   284→        \"\"\"Build the full prompt with system prompt, diff and context.\n   285→\n   286→        Legacy mode: Used when system prompt is concatenated with user prompt.\n   287→        \"\"\"\n   288→        context_section = self._build_context_section(\n   289→            current_branch=current_branch,\n   290→            parent_branch=parent_branch,\n   291→            commit_messages=commit_messages,\n   292→            plan_context=plan_context,\n   293→        )\n   294→\n   295→        system_prompt = get_commit_message_prompt(repo_root)\n   296→        return f\"\"\"{system_prompt}\n   297→\n   298→{context_section}\n   299→\n   300→## Diff\n   301→\n   302→```diff\n   303→{diff_content}\n   304→```\n   305→\n   306→Generate a commit message for this diff:\"\"\"\n   307→\n   308→    def _parse_output(self, output: str) -> tuple[str, str]:\n   309→        \"\"\"Parse Claude output into title and body.\n   310→\n   311→        The first non-empty line is the title, the rest is the body.\n   312→        Handles case where output is wrapped in markdown code fences.\n   313→\n   314→        Args:\n   315→            output: Raw output from Claude\n   316→\n   317→        Returns:\n   318→            Tuple of (title, body)\n   319→        \"\"\"\n   320→        lines = output.strip().split(\"\\n\")\n   321→\n   322→        # Strip leading code fence if present (handles ```markdown, ```text, ```, etc.)\n   323→        if lines and lines[0].strip().startswith(\"```\"):\n   324→            lines = lines[1:]\n   325→\n   326→        # Strip trailing code fence if present\n   327→        if lines and lines[-1].strip() == \"```\":\n   328→            lines = lines[:-1]\n   329→\n   330→        # Find first non-empty line as title\n   331→        title = \"\"\n   332→        body_start_idx = 0\n   333→        for i, line in enumerate(lines):\n   334→            if line.strip():\n   335→                title = line.strip()\n   336→                body_start_idx = i + 1\n   337→                break\n   338→\n   339→        # Rest is body (skip empty lines between title and body)\n   340→        body_lines = lines[body_start_idx:]\n   341→        while body_lines and not body_lines[0].strip():\n   342→            body_lines = body_lines[1:]\n   343→\n   344→        body = \"\\n\".join(body_lines).strip()\n   345→\n   346→        return title, body\n   347→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"5a229433-b99d-4b97-91d7-7c6cc03ed154","timestamp":"2026-02-22T14:37:30.068Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/core/commit_message_generator.py","content":"\"\"\"Commit message generation via Claude CLI.\n\nThis module provides commit message generation for PR submissions,\nusing Claude CLI to analyze diffs and generate descriptive messages.\n\nThe commit message prompt is loaded from the shared prompt file at:\npackages/erk-shared/src/erk_shared/gateway/gt/commit_message_prompt.md\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Generator\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nfrom erk.core.prompt_executor import PromptExecutor\nfrom erk_shared.gateway.gt.events import CompletionEvent, ProgressEvent\nfrom erk_shared.gateway.gt.prompts import get_commit_message_prompt\n\nif TYPE_CHECKING:\n    from erk.core.plan_context_provider import PlanContext\n\n# Feature flag: Use --system-prompt to replace Claude Code's default system prompt\n# When True: More deterministic, no Claude Code behaviors (passes system prompt separately)\n# When False: Legacy behavior (system prompt concatenated with user prompt)\nUSE_SYSTEM_PROMPT_REPLACEMENT = True\n\n\n@dataclass(frozen=True)\nclass CommitMessageRequest:\n    \"\"\"Request for generating a commit message.\n\n    Attributes:\n        diff_file: Path to the file containing the diff content\n        repo_root: Path to the repository root directory\n        current_branch: Name of the current branch\n        parent_branch: Name of the parent branch\n        commit_messages: Optional list of existing commit messages for context\n        plan_context: Optional plan context from linked erk-plan issue\n    \"\"\"\n\n    diff_file: Path\n    repo_root: Path\n    current_branch: str\n    parent_branch: str\n    commit_messages: list[str] | None\n    plan_context: PlanContext | None\n\n\n@dataclass(frozen=True)\nclass CommitMessageResult:\n    \"\"\"Result of commit message generation.\n\n    Attributes:\n        success: Whether generation succeeded\n        title: PR title (first line of commit message) if successful\n        body: PR body (remaining lines) if successful\n        error_message: Error description if generation failed\n    \"\"\"\n\n    success: bool\n    title: str | None\n    body: str | None\n    error_message: str | None\n\n\nclass CommitMessageGenerator:\n    \"\"\"Generates commit messages via Claude CLI.\n\n    This is a concrete class (not ABC) that uses PromptExecutor for\n    testability. In tests, inject FakePromptExecutor with simulated_prompt_output.\n    \"\"\"\n\n    def __init__(self, executor: PromptExecutor, model: str = \"haiku\") -> None:\n        \"\"\"Initialize generator with executor.\n\n        Args:\n            executor: Prompt executor for prompt execution\n            model: Model to use for generation (default \"haiku\" for speed/cost)\n        \"\"\"\n        self._executor = executor\n        self._model = model\n\n    def generate(\n        self, request: CommitMessageRequest\n    ) -> Generator[ProgressEvent | CompletionEvent[CommitMessageResult]]:\n        \"\"\"Generate commit message from diff with progress updates.\n\n        Reads the diff file, sends it to Claude with the commit message prompt,\n        and parses the response into title and body.\n\n        Args:\n            request: CommitMessageRequest with diff file and context\n\n        Yields:\n            ProgressEvent for status updates\n            CompletionEvent with CommitMessageResult on completion\n        \"\"\"\n        # LBYL: Check diff file exists\n        yield ProgressEvent(\"Reading diff file...\")\n        if not request.diff_file.exists():\n            yield CompletionEvent(\n                CommitMessageResult(\n                    success=False,\n                    title=None,\n                    body=None,\n                    error_message=f\"Diff file not found: {request.diff_file}\",\n                )\n            )\n            return\n\n        # Read diff content\n        diff_content = request.diff_file.read_text(encoding=\"utf-8\")\n        if not diff_content.strip():\n            yield CompletionEvent(\n                CommitMessageResult(\n                    success=False,\n                    title=None,\n                    body=None,\n                    error_message=\"Diff file is empty\",\n                )\n            )\n            return\n\n        diff_size = len(diff_content)\n        yield ProgressEvent(f\"Diff loaded ({diff_size:,} chars)\", style=\"success\")\n\n        # Build prompt with context\n        yield ProgressEvent(\"Analyzing changes with Claude...\")\n\n        # Execute prompt via Claude CLI\n        if USE_SYSTEM_PROMPT_REPLACEMENT:\n            # Use --system-prompt flag for more deterministic behavior\n            user_prompt = self._build_user_prompt(\n                diff_content=diff_content,\n                current_branch=request.current_branch,\n                parent_branch=request.parent_branch,\n                commit_messages=request.commit_messages,\n                plan_context=request.plan_context,\n            )\n            result = self._executor.execute_prompt(\n                user_prompt,\n                model=self._model,\n                tools=None,\n                cwd=request.repo_root,\n                system_prompt=get_commit_message_prompt(request.repo_root),\n                dangerous=False,\n            )\n        else:\n            # Legacy: system prompt concatenated with user prompt\n            prompt = self._build_prompt(\n                diff_content=diff_content,\n                current_branch=request.current_branch,\n                parent_branch=request.parent_branch,\n                repo_root=request.repo_root,\n                commit_messages=request.commit_messages,\n                plan_context=request.plan_context,\n            )\n            result = self._executor.execute_prompt(\n                prompt,\n                model=self._model,\n                tools=None,\n                cwd=request.repo_root,\n                system_prompt=None,\n                dangerous=False,\n            )\n\n        if not result.success:\n            yield CompletionEvent(\n                CommitMessageResult(\n                    success=False,\n                    title=None,\n                    body=None,\n                    error_message=result.error or \"Claude CLI execution failed\",\n                )\n            )\n            return\n\n        # Parse output into title and body\n        title, body = self._parse_output(result.output)\n\n        yield ProgressEvent(\"PR description generated\", style=\"success\")\n        yield CompletionEvent(\n            CommitMessageResult(\n                success=True,\n                title=title,\n                body=body,\n                error_message=None,\n            )\n        )\n\n    def _build_context_section(\n        self,\n        *,\n        current_branch: str,\n        parent_branch: str,\n        commit_messages: list[str] | None,\n        plan_context: PlanContext | None,\n    ) -> str:\n        \"\"\"Build the context section with branch info, commit messages, and plan context.\"\"\"\n        context_section = f\"\"\"## Context\n\n- Current branch: {current_branch}\n- Parent branch: {parent_branch}\"\"\"\n\n        # Add plan context section if present (highest priority context)\n        if plan_context is not None:\n            context_section += f\"\"\"\n\n## Implementation Plan (Issue #{plan_context.plan_id})\n\nThe following plan describes the intent and rationale for these changes:\n\n{plan_context.plan_content}\"\"\"\n\n            if plan_context.objective_summary is not None:\n                context_section += f\"\"\"\n\n### Parent Objective\n\n{plan_context.objective_summary}\"\"\"\n\n            context_section += \"\"\"\n\nUse this plan as the primary source of truth for understanding WHY changes were made.\"\"\"\n\n        # Add commit messages section if present\n        if commit_messages:\n            messages_text = \"\\n\\n---\\n\\n\".join(commit_messages)\n            context_section += f\"\"\"\n\n## Developer's Commit Messages\n\nThe following commit messages were written by the developer during implementation:\n\n{messages_text}\n\nUse these commit messages as additional context. They describe the developer's intent\nand may contain details not visible in the diff alone.\"\"\"\n\n        return context_section\n\n    def _build_user_prompt(\n        self,\n        *,\n        diff_content: str,\n        current_branch: str,\n        parent_branch: str,\n        commit_messages: list[str] | None,\n        plan_context: PlanContext | None,\n    ) -> str:\n        \"\"\"Build user prompt with context and diff only (no system prompt).\n\n        Used when system prompt is passed separately via --system-prompt flag.\n        \"\"\"\n        context_section = self._build_context_section(\n            current_branch=current_branch,\n            parent_branch=parent_branch,\n            commit_messages=commit_messages,\n            plan_context=plan_context,\n        )\n\n        return f\"\"\"{context_section}\n\n## Diff\n\n```diff\n{diff_content}\n```\n\nGenerate a commit message for this diff:\"\"\"\n\n    def _build_prompt(\n        self,\n        *,\n        diff_content: str,\n        current_branch: str,\n        parent_branch: str,\n        repo_root: Path,\n        commit_messages: list[str] | None,\n        plan_context: PlanContext | None,\n    ) -> str:\n        \"\"\"Build the full prompt with system prompt, diff and context.\n\n        Legacy mode: Used when system prompt is concatenated with user prompt.\n        \"\"\"\n        context_section = self._build_context_section(\n            current_branch=current_branch,\n            parent_branch=parent_branch,\n            commit_messages=commit_messages,\n            plan_context=plan_context,\n        )\n\n        system_prompt = get_commit_message_prompt(repo_root)\n        return f\"\"\"{system_prompt}\n\n{context_section}\n\n## Diff\n\n```diff\n{diff_content}\n```\n\nGenerate a commit message for this diff:\"\"\"\n\n    def _parse_output(self, output: str) -> tuple[str, str]:\n        \"\"\"Parse Claude output into title and body.\n\n        The first non-empty line is the title, the rest is the body.\n        Handles case where output is wrapped in markdown code fences.\n\n        Args:\n            output: Raw output from Claude\n\n        Returns:\n            Tuple of (title, body)\n        \"\"\"\n        lines = output.strip().split(\"\\n\")\n\n        # Strip leading code fence if present (handles ```markdown, ```text, ```, etc.)\n        if lines and lines[0].strip().startswith(\"```\"):\n            lines = lines[1:]\n\n        # Strip trailing code fence if present\n        if lines and lines[-1].strip() == \"```\":\n            lines = lines[:-1]\n\n        # Find first non-empty line as title\n        title = \"\"\n        body_start_idx = 0\n        for i, line in enumerate(lines):\n            if line.strip():\n                title = line.strip()\n                body_start_idx = i + 1\n                break\n\n        # Rest is body (skip empty lines between title and body)\n        body_lines = lines[body_start_idx:]\n        while body_lines and not body_lines[0].strip():\n            body_lines = body_lines[1:]\n\n        body = \"\\n\".join(body_lines).strip()\n\n        return title, body\n","numLines":347,"startLine":1,"totalLines":347}}}
{"parentUuid":"5a229433-b99d-4b97-91d7-7c6cc03ed154","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Af87i38cyzn8JqmaoJmjNE","type":"tool_result","content":"     1→\"\"\"Helper functions for accessing context dependencies with LBYL checks.\n     2→\n     3→This module provides getter functions that encapsulate the \"Look Before You Leap\"\n     4→pattern for accessing dependencies from the ErkContext. These functions:\n     5→\n     6→1. Check that context is initialized\n     7→2. Return the typed dependency\n     8→3. Exit with clear error message if context is missing\n     9→\n    10→This eliminates code duplication across kit CLI commands.\n    11→\"\"\"\n    12→\n    13→from __future__ import annotations\n    14→\n    15→from pathlib import Path\n    16→\n    17→import click\n    18→\n    19→from erk_shared.context.context import ErkContext\n    20→from erk_shared.context.types import LoadedConfig, NoRepoSentinel\n    21→from erk_shared.core.prompt_executor import PromptExecutor\n    22→from erk_shared.gateway.branch_manager.abc import BranchManager\n    23→from erk_shared.gateway.claude_installation.abc import ClaudeInstallation\n    24→from erk_shared.gateway.git.abc import Git\n    25→from erk_shared.gateway.github.abc import GitHub\n    26→from erk_shared.gateway.github.issues.abc import GitHubIssues\n    27→from erk_shared.gateway.time.abc import Time\n    28→from erk_shared.plan_store.backend import PlanBackend\n    29→\n    30→\n    31→def require_context(ctx: click.Context) -> ErkContext:\n    32→    \"\"\"Get the full ErkContext, exiting with error if not initialized.\n    33→\n    34→    Uses LBYL pattern to check context before accessing. If context is not\n    35→    initialized (ctx.obj is None), prints error to stderr and exits with code 1.\n    36→\n    37→    Args:\n    38→        ctx: Click context (must have ErkContext in ctx.obj)\n    39→\n    40→    Returns:\n    41→        ErkContext instance from context\n    42→\n    43→    Raises:\n    44→        SystemExit: If context not initialized (exits with code 1)\n    45→\n    46→    Example:\n    47→        >>> @click.command()\n    48→        >>> @click.pass_context\n    49→        >>> def my_command(ctx: click.Context) -> None:\n    50→        ...     erk_ctx = require_context(ctx)\n    51→        ...     # Access any attribute from erk_ctx\n    52→    \"\"\"\n    53→    if ctx.obj is None:\n    54→        click.echo(\"Error: Context not initialized\", err=True)\n    55→        raise SystemExit(1)\n    56→\n    57→    if not isinstance(ctx.obj, ErkContext):\n    58→        click.echo(\"Error: Context must be ErkContext\", err=True)\n    59→        raise SystemExit(1)\n    60→\n    61→    return ctx.obj\n    62→\n    63→\n    64→def require_issues(ctx: click.Context) -> GitHubIssues:\n    65→    \"\"\"Get GitHub Issues from context, exiting with error if not initialized.\n    66→\n    67→    Uses LBYL pattern to check context before accessing. If context is not\n    68→    initialized (ctx.obj is None), prints error to stderr and exits with code 1.\n    69→\n    70→    Args:\n    71→        ctx: Click context (must have ErkContext in ctx.obj)\n    72→\n    73→    Returns:\n    74→        GitHubIssues instance from context\n    75→\n    76→    Raises:\n    77→        SystemExit: If context not initialized (exits with code 1)\n    78→\n    79→    Example:\n    80→        >>> @click.command()\n    81→        >>> @click.pass_context\n    82→        >>> def my_command(ctx: click.Context) -> None:\n    83→        ...     issues = require_issues(ctx)\n    84→        ...     issues.add_comment(repo_root, issue_number, body)\n    85→    \"\"\"\n    86→    if ctx.obj is None:\n    87→        click.echo(\"Error: Context not initialized\", err=True)\n    88→        raise SystemExit(1)\n    89→\n    90→    if not isinstance(ctx.obj, ErkContext):\n    91→        click.echo(\"Error: Context must be ErkContext\", err=True)\n    92→        raise SystemExit(1)\n    93→\n    94→    return ctx.obj.issues\n    95→\n    96→\n    97→def require_repo_root(ctx: click.Context) -> Path:\n    98→    \"\"\"Get repo root from context, exiting with error if not initialized.\n    99→\n   100→    Uses LBYL pattern to check context before accessing.\n   101→\n   102→    Args:\n   103→        ctx: Click context (must have ErkContext in ctx.obj)\n   104→\n   105→    Returns:\n   106→        Path to repository root\n   107→\n   108→    Raises:\n   109→        SystemExit: If context not initialized (exits with code 1)\n   110→\n   111→    Example:\n   112→        >>> @click.command()\n   113→        >>> @click.pass_context\n   114→        >>> def my_command(ctx: click.Context) -> None:\n   115→        ...     repo_root = require_repo_root(ctx)\n   116→        ...     issues = require_issues(ctx)\n   117→        ...     issues.create_issue(repo_root, title, body, labels)\n   118→    \"\"\"\n   119→    if ctx.obj is None:\n   120→        click.echo(\"Error: Context not initialized\", err=True)\n   121→        raise SystemExit(1)\n   122→\n   123→    if not isinstance(ctx.obj, ErkContext):\n   124→        click.echo(\"Error: Context must be ErkContext\", err=True)\n   125→        raise SystemExit(1)\n   126→\n   127→    repo = ctx.obj.repo\n   128→    if isinstance(repo, NoRepoSentinel):\n   129→        click.echo(\"Error: Not in a git repository\", err=True)\n   130→        raise SystemExit(1)\n   131→\n   132→    return repo.root\n   133→\n   134→\n   135→def require_project_root(ctx: click.Context) -> Path:\n   136→    \"\"\"Get project root from context, which is always the repo root.\n   137→\n   138→    Simplified: With the project system removed, project root is always repo root.\n   139→\n   140→    Args:\n   141→        ctx: Click context (must have ErkContext in ctx.obj)\n   142→\n   143→    Returns:\n   144→        Path to repo root (always, since project system is removed)\n   145→\n   146→    Raises:\n   147→        SystemExit: If context not initialized (exits with code 1)\n   148→\n   149→    Example:\n   150→        >>> @click.command()\n   151→        >>> @click.pass_context\n   152→        >>> def my_command(ctx: click.Context) -> None:\n   153→        ...     project_root = require_project_root(ctx)\n   154→        ...     docs_dir = project_root / \"docs\" / \"agent\"\n   155→    \"\"\"\n   156→    # With project system removed, project root is always repo root\n   157→    return require_repo_root(ctx)\n   158→\n   159→\n   160→def require_git(ctx: click.Context) -> Git:\n   161→    \"\"\"Get Git from context, exiting with error if not initialized.\n   162→\n   163→    Uses LBYL pattern to check context before accessing.\n   164→\n   165→    Args:\n   166→        ctx: Click context (must have ErkContext in ctx.obj)\n   167→\n   168→    Returns:\n   169→        Git instance from context\n   170→\n   171→    Raises:\n   172→        SystemExit: If context not initialized (exits with code 1)\n   173→\n   174→    Example:\n   175→        >>> @click.command()\n   176→        >>> @click.pass_context\n   177→        >>> def my_command(ctx: click.Context) -> None:\n   178→        ...     git = require_git(ctx)\n   179→        ...     cwd = require_cwd(ctx)\n   180→        ...     branch = git.branch.get_current_branch(cwd)\n   181→    \"\"\"\n   182→    if ctx.obj is None:\n   183→        click.echo(\"Error: Context not initialized\", err=True)\n   184→        raise SystemExit(1)\n   185→\n   186→    return ctx.obj.git\n   187→\n   188→\n   189→def require_github(ctx: click.Context) -> GitHub:\n   190→    \"\"\"Get GitHub from context, exiting with error if not initialized.\n   191→\n   192→    Uses LBYL pattern to check context before accessing.\n   193→\n   194→    Args:\n   195→        ctx: Click context (must have ErkContext in ctx.obj)\n   196→\n   197→    Returns:\n   198→        GitHub instance from context\n   199→\n   200→    Raises:\n   201→        SystemExit: If context not initialized (exits with code 1)\n   202→\n   203→    Example:\n   204→        >>> @click.command()\n   205→        >>> @click.pass_context\n   206→        >>> def my_command(ctx: click.Context) -> None:\n   207→        ...     github = require_github(ctx)\n   208→        ...     repo_root = require_repo_root(ctx)\n   209→        ...     pr_info = github.get_pr_status(repo_root, \"main\", debug=False)\n   210→    \"\"\"\n   211→    if ctx.obj is None:\n   212→        click.echo(\"Error: Context not initialized\", err=True)\n   213→        raise SystemExit(1)\n   214→\n   215→    return ctx.obj.github\n   216→\n   217→\n   218→def require_cwd(ctx: click.Context) -> Path:\n   219→    \"\"\"Get current working directory from context, exiting with error if not initialized.\n   220→\n   221→    Uses LBYL pattern to check context before accessing.\n   222→\n   223→    Args:\n   224→        ctx: Click context (must have ErkContext in ctx.obj)\n   225→\n   226→    Returns:\n   227→        Path to current working directory (worktree path)\n   228→\n   229→    Raises:\n   230→        SystemExit: If context not initialized (exits with code 1)\n   231→\n   232→    Example:\n   233→        >>> @click.command()\n   234→        >>> @click.pass_context\n   235→        >>> def my_command(ctx: click.Context) -> None:\n   236→        ...     cwd = require_cwd(ctx)\n   237→        ...     git = require_git(ctx)\n   238→        ...     branch = git.branch.get_current_branch(cwd)\n   239→    \"\"\"\n   240→    if ctx.obj is None:\n   241→        click.echo(\"Error: Context not initialized\", err=True)\n   242→        raise SystemExit(1)\n   243→\n   244→    return ctx.obj.cwd\n   245→\n   246→\n   247→def require_claude_installation(ctx: click.Context) -> ClaudeInstallation:\n   248→    \"\"\"Get ClaudeInstallation from context, exiting with error if not initialized.\n   249→\n   250→    Uses LBYL pattern to check context before accessing.\n   251→\n   252→    Args:\n   253→        ctx: Click context (must have ErkContext in ctx.obj)\n   254→\n   255→    Returns:\n   256→        ClaudeInstallation instance from context\n   257→\n   258→    Raises:\n   259→        SystemExit: If context not initialized (exits with code 1)\n   260→\n   261→    Example:\n   262→        >>> @click.command()\n   263→        >>> @click.pass_context\n   264→        >>> def my_command(ctx: click.Context) -> None:\n   265→        ...     installation = require_claude_installation(ctx)\n   266→        ...     sessions = installation.find_sessions(cwd, ...)\n   267→    \"\"\"\n   268→    if ctx.obj is None:\n   269→        click.echo(\"Error: Context not initialized\", err=True)\n   270→        raise SystemExit(1)\n   271→\n   272→    return ctx.obj.claude_installation\n   273→\n   274→\n   275→def get_current_branch(ctx: click.Context) -> str | None:\n   276→    \"\"\"Get current git branch from context.\n   277→\n   278→    Convenience method that combines require_cwd and require_git to get\n   279→    the current branch name. Returns None if branch cannot be determined.\n   280→\n   281→    Args:\n   282→        ctx: Click context (must have ErkContext in ctx.obj)\n   283→\n   284→    Returns:\n   285→        Current branch name as string, or None if not determinable\n   286→\n   287→    Raises:\n   288→        SystemExit: If context not initialized (exits with code 1)\n   289→\n   290→    Example:\n   291→        >>> @click.command()\n   292→        >>> @click.pass_context\n   293→        >>> def my_command(ctx: click.Context) -> None:\n   294→        ...     branch = get_current_branch(ctx)\n   295→        ...     if branch is None:\n   296→        ...         # handle error\n   297→        ...     pr = github.get_pr_for_branch(repo_root, branch)\n   298→    \"\"\"\n   299→    cwd = require_cwd(ctx)\n   300→    git = require_git(ctx)\n   301→    return git.branch.get_current_branch(cwd)\n   302→\n   303→\n   304→def require_prompt_executor(ctx: click.Context) -> PromptExecutor:\n   305→    \"\"\"Get PromptExecutor from context, exiting with error if not initialized.\n   306→\n   307→    Uses LBYL pattern to check context before accessing.\n   308→\n   309→    Args:\n   310→        ctx: Click context (must have ErkContext in ctx.obj)\n   311→\n   312→    Returns:\n   313→        PromptExecutor instance from context\n   314→\n   315→    Raises:\n   316→        SystemExit: If context not initialized (exits with code 1)\n   317→\n   318→    Example:\n   319→        >>> @click.command()\n   320→        >>> @click.pass_context\n   321→        >>> def my_command(ctx: click.Context) -> None:\n   322→        ...     executor = require_prompt_executor(ctx)\n   323→        ...     result = executor.execute_prompt(\"Generate summary\", model=\"haiku\")\n   324→    \"\"\"\n   325→    if ctx.obj is None:\n   326→        click.echo(\"Error: Context not initialized\", err=True)\n   327→        raise SystemExit(1)\n   328→\n   329→    return ctx.obj.prompt_executor\n   330→\n   331→\n   332→def require_local_config(ctx: click.Context) -> LoadedConfig:\n   333→    \"\"\"Get local config from context, exiting with error if not initialized.\n   334→\n   335→    Uses LBYL pattern to check context before accessing.\n   336→\n   337→    Args:\n   338→        ctx: Click context (must have ErkContext in ctx.obj)\n   339→\n   340→    Returns:\n   341→        LoadedConfig instance from context\n   342→\n   343→    Raises:\n   344→        SystemExit: If context not initialized (exits with code 1)\n   345→\n   346→    Example:\n   347→        >>> @click.command()\n   348→        >>> @click.pass_context\n   349→        >>> def my_command(ctx: click.Context) -> None:\n   350→        ...     config = require_local_config(ctx)\n   351→        ...     plans_repo = config.plans_repo\n   352→    \"\"\"\n   353→    if ctx.obj is None:\n   354→        click.echo(\"Error: Context not initialized\", err=True)\n   355→        raise SystemExit(1)\n   356→\n   357→    return ctx.obj.local_config\n   358→\n   359→\n   360→def get_repo_identifier(ctx: click.Context) -> str | None:\n   361→    \"\"\"Get the GitHub repo identifier (owner/repo) from context.\n   362→\n   363→    Convenience method that returns the repo identity in \"owner/repo\" format,\n   364→    or None if not in a GitHub-connected repository.\n   365→\n   366→    Args:\n   367→        ctx: Click context (must have ErkContext in ctx.obj)\n   368→\n   369→    Returns:\n   370→        Repo identifier as \"owner/repo\" string, or None if not available\n   371→\n   372→    Raises:\n   373→        SystemExit: If context not initialized (exits with code 1)\n   374→\n   375→    Example:\n   376→        >>> @click.command()\n   377→        >>> @click.pass_context\n   378→        >>> def my_command(ctx: click.Context) -> None:\n   379→        ...     repo_id = get_repo_identifier(ctx)\n   380→        ...     if repo_id:\n   381→        ...         print(f\"Working in {repo_id}\")\n   382→    \"\"\"\n   383→    if ctx.obj is None:\n   384→        click.echo(\"Error: Context not initialized\", err=True)\n   385→        raise SystemExit(1)\n   386→\n   387→    repo = ctx.obj.repo\n   388→    if isinstance(repo, NoRepoSentinel):\n   389→        return None\n   390→\n   391→    if repo.github is None:\n   392→        return None\n   393→\n   394→    return f\"{repo.github.owner}/{repo.github.repo}\"\n   395→\n   396→\n   397→def require_plan_backend(ctx: click.Context) -> PlanBackend:\n   398→    \"\"\"Get PlanBackend from context, exiting with error if not initialized.\n   399→\n   400→    Uses LBYL pattern to check context before accessing.\n   401→\n   402→    Args:\n   403→        ctx: Click context (must have ErkContext in ctx.obj)\n   404→\n   405→    Returns:\n   406→        PlanBackend instance from context\n   407→\n   408→    Raises:\n   409→        SystemExit: If context not initialized (exits with code 1)\n   410→\n   411→    Example:\n   412→        >>> @click.command()\n   413→        >>> @click.pass_context\n   414→        >>> def my_command(ctx: click.Context) -> None:\n   415→        ...     backend = require_plan_backend(ctx)\n   416→        ...     result = backend.create_plan(repo_root, title, content, labels, metadata)\n   417→    \"\"\"\n   418→    if ctx.obj is None:\n   419→        click.echo(\"Error: Context not initialized\", err=True)\n   420→        raise SystemExit(1)\n   421→\n   422→    return ctx.obj.plan_backend\n   423→\n   424→\n   425→def require_time(ctx: click.Context) -> Time:\n   426→    \"\"\"Get Time from context, exiting with error if not initialized.\n   427→\n   428→    Uses LBYL pattern to check context before accessing.\n   429→\n   430→    Args:\n   431→        ctx: Click context (must have ErkContext in ctx.obj)\n   432→\n   433→    Returns:\n   434→        Time instance from context\n   435→\n   436→    Raises:\n   437→        SystemExit: If context not initialized (exits with code 1)\n   438→\n   439→    Example:\n   440→        >>> @click.command()\n   441→        >>> @click.pass_context\n   442→        >>> def my_command(ctx: click.Context) -> None:\n   443→        ...     time = require_time(ctx)\n   444→        ...     timestamp = time.now().isoformat()\n   445→    \"\"\"\n   446→    if ctx.obj is None:\n   447→        click.echo(\"Error: Context not initialized\", err=True)\n   448→        raise SystemExit(1)\n   449→\n   450→    return ctx.obj.time\n   451→\n   452→\n   453→def require_branch_manager(ctx: click.Context) -> BranchManager:\n   454→    \"\"\"Get BranchManager from context, exiting with error if not initialized.\n   455→\n   456→    Uses LBYL pattern to check context before accessing.\n   457→\n   458→    Args:\n   459→        ctx: Click context (must have ErkContext in ctx.obj)\n   460→\n   461→    Returns:\n   462→        BranchManager instance from context (GitBranchManager or GraphiteBranchManager)\n   463→\n   464→    Raises:\n   465→        SystemExit: If context not initialized (exits with code 1)\n   466→\n   467→    Example:\n   468→        >>> @click.command()\n   469→        >>> @click.pass_context\n   470→        >>> def my_command(ctx: click.Context) -> None:\n   471→        ...     branch_manager = require_branch_manager(ctx)\n   472→        ...     branch_manager.create_branch(repo_root, \"feature-branch\", \"main\")\n   473→    \"\"\"\n   474→    if ctx.obj is None:\n   475→        click.echo(\"Error: Context not initialized\", err=True)\n   476→        raise SystemExit(1)\n   477→\n   478→    return ctx.obj.branch_manager\n   479→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"eedfe95f-fa02-46fd-abcb-1764554a6cfd","timestamp":"2026-02-22T14:37:30.068Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/helpers.py","content":"\"\"\"Helper functions for accessing context dependencies with LBYL checks.\n\nThis module provides getter functions that encapsulate the \"Look Before You Leap\"\npattern for accessing dependencies from the ErkContext. These functions:\n\n1. Check that context is initialized\n2. Return the typed dependency\n3. Exit with clear error message if context is missing\n\nThis eliminates code duplication across kit CLI commands.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom pathlib import Path\n\nimport click\n\nfrom erk_shared.context.context import ErkContext\nfrom erk_shared.context.types import LoadedConfig, NoRepoSentinel\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.gateway.branch_manager.abc import BranchManager\nfrom erk_shared.gateway.claude_installation.abc import ClaudeInstallation\nfrom erk_shared.gateway.git.abc import Git\nfrom erk_shared.gateway.github.abc import GitHub\nfrom erk_shared.gateway.github.issues.abc import GitHubIssues\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.plan_store.backend import PlanBackend\n\n\ndef require_context(ctx: click.Context) -> ErkContext:\n    \"\"\"Get the full ErkContext, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing. If context is not\n    initialized (ctx.obj is None), prints error to stderr and exits with code 1.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        ErkContext instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     erk_ctx = require_context(ctx)\n        ...     # Access any attribute from erk_ctx\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    if not isinstance(ctx.obj, ErkContext):\n        click.echo(\"Error: Context must be ErkContext\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj\n\n\ndef require_issues(ctx: click.Context) -> GitHubIssues:\n    \"\"\"Get GitHub Issues from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing. If context is not\n    initialized (ctx.obj is None), prints error to stderr and exits with code 1.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        GitHubIssues instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     issues = require_issues(ctx)\n        ...     issues.add_comment(repo_root, issue_number, body)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    if not isinstance(ctx.obj, ErkContext):\n        click.echo(\"Error: Context must be ErkContext\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.issues\n\n\ndef require_repo_root(ctx: click.Context) -> Path:\n    \"\"\"Get repo root from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Path to repository root\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     repo_root = require_repo_root(ctx)\n        ...     issues = require_issues(ctx)\n        ...     issues.create_issue(repo_root, title, body, labels)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    if not isinstance(ctx.obj, ErkContext):\n        click.echo(\"Error: Context must be ErkContext\", err=True)\n        raise SystemExit(1)\n\n    repo = ctx.obj.repo\n    if isinstance(repo, NoRepoSentinel):\n        click.echo(\"Error: Not in a git repository\", err=True)\n        raise SystemExit(1)\n\n    return repo.root\n\n\ndef require_project_root(ctx: click.Context) -> Path:\n    \"\"\"Get project root from context, which is always the repo root.\n\n    Simplified: With the project system removed, project root is always repo root.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Path to repo root (always, since project system is removed)\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     project_root = require_project_root(ctx)\n        ...     docs_dir = project_root / \"docs\" / \"agent\"\n    \"\"\"\n    # With project system removed, project root is always repo root\n    return require_repo_root(ctx)\n\n\ndef require_git(ctx: click.Context) -> Git:\n    \"\"\"Get Git from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Git instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     git = require_git(ctx)\n        ...     cwd = require_cwd(ctx)\n        ...     branch = git.branch.get_current_branch(cwd)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.git\n\n\ndef require_github(ctx: click.Context) -> GitHub:\n    \"\"\"Get GitHub from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        GitHub instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     github = require_github(ctx)\n        ...     repo_root = require_repo_root(ctx)\n        ...     pr_info = github.get_pr_status(repo_root, \"main\", debug=False)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.github\n\n\ndef require_cwd(ctx: click.Context) -> Path:\n    \"\"\"Get current working directory from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Path to current working directory (worktree path)\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     cwd = require_cwd(ctx)\n        ...     git = require_git(ctx)\n        ...     branch = git.branch.get_current_branch(cwd)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.cwd\n\n\ndef require_claude_installation(ctx: click.Context) -> ClaudeInstallation:\n    \"\"\"Get ClaudeInstallation from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        ClaudeInstallation instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     installation = require_claude_installation(ctx)\n        ...     sessions = installation.find_sessions(cwd, ...)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.claude_installation\n\n\ndef get_current_branch(ctx: click.Context) -> str | None:\n    \"\"\"Get current git branch from context.\n\n    Convenience method that combines require_cwd and require_git to get\n    the current branch name. Returns None if branch cannot be determined.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Current branch name as string, or None if not determinable\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     branch = get_current_branch(ctx)\n        ...     if branch is None:\n        ...         # handle error\n        ...     pr = github.get_pr_for_branch(repo_root, branch)\n    \"\"\"\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    return git.branch.get_current_branch(cwd)\n\n\ndef require_prompt_executor(ctx: click.Context) -> PromptExecutor:\n    \"\"\"Get PromptExecutor from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        PromptExecutor instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     executor = require_prompt_executor(ctx)\n        ...     result = executor.execute_prompt(\"Generate summary\", model=\"haiku\")\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.prompt_executor\n\n\ndef require_local_config(ctx: click.Context) -> LoadedConfig:\n    \"\"\"Get local config from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        LoadedConfig instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     config = require_local_config(ctx)\n        ...     plans_repo = config.plans_repo\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.local_config\n\n\ndef get_repo_identifier(ctx: click.Context) -> str | None:\n    \"\"\"Get the GitHub repo identifier (owner/repo) from context.\n\n    Convenience method that returns the repo identity in \"owner/repo\" format,\n    or None if not in a GitHub-connected repository.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Repo identifier as \"owner/repo\" string, or None if not available\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     repo_id = get_repo_identifier(ctx)\n        ...     if repo_id:\n        ...         print(f\"Working in {repo_id}\")\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    repo = ctx.obj.repo\n    if isinstance(repo, NoRepoSentinel):\n        return None\n\n    if repo.github is None:\n        return None\n\n    return f\"{repo.github.owner}/{repo.github.repo}\"\n\n\ndef require_plan_backend(ctx: click.Context) -> PlanBackend:\n    \"\"\"Get PlanBackend from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        PlanBackend instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     backend = require_plan_backend(ctx)\n        ...     result = backend.create_plan(repo_root, title, content, labels, metadata)\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.plan_backend\n\n\ndef require_time(ctx: click.Context) -> Time:\n    \"\"\"Get Time from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        Time instance from context\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     time = require_time(ctx)\n        ...     timestamp = time.now().isoformat()\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.time\n\n\ndef require_branch_manager(ctx: click.Context) -> BranchManager:\n    \"\"\"Get BranchManager from context, exiting with error if not initialized.\n\n    Uses LBYL pattern to check context before accessing.\n\n    Args:\n        ctx: Click context (must have ErkContext in ctx.obj)\n\n    Returns:\n        BranchManager instance from context (GitBranchManager or GraphiteBranchManager)\n\n    Raises:\n        SystemExit: If context not initialized (exits with code 1)\n\n    Example:\n        >>> @click.command()\n        >>> @click.pass_context\n        >>> def my_command(ctx: click.Context) -> None:\n        ...     branch_manager = require_branch_manager(ctx)\n        ...     branch_manager.create_branch(repo_root, \"feature-branch\", \"main\")\n    \"\"\"\n    if ctx.obj is None:\n        click.echo(\"Error: Context not initialized\", err=True)\n        raise SystemExit(1)\n\n    return ctx.obj.branch_manager\n","numLines":479,"startLine":1,"totalLines":479}}}
{"parentUuid":"eedfe95f-fa02-46fd-abcb-1764554a6cfd","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013y6SDaCEVZu2WUCQtRx6GS","type":"tool_result","content":"     1→\"\"\"Naming utilities for filenames and worktree names.\n     2→\n     3→This module provides pure utility functions for transforming titles and names\n     4→into sanitized, filesystem-safe identifiers. All functions are pure (no I/O)\n     5→and follow LBYL patterns.\n     6→\n     7→Functions that require git operations accept a git_ops parameter via dependency\n     8→injection to maintain separation from I/O concerns.\n     9→\"\"\"\n    10→\n    11→import re\n    12→import unicodedata\n    13→from dataclasses import dataclass\n    14→from datetime import datetime\n    15→from pathlib import Path\n    16→\n    17→_SAFE_COMPONENT_RE = re.compile(r\"[^A-Za-z0-9_/-]+\")\n    18→\n    19→# Date suffix format for plan-derived worktree names: -YY-MM-DD-HHMM\n    20→WORKTREE_DATE_SUFFIX_FORMAT = \"%y-%m-%d-%H%M\"\n    21→\n    22→# Branch timestamp suffix format: -MM-DD-HHMM (appended after truncation)\n    23→BRANCH_TIMESTAMP_SUFFIX_FORMAT = \"%m-%d-%H%M\"\n    24→\n    25→# Regex pattern to detect existing timestamp suffix (MM-DD-HHMM)\n    26→_TIMESTAMP_SUFFIX_PATTERN = re.compile(r\"-\\d{2}-\\d{2}-\\d{4}$\")\n    27→\n    28→\n    29→def has_timestamp_suffix(name: str) -> bool:\n    30→    \"\"\"Check if a name already ends with a timestamp suffix (-MM-DD-HHMM).\n    31→\n    32→    Args:\n    33→        name: Branch or worktree name to check\n    34→\n    35→    Returns:\n    36→        True if name ends with timestamp suffix pattern, False otherwise\n    37→\n    38→    Examples:\n    39→        >>> has_timestamp_suffix(\"42-feature-01-15-1430\")\n    40→        True\n    41→        >>> has_timestamp_suffix(\"42-feature\")\n    42→        False\n    43→        >>> has_timestamp_suffix(\"42-feature-branch\")\n    44→        False\n    45→    \"\"\"\n    46→    return _TIMESTAMP_SUFFIX_PATTERN.search(name) is not None\n    47→\n    48→\n    49→def format_branch_timestamp_suffix(dt: datetime) -> str:\n    50→    \"\"\"Format a datetime as a branch timestamp suffix.\n    51→\n    52→    Returns a suffix in the format -MM-DD-HHMM to be appended to branch names.\n    53→\n    54→    Args:\n    55→        dt: Datetime to format\n    56→\n    57→    Returns:\n    58→        Formatted suffix string (e.g., \"-01-15-1430\")\n    59→\n    60→    Examples:\n    61→        >>> from datetime import datetime\n    62→        >>> format_branch_timestamp_suffix(datetime(2024, 1, 15, 14, 30))\n    63→        \"-01-15-1430\"\n    64→        >>> format_branch_timestamp_suffix(datetime(2024, 12, 31, 23, 59))\n    65→        \"-12-31-2359\"\n    66→    \"\"\"\n    67→    return f\"-{dt.strftime(BRANCH_TIMESTAMP_SUFFIX_FORMAT)}\"\n    68→\n    69→\n    70→_OBJECTIVE_SLUG_PATTERN = re.compile(r\"^[a-z][a-z0-9]*(-[a-z0-9]+)*$\")\n    71→\n    72→# Plan title constraints\n    73→_PLAN_TITLE_MIN_LENGTH = 5\n    74→_PLAN_TITLE_MAX_LENGTH = 100\n    75→\n    76→\n    77→@dataclass(frozen=True)\n    78→class ValidPlanTitle:\n    79→    \"\"\"Validation success for a plan title.\n    80→\n    81→    Attributes:\n    82→        title: The validated title value.\n    83→    \"\"\"\n    84→\n    85→    title: str\n    86→\n    87→\n    88→@dataclass(frozen=True)\n    89→class InvalidPlanTitle:\n    90→    \"\"\"Validation failure for a plan title.\n    91→\n    92→    Attributes:\n    93→        raw_title: The original title value that failed validation.\n    94→        reason: A short description of why validation failed.\n    95→    \"\"\"\n    96→\n    97→    raw_title: str\n    98→    reason: str\n    99→\n   100→    @property\n   101→    def error_type(self) -> str:\n   102→        return \"invalid-plan-title\"\n   103→\n   104→    @property\n   105→    def message(self) -> str:\n   106→        \"\"\"Full error message with rules, actual value, and examples.\n   107→\n   108→        Designed so an agent receiving this message can self-correct.\n   109→        \"\"\"\n   110→        return (\n   111→            f\"Invalid plan title: {self.reason}\\n\"\n   112→            f\"  Actual value: {self.raw_title!r}\\n\"\n   113→            f\"  Rules:\\n\"\n   114→            f\"    - {_PLAN_TITLE_MIN_LENGTH}-{_PLAN_TITLE_MAX_LENGTH} characters\\n\"\n   115→            f\"    - Must contain at least one alphabetic character\\n\"\n   116→            f\"    - Must retain meaningful content after sanitization\\n\"\n   117→            f\"      (emojis, special characters, and accents are stripped)\\n\"\n   118→            f\"  Valid examples: Add User Authentication,\"\n   119→            f\" Refactor Gateway Layer\\n\"\n   120→            f\"  Invalid examples: \\U0001f680\\U0001f389, 123, #!@, Plan\"\n   121→        )\n   122→\n   123→\n   124→def validate_plan_title(title: str) -> ValidPlanTitle | InvalidPlanTitle:\n   125→    \"\"\"Validate a plan title against minimum content requirements.\n   126→\n   127→    This is an agent-facing validation gate. It ensures plan titles have enough\n   128→    meaningful content before they are used to generate filenames, branch names,\n   129→    or issue titles. Human-facing paths (like generate_filename_from_title) can\n   130→    still transform arbitrary input silently.\n   131→\n   132→    Returns ValidPlanTitle on success, or InvalidPlanTitle describing the failure.\n   133→\n   134→    Args:\n   135→        title: The plan title string to validate.\n   136→\n   137→    Returns:\n   138→        ValidPlanTitle if valid, InvalidPlanTitle if invalid.\n   139→\n   140→    Examples:\n   141→        >>> validate_plan_title(\"Add User Authentication\")\n   142→        ValidPlanTitle(title='Add User Authentication')\n   143→        >>> validate_plan_title(\"\")\n   144→        InvalidPlanTitle(raw_title='', reason='...')\n   145→        >>> validate_plan_title(\"🚀🎉\")\n   146→        InvalidPlanTitle(raw_title='🚀🎉', reason='...')\n   147→    \"\"\"\n   148→    stripped = title.strip()\n   149→\n   150→    if not stripped:\n   151→        return InvalidPlanTitle(raw_title=title, reason=\"Title is empty or whitespace-only\")\n   152→\n   153→    if len(stripped) < _PLAN_TITLE_MIN_LENGTH:\n   154→        return InvalidPlanTitle(\n   155→            raw_title=title,\n   156→            reason=f\"Too short ({len(stripped)} characters, minimum {_PLAN_TITLE_MIN_LENGTH})\",\n   157→        )\n   158→\n   159→    if len(stripped) > _PLAN_TITLE_MAX_LENGTH:\n   160→        return InvalidPlanTitle(\n   161→            raw_title=title,\n   162→            reason=f\"Too long ({len(stripped)} characters, maximum {_PLAN_TITLE_MAX_LENGTH})\",\n   163→        )\n   164→\n   165→    if not any(c.isalpha() for c in stripped):\n   166→        return InvalidPlanTitle(\n   167→            raw_title=title,\n   168→            reason=\"Must contain at least one alphabetic character\",\n   169→        )\n   170→\n   171→    # Check that sanitization retains meaningful content.\n   172→    # generate_filename_from_title strips emojis, accents, and special chars.\n   173→    # If the result is \"plan.md\" (the fallback), the title has no usable content.\n   174→    filename = generate_filename_from_title(stripped)\n   175→    if filename == \"plan.md\":\n   176→        return InvalidPlanTitle(\n   177→            raw_title=title,\n   178→            reason=\"No usable content after sanitization (only emojis or special characters)\",\n   179→        )\n   180→\n   181→    return ValidPlanTitle(title=stripped)\n   182→\n   183→\n   184→@dataclass(frozen=True)\n   185→class ValidObjectiveSlug:\n   186→    \"\"\"Validation success for an objective slug.\n   187→\n   188→    Attributes:\n   189→        slug: The validated slug value.\n   190→    \"\"\"\n   191→\n   192→    slug: str\n   193→\n   194→\n   195→@dataclass(frozen=True)\n   196→class InvalidObjectiveSlug:\n   197→    \"\"\"Validation failure for an objective slug.\n   198→\n   199→    Attributes:\n   200→        raw_slug: The original slug value that failed validation.\n   201→        reason: A short description of why validation failed.\n   202→    \"\"\"\n   203→\n   204→    raw_slug: str\n   205→    reason: str\n   206→\n   207→    @property\n   208→    def message(self) -> str:\n   209→        \"\"\"Full error message with pattern, rules, actual value, and examples.\n   210→\n   211→        Designed so an agent receiving this message can self-correct.\n   212→        \"\"\"\n   213→        return (\n   214→            f\"Invalid objective slug: {self.reason}\\n\"\n   215→            f\"  Actual value: {self.raw_slug!r}\\n\"\n   216→            f\"  Pattern: ^[a-z][a-z0-9]*(-[a-z0-9]+)*$\\n\"\n   217→            f\"  Rules:\\n\"\n   218→            f\"    - 3-40 characters\\n\"\n   219→            f\"    - Lowercase letters and digits only\\n\"\n   220→            f\"    - Must start with a letter\\n\"\n   221→            f\"    - Hyphens allowed between words (no consecutive hyphens)\\n\"\n   222→            f\"  Valid examples: build-auth-system, refactor-gateway, add-dark-mode\\n\"\n   223→            f\"  Invalid examples: Build-Auth, 123-start, my--slug, ab\"\n   224→        )\n   225→\n   226→\n   227→def validate_objective_slug(slug: str) -> ValidObjectiveSlug | InvalidObjectiveSlug:\n   228→    \"\"\"Validate an objective slug against the required format.\n   229→\n   230→    Returns ValidObjectiveSlug on success, or InvalidObjectiveSlug describing the failure.\n   231→\n   232→    Args:\n   233→        slug: The slug string to validate.\n   234→\n   235→    Returns:\n   236→        ValidObjectiveSlug if valid, InvalidObjectiveSlug if invalid.\n   237→\n   238→    Examples:\n   239→        >>> validate_objective_slug(\"build-auth-system\")  # valid\n   240→        ValidObjectiveSlug(slug='build-auth-system')\n   241→        >>> validate_objective_slug(\"AB\")  # invalid\n   242→        InvalidObjectiveSlug(raw_slug='AB', reason='...')\n   243→    \"\"\"\n   244→    if len(slug) < 3:\n   245→        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Too short (minimum 3 characters)\")\n   246→    if len(slug) > 40:\n   247→        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Too long (maximum 40 characters)\")\n   248→    if _OBJECTIVE_SLUG_PATTERN.match(slug) is None:\n   249→        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Does not match required pattern\")\n   250→    return ValidObjectiveSlug(slug=slug)\n   251→\n   252→\n   253→def sanitize_worktree_name(name: str) -> str:\n   254→    \"\"\"Sanitize a worktree name for use as a directory name.\n   255→\n   256→    - If name already has timestamp suffix (-MM-DD-HHMM), returns as-is (idempotent)\n   257→    - Lowercases input\n   258→    - Replaces underscores with hyphens\n   259→    - Replaces characters outside `[A-Za-z0-9-]` with `-`\n   260→    - Collapses consecutive `-`\n   261→    - Strips leading/trailing `-`\n   262→    - Truncates to 31 characters maximum (matches branch component sanitization)\n   263→    Returns `\"work\"` if the result is empty.\n   264→\n   265→    The 31-character limit ensures worktree names match their corresponding branch\n   266→    names, maintaining consistency across the worktree/branch model.\n   267→\n   268→    Args:\n   269→        name: Arbitrary string to sanitize\n   270→\n   271→    Returns:\n   272→        Sanitized worktree name (max 31 chars, unless timestamp already present)\n   273→\n   274→    Examples:\n   275→        >>> sanitize_worktree_name(\"My_Feature\")\n   276→        \"my-feature\"\n   277→        >>> sanitize_worktree_name(\"a\" * 40)\n   278→        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 31 chars\n   279→        >>> sanitize_worktree_name(\"42-feature-01-15-1430\")\n   280→        \"42-feature-01-15-1430\"  # timestamp preserved (idempotent)\n   281→    \"\"\"\n   282→    # If name already has a timestamp suffix, return as-is (idempotent)\n   283→    if has_timestamp_suffix(name):\n   284→        return name\n   285→\n   286→    lowered = name.strip().lower()\n   287→    # Replace underscores with hyphens\n   288→    replaced_underscores = lowered.replace(\"_\", \"-\")\n   289→    # Replace unsafe characters with hyphens\n   290→    replaced = re.sub(r\"[^a-z0-9-]+\", \"-\", replaced_underscores)\n   291→    # Collapse consecutive hyphens\n   292→    collapsed = re.sub(r\"-+\", \"-\", replaced)\n   293→    # Strip leading/trailing hyphens\n   294→    trimmed = collapsed.strip(\"-\")\n   295→    result = trimmed or \"work\"\n   296→\n   297→    # Truncate to 31 characters and strip trailing hyphens\n   298→    if len(result) > 31:\n   299→        result = result[:31].rstrip(\"-\")\n   300→\n   301→    return result\n   302→\n   303→\n   304→def sanitize_branch_component(name: str) -> str:\n   305→    \"\"\"Return a sanitized, predictable branch component from an arbitrary name.\n   306→\n   307→    - Lowercases input\n   308→    - Replaces characters outside `[A-Za-z0-9_/-]` with `-`\n   309→    - Collapses consecutive `-`\n   310→    - Strips leading/trailing `-` and `/`\n   311→    - Truncates to 31 characters maximum (matches worktree behavior)\n   312→    Returns `\"work\"` if the result is empty.\n   313→\n   314→    Args:\n   315→        name: Arbitrary string to sanitize\n   316→\n   317→    Returns:\n   318→        Sanitized branch component name (max 31 chars)\n   319→\n   320→    Examples:\n   321→        >>> sanitize_branch_component(\"My Feature!\")\n   322→        \"my-feature\"\n   323→        >>> sanitize_branch_component(\"fix/bug-123\")\n   324→        \"fix/bug-123\"\n   325→        >>> sanitize_branch_component(\"\")\n   326→        \"work\"\n   327→        >>> sanitize_branch_component(\"a\" * 40)\n   328→        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 31 chars\n   329→    \"\"\"\n   330→    lowered = name.strip().lower()\n   331→    replaced = _SAFE_COMPONENT_RE.sub(\"-\", lowered)\n   332→    collapsed = re.sub(r\"-+\", \"-\", replaced)\n   333→    trimmed = collapsed.strip(\"-/\")\n   334→    result = trimmed or \"work\"\n   335→\n   336→    # Truncate to 31 characters and strip trailing hyphens (matching worktree behavior)\n   337→    if len(result) > 31:\n   338→        result = result[:31].rstrip(\"-\")\n   339→\n   340→    return result\n   341→\n   342→\n   343→def generate_filename_from_title(title: str) -> str:\n   344→    \"\"\"Convert title to kebab-case filename with -plan.md suffix.\n   345→\n   346→    Comprehensive transformation:\n   347→    1. Lowercase\n   348→    2. Replace spaces with hyphens\n   349→    3. Unicode normalization (NFD)\n   350→    4. Remove emojis and non-alphanumeric characters (except hyphens)\n   351→    5. Collapse consecutive hyphens\n   352→    6. Strip leading/trailing hyphens\n   353→    7. Validate at least one alphanumeric character remains\n   354→    8. Append \"-plan.md\"\n   355→\n   356→    Returns \"plan.md\" if title is empty after cleanup.\n   357→\n   358→    Args:\n   359→        title: Plan title to convert\n   360→\n   361→    Returns:\n   362→        Sanitized filename ending with -plan.md\n   363→\n   364→    Example:\n   365→        >>> generate_filename_from_title(\"User Auth Feature\")\n   366→        'user-auth-feature-plan.md'\n   367→\n   368→        >>> generate_filename_from_title(\"Fix: Bug #123\")\n   369→        'fix-bug-123-plan.md'\n   370→\n   371→        >>> generate_filename_from_title(\"🚀 Feature Launch 🎉\")\n   372→        'feature-launch-plan.md'\n   373→\n   374→        >>> generate_filename_from_title(\"café\")\n   375→        'cafe-plan.md'\n   376→    \"\"\"\n   377→    # Step 1: Lowercase and strip whitespace\n   378→    lowered = title.strip().lower()\n   379→\n   380→    # Step 2: Unicode normalization (NFD form for decomposition)\n   381→    # Decompose combined characters (é → e + ´)\n   382→    normalized = unicodedata.normalize(\"NFD\", lowered)\n   383→\n   384→    # Step 3: Remove emojis and non-ASCII characters, convert to ASCII\n   385→    # Keep only ASCII alphanumeric, spaces, and hyphens\n   386→    cleaned = \"\"\n   387→    for char in normalized:\n   388→        # Keep ASCII alphanumeric, spaces, and hyphens\n   389→        if ord(char) < 128 and (char.isalnum() or char in (\" \", \"-\")):\n   390→            cleaned += char\n   391→        # Skip combining marks (accents) and emoji\n   392→        # Skip non-ASCII characters (CJK, emoji, special symbols)\n   393→\n   394→    # Step 4: Replace spaces with hyphens\n   395→    replaced = cleaned.replace(\" \", \"-\")\n   396→\n   397→    # Step 5: Collapse consecutive hyphens\n   398→    collapsed = re.sub(r\"-+\", \"-\", replaced)\n   399→\n   400→    # Step 6: Strip leading/trailing hyphens\n   401→    trimmed = collapsed.strip(\"-\")\n   402→\n   403→    # Step 7: Validate at least one alphanumeric character\n   404→    if not trimmed or not any(c.isalnum() for c in trimmed):\n   405→        return \"plan.md\"\n   406→\n   407→    return f\"{trimmed}-plan.md\"\n   408→\n   409→\n   410→def strip_plan_from_filename(filename: str) -> str:\n   411→    \"\"\"Remove 'plan' or 'implementation plan' from a filename stem intelligently.\n   412→\n   413→    Handles case-insensitive matching and common separators (-, _, space).\n   414→    If removal would leave empty string, returns original unchanged.\n   415→\n   416→    Args:\n   417→        filename: Filename stem (without extension) to process\n   418→\n   419→    Returns:\n   420→        Filename with plan-related words removed, or original if would be empty\n   421→\n   422→    Examples:\n   423→        >>> strip_plan_from_filename(\"devclikit-extraction-plan\")\n   424→        \"devclikit-extraction\"\n   425→        >>> strip_plan_from_filename(\"my-feature-plan\")\n   426→        \"my-feature\"\n   427→        >>> strip_plan_from_filename(\"implementation-plan-for-auth\")\n   428→        \"for-auth\"\n   429→        >>> strip_plan_from_filename(\"feature_implementation_plan\")\n   430→        \"feature\"\n   431→        >>> strip_plan_from_filename(\"plan\")\n   432→        \"plan\"  # preserved - would be empty\n   433→    \"\"\"\n   434→    original_trimmed = filename.strip(\"-_ \\t\\n\\r\")\n   435→    original_is_plan = original_trimmed.casefold() == \"plan\" if original_trimmed else False\n   436→\n   437→    # First, handle \"implementation plan\" with various separators\n   438→    # Pattern matches \"implementation\" + separator + \"plan\" as complete words\n   439→    impl_pattern = r\"(^|[-_\\s])(implementation)([-_\\s])(plan)([-_\\s]|$)\"\n   440→\n   441→    def replace_impl_plan(match: re.Match[str]) -> str:\n   442→        prefix = match.group(1)\n   443→        implementation_word = match.group(2)  # Preserves original case\n   444→        suffix = match.group(5)\n   445→\n   446→        if suffix == \"\" and prefix:\n   447→            prefix_start = match.start(1)\n   448→            preceding_segment = filename[:prefix_start]\n   449→            trimmed_segment = preceding_segment.strip(\"-_ \\t\\n\\r\")\n   450→            if trimmed_segment:\n   451→                preceding_tokens = re.split(r\"[-_\\s]+\", trimmed_segment)\n   452→                if preceding_tokens:\n   453→                    preceding_token = preceding_tokens[-1]\n   454→                    if preceding_token.casefold() == \"plan\":\n   455→                        return f\"{prefix}{implementation_word}\"\n   456→\n   457→        # If entire string is \"implementation-plan\", keep just \"implementation\"\n   458→        if not prefix and not suffix:\n   459→            return implementation_word\n   460→\n   461→        # If in the middle, preserve one separator\n   462→        if prefix and suffix:\n   463→            return prefix if prefix.strip() else suffix\n   464→\n   465→        # At start or end: remove it and the adjacent separator\n   466→        return \"\"\n   467→\n   468→    cleaned = re.sub(impl_pattern, replace_impl_plan, filename, flags=re.IGNORECASE)\n   469→\n   470→    # Then handle standalone \"plan\" as a complete word\n   471→    plan_pattern = r\"(^|[-_\\s])(plan)([-_\\s]|$)\"\n   472→\n   473→    def replace_plan(match: re.Match[str]) -> str:\n   474→        prefix = match.group(1)\n   475→        suffix = match.group(3)\n   476→\n   477→        # If both prefix and suffix are empty (entire string is \"plan\"), keep it\n   478→        if not prefix and not suffix:\n   479→            return \"plan\"\n   480→\n   481→        # If plan is in the middle, preserve one separator\n   482→        if prefix and suffix:\n   483→            # Use the prefix separator if available, otherwise use suffix\n   484→            return prefix if prefix.strip() else suffix\n   485→\n   486→        # Plan at start or end: remove it and the adjacent separator\n   487→        return \"\"\n   488→\n   489→    cleaned = re.sub(plan_pattern, replace_plan, cleaned, flags=re.IGNORECASE)\n   490→\n   491→    def clean_separators(text: str) -> str:\n   492→        stripped = text.strip(\"-_ \\t\\n\\r\")\n   493→        stripped = re.sub(r\"--+\", \"-\", stripped)\n   494→        stripped = re.sub(r\"__+\", \"_\", stripped)\n   495→        stripped = re.sub(r\"\\s+\", \" \", stripped)\n   496→        return stripped\n   497→\n   498→    cleaned = clean_separators(cleaned)\n   499→\n   500→    plan_only_cleaned = clean_separators(\n   501→        re.sub(plan_pattern, replace_plan, filename, flags=re.IGNORECASE)\n   502→    )\n   503→\n   504→    if (\n   505→        cleaned.casefold() == \"plan\"\n   506→        and plan_only_cleaned\n   507→        and plan_only_cleaned.casefold() != \"plan\"\n   508→    ):\n   509→        cleaned = plan_only_cleaned\n   510→\n   511→    # If stripping left us with nothing or just \"plan\", preserve original\n   512→    if not cleaned or (cleaned.casefold() == \"plan\" and original_is_plan):\n   513→        return filename\n   514→\n   515→    return cleaned\n   516→\n   517→\n   518→def extract_trailing_number(name: str) -> tuple[str, int | None]:\n   519→    r\"\"\"Extract trailing number from a name.\n   520→\n   521→    Detects trailing numbers in names using regex pattern `^(.+?)-(\\d+)$`.\n   522→    Returns tuple of (base_name, number) or (name, None).\n   523→\n   524→    Args:\n   525→        name: Name to parse\n   526→\n   527→    Returns:\n   528→        Tuple of (base_name, number) if trailing number found, else (name, None)\n   529→\n   530→    Examples:\n   531→        >>> extract_trailing_number(\"my-feature\")\n   532→        (\"my-feature\", None)\n   533→        >>> extract_trailing_number(\"my-feature-2\")\n   534→        (\"my-feature\", 2)\n   535→        >>> extract_trailing_number(\"fix-42\")\n   536→        (\"fix\", 42)\n   537→    \"\"\"\n   538→    match = re.match(r\"^(.+?)-(\\d+)$\", name)\n   539→    if match:\n   540→        base_name = match.group(1)\n   541→        number = int(match.group(2))\n   542→        return (base_name, number)\n   543→    return (name, None)\n   544→\n   545→\n   546→def extract_leading_issue_number(branch_name: str) -> int | None:\n   547→    \"\"\"Extract leading issue number from a branch name.\n   548→\n   549→    Branch names follow the pattern: P{issue_number}-{slug}-{timestamp}\n   550→    Examples: \"P2382-convert-erk-create-raw-ext-12-05-2359\"\n   551→\n   552→    Also supports legacy format without \"P\" prefix for backwards compatibility.\n   553→\n   554→    Args:\n   555→        branch_name: Branch name to parse\n   556→\n   557→    Returns:\n   558→        Issue number if branch starts with optional \"P\" followed by digits and hyphen, else None\n   559→\n   560→    Examples:\n   561→        >>> extract_leading_issue_number(\"P2382-convert-erk-create-raw-ext-12-05-2359\")\n   562→        2382\n   563→        >>> extract_leading_issue_number(\"P42-fix-bug\")\n   564→        42\n   565→        >>> extract_leading_issue_number(\"2382-convert-erk-create-raw-ext-12-05-2359\")\n   566→        2382\n   567→        >>> extract_leading_issue_number(\"42-fix-bug\")\n   568→        42\n   569→        >>> extract_leading_issue_number(\"feature-branch\")\n   570→        None\n   571→        >>> extract_leading_issue_number(\"master\")\n   572→        None\n   573→    \"\"\"\n   574→    match = re.match(r\"^[Pp]?(\\d+)-\", branch_name)\n   575→    if match:\n   576→        return int(match.group(1))\n   577→    return None\n   578→\n   579→\n   580→def extract_objective_number(branch_name: str) -> int | None:\n   581→    \"\"\"Extract objective number from branch name.\n   582→\n   583→    Supports branch naming patterns:\n   584→\n   585→    - Issue-based: ``P{plan}-O{objective}-{slug}-{timestamp}``\n   586→    - Draft-PR (current): ``planned/O{objective}-{slug}-{timestamp}``\n   587→    - Draft-PR (legacy): ``plan/O{objective}-{slug}-{timestamp}``\n   588→\n   589→    Also supports lowercase \"o\" prefix for case-insensitive matching.\n   590→\n   591→    Args:\n   592→        branch_name: Branch name to parse\n   593→\n   594→    Returns:\n   595→        Objective number if branch contains O{number} after the prefix, else None\n   596→\n   597→    Examples:\n   598→        >>> extract_objective_number(\"P123-O456-fix-auth-bug-01-15-1430\")\n   599→        456\n   600→        >>> extract_objective_number(\"P123-o456-fix-bug\")\n   601→        456\n   602→        >>> extract_objective_number(\"planned/O456-fix-auth-01-15-1430\")\n   603→        456\n   604→        >>> extract_objective_number(\"plan/O456-fix-auth-01-15-1430\")\n   605→        456\n   606→        >>> extract_objective_number(\"P123-fix-auth-bug-01-15-1430\")\n   607→        None\n   608→        >>> extract_objective_number(\"feature-branch\")\n   609→        None\n   610→    \"\"\"\n   611→    match = re.match(r\"^(?:[Pp]?\\d+-|plan(?:ned)?/)[Oo](\\d+)-\", branch_name)\n   612→    if match:\n   613→        return int(match.group(1))\n   614→    return None\n   615→\n   616→\n   617→def extract_plan_review_issue_number(branch_name: str) -> int | None:\n   618→    \"\"\"Extract issue number from a plan review branch name.\n   619→\n   620→    Plan review branches follow the pattern: planned/review-{issue_number}-{timestamp}\n   621→    Examples: \"planned/review-6214-01-15-1430\"\n   622→\n   623→    Args:\n   624→        branch_name: Branch name to parse\n   625→\n   626→    Returns:\n   627→        Issue number if branch matches planned/review-{number}- pattern, else None\n   628→\n   629→    Examples:\n   630→        >>> extract_plan_review_issue_number(\"planned/review-6214-01-15-1430\")\n   631→        6214\n   632→        >>> extract_plan_review_issue_number(\"planned/review-42-01-28-0930\")\n   633→        42\n   634→        >>> extract_plan_review_issue_number(\"P2382-convert-erk-create-raw-ext\")\n   635→        None\n   636→        >>> extract_plan_review_issue_number(\"feature-branch\")\n   637→        None\n   638→    \"\"\"\n   639→    match = re.match(r\"^planned/review-(\\d+)-\", branch_name)\n   640→    if match:\n   641→        return int(match.group(1))\n   642→    return None\n   643→\n   644→\n   645→def ensure_unique_worktree_name_with_date(base_name: str, worktrees_dir: Path, git_ops) -> str:\n   646→    \"\"\"Ensure unique worktree name with datetime suffix and smart versioning.\n   647→\n   648→    Adds datetime suffix in format -YY-MM-DD-HHMM to the base name.\n   649→    If a worktree with that name exists, increments numeric suffix starting at 2 AFTER the datetime.\n   650→    Uses LBYL pattern: checks via git_ops.worktree.path_exists() before operations.\n   651→\n   652→    This function is used for plan-derived worktrees where multiple worktrees may be\n   653→    created from the same plan, requiring datetime-based disambiguation.\n   654→\n   655→    Args:\n   656→        base_name: Sanitized worktree base name (without datetime suffix)\n   657→        worktrees_dir: Directory containing worktrees\n   658→        git_ops: Git operations interface for checking path existence\n   659→\n   660→    Returns:\n   661→        Guaranteed unique worktree name with datetime suffix\n   662→\n   663→    Examples:\n   664→        First time: \"my-feature\" → \"my-feature-25-11-08-1430\"\n   665→        Duplicate: \"my-feature\" → \"my-feature-25-11-08-1430-2\"\n   666→        Next minute: \"my-feature\" → \"my-feature-25-11-08-1431\"\n   667→    \"\"\"\n   668→    date_suffix = datetime.now().strftime(WORKTREE_DATE_SUFFIX_FORMAT)\n   669→    candidate_name = f\"{base_name}-{date_suffix}\"\n   670→\n   671→    # Check if the base candidate exists\n   672→    if not git_ops.worktree.path_exists(worktrees_dir / candidate_name):\n   673→        return candidate_name\n   674→\n   675→    # Name exists, find next available number (append after date)\n   676→    counter = 2\n   677→    while True:\n   678→        versioned_name = f\"{base_name}-{date_suffix}-{counter}\"\n   679→        if not git_ops.worktree.path_exists(worktrees_dir / versioned_name):\n   680→            return versioned_name\n   681→        counter += 1\n   682→\n   683→\n   684→def ensure_simple_worktree_name(base_name: str, worktrees_dir: Path, git_ops) -> str:\n   685→    \"\"\"Ensure simple worktree name without date suffix for manual checkouts.\n   686→\n   687→    Returns the simple name if no worktree exists at that path.\n   688→    If a worktree already exists, returns the simple name (caller validates branch match).\n   689→    Uses LBYL pattern: checks via git_ops.worktree.path_exists() before operations.\n   690→\n   691→    This function is used for manual checkout operations where predictable names are\n   692→    desired (e.g., `erk co feature` → `feature` not `feature-25-11-08`).\n   693→\n   694→    Args:\n   695→        base_name: Sanitized worktree base name\n   696→        worktrees_dir: Directory containing worktrees\n   697→        git_ops: Git operations interface for checking path existence\n   698→\n   699→    Returns:\n   700→        Simple worktree name without date suffix\n   701→\n   702→    Examples:\n   703→        First time: \"my-feature\" → \"my-feature\"\n   704→        Exists: \"my-feature\" → \"my-feature\" (caller handles validation)\n   705→    \"\"\"\n   706→    candidate_name = base_name\n   707→    # Always return simple name - collision handling happens in caller\n   708→    return candidate_name\n   709→\n   710→\n   711→def ensure_unique_worktree_name(base_name: str, worktrees_dir: Path, git_ops) -> str:\n   712→    \"\"\"Deprecated: Use ensure_unique_worktree_name_with_date for plan-derived worktrees.\n   713→\n   714→    This function is kept for backward compatibility but will be removed in the future.\n   715→    New code should use:\n   716→    - ensure_unique_worktree_name_with_date() for plan-derived worktrees\n   717→    - ensure_simple_worktree_name() for manual checkout operations\n   718→    \"\"\"\n   719→    return ensure_unique_worktree_name_with_date(base_name, worktrees_dir, git_ops)\n   720→\n   721→\n   722→def default_branch_for_worktree(name: str) -> str:\n   723→    \"\"\"Default branch name for a worktree with the given `name`.\n   724→\n   725→    Returns the sanitized name directly (without any prefix).\n   726→\n   727→    Args:\n   728→        name: Worktree name\n   729→\n   730→    Returns:\n   731→        Default branch name (sanitized)\n   732→\n   733→    Examples:\n   734→        >>> default_branch_for_worktree(\"my-feature\")\n   735→        \"my-feature\"\n   736→        >>> default_branch_for_worktree(\"Fix Bug!\")\n   737→        \"fix-bug\"\n   738→    \"\"\"\n   739→    return sanitize_branch_component(name)\n   740→\n   741→\n   742→def generate_issue_branch_name(\n   743→    issue_number: int | str,\n   744→    title: str,\n   745→    timestamp: datetime,\n   746→    *,\n   747→    objective_id: int | None,\n   748→) -> str:\n   749→    \"\"\"Generate branch name for issue-based worktree.\n   750→\n   751→    Format: P{issue_number}-{sanitized_title}-{timestamp}\n   752→    Or with objective: P{issue_number}-O{objective_id}-{sanitized_title}-{timestamp}\n   753→    Example: P123-fix-auth-bug-01-15-1430\n   754→    Example with objective: P123-O456-fix-auth-bug-01-15-1430\n   755→\n   756→    The branch name is constructed as:\n   757→    1. P prefix + issue number + hyphen\n   758→    2. If objective_id provided: O prefix + objective_id + hyphen\n   759→    3. Sanitized title (lowercased, special chars replaced)\n   760→    4. Truncated to 31 chars total (before timestamp)\n   761→    5. Timestamp suffix appended (format: -MM-DD-HHMM)\n   762→\n   763→    Args:\n   764→        issue_number: GitHub issue number\n   765→        title: Issue title to sanitize\n   766→        timestamp: Timestamp for the suffix\n   767→        objective_id: Optional objective ID to encode in branch name\n   768→\n   769→    Returns:\n   770→        Branch name in format P{num}-{slug}-{timestamp} or P{num}-O{obj}-{slug}-{timestamp}\n   771→\n   772→    Examples:\n   773→        >>> from datetime import datetime\n   774→        >>> generate_issue_branch_name(\n   775→        ...     123, \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=None\n   776→        ... )\n   777→        \"P123-fix-auth-bug-01-15-1430\"\n   778→        >>> generate_issue_branch_name(\n   779→        ...     123, \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=456\n   780→        ... )\n   781→        \"P123-O456-fix-auth-bug-01-15-1430\"\n   782→    \"\"\"\n   783→    prefix = f\"P{issue_number}-\"\n   784→    if objective_id is not None:\n   785→        prefix += f\"O{objective_id}-\"\n   786→    sanitized_title = sanitize_worktree_name(title)\n   787→    base_branch_name = (prefix + sanitized_title)[:31].rstrip(\"-\")\n   788→    timestamp_suffix = format_branch_timestamp_suffix(timestamp)\n   789→    return base_branch_name + timestamp_suffix\n   790→\n   791→\n   792→def generate_draft_pr_branch_name(\n   793→    title: str,\n   794→    timestamp: datetime,\n   795→    *,\n   796→    objective_id: int | None,\n   797→) -> str:\n   798→    \"\"\"Generate branch name for draft-PR-backed plans.\n   799→\n   800→    Format: planned/{sanitized_title}-{timestamp}\n   801→    Or with objective: planned/O{objective_id}-{sanitized_title}-{timestamp}\n   802→    Example: planned/fix-auth-bug-01-15-1430\n   803→    Example with objective: planned/O456-fix-auth-bug-01-15-1430\n   804→\n   805→    No P{issue} prefix since the PR number isn't known until after creation.\n   806→\n   807→    Args:\n   808→        title: Plan title to sanitize\n   809→        timestamp: Timestamp for the suffix\n   810→        objective_id: Optional objective ID to encode in branch name\n   811→\n   812→    Returns:\n   813→        Branch name in format planned/{slug}-{timestamp}\n   814→\n   815→    Examples:\n   816→        >>> from datetime import datetime\n   817→        >>> generate_draft_pr_branch_name(\n   818→        ...     \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=None\n   819→        ... )\n   820→        \"planned/fix-auth-bug-01-15-1430\"\n   821→        >>> generate_draft_pr_branch_name(\n   822→        ...     \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=456\n   823→        ... )\n   824→        \"planned/O456-fix-auth-bug-01-15-1430\"\n   825→    \"\"\"\n   826→    prefix = \"planned/\"\n   827→    if objective_id is not None:\n   828→        prefix += f\"O{objective_id}-\"\n   829→    sanitized_title = sanitize_worktree_name(title)\n   830→    base_branch_name = (prefix + sanitized_title)[:31].rstrip(\"-\")\n   831→    timestamp_suffix = format_branch_timestamp_suffix(timestamp)\n   832→    return base_branch_name + timestamp_suffix\n   833→\n   834→\n   835→def derive_branch_name_from_title(title: str) -> str:\n   836→    \"\"\"Derive branch name from issue/plan title.\n   837→\n   838→    This function matches the logic used by the erk-impl workflow\n   839→    to ensure CLI and workflow produce identical branch names.\n   840→\n   841→    Transforms:\n   842→    - Lowercase\n   843→    - Replace non-alphanumeric (except hyphen) with hyphen\n   844→    - Collapse consecutive hyphens\n   845→    - Strip leading/trailing hyphens\n   846→    - Truncate to 30 chars\n   847→    - Strip trailing hyphen after truncation\n   848→\n   849→    Args:\n   850→        title: Issue or plan title\n   851→\n   852→    Returns:\n   853→        Branch name (max 30 chars, kebab-case)\n   854→\n   855→    Examples:\n   856→        >>> derive_branch_name_from_title(\"My Feature\")\n   857→        \"my-feature\"\n   858→        >>> derive_branch_name_from_title(\"Fix Bug #123!\")\n   859→        \"fix-bug-123\"\n   860→        >>> derive_branch_name_from_title(\"A\" * 40)\n   861→        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 30 chars (one less than sanitize_branch_component)\n   862→    \"\"\"\n   863→    # Convert to lowercase\n   864→    branch_name = title.lower()\n   865→    # Replace non-alphanumeric (except hyphen) with hyphen\n   866→    branch_name = re.sub(r\"[^a-z0-9-]\", \"-\", branch_name)\n   867→    # Collapse consecutive hyphens\n   868→    branch_name = re.sub(r\"-+\", \"-\", branch_name)\n   869→    # Strip leading/trailing hyphens\n   870→    branch_name = branch_name.strip(\"-\")\n   871→\n   872→    # Truncate to 30 chars (matches workflow logic)\n   873→    branch_name = branch_name[:30]\n   874→\n   875→    # Strip trailing hyphen after truncation\n   876→    branch_name = branch_name.rstrip(\"-\")\n   877→\n   878→    return branch_name\n   879→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"ffe89728-0a98-4ace-8193-072bf3be89ee","timestamp":"2026-02-22T14:37:30.226Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/naming.py","content":"\"\"\"Naming utilities for filenames and worktree names.\n\nThis module provides pure utility functions for transforming titles and names\ninto sanitized, filesystem-safe identifiers. All functions are pure (no I/O)\nand follow LBYL patterns.\n\nFunctions that require git operations accept a git_ops parameter via dependency\ninjection to maintain separation from I/O concerns.\n\"\"\"\n\nimport re\nimport unicodedata\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom pathlib import Path\n\n_SAFE_COMPONENT_RE = re.compile(r\"[^A-Za-z0-9_/-]+\")\n\n# Date suffix format for plan-derived worktree names: -YY-MM-DD-HHMM\nWORKTREE_DATE_SUFFIX_FORMAT = \"%y-%m-%d-%H%M\"\n\n# Branch timestamp suffix format: -MM-DD-HHMM (appended after truncation)\nBRANCH_TIMESTAMP_SUFFIX_FORMAT = \"%m-%d-%H%M\"\n\n# Regex pattern to detect existing timestamp suffix (MM-DD-HHMM)\n_TIMESTAMP_SUFFIX_PATTERN = re.compile(r\"-\\d{2}-\\d{2}-\\d{4}$\")\n\n\ndef has_timestamp_suffix(name: str) -> bool:\n    \"\"\"Check if a name already ends with a timestamp suffix (-MM-DD-HHMM).\n\n    Args:\n        name: Branch or worktree name to check\n\n    Returns:\n        True if name ends with timestamp suffix pattern, False otherwise\n\n    Examples:\n        >>> has_timestamp_suffix(\"42-feature-01-15-1430\")\n        True\n        >>> has_timestamp_suffix(\"42-feature\")\n        False\n        >>> has_timestamp_suffix(\"42-feature-branch\")\n        False\n    \"\"\"\n    return _TIMESTAMP_SUFFIX_PATTERN.search(name) is not None\n\n\ndef format_branch_timestamp_suffix(dt: datetime) -> str:\n    \"\"\"Format a datetime as a branch timestamp suffix.\n\n    Returns a suffix in the format -MM-DD-HHMM to be appended to branch names.\n\n    Args:\n        dt: Datetime to format\n\n    Returns:\n        Formatted suffix string (e.g., \"-01-15-1430\")\n\n    Examples:\n        >>> from datetime import datetime\n        >>> format_branch_timestamp_suffix(datetime(2024, 1, 15, 14, 30))\n        \"-01-15-1430\"\n        >>> format_branch_timestamp_suffix(datetime(2024, 12, 31, 23, 59))\n        \"-12-31-2359\"\n    \"\"\"\n    return f\"-{dt.strftime(BRANCH_TIMESTAMP_SUFFIX_FORMAT)}\"\n\n\n_OBJECTIVE_SLUG_PATTERN = re.compile(r\"^[a-z][a-z0-9]*(-[a-z0-9]+)*$\")\n\n# Plan title constraints\n_PLAN_TITLE_MIN_LENGTH = 5\n_PLAN_TITLE_MAX_LENGTH = 100\n\n\n@dataclass(frozen=True)\nclass ValidPlanTitle:\n    \"\"\"Validation success for a plan title.\n\n    Attributes:\n        title: The validated title value.\n    \"\"\"\n\n    title: str\n\n\n@dataclass(frozen=True)\nclass InvalidPlanTitle:\n    \"\"\"Validation failure for a plan title.\n\n    Attributes:\n        raw_title: The original title value that failed validation.\n        reason: A short description of why validation failed.\n    \"\"\"\n\n    raw_title: str\n    reason: str\n\n    @property\n    def error_type(self) -> str:\n        return \"invalid-plan-title\"\n\n    @property\n    def message(self) -> str:\n        \"\"\"Full error message with rules, actual value, and examples.\n\n        Designed so an agent receiving this message can self-correct.\n        \"\"\"\n        return (\n            f\"Invalid plan title: {self.reason}\\n\"\n            f\"  Actual value: {self.raw_title!r}\\n\"\n            f\"  Rules:\\n\"\n            f\"    - {_PLAN_TITLE_MIN_LENGTH}-{_PLAN_TITLE_MAX_LENGTH} characters\\n\"\n            f\"    - Must contain at least one alphabetic character\\n\"\n            f\"    - Must retain meaningful content after sanitization\\n\"\n            f\"      (emojis, special characters, and accents are stripped)\\n\"\n            f\"  Valid examples: Add User Authentication,\"\n            f\" Refactor Gateway Layer\\n\"\n            f\"  Invalid examples: \\U0001f680\\U0001f389, 123, #!@, Plan\"\n        )\n\n\ndef validate_plan_title(title: str) -> ValidPlanTitle | InvalidPlanTitle:\n    \"\"\"Validate a plan title against minimum content requirements.\n\n    This is an agent-facing validation gate. It ensures plan titles have enough\n    meaningful content before they are used to generate filenames, branch names,\n    or issue titles. Human-facing paths (like generate_filename_from_title) can\n    still transform arbitrary input silently.\n\n    Returns ValidPlanTitle on success, or InvalidPlanTitle describing the failure.\n\n    Args:\n        title: The plan title string to validate.\n\n    Returns:\n        ValidPlanTitle if valid, InvalidPlanTitle if invalid.\n\n    Examples:\n        >>> validate_plan_title(\"Add User Authentication\")\n        ValidPlanTitle(title='Add User Authentication')\n        >>> validate_plan_title(\"\")\n        InvalidPlanTitle(raw_title='', reason='...')\n        >>> validate_plan_title(\"🚀🎉\")\n        InvalidPlanTitle(raw_title='🚀🎉', reason='...')\n    \"\"\"\n    stripped = title.strip()\n\n    if not stripped:\n        return InvalidPlanTitle(raw_title=title, reason=\"Title is empty or whitespace-only\")\n\n    if len(stripped) < _PLAN_TITLE_MIN_LENGTH:\n        return InvalidPlanTitle(\n            raw_title=title,\n            reason=f\"Too short ({len(stripped)} characters, minimum {_PLAN_TITLE_MIN_LENGTH})\",\n        )\n\n    if len(stripped) > _PLAN_TITLE_MAX_LENGTH:\n        return InvalidPlanTitle(\n            raw_title=title,\n            reason=f\"Too long ({len(stripped)} characters, maximum {_PLAN_TITLE_MAX_LENGTH})\",\n        )\n\n    if not any(c.isalpha() for c in stripped):\n        return InvalidPlanTitle(\n            raw_title=title,\n            reason=\"Must contain at least one alphabetic character\",\n        )\n\n    # Check that sanitization retains meaningful content.\n    # generate_filename_from_title strips emojis, accents, and special chars.\n    # If the result is \"plan.md\" (the fallback), the title has no usable content.\n    filename = generate_filename_from_title(stripped)\n    if filename == \"plan.md\":\n        return InvalidPlanTitle(\n            raw_title=title,\n            reason=\"No usable content after sanitization (only emojis or special characters)\",\n        )\n\n    return ValidPlanTitle(title=stripped)\n\n\n@dataclass(frozen=True)\nclass ValidObjectiveSlug:\n    \"\"\"Validation success for an objective slug.\n\n    Attributes:\n        slug: The validated slug value.\n    \"\"\"\n\n    slug: str\n\n\n@dataclass(frozen=True)\nclass InvalidObjectiveSlug:\n    \"\"\"Validation failure for an objective slug.\n\n    Attributes:\n        raw_slug: The original slug value that failed validation.\n        reason: A short description of why validation failed.\n    \"\"\"\n\n    raw_slug: str\n    reason: str\n\n    @property\n    def message(self) -> str:\n        \"\"\"Full error message with pattern, rules, actual value, and examples.\n\n        Designed so an agent receiving this message can self-correct.\n        \"\"\"\n        return (\n            f\"Invalid objective slug: {self.reason}\\n\"\n            f\"  Actual value: {self.raw_slug!r}\\n\"\n            f\"  Pattern: ^[a-z][a-z0-9]*(-[a-z0-9]+)*$\\n\"\n            f\"  Rules:\\n\"\n            f\"    - 3-40 characters\\n\"\n            f\"    - Lowercase letters and digits only\\n\"\n            f\"    - Must start with a letter\\n\"\n            f\"    - Hyphens allowed between words (no consecutive hyphens)\\n\"\n            f\"  Valid examples: build-auth-system, refactor-gateway, add-dark-mode\\n\"\n            f\"  Invalid examples: Build-Auth, 123-start, my--slug, ab\"\n        )\n\n\ndef validate_objective_slug(slug: str) -> ValidObjectiveSlug | InvalidObjectiveSlug:\n    \"\"\"Validate an objective slug against the required format.\n\n    Returns ValidObjectiveSlug on success, or InvalidObjectiveSlug describing the failure.\n\n    Args:\n        slug: The slug string to validate.\n\n    Returns:\n        ValidObjectiveSlug if valid, InvalidObjectiveSlug if invalid.\n\n    Examples:\n        >>> validate_objective_slug(\"build-auth-system\")  # valid\n        ValidObjectiveSlug(slug='build-auth-system')\n        >>> validate_objective_slug(\"AB\")  # invalid\n        InvalidObjectiveSlug(raw_slug='AB', reason='...')\n    \"\"\"\n    if len(slug) < 3:\n        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Too short (minimum 3 characters)\")\n    if len(slug) > 40:\n        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Too long (maximum 40 characters)\")\n    if _OBJECTIVE_SLUG_PATTERN.match(slug) is None:\n        return InvalidObjectiveSlug(raw_slug=slug, reason=\"Does not match required pattern\")\n    return ValidObjectiveSlug(slug=slug)\n\n\ndef sanitize_worktree_name(name: str) -> str:\n    \"\"\"Sanitize a worktree name for use as a directory name.\n\n    - If name already has timestamp suffix (-MM-DD-HHMM), returns as-is (idempotent)\n    - Lowercases input\n    - Replaces underscores with hyphens\n    - Replaces characters outside `[A-Za-z0-9-]` with `-`\n    - Collapses consecutive `-`\n    - Strips leading/trailing `-`\n    - Truncates to 31 characters maximum (matches branch component sanitization)\n    Returns `\"work\"` if the result is empty.\n\n    The 31-character limit ensures worktree names match their corresponding branch\n    names, maintaining consistency across the worktree/branch model.\n\n    Args:\n        name: Arbitrary string to sanitize\n\n    Returns:\n        Sanitized worktree name (max 31 chars, unless timestamp already present)\n\n    Examples:\n        >>> sanitize_worktree_name(\"My_Feature\")\n        \"my-feature\"\n        >>> sanitize_worktree_name(\"a\" * 40)\n        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 31 chars\n        >>> sanitize_worktree_name(\"42-feature-01-15-1430\")\n        \"42-feature-01-15-1430\"  # timestamp preserved (idempotent)\n    \"\"\"\n    # If name already has a timestamp suffix, return as-is (idempotent)\n    if has_timestamp_suffix(name):\n        return name\n\n    lowered = name.strip().lower()\n    # Replace underscores with hyphens\n    replaced_underscores = lowered.replace(\"_\", \"-\")\n    # Replace unsafe characters with hyphens\n    replaced = re.sub(r\"[^a-z0-9-]+\", \"-\", replaced_underscores)\n    # Collapse consecutive hyphens\n    collapsed = re.sub(r\"-+\", \"-\", replaced)\n    # Strip leading/trailing hyphens\n    trimmed = collapsed.strip(\"-\")\n    result = trimmed or \"work\"\n\n    # Truncate to 31 characters and strip trailing hyphens\n    if len(result) > 31:\n        result = result[:31].rstrip(\"-\")\n\n    return result\n\n\ndef sanitize_branch_component(name: str) -> str:\n    \"\"\"Return a sanitized, predictable branch component from an arbitrary name.\n\n    - Lowercases input\n    - Replaces characters outside `[A-Za-z0-9_/-]` with `-`\n    - Collapses consecutive `-`\n    - Strips leading/trailing `-` and `/`\n    - Truncates to 31 characters maximum (matches worktree behavior)\n    Returns `\"work\"` if the result is empty.\n\n    Args:\n        name: Arbitrary string to sanitize\n\n    Returns:\n        Sanitized branch component name (max 31 chars)\n\n    Examples:\n        >>> sanitize_branch_component(\"My Feature!\")\n        \"my-feature\"\n        >>> sanitize_branch_component(\"fix/bug-123\")\n        \"fix/bug-123\"\n        >>> sanitize_branch_component(\"\")\n        \"work\"\n        >>> sanitize_branch_component(\"a\" * 40)\n        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 31 chars\n    \"\"\"\n    lowered = name.strip().lower()\n    replaced = _SAFE_COMPONENT_RE.sub(\"-\", lowered)\n    collapsed = re.sub(r\"-+\", \"-\", replaced)\n    trimmed = collapsed.strip(\"-/\")\n    result = trimmed or \"work\"\n\n    # Truncate to 31 characters and strip trailing hyphens (matching worktree behavior)\n    if len(result) > 31:\n        result = result[:31].rstrip(\"-\")\n\n    return result\n\n\ndef generate_filename_from_title(title: str) -> str:\n    \"\"\"Convert title to kebab-case filename with -plan.md suffix.\n\n    Comprehensive transformation:\n    1. Lowercase\n    2. Replace spaces with hyphens\n    3. Unicode normalization (NFD)\n    4. Remove emojis and non-alphanumeric characters (except hyphens)\n    5. Collapse consecutive hyphens\n    6. Strip leading/trailing hyphens\n    7. Validate at least one alphanumeric character remains\n    8. Append \"-plan.md\"\n\n    Returns \"plan.md\" if title is empty after cleanup.\n\n    Args:\n        title: Plan title to convert\n\n    Returns:\n        Sanitized filename ending with -plan.md\n\n    Example:\n        >>> generate_filename_from_title(\"User Auth Feature\")\n        'user-auth-feature-plan.md'\n\n        >>> generate_filename_from_title(\"Fix: Bug #123\")\n        'fix-bug-123-plan.md'\n\n        >>> generate_filename_from_title(\"🚀 Feature Launch 🎉\")\n        'feature-launch-plan.md'\n\n        >>> generate_filename_from_title(\"café\")\n        'cafe-plan.md'\n    \"\"\"\n    # Step 1: Lowercase and strip whitespace\n    lowered = title.strip().lower()\n\n    # Step 2: Unicode normalization (NFD form for decomposition)\n    # Decompose combined characters (é → e + ´)\n    normalized = unicodedata.normalize(\"NFD\", lowered)\n\n    # Step 3: Remove emojis and non-ASCII characters, convert to ASCII\n    # Keep only ASCII alphanumeric, spaces, and hyphens\n    cleaned = \"\"\n    for char in normalized:\n        # Keep ASCII alphanumeric, spaces, and hyphens\n        if ord(char) < 128 and (char.isalnum() or char in (\" \", \"-\")):\n            cleaned += char\n        # Skip combining marks (accents) and emoji\n        # Skip non-ASCII characters (CJK, emoji, special symbols)\n\n    # Step 4: Replace spaces with hyphens\n    replaced = cleaned.replace(\" \", \"-\")\n\n    # Step 5: Collapse consecutive hyphens\n    collapsed = re.sub(r\"-+\", \"-\", replaced)\n\n    # Step 6: Strip leading/trailing hyphens\n    trimmed = collapsed.strip(\"-\")\n\n    # Step 7: Validate at least one alphanumeric character\n    if not trimmed or not any(c.isalnum() for c in trimmed):\n        return \"plan.md\"\n\n    return f\"{trimmed}-plan.md\"\n\n\ndef strip_plan_from_filename(filename: str) -> str:\n    \"\"\"Remove 'plan' or 'implementation plan' from a filename stem intelligently.\n\n    Handles case-insensitive matching and common separators (-, _, space).\n    If removal would leave empty string, returns original unchanged.\n\n    Args:\n        filename: Filename stem (without extension) to process\n\n    Returns:\n        Filename with plan-related words removed, or original if would be empty\n\n    Examples:\n        >>> strip_plan_from_filename(\"devclikit-extraction-plan\")\n        \"devclikit-extraction\"\n        >>> strip_plan_from_filename(\"my-feature-plan\")\n        \"my-feature\"\n        >>> strip_plan_from_filename(\"implementation-plan-for-auth\")\n        \"for-auth\"\n        >>> strip_plan_from_filename(\"feature_implementation_plan\")\n        \"feature\"\n        >>> strip_plan_from_filename(\"plan\")\n        \"plan\"  # preserved - would be empty\n    \"\"\"\n    original_trimmed = filename.strip(\"-_ \\t\\n\\r\")\n    original_is_plan = original_trimmed.casefold() == \"plan\" if original_trimmed else False\n\n    # First, handle \"implementation plan\" with various separators\n    # Pattern matches \"implementation\" + separator + \"plan\" as complete words\n    impl_pattern = r\"(^|[-_\\s])(implementation)([-_\\s])(plan)([-_\\s]|$)\"\n\n    def replace_impl_plan(match: re.Match[str]) -> str:\n        prefix = match.group(1)\n        implementation_word = match.group(2)  # Preserves original case\n        suffix = match.group(5)\n\n        if suffix == \"\" and prefix:\n            prefix_start = match.start(1)\n            preceding_segment = filename[:prefix_start]\n            trimmed_segment = preceding_segment.strip(\"-_ \\t\\n\\r\")\n            if trimmed_segment:\n                preceding_tokens = re.split(r\"[-_\\s]+\", trimmed_segment)\n                if preceding_tokens:\n                    preceding_token = preceding_tokens[-1]\n                    if preceding_token.casefold() == \"plan\":\n                        return f\"{prefix}{implementation_word}\"\n\n        # If entire string is \"implementation-plan\", keep just \"implementation\"\n        if not prefix and not suffix:\n            return implementation_word\n\n        # If in the middle, preserve one separator\n        if prefix and suffix:\n            return prefix if prefix.strip() else suffix\n\n        # At start or end: remove it and the adjacent separator\n        return \"\"\n\n    cleaned = re.sub(impl_pattern, replace_impl_plan, filename, flags=re.IGNORECASE)\n\n    # Then handle standalone \"plan\" as a complete word\n    plan_pattern = r\"(^|[-_\\s])(plan)([-_\\s]|$)\"\n\n    def replace_plan(match: re.Match[str]) -> str:\n        prefix = match.group(1)\n        suffix = match.group(3)\n\n        # If both prefix and suffix are empty (entire string is \"plan\"), keep it\n        if not prefix and not suffix:\n            return \"plan\"\n\n        # If plan is in the middle, preserve one separator\n        if prefix and suffix:\n            # Use the prefix separator if available, otherwise use suffix\n            return prefix if prefix.strip() else suffix\n\n        # Plan at start or end: remove it and the adjacent separator\n        return \"\"\n\n    cleaned = re.sub(plan_pattern, replace_plan, cleaned, flags=re.IGNORECASE)\n\n    def clean_separators(text: str) -> str:\n        stripped = text.strip(\"-_ \\t\\n\\r\")\n        stripped = re.sub(r\"--+\", \"-\", stripped)\n        stripped = re.sub(r\"__+\", \"_\", stripped)\n        stripped = re.sub(r\"\\s+\", \" \", stripped)\n        return stripped\n\n    cleaned = clean_separators(cleaned)\n\n    plan_only_cleaned = clean_separators(\n        re.sub(plan_pattern, replace_plan, filename, flags=re.IGNORECASE)\n    )\n\n    if (\n        cleaned.casefold() == \"plan\"\n        and plan_only_cleaned\n        and plan_only_cleaned.casefold() != \"plan\"\n    ):\n        cleaned = plan_only_cleaned\n\n    # If stripping left us with nothing or just \"plan\", preserve original\n    if not cleaned or (cleaned.casefold() == \"plan\" and original_is_plan):\n        return filename\n\n    return cleaned\n\n\ndef extract_trailing_number(name: str) -> tuple[str, int | None]:\n    r\"\"\"Extract trailing number from a name.\n\n    Detects trailing numbers in names using regex pattern `^(.+?)-(\\d+)$`.\n    Returns tuple of (base_name, number) or (name, None).\n\n    Args:\n        name: Name to parse\n\n    Returns:\n        Tuple of (base_name, number) if trailing number found, else (name, None)\n\n    Examples:\n        >>> extract_trailing_number(\"my-feature\")\n        (\"my-feature\", None)\n        >>> extract_trailing_number(\"my-feature-2\")\n        (\"my-feature\", 2)\n        >>> extract_trailing_number(\"fix-42\")\n        (\"fix\", 42)\n    \"\"\"\n    match = re.match(r\"^(.+?)-(\\d+)$\", name)\n    if match:\n        base_name = match.group(1)\n        number = int(match.group(2))\n        return (base_name, number)\n    return (name, None)\n\n\ndef extract_leading_issue_number(branch_name: str) -> int | None:\n    \"\"\"Extract leading issue number from a branch name.\n\n    Branch names follow the pattern: P{issue_number}-{slug}-{timestamp}\n    Examples: \"P2382-convert-erk-create-raw-ext-12-05-2359\"\n\n    Also supports legacy format without \"P\" prefix for backwards compatibility.\n\n    Args:\n        branch_name: Branch name to parse\n\n    Returns:\n        Issue number if branch starts with optional \"P\" followed by digits and hyphen, else None\n\n    Examples:\n        >>> extract_leading_issue_number(\"P2382-convert-erk-create-raw-ext-12-05-2359\")\n        2382\n        >>> extract_leading_issue_number(\"P42-fix-bug\")\n        42\n        >>> extract_leading_issue_number(\"2382-convert-erk-create-raw-ext-12-05-2359\")\n        2382\n        >>> extract_leading_issue_number(\"42-fix-bug\")\n        42\n        >>> extract_leading_issue_number(\"feature-branch\")\n        None\n        >>> extract_leading_issue_number(\"master\")\n        None\n    \"\"\"\n    match = re.match(r\"^[Pp]?(\\d+)-\", branch_name)\n    if match:\n        return int(match.group(1))\n    return None\n\n\ndef extract_objective_number(branch_name: str) -> int | None:\n    \"\"\"Extract objective number from branch name.\n\n    Supports branch naming patterns:\n\n    - Issue-based: ``P{plan}-O{objective}-{slug}-{timestamp}``\n    - Draft-PR (current): ``planned/O{objective}-{slug}-{timestamp}``\n    - Draft-PR (legacy): ``plan/O{objective}-{slug}-{timestamp}``\n\n    Also supports lowercase \"o\" prefix for case-insensitive matching.\n\n    Args:\n        branch_name: Branch name to parse\n\n    Returns:\n        Objective number if branch contains O{number} after the prefix, else None\n\n    Examples:\n        >>> extract_objective_number(\"P123-O456-fix-auth-bug-01-15-1430\")\n        456\n        >>> extract_objective_number(\"P123-o456-fix-bug\")\n        456\n        >>> extract_objective_number(\"planned/O456-fix-auth-01-15-1430\")\n        456\n        >>> extract_objective_number(\"plan/O456-fix-auth-01-15-1430\")\n        456\n        >>> extract_objective_number(\"P123-fix-auth-bug-01-15-1430\")\n        None\n        >>> extract_objective_number(\"feature-branch\")\n        None\n    \"\"\"\n    match = re.match(r\"^(?:[Pp]?\\d+-|plan(?:ned)?/)[Oo](\\d+)-\", branch_name)\n    if match:\n        return int(match.group(1))\n    return None\n\n\ndef extract_plan_review_issue_number(branch_name: str) -> int | None:\n    \"\"\"Extract issue number from a plan review branch name.\n\n    Plan review branches follow the pattern: planned/review-{issue_number}-{timestamp}\n    Examples: \"planned/review-6214-01-15-1430\"\n\n    Args:\n        branch_name: Branch name to parse\n\n    Returns:\n        Issue number if branch matches planned/review-{number}- pattern, else None\n\n    Examples:\n        >>> extract_plan_review_issue_number(\"planned/review-6214-01-15-1430\")\n        6214\n        >>> extract_plan_review_issue_number(\"planned/review-42-01-28-0930\")\n        42\n        >>> extract_plan_review_issue_number(\"P2382-convert-erk-create-raw-ext\")\n        None\n        >>> extract_plan_review_issue_number(\"feature-branch\")\n        None\n    \"\"\"\n    match = re.match(r\"^planned/review-(\\d+)-\", branch_name)\n    if match:\n        return int(match.group(1))\n    return None\n\n\ndef ensure_unique_worktree_name_with_date(base_name: str, worktrees_dir: Path, git_ops) -> str:\n    \"\"\"Ensure unique worktree name with datetime suffix and smart versioning.\n\n    Adds datetime suffix in format -YY-MM-DD-HHMM to the base name.\n    If a worktree with that name exists, increments numeric suffix starting at 2 AFTER the datetime.\n    Uses LBYL pattern: checks via git_ops.worktree.path_exists() before operations.\n\n    This function is used for plan-derived worktrees where multiple worktrees may be\n    created from the same plan, requiring datetime-based disambiguation.\n\n    Args:\n        base_name: Sanitized worktree base name (without datetime suffix)\n        worktrees_dir: Directory containing worktrees\n        git_ops: Git operations interface for checking path existence\n\n    Returns:\n        Guaranteed unique worktree name with datetime suffix\n\n    Examples:\n        First time: \"my-feature\" → \"my-feature-25-11-08-1430\"\n        Duplicate: \"my-feature\" → \"my-feature-25-11-08-1430-2\"\n        Next minute: \"my-feature\" → \"my-feature-25-11-08-1431\"\n    \"\"\"\n    date_suffix = datetime.now().strftime(WORKTREE_DATE_SUFFIX_FORMAT)\n    candidate_name = f\"{base_name}-{date_suffix}\"\n\n    # Check if the base candidate exists\n    if not git_ops.worktree.path_exists(worktrees_dir / candidate_name):\n        return candidate_name\n\n    # Name exists, find next available number (append after date)\n    counter = 2\n    while True:\n        versioned_name = f\"{base_name}-{date_suffix}-{counter}\"\n        if not git_ops.worktree.path_exists(worktrees_dir / versioned_name):\n            return versioned_name\n        counter += 1\n\n\ndef ensure_simple_worktree_name(base_name: str, worktrees_dir: Path, git_ops) -> str:\n    \"\"\"Ensure simple worktree name without date suffix for manual checkouts.\n\n    Returns the simple name if no worktree exists at that path.\n    If a worktree already exists, returns the simple name (caller validates branch match).\n    Uses LBYL pattern: checks via git_ops.worktree.path_exists() before operations.\n\n    This function is used for manual checkout operations where predictable names are\n    desired (e.g., `erk co feature` → `feature` not `feature-25-11-08`).\n\n    Args:\n        base_name: Sanitized worktree base name\n        worktrees_dir: Directory containing worktrees\n        git_ops: Git operations interface for checking path existence\n\n    Returns:\n        Simple worktree name without date suffix\n\n    Examples:\n        First time: \"my-feature\" → \"my-feature\"\n        Exists: \"my-feature\" → \"my-feature\" (caller handles validation)\n    \"\"\"\n    candidate_name = base_name\n    # Always return simple name - collision handling happens in caller\n    return candidate_name\n\n\ndef ensure_unique_worktree_name(base_name: str, worktrees_dir: Path, git_ops) -> str:\n    \"\"\"Deprecated: Use ensure_unique_worktree_name_with_date for plan-derived worktrees.\n\n    This function is kept for backward compatibility but will be removed in the future.\n    New code should use:\n    - ensure_unique_worktree_name_with_date() for plan-derived worktrees\n    - ensure_simple_worktree_name() for manual checkout operations\n    \"\"\"\n    return ensure_unique_worktree_name_with_date(base_name, worktrees_dir, git_ops)\n\n\ndef default_branch_for_worktree(name: str) -> str:\n    \"\"\"Default branch name for a worktree with the given `name`.\n\n    Returns the sanitized name directly (without any prefix).\n\n    Args:\n        name: Worktree name\n\n    Returns:\n        Default branch name (sanitized)\n\n    Examples:\n        >>> default_branch_for_worktree(\"my-feature\")\n        \"my-feature\"\n        >>> default_branch_for_worktree(\"Fix Bug!\")\n        \"fix-bug\"\n    \"\"\"\n    return sanitize_branch_component(name)\n\n\ndef generate_issue_branch_name(\n    issue_number: int | str,\n    title: str,\n    timestamp: datetime,\n    *,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate branch name for issue-based worktree.\n\n    Format: P{issue_number}-{sanitized_title}-{timestamp}\n    Or with objective: P{issue_number}-O{objective_id}-{sanitized_title}-{timestamp}\n    Example: P123-fix-auth-bug-01-15-1430\n    Example with objective: P123-O456-fix-auth-bug-01-15-1430\n\n    The branch name is constructed as:\n    1. P prefix + issue number + hyphen\n    2. If objective_id provided: O prefix + objective_id + hyphen\n    3. Sanitized title (lowercased, special chars replaced)\n    4. Truncated to 31 chars total (before timestamp)\n    5. Timestamp suffix appended (format: -MM-DD-HHMM)\n\n    Args:\n        issue_number: GitHub issue number\n        title: Issue title to sanitize\n        timestamp: Timestamp for the suffix\n        objective_id: Optional objective ID to encode in branch name\n\n    Returns:\n        Branch name in format P{num}-{slug}-{timestamp} or P{num}-O{obj}-{slug}-{timestamp}\n\n    Examples:\n        >>> from datetime import datetime\n        >>> generate_issue_branch_name(\n        ...     123, \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=None\n        ... )\n        \"P123-fix-auth-bug-01-15-1430\"\n        >>> generate_issue_branch_name(\n        ...     123, \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=456\n        ... )\n        \"P123-O456-fix-auth-bug-01-15-1430\"\n    \"\"\"\n    prefix = f\"P{issue_number}-\"\n    if objective_id is not None:\n        prefix += f\"O{objective_id}-\"\n    sanitized_title = sanitize_worktree_name(title)\n    base_branch_name = (prefix + sanitized_title)[:31].rstrip(\"-\")\n    timestamp_suffix = format_branch_timestamp_suffix(timestamp)\n    return base_branch_name + timestamp_suffix\n\n\ndef generate_draft_pr_branch_name(\n    title: str,\n    timestamp: datetime,\n    *,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate branch name for draft-PR-backed plans.\n\n    Format: planned/{sanitized_title}-{timestamp}\n    Or with objective: planned/O{objective_id}-{sanitized_title}-{timestamp}\n    Example: planned/fix-auth-bug-01-15-1430\n    Example with objective: planned/O456-fix-auth-bug-01-15-1430\n\n    No P{issue} prefix since the PR number isn't known until after creation.\n\n    Args:\n        title: Plan title to sanitize\n        timestamp: Timestamp for the suffix\n        objective_id: Optional objective ID to encode in branch name\n\n    Returns:\n        Branch name in format planned/{slug}-{timestamp}\n\n    Examples:\n        >>> from datetime import datetime\n        >>> generate_draft_pr_branch_name(\n        ...     \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=None\n        ... )\n        \"planned/fix-auth-bug-01-15-1430\"\n        >>> generate_draft_pr_branch_name(\n        ...     \"Fix Auth Bug\", datetime(2024, 1, 15, 14, 30), objective_id=456\n        ... )\n        \"planned/O456-fix-auth-bug-01-15-1430\"\n    \"\"\"\n    prefix = \"planned/\"\n    if objective_id is not None:\n        prefix += f\"O{objective_id}-\"\n    sanitized_title = sanitize_worktree_name(title)\n    base_branch_name = (prefix + sanitized_title)[:31].rstrip(\"-\")\n    timestamp_suffix = format_branch_timestamp_suffix(timestamp)\n    return base_branch_name + timestamp_suffix\n\n\ndef derive_branch_name_from_title(title: str) -> str:\n    \"\"\"Derive branch name from issue/plan title.\n\n    This function matches the logic used by the erk-impl workflow\n    to ensure CLI and workflow produce identical branch names.\n\n    Transforms:\n    - Lowercase\n    - Replace non-alphanumeric (except hyphen) with hyphen\n    - Collapse consecutive hyphens\n    - Strip leading/trailing hyphens\n    - Truncate to 30 chars\n    - Strip trailing hyphen after truncation\n\n    Args:\n        title: Issue or plan title\n\n    Returns:\n        Branch name (max 30 chars, kebab-case)\n\n    Examples:\n        >>> derive_branch_name_from_title(\"My Feature\")\n        \"my-feature\"\n        >>> derive_branch_name_from_title(\"Fix Bug #123!\")\n        \"fix-bug-123\"\n        >>> derive_branch_name_from_title(\"A\" * 40)\n        \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"  # 30 chars (one less than sanitize_branch_component)\n    \"\"\"\n    # Convert to lowercase\n    branch_name = title.lower()\n    # Replace non-alphanumeric (except hyphen) with hyphen\n    branch_name = re.sub(r\"[^a-z0-9-]\", \"-\", branch_name)\n    # Collapse consecutive hyphens\n    branch_name = re.sub(r\"-+\", \"-\", branch_name)\n    # Strip leading/trailing hyphens\n    branch_name = branch_name.strip(\"-\")\n\n    # Truncate to 30 chars (matches workflow logic)\n    branch_name = branch_name[:30]\n\n    # Strip trailing hyphen after truncation\n    branch_name = branch_name.rstrip(\"-\")\n\n    return branch_name\n","numLines":879,"startLine":1,"totalLines":879}}}
{"parentUuid":"ffe89728-0a98-4ace-8193-072bf3be89ee","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01EF9m7QuEYXWJymikT4UYFV","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the FakePromptExecutor and PromptExecutor to understand the interface:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5683,"cache_creation_input_tokens":21541,"cache_read_input_tokens":38726,"cache_creation":{"ephemeral_5m_input_tokens":21541,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2qjyEsgaAGJLv5MVq","type":"assistant","uuid":"55ed16fd-26e2-4ed6-be68-67f3d1b65d83","timestamp":"2026-02-22T14:37:33.107Z"}
{"parentUuid":"55ed16fd-26e2-4ed6-be68-67f3d1b65d83","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01EF9m7QuEYXWJymikT4UYFV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0122N5Z3FHKbx71aejm3mJWr","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/core/fakes.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5683,"cache_creation_input_tokens":21541,"cache_read_input_tokens":38726,"cache_creation":{"ephemeral_5m_input_tokens":21541,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2qjyEsgaAGJLv5MVq","type":"assistant","uuid":"258dcb16-e4e4-4c8d-a473-2f773072a0b2","timestamp":"2026-02-22T14:37:34.178Z"}
{"parentUuid":"258dcb16-e4e4-4c8d-a473-2f773072a0b2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01EF9m7QuEYXWJymikT4UYFV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DsW3wAGPYrLkgVRfQ9b3P9","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/core/prompt_executor.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5683,"cache_creation_input_tokens":21541,"cache_read_input_tokens":38726,"cache_creation":{"ephemeral_5m_input_tokens":21541,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH2qjyEsgaAGJLv5MVq","type":"assistant","uuid":"ef4df1aa-8398-4cd2-bac6-affaec04a3de","timestamp":"2026-02-22T14:37:34.675Z"}
{"parentUuid":"ef4df1aa-8398-4cd2-bac6-affaec04a3de","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0122N5Z3FHKbx71aejm3mJWr","type":"tool_result","content":"     1→\"\"\"Fake implementations for erk-specific ABCs.\n     2→\n     3→These fakes are used in tests and in contexts (like erk-kits) that\n     4→don't need the real erk implementations.\n     5→\"\"\"\n     6→\n     7→from collections.abc import Iterator\n     8→from dataclasses import dataclass, field\n     9→from pathlib import Path\n    10→from typing import NamedTuple\n    11→\n    12→from erk_shared.context.types import PermissionMode\n    13→from erk_shared.core.objective_list_service import ObjectiveListService\n    14→from erk_shared.core.plan_list_service import PlanListData, PlanListService\n    15→from erk_shared.core.prompt_executor import (\n    16→    ExecutorEvent,\n    17→    PromptExecutor,\n    18→    PromptResult,\n    19→)\n    20→from erk_shared.core.script_writer import ScriptResult, ScriptWriter\n    21→from erk_shared.gateway.codespace_registry.abc import CodespaceRegistry, RegisteredCodespace\n    22→from erk_shared.gateway.github.types import GitHubRepoLocation\n    23→\n    24→\n    25→class InteractiveCall(NamedTuple):\n    26→    \"\"\"Record of an execute_interactive call.\"\"\"\n    27→\n    28→    worktree_path: Path\n    29→    dangerous: bool\n    30→    command: str\n    31→    target_subpath: Path | None\n    32→    model: str | None\n    33→    permission_mode: PermissionMode\n    34→\n    35→\n    36→class PromptCall(NamedTuple):\n    37→    \"\"\"Record of an execute_prompt call.\"\"\"\n    38→\n    39→    prompt: str\n    40→    model: str\n    41→    tools: list[str] | None\n    42→    cwd: Path | None\n    43→    system_prompt: str | None\n    44→    dangerous: bool\n    45→\n    46→\n    47→class PassthroughCall(NamedTuple):\n    48→    \"\"\"Record of an execute_prompt_passthrough call.\"\"\"\n    49→\n    50→    prompt: str\n    51→    model: str\n    52→    tools: list[str] | None\n    53→    cwd: Path\n    54→    dangerous: bool\n    55→\n    56→\n    57→class FakePromptExecutor(PromptExecutor):\n    58→    \"\"\"Fake PromptExecutor for testing.\n    59→\n    60→    Attributes:\n    61→        is_available: Whether the executor should appear available\n    62→        interactive_calls: List of InteractiveCall records\n    63→        prompt_calls: List of PromptCall records\n    64→        passthrough_calls: List of PassthroughCall records\n    65→        prompt_results: Queue of PromptResult to return from execute_prompt\n    66→        streaming_events: Events to yield from execute_command_streaming\n    67→        passthrough_exit_code: Exit code to return from execute_prompt_passthrough\n    68→    \"\"\"\n    69→\n    70→    def __init__(\n    71→        self,\n    72→        *,\n    73→        is_available: bool = True,\n    74→        prompt_results: list[PromptResult] | None = None,\n    75→        streaming_events: list[ExecutorEvent] | None = None,\n    76→        passthrough_exit_code: int = 0,\n    77→    ) -> None:\n    78→        self.is_available_value = is_available\n    79→        self.interactive_calls: list[InteractiveCall] = []\n    80→        self.prompt_calls: list[PromptCall] = []\n    81→        self.passthrough_calls: list[PassthroughCall] = []\n    82→        self.prompt_results = list(prompt_results) if prompt_results else []\n    83→        self.streaming_events = list(streaming_events) if streaming_events else []\n    84→        self.passthrough_exit_code = passthrough_exit_code\n    85→        self._prompt_result_index = 0\n    86→\n    87→    def is_available(self) -> bool:\n    88→        return self.is_available_value\n    89→\n    90→    def execute_command_streaming(\n    91→        self,\n    92→        *,\n    93→        command: str,\n    94→        worktree_path: Path,\n    95→        dangerous: bool,\n    96→        verbose: bool = False,\n    97→        debug: bool = False,\n    98→        model: str | None = None,\n    99→        permission_mode: PermissionMode,\n   100→        allow_dangerous: bool = False,\n   101→    ) -> Iterator[ExecutorEvent]:\n   102→        yield from self.streaming_events\n   103→\n   104→    def execute_interactive(\n   105→        self,\n   106→        *,\n   107→        worktree_path: Path,\n   108→        dangerous: bool,\n   109→        command: str,\n   110→        target_subpath: Path | None,\n   111→        model: str | None = None,\n   112→        permission_mode: PermissionMode,\n   113→    ) -> None:\n   114→        self.interactive_calls.append(\n   115→            InteractiveCall(\n   116→                worktree_path=worktree_path,\n   117→                dangerous=dangerous,\n   118→                command=command,\n   119→                target_subpath=target_subpath,\n   120→                model=model,\n   121→                permission_mode=permission_mode,\n   122→            )\n   123→        )\n   124→\n   125→    def execute_prompt(\n   126→        self,\n   127→        prompt: str,\n   128→        *,\n   129→        model: str,\n   130→        tools: list[str] | None,\n   131→        cwd: Path | None,\n   132→        system_prompt: str | None,\n   133→        dangerous: bool,\n   134→    ) -> PromptResult:\n   135→        self.prompt_calls.append(\n   136→            PromptCall(\n   137→                prompt=prompt,\n   138→                model=model,\n   139→                tools=tools,\n   140→                cwd=cwd,\n   141→                system_prompt=system_prompt,\n   142→                dangerous=dangerous,\n   143→            )\n   144→        )\n   145→        if self._prompt_result_index < len(self.prompt_results):\n   146→            result = self.prompt_results[self._prompt_result_index]\n   147→            self._prompt_result_index += 1\n   148→            return result\n   149→        return PromptResult(success=True, output=\"\", error=None)\n   150→\n   151→    def execute_prompt_passthrough(\n   152→        self,\n   153→        prompt: str,\n   154→        *,\n   155→        model: str,\n   156→        tools: list[str] | None,\n   157→        cwd: Path,\n   158→        dangerous: bool,\n   159→    ) -> int:\n   160→        self.passthrough_calls.append(\n   161→            PassthroughCall(\n   162→                prompt=prompt,\n   163→                model=model,\n   164→                tools=tools,\n   165→                cwd=cwd,\n   166→                dangerous=dangerous,\n   167→            )\n   168→        )\n   169→        return self.passthrough_exit_code\n   170→\n   171→\n   172→class FakeScriptWriter(ScriptWriter):\n   173→    \"\"\"Fake ScriptWriter for testing.\n   174→\n   175→    Records script writes without touching filesystem.\n   176→    \"\"\"\n   177→\n   178→    def __init__(self) -> None:\n   179→        self.written_scripts: list[ScriptResult] = []\n   180→\n   181→    def write_activation_script(\n   182→        self,\n   183→        content: str,\n   184→        *,\n   185→        command_name: str,\n   186→        comment: str,\n   187→    ) -> ScriptResult:\n   188→        result = ScriptResult(\n   189→            path=Path(f\"/fake/scripts/{command_name}.sh\"),\n   190→            content=f\"# {comment}\\n{content}\",\n   191→        )\n   192→        self.written_scripts.append(result)\n   193→        return result\n   194→\n   195→    def write_worktree_script(\n   196→        self,\n   197→        content: str,\n   198→        *,\n   199→        worktree_path: Path,\n   200→        script_name: str,\n   201→        command_name: str,\n   202→        comment: str,\n   203→    ) -> ScriptResult:\n   204→        \"\"\"Write script to a worktree location (fake version).\n   205→\n   206→        Uses the real target path as sentinel for testing.\n   207→        \"\"\"\n   208→        script_path = worktree_path / \".erk\" / \"bin\" / f\"{script_name}.sh\"\n   209→        result = ScriptResult(\n   210→            path=script_path,\n   211→            content=f\"# {comment}\\n{content}\",\n   212→        )\n   213→        self.written_scripts.append(result)\n   214→        return result\n   215→\n   216→\n   217→@dataclass\n   218→class FakeCodespaceRegistry(CodespaceRegistry):\n   219→    \"\"\"Fake CodespaceRegistry for testing.\n   220→\n   221→    Stores codespaces in memory.\n   222→    \"\"\"\n   223→\n   224→    codespaces: dict[str, RegisteredCodespace] = field(default_factory=dict)\n   225→    default_name: str | None = None\n   226→\n   227→    def list_codespaces(self) -> list[RegisteredCodespace]:\n   228→        return list(self.codespaces.values())\n   229→\n   230→    def get(self, name: str) -> RegisteredCodespace | None:\n   231→        return self.codespaces.get(name)\n   232→\n   233→    def get_default(self) -> RegisteredCodespace | None:\n   234→        if self.default_name is None:\n   235→            return None\n   236→        return self.codespaces.get(self.default_name)\n   237→\n   238→    def get_default_name(self) -> str | None:\n   239→        return self.default_name\n   240→\n   241→    def set_default(self, name: str) -> None:\n   242→        if name not in self.codespaces:\n   243→            raise ValueError(f\"No codespace with name '{name}' exists\")\n   244→        self.default_name = name\n   245→\n   246→    def register(self, codespace: RegisteredCodespace) -> None:\n   247→        if codespace.name in self.codespaces:\n   248→            raise ValueError(f\"Codespace with name '{codespace.name}' already exists\")\n   249→        self.codespaces[codespace.name] = codespace\n   250→\n   251→    def unregister(self, name: str) -> None:\n   252→        if name not in self.codespaces:\n   253→            raise ValueError(f\"No codespace with name '{name}' exists\")\n   254→        del self.codespaces[name]\n   255→        if self.default_name == name:\n   256→            self.default_name = None\n   257→\n   258→\n   259→class FakePlanListService(PlanListService):\n   260→    \"\"\"Fake PlanListService for testing.\n   261→\n   262→    Returns pre-configured data.\n   263→    \"\"\"\n   264→\n   265→    def __init__(self, data: PlanListData | None = None) -> None:\n   266→        self._data = data or PlanListData(plans=[], pr_linkages={}, workflow_runs={})\n   267→\n   268→    def get_plan_list_data(\n   269→        self,\n   270→        *,\n   271→        location: GitHubRepoLocation,\n   272→        labels: list[str],\n   273→        state: str | None = None,\n   274→        limit: int | None = None,\n   275→        skip_workflow_runs: bool = False,\n   276→        creator: str | None = None,\n   277→    ) -> PlanListData:\n   278→        return self._data\n   279→\n   280→\n   281→class FakeObjectiveListService(ObjectiveListService):\n   282→    \"\"\"Fake ObjectiveListService for testing.\n   283→\n   284→    Returns pre-configured data.\n   285→    \"\"\"\n   286→\n   287→    def __init__(self, *, data: PlanListData | None) -> None:\n   288→        self._data = data or PlanListData(plans=[], pr_linkages={}, workflow_runs={})\n   289→\n   290→    def get_objective_list_data(\n   291→        self,\n   292→        *,\n   293→        location: GitHubRepoLocation,\n   294→        state: str | None = None,\n   295→        limit: int | None = None,\n   296→        skip_workflow_runs: bool = False,\n   297→        creator: str | None = None,\n   298→    ) -> PlanListData:\n   299→        return self._data\n   300→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c18d6c4c-e46d-4fd0-b479-e1ea6720c337","timestamp":"2026-02-22T14:37:34.694Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/core/fakes.py","content":"\"\"\"Fake implementations for erk-specific ABCs.\n\nThese fakes are used in tests and in contexts (like erk-kits) that\ndon't need the real erk implementations.\n\"\"\"\n\nfrom collections.abc import Iterator\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import NamedTuple\n\nfrom erk_shared.context.types import PermissionMode\nfrom erk_shared.core.objective_list_service import ObjectiveListService\nfrom erk_shared.core.plan_list_service import PlanListData, PlanListService\nfrom erk_shared.core.prompt_executor import (\n    ExecutorEvent,\n    PromptExecutor,\n    PromptResult,\n)\nfrom erk_shared.core.script_writer import ScriptResult, ScriptWriter\nfrom erk_shared.gateway.codespace_registry.abc import CodespaceRegistry, RegisteredCodespace\nfrom erk_shared.gateway.github.types import GitHubRepoLocation\n\n\nclass InteractiveCall(NamedTuple):\n    \"\"\"Record of an execute_interactive call.\"\"\"\n\n    worktree_path: Path\n    dangerous: bool\n    command: str\n    target_subpath: Path | None\n    model: str | None\n    permission_mode: PermissionMode\n\n\nclass PromptCall(NamedTuple):\n    \"\"\"Record of an execute_prompt call.\"\"\"\n\n    prompt: str\n    model: str\n    tools: list[str] | None\n    cwd: Path | None\n    system_prompt: str | None\n    dangerous: bool\n\n\nclass PassthroughCall(NamedTuple):\n    \"\"\"Record of an execute_prompt_passthrough call.\"\"\"\n\n    prompt: str\n    model: str\n    tools: list[str] | None\n    cwd: Path\n    dangerous: bool\n\n\nclass FakePromptExecutor(PromptExecutor):\n    \"\"\"Fake PromptExecutor for testing.\n\n    Attributes:\n        is_available: Whether the executor should appear available\n        interactive_calls: List of InteractiveCall records\n        prompt_calls: List of PromptCall records\n        passthrough_calls: List of PassthroughCall records\n        prompt_results: Queue of PromptResult to return from execute_prompt\n        streaming_events: Events to yield from execute_command_streaming\n        passthrough_exit_code: Exit code to return from execute_prompt_passthrough\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        is_available: bool = True,\n        prompt_results: list[PromptResult] | None = None,\n        streaming_events: list[ExecutorEvent] | None = None,\n        passthrough_exit_code: int = 0,\n    ) -> None:\n        self.is_available_value = is_available\n        self.interactive_calls: list[InteractiveCall] = []\n        self.prompt_calls: list[PromptCall] = []\n        self.passthrough_calls: list[PassthroughCall] = []\n        self.prompt_results = list(prompt_results) if prompt_results else []\n        self.streaming_events = list(streaming_events) if streaming_events else []\n        self.passthrough_exit_code = passthrough_exit_code\n        self._prompt_result_index = 0\n\n    def is_available(self) -> bool:\n        return self.is_available_value\n\n    def execute_command_streaming(\n        self,\n        *,\n        command: str,\n        worktree_path: Path,\n        dangerous: bool,\n        verbose: bool = False,\n        debug: bool = False,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n        allow_dangerous: bool = False,\n    ) -> Iterator[ExecutorEvent]:\n        yield from self.streaming_events\n\n    def execute_interactive(\n        self,\n        *,\n        worktree_path: Path,\n        dangerous: bool,\n        command: str,\n        target_subpath: Path | None,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n    ) -> None:\n        self.interactive_calls.append(\n            InteractiveCall(\n                worktree_path=worktree_path,\n                dangerous=dangerous,\n                command=command,\n                target_subpath=target_subpath,\n                model=model,\n                permission_mode=permission_mode,\n            )\n        )\n\n    def execute_prompt(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path | None,\n        system_prompt: str | None,\n        dangerous: bool,\n    ) -> PromptResult:\n        self.prompt_calls.append(\n            PromptCall(\n                prompt=prompt,\n                model=model,\n                tools=tools,\n                cwd=cwd,\n                system_prompt=system_prompt,\n                dangerous=dangerous,\n            )\n        )\n        if self._prompt_result_index < len(self.prompt_results):\n            result = self.prompt_results[self._prompt_result_index]\n            self._prompt_result_index += 1\n            return result\n        return PromptResult(success=True, output=\"\", error=None)\n\n    def execute_prompt_passthrough(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path,\n        dangerous: bool,\n    ) -> int:\n        self.passthrough_calls.append(\n            PassthroughCall(\n                prompt=prompt,\n                model=model,\n                tools=tools,\n                cwd=cwd,\n                dangerous=dangerous,\n            )\n        )\n        return self.passthrough_exit_code\n\n\nclass FakeScriptWriter(ScriptWriter):\n    \"\"\"Fake ScriptWriter for testing.\n\n    Records script writes without touching filesystem.\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.written_scripts: list[ScriptResult] = []\n\n    def write_activation_script(\n        self,\n        content: str,\n        *,\n        command_name: str,\n        comment: str,\n    ) -> ScriptResult:\n        result = ScriptResult(\n            path=Path(f\"/fake/scripts/{command_name}.sh\"),\n            content=f\"# {comment}\\n{content}\",\n        )\n        self.written_scripts.append(result)\n        return result\n\n    def write_worktree_script(\n        self,\n        content: str,\n        *,\n        worktree_path: Path,\n        script_name: str,\n        command_name: str,\n        comment: str,\n    ) -> ScriptResult:\n        \"\"\"Write script to a worktree location (fake version).\n\n        Uses the real target path as sentinel for testing.\n        \"\"\"\n        script_path = worktree_path / \".erk\" / \"bin\" / f\"{script_name}.sh\"\n        result = ScriptResult(\n            path=script_path,\n            content=f\"# {comment}\\n{content}\",\n        )\n        self.written_scripts.append(result)\n        return result\n\n\n@dataclass\nclass FakeCodespaceRegistry(CodespaceRegistry):\n    \"\"\"Fake CodespaceRegistry for testing.\n\n    Stores codespaces in memory.\n    \"\"\"\n\n    codespaces: dict[str, RegisteredCodespace] = field(default_factory=dict)\n    default_name: str | None = None\n\n    def list_codespaces(self) -> list[RegisteredCodespace]:\n        return list(self.codespaces.values())\n\n    def get(self, name: str) -> RegisteredCodespace | None:\n        return self.codespaces.get(name)\n\n    def get_default(self) -> RegisteredCodespace | None:\n        if self.default_name is None:\n            return None\n        return self.codespaces.get(self.default_name)\n\n    def get_default_name(self) -> str | None:\n        return self.default_name\n\n    def set_default(self, name: str) -> None:\n        if name not in self.codespaces:\n            raise ValueError(f\"No codespace with name '{name}' exists\")\n        self.default_name = name\n\n    def register(self, codespace: RegisteredCodespace) -> None:\n        if codespace.name in self.codespaces:\n            raise ValueError(f\"Codespace with name '{codespace.name}' already exists\")\n        self.codespaces[codespace.name] = codespace\n\n    def unregister(self, name: str) -> None:\n        if name not in self.codespaces:\n            raise ValueError(f\"No codespace with name '{name}' exists\")\n        del self.codespaces[name]\n        if self.default_name == name:\n            self.default_name = None\n\n\nclass FakePlanListService(PlanListService):\n    \"\"\"Fake PlanListService for testing.\n\n    Returns pre-configured data.\n    \"\"\"\n\n    def __init__(self, data: PlanListData | None = None) -> None:\n        self._data = data or PlanListData(plans=[], pr_linkages={}, workflow_runs={})\n\n    def get_plan_list_data(\n        self,\n        *,\n        location: GitHubRepoLocation,\n        labels: list[str],\n        state: str | None = None,\n        limit: int | None = None,\n        skip_workflow_runs: bool = False,\n        creator: str | None = None,\n    ) -> PlanListData:\n        return self._data\n\n\nclass FakeObjectiveListService(ObjectiveListService):\n    \"\"\"Fake ObjectiveListService for testing.\n\n    Returns pre-configured data.\n    \"\"\"\n\n    def __init__(self, *, data: PlanListData | None) -> None:\n        self._data = data or PlanListData(plans=[], pr_linkages={}, workflow_runs={})\n\n    def get_objective_list_data(\n        self,\n        *,\n        location: GitHubRepoLocation,\n        state: str | None = None,\n        limit: int | None = None,\n        skip_workflow_runs: bool = False,\n        creator: str | None = None,\n    ) -> PlanListData:\n        return self._data\n","numLines":300,"startLine":1,"totalLines":300}}}
{"parentUuid":"c18d6c4c-e46d-4fd0-b479-e1ea6720c337","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DsW3wAGPYrLkgVRfQ9b3P9","type":"tool_result","content":"     1→\"\"\"Claude CLI prompt execution implementation.\n     2→\n     3→This module provides the ClaudePromptExecutor implementation and re-exports\n     4→ABC and types from erk_shared.core.\n     5→\"\"\"\n     6→\n     7→from __future__ import annotations\n     8→\n     9→import json\n    10→import logging\n    11→import os\n    12→import shutil\n    13→import subprocess\n    14→import sys\n    15→import threading\n    16→from collections.abc import Iterator\n    17→from pathlib import Path\n    18→from typing import TYPE_CHECKING\n    19→\n    20→if TYPE_CHECKING:\n    21→    from erk_shared.context.types import PermissionMode\n    22→\n    23→from erk_shared.context.types import permission_mode_to_claude\n    24→from erk_shared.core.prompt_executor import (\n    25→    CommandResult,  # noqa: F401 - re-exported for erk.cli.output\n    26→    ErrorEvent,\n    27→    ExecutorEvent,\n    28→    IssueNumberEvent,\n    29→    NoOutputEvent,\n    30→    NoTurnsEvent,\n    31→    PrNumberEvent,\n    32→    ProcessErrorEvent,\n    33→    PromptExecutor,\n    34→    PromptResult,\n    35→    PrTitleEvent,\n    36→    PrUrlEvent,\n    37→    SpinnerUpdateEvent,\n    38→    TextEvent,\n    39→    ToolEvent,\n    40→)\n    41→from erk_shared.gateway.console.abc import Console\n    42→from erk_shared.gateway.console.real import InteractiveConsole\n    43→from erk_shared.subprocess_utils import build_claude_subprocess_env\n    44→\n    45→# Constants for process execution\n    46→PROCESS_TIMEOUT_SECONDS = 600  # 10 minutes\n    47→STDERR_JOIN_TIMEOUT = 5.0  # 5 seconds (increased from 1.0)\n    48→\n    49→logger = logging.getLogger(__name__)\n    50→\n    51→\n    52→def format_prompt_error(\n    53→    *,\n    54→    returncode: int,\n    55→    stderr: str,\n    56→    stdout: str,\n    57→) -> str:\n    58→    \"\"\"Format error message for failed prompt execution.\n    59→\n    60→    Constructs a structured error message from subprocess failure details.\n    61→\n    62→    Args:\n    63→        returncode: Process exit code\n    64→        stderr: Standard error output\n    65→        stdout: Standard output (truncated to 500 characters)\n    66→\n    67→    Returns:\n    68→        Formatted error string like \"Exit code 1 | stderr: ... | stdout: ...\"\n    69→    \"\"\"\n    70→    error_parts = [f\"Exit code {returncode}\"]\n    71→    if stderr and stderr.strip():\n    72→        error_parts.append(f\"stderr: {stderr.strip()}\")\n    73→    if stdout and stdout.strip():\n    74→        stdout_preview = stdout.strip()[:500]\n    75→        error_parts.append(f\"stdout: {stdout_preview}\")\n    76→    return \" | \".join(error_parts)\n    77→\n    78→\n    79→class ClaudePromptExecutor(PromptExecutor):\n    80→    \"\"\"Production implementation using subprocess and Claude CLI.\"\"\"\n    81→\n    82→    def __init__(self, console: Console | None) -> None:\n    83→        \"\"\"Initialize ClaudePromptExecutor with Console dependency.\n    84→\n    85→        Args:\n    86→            console: Console gateway for TTY detection.\n    87→                If None, creates an InteractiveConsole instance.\n    88→        \"\"\"\n    89→        self._console = console if console is not None else InteractiveConsole()\n    90→\n    91→    def is_available(self) -> bool:\n    92→        \"\"\"Check if Claude CLI is in PATH using shutil.which.\"\"\"\n    93→        return shutil.which(\"claude\") is not None\n    94→\n    95→    @staticmethod\n    96→    def _subprocess_env() -> dict[str, str]:\n    97→        \"\"\"Build environment for claude subprocess with nested session guard removed.\"\"\"\n    98→        return build_claude_subprocess_env()\n    99→\n   100→    def execute_command_streaming(\n   101→        self,\n   102→        *,\n   103→        command: str,\n   104→        worktree_path: Path,\n   105→        dangerous: bool,\n   106→        verbose: bool = False,\n   107→        debug: bool = False,\n   108→        model: str | None = None,\n   109→        permission_mode: PermissionMode,\n   110→        allow_dangerous: bool = False,\n   111→    ) -> Iterator[ExecutorEvent]:\n   112→        \"\"\"Execute Claude CLI command and yield typed events in real-time.\n   113→\n   114→        Implementation details:\n   115→        - Uses subprocess.Popen() for streaming stdout line-by-line\n   116→        - Passes --permission-mode with the provided mode, --output-format stream-json\n   117→        - Optionally passes --dangerously-skip-permissions when dangerous=True\n   118→        - Optionally passes --allow-dangerously-skip-permissions when allow_dangerous=True\n   119→        - Optionally passes --model when model is specified\n   120→        - In verbose mode: streams output to terminal (no parsing, no events yielded)\n   121→        - In filtered mode: parses stream-json and yields events in real-time\n   122→        - In debug mode: emits additional debug information to stderr\n   123→        \"\"\"\n   124→        # Map generic permission_mode to Claude-specific permission_mode\n   125→        claude_permission_mode = permission_mode_to_claude(permission_mode)\n   126→\n   127→        cmd_args = [\n   128→            \"claude\",\n   129→            \"--print\",\n   130→            \"--no-session-persistence\",\n   131→            \"--verbose\",\n   132→            \"--permission-mode\",\n   133→            claude_permission_mode,\n   134→            \"--output-format\",\n   135→            \"stream-json\",\n   136→        ]\n   137→        if dangerous:\n   138→            cmd_args.append(\"--dangerously-skip-permissions\")\n   139→        if allow_dangerous:\n   140→            cmd_args.append(\"--allow-dangerously-skip-permissions\")\n   141→        if model is not None:\n   142→            cmd_args.extend([\"--model\", model])\n   143→        cmd_args.append(command)\n   144→\n   145→        if verbose:\n   146→            # Verbose mode - stream to terminal, no parsing, no events\n   147→            result = subprocess.run(\n   148→                cmd_args, cwd=worktree_path, check=False, env=self._subprocess_env()\n   149→            )\n   150→\n   151→            if result.returncode != 0:\n   152→                error_msg = f\"Claude command {command} failed with exit code {result.returncode}\"\n   153→                yield ErrorEvent(message=error_msg)\n   154→            return\n   155→\n   156→        # Filtered mode - streaming with real-time parsing\n   157→        if debug:\n   158→            print(f\"[DEBUG executor] Starting Popen with args: {cmd_args}\", file=sys.stderr)\n   159→            print(f\"[DEBUG executor] cwd: {worktree_path}\", file=sys.stderr)\n   160→            sys.stderr.flush()\n   161→\n   162→        # Handle Popen errors (e.g., claude not found, permission denied)\n   163→        try:\n   164→            process = subprocess.Popen(\n   165→                cmd_args,\n   166→                cwd=worktree_path,\n   167→                stdout=subprocess.PIPE,\n   168→                stderr=subprocess.PIPE,\n   169→                text=True,\n   170→                bufsize=1,  # Line buffered\n   171→                env=self._subprocess_env(),\n   172→            )\n   173→        except OSError as e:\n   174→            yield ProcessErrorEvent(\n   175→                message=f\"Failed to start Claude CLI: {e}\\nCommand: {' '.join(cmd_args)}\"\n   176→            )\n   177→            return\n   178→\n   179→        if debug:\n   180→            print(f\"[DEBUG executor] Popen started, pid={process.pid}\", file=sys.stderr)\n   181→            sys.stderr.flush()\n   182→\n   183→        stderr_output: list[str] = []\n   184→\n   185→        # Capture stderr in background thread\n   186→        def capture_stderr() -> None:\n   187→            if process.stderr:\n   188→                for line in process.stderr:\n   189→                    stderr_output.append(line)\n   190→\n   191→        stderr_thread = threading.Thread(target=capture_stderr, daemon=True)\n   192→        stderr_thread.start()\n   193→\n   194→        # Process stdout line by line in real-time\n   195→        line_count = 0\n   196→        if debug:\n   197→            print(\"[DEBUG executor] Starting to read stdout...\", file=sys.stderr)\n   198→            sys.stderr.flush()\n   199→        if process.stdout:\n   200→            for line in process.stdout:\n   201→                line_count += 1\n   202→                if debug:\n   203→                    print(\n   204→                        f\"[DEBUG executor] Line #{line_count}: {line[:100]!r}...\", file=sys.stderr\n   205→                    )\n   206→                    sys.stderr.flush()\n   207→                if not line.strip():\n   208→                    continue\n   209→\n   210→                # Try to parse as JSON\n   211→                parsed = self._parse_stream_json_line(line, worktree_path, command)\n   212→                if parsed is None:\n   213→                    if debug:\n   214→                        print(\n   215→                            f\"[DEBUG executor] Line #{line_count} parsed to None\", file=sys.stderr\n   216→                        )\n   217→                        sys.stderr.flush()\n   218→                    continue\n   219→\n   220→                if debug:\n   221→                    print(f\"[DEBUG executor] Line #{line_count} parsed: {parsed}\", file=sys.stderr)\n   222→                    sys.stderr.flush()\n   223→\n   224→                # Yield text content and extract metadata from it\n   225→                text_content = parsed.get(\"text_content\")\n   226→                if text_content is not None and isinstance(text_content, str):\n   227→                    yield TextEvent(content=text_content)\n   228→\n   229→                    # Also try to extract PR metadata from text (simpler than nested JSON)\n   230→                    from erk.core.output_filter import extract_pr_metadata_from_text\n   231→\n   232→                    text_metadata = extract_pr_metadata_from_text(text_content)\n   233→                    text_pr_url = text_metadata.get(\"pr_url\")\n   234→                    if text_pr_url is not None:\n   235→                        yield PrUrlEvent(url=str(text_pr_url))\n   236→                    text_pr_number = text_metadata.get(\"pr_number\")\n   237→                    if text_pr_number is not None:\n   238→                        yield PrNumberEvent(number=int(text_pr_number))\n   239→                    text_pr_title = text_metadata.get(\"pr_title\")\n   240→                    if text_pr_title is not None:\n   241→                        yield PrTitleEvent(title=str(text_pr_title))\n   242→                    text_issue_number = text_metadata.get(\"issue_number\")\n   243→                    if text_issue_number is not None:\n   244→                        yield IssueNumberEvent(number=int(text_issue_number))\n   245→\n   246→                # Yield tool summaries\n   247→                tool_summary = parsed.get(\"tool_summary\")\n   248→                if tool_summary is not None and isinstance(tool_summary, str):\n   249→                    yield ToolEvent(summary=tool_summary)\n   250→\n   251→                # Yield spinner updates\n   252→                spinner_text = parsed.get(\"spinner_update\")\n   253→                if spinner_text is not None and isinstance(spinner_text, str):\n   254→                    yield SpinnerUpdateEvent(status=spinner_text)\n   255→\n   256→                # Yield PR URL\n   257→                pr_url_value = parsed.get(\"pr_url\")\n   258→                if pr_url_value is not None:\n   259→                    yield PrUrlEvent(url=str(pr_url_value))\n   260→\n   261→                # Yield PR number\n   262→                pr_number_value = parsed.get(\"pr_number\")\n   263→                if pr_number_value is not None:\n   264→                    yield PrNumberEvent(number=int(pr_number_value))\n   265→\n   266→                # Yield PR title\n   267→                pr_title_value = parsed.get(\"pr_title\")\n   268→                if pr_title_value is not None:\n   269→                    yield PrTitleEvent(title=str(pr_title_value))\n   270→\n   271→                # Yield issue number\n   272→                issue_number_value = parsed.get(\"issue_number\")\n   273→                if issue_number_value is not None:\n   274→                    yield IssueNumberEvent(number=int(issue_number_value))\n   275→\n   276→                # Detect zero-turn completions (hook blocking)\n   277→                num_turns = parsed.get(\"num_turns\")\n   278→                if num_turns is not None and num_turns == 0:\n   279→                    diag = f\"Claude command {command} completed without processing\"\n   280→                    diag += \"\\n  This usually means a hook blocked the command\"\n   281→                    diag += \"\\n  Run 'claude' directly to see hook error messages\"\n   282→                    diag += f\"\\n  Working directory: {worktree_path}\"\n   283→                    yield NoTurnsEvent(diagnostic=diag)\n   284→\n   285→        if debug:\n   286→            print(\n   287→                f\"[DEBUG executor] stdout reading complete, total lines: {line_count}\",\n   288→                file=sys.stderr,\n   289→            )\n   290→            sys.stderr.flush()\n   291→\n   292→        # Wait for process to complete with timeout\n   293→        try:\n   294→            returncode = process.wait(timeout=PROCESS_TIMEOUT_SECONDS)\n   295→        except subprocess.TimeoutExpired:\n   296→            process.kill()\n   297→            process.wait()\n   298→            timeout_minutes = PROCESS_TIMEOUT_SECONDS // 60\n   299→            yield ProcessErrorEvent(\n   300→                message=f\"Claude command {command} timed out after {timeout_minutes} minutes\"\n   301→            )\n   302→            return\n   303→\n   304→        # Wait for stderr thread to finish with increased timeout\n   305→        stderr_thread.join(timeout=STDERR_JOIN_TIMEOUT)\n   306→\n   307→        # Detect no output condition - yield before checking exit code\n   308→        if line_count == 0:\n   309→            diag = f\"Claude command {command} completed but produced no output\"\n   310→            diag += f\"\\n  Exit code: {returncode}\"\n   311→            diag += f\"\\n  Working directory: {worktree_path}\"\n   312→            if stderr_output:\n   313→                diag += \"\\n  Stderr:\\n\" + \"\".join(stderr_output)\n   314→            yield NoOutputEvent(diagnostic=diag)\n   315→\n   316→            if returncode != 0:\n   317→                yield ErrorEvent(message=f\"Exit code {returncode}\")\n   318→            return\n   319→\n   320→        # Enhanced error messages for non-zero exit codes\n   321→        if returncode != 0:\n   322→            error_msg = f\"Claude command {command} failed\"\n   323→            error_msg += f\"\\n  Exit code: {returncode}\"\n   324→            error_msg += f\"\\n  Lines processed: {line_count}\"\n   325→            if stderr_output:\n   326→                error_msg += \"\\n  Stderr:\\n\" + \"\".join(stderr_output).strip()\n   327→            yield ErrorEvent(message=error_msg)\n   328→\n   329→        # Debug summary\n   330→        if debug:\n   331→            print(\"[DEBUG executor] === Summary ===\", file=sys.stderr)\n   332→            print(f\"[DEBUG executor] Exit code: {returncode}\", file=sys.stderr)\n   333→            print(f\"[DEBUG executor] Lines: {line_count}\", file=sys.stderr)\n   334→            if stderr_output:\n   335→                print(f\"[DEBUG executor] Stderr: {''.join(stderr_output)}\", file=sys.stderr)\n   336→            sys.stderr.flush()\n   337→\n   338→    def _parse_stream_json_line(\n   339→        self, line: str, worktree_path: Path, command: str\n   340→    ) -> dict[str, str | int | bool | None] | None:\n   341→        \"\"\"Parse a single stream-json line and extract relevant information.\n   342→\n   343→        Args:\n   344→            line: JSON line from stream-json output\n   345→            worktree_path: Path to worktree for relativizing paths\n   346→            command: The slash command being executed\n   347→\n   348→        Returns:\n   349→            Dict with text_content, tool_summary, spinner_update, pr_url, pr_number,\n   350→            pr_title, and issue_number keys, or None if not JSON\n   351→        \"\"\"\n   352→        # Import here to avoid circular dependency\n   353→        from erk.core.output_filter import (\n   354→            determine_spinner_status,\n   355→            extract_pr_metadata,\n   356→            extract_text_content,\n   357→            summarize_tool_use,\n   358→        )\n   359→\n   360→        if not line.strip():\n   361→            return None\n   362→\n   363→        # Parse JSON safely - JSON parsing requires exception handling\n   364→        data: dict | None = None\n   365→        if line.strip():\n   366→            try:\n   367→                parsed = json.loads(line)\n   368→                if isinstance(parsed, dict):\n   369→                    data = parsed\n   370→            except json.JSONDecodeError:\n   371→                return None\n   372→\n   373→        if data is None:\n   374→            return None\n   375→\n   376→        result: dict[str, str | int | bool | None] = {\n   377→            \"text_content\": None,\n   378→            \"tool_summary\": None,\n   379→            \"spinner_update\": None,\n   380→            \"pr_url\": None,\n   381→            \"pr_number\": None,\n   382→            \"pr_title\": None,\n   383→            \"issue_number\": None,\n   384→            \"num_turns\": None,\n   385→            \"is_error\": None,\n   386→            \"result_text\": None,\n   387→        }\n   388→\n   389→        # stream-json format uses \"type\": \"assistant\" with nested \"message\" object\n   390→        # (not \"type\": \"assistant_message\" with content at top level)\n   391→        msg_type = data.get(\"type\")\n   392→        message = data.get(\"message\", {})\n   393→        if not isinstance(message, dict):\n   394→            message = {}\n   395→\n   396→        # Extract text from assistant messages\n   397→        if msg_type == \"assistant\":\n   398→            text = extract_text_content(message)\n   399→            if text:\n   400→                result[\"text_content\"] = text\n   401→\n   402→            # Extract tool summaries and spinner updates\n   403→            content = message.get(\"content\", [])\n   404→            if isinstance(content, list):\n   405→                for item in content:\n   406→                    if isinstance(item, dict) and item.get(\"type\") == \"tool_use\":\n   407→                        summary = summarize_tool_use(item, worktree_path)\n   408→                        if summary:\n   409→                            result[\"tool_summary\"] = summary\n   410→\n   411→                        # Generate spinner update for all tools (even suppressible ones)\n   412→                        spinner_text = determine_spinner_status(item, command, worktree_path)\n   413→                        result[\"spinner_update\"] = spinner_text\n   414→                        break\n   415→\n   416→        # Extract PR metadata from tool results\n   417→        if msg_type == \"user\":\n   418→            content = message.get(\"content\", [])\n   419→            if isinstance(content, list):\n   420→                for item in content:\n   421→                    if isinstance(item, dict) and item.get(\"type\") == \"tool_result\":\n   422→                        tool_content = item.get(\"content\")\n   423→                        # Handle both string and list formats\n   424→                        # String format: raw JSON string\n   425→                        # List format: [{\"type\": \"text\", \"text\": \"...\"}]\n   426→                        content_str: str | None = None\n   427→                        if isinstance(tool_content, str):\n   428→                            content_str = tool_content\n   429→                        elif isinstance(tool_content, list):\n   430→                            # Extract text from list of content items\n   431→                            for content_item in tool_content:\n   432→                                is_text_item = (\n   433→                                    isinstance(content_item, dict)\n   434→                                    and content_item.get(\"type\") == \"text\"\n   435→                                )\n   436→                                if is_text_item:\n   437→                                    text = content_item.get(\"text\")\n   438→                                    if isinstance(text, str):\n   439→                                        content_str = text\n   440→                                        break\n   441→                        if content_str is not None:\n   442→                            pr_metadata = extract_pr_metadata(content_str)\n   443→                            if pr_metadata.get(\"pr_url\"):\n   444→                                result[\"pr_url\"] = pr_metadata[\"pr_url\"]\n   445→                                result[\"pr_number\"] = pr_metadata[\"pr_number\"]\n   446→                                result[\"pr_title\"] = pr_metadata[\"pr_title\"]\n   447→                                result[\"issue_number\"] = pr_metadata.get(\"issue_number\")\n   448→                                break\n   449→\n   450→        # Parse type: result messages for num_turns (hook blocking detection)\n   451→        if msg_type == \"result\":\n   452→            num_turns = data.get(\"num_turns\")\n   453→            if num_turns is not None:\n   454→                result[\"num_turns\"] = num_turns\n   455→            result[\"is_error\"] = data.get(\"is_error\", False)\n   456→            result_text = data.get(\"result\")\n   457→            if result_text is not None:\n   458→                result[\"result_text\"] = result_text\n   459→\n   460→        return result\n   461→\n   462→    def execute_interactive(\n   463→        self,\n   464→        *,\n   465→        worktree_path: Path,\n   466→        dangerous: bool,\n   467→        command: str,\n   468→        target_subpath: Path | None,\n   469→        model: str | None = None,\n   470→        permission_mode: PermissionMode,\n   471→    ) -> None:\n   472→        \"\"\"Execute Claude CLI in interactive mode by replacing current process.\n   473→\n   474→        Implementation details:\n   475→        - Verifies Claude CLI is available\n   476→        - Changes to worktree directory (and to subpath if provided)\n   477→        - Builds command arguments with the specified command\n   478→        - Replaces current process using os.execvp\n   479→\n   480→        Note:\n   481→            This function never returns - the process is replaced by Claude CLI.\n   482→\n   483→            The target_subpath is trusted to exist because it was computed from\n   484→            the source worktree's directory structure. Since the new worktree\n   485→            shares git history with the source, the path should exist.\n   486→        \"\"\"\n   487→        # Verify Claude is available\n   488→        if not self.is_available():\n   489→            raise RuntimeError(\"Claude CLI not found\\nInstall from: https://claude.com/download\")\n   490→\n   491→        # Change to worktree directory (optionally to subpath)\n   492→        # Trust the computed subpath exists - it was derived from the source worktree\n   493→        # which has the same git history. If it doesn't exist, os.chdir will raise\n   494→        # FileNotFoundError which is the appropriate error.\n   495→        if target_subpath is not None:\n   496→            target_dir = worktree_path / target_subpath\n   497→            os.chdir(target_dir)\n   498→        else:\n   499→            os.chdir(worktree_path)\n   500→\n   501→        # Map generic permission_mode to Claude-specific permission_mode\n   502→        claude_permission_mode = permission_mode_to_claude(permission_mode)\n   503→\n   504→        # Build command arguments\n   505→        cmd_args = [\"claude\", \"--permission-mode\", claude_permission_mode]\n   506→        if dangerous:\n   507→            cmd_args.append(\"--dangerously-skip-permissions\")\n   508→        if model is not None:\n   509→            cmd_args.extend([\"--model\", model])\n   510→        # Only append command if non-empty (allows launching Claude for planning)\n   511→        if command:\n   512→            cmd_args.append(command)\n   513→\n   514→        # Redirect stdin/stdout/stderr to /dev/tty only if they are not already TTYs.\n   515→        # This ensures Claude gets terminal access when running as subprocess with\n   516→        # captured stdout (e.g., shell integration), while avoiding unnecessary\n   517→        # redirection when already running in a terminal (which can break tools\n   518→        # like Bun that expect specific TTY capabilities).\n   519→        if not (self._console.is_stdout_tty() and self._console.is_stderr_tty()):\n   520→            try:\n   521→                tty_fd = os.open(\"/dev/tty\", os.O_RDWR)\n   522→                os.dup2(tty_fd, 0)  # stdin\n   523→                os.dup2(tty_fd, 1)  # stdout\n   524→                os.dup2(tty_fd, 2)  # stderr\n   525→                os.close(tty_fd)\n   526→            except OSError:\n   527→                logger.debug(\n   528→                    \"Unable to redirect stdin/stdout/stderr to /dev/tty; \"\n   529→                    \"falling back to inherited descriptors\"\n   530→                )\n   531→\n   532→        # Strip nested session guard before replacing process.\n   533→        # Claude Code sets CLAUDECODE=1 to block nested sessions, but execvp\n   534→        # replaces the current process entirely — no resources are shared.\n   535→        os.environ.pop(\"CLAUDECODE\", None)\n   536→\n   537→        # Replace current process with Claude\n   538→        os.execvp(\"claude\", cmd_args)\n   539→        # Never returns - process is replaced\n   540→\n   541→    def execute_prompt(\n   542→        self,\n   543→        prompt: str,\n   544→        *,\n   545→        model: str,\n   546→        tools: list[str] | None,\n   547→        cwd: Path | None,\n   548→        system_prompt: str | None,\n   549→        dangerous: bool,\n   550→    ) -> PromptResult:\n   551→        \"\"\"Execute a single prompt and return the result.\n   552→\n   553→        Implementation details:\n   554→        - Uses subprocess.run with --print and --output-format text\n   555→        - When system_prompt is provided, uses --system-prompt to replace\n   556→          Claude Code's default system prompt\n   557→        - When dangerous is True, adds --dangerously-skip-permissions\n   558→        - Returns PromptResult with success status and output\n   559→        \"\"\"\n   560→        cmd = [\n   561→            \"claude\",\n   562→            \"--print\",\n   563→            \"--no-session-persistence\",\n   564→            \"--output-format\",\n   565→            \"text\",\n   566→            \"--model\",\n   567→            model,\n   568→        ]\n   569→        if dangerous:\n   570→            cmd.append(\"--dangerously-skip-permissions\")\n   571→        if system_prompt is not None:\n   572→            cmd.extend([\"--system-prompt\", system_prompt])\n   573→        if tools is not None:\n   574→            cmd.extend([\"--allowedTools\", \",\".join(tools)])\n   575→        cmd.append(prompt)\n   576→\n   577→        result = subprocess.run(\n   578→            cmd,\n   579→            capture_output=True,\n   580→            text=True,\n   581→            cwd=cwd,\n   582→            check=False,\n   583→            env=self._subprocess_env(),\n   584→        )\n   585→\n   586→        if result.returncode != 0:\n   587→            return PromptResult(\n   588→                success=False,\n   589→                output=\"\",\n   590→                error=format_prompt_error(\n   591→                    returncode=result.returncode,\n   592→                    stderr=result.stderr,\n   593→                    stdout=result.stdout,\n   594→                ),\n   595→            )\n   596→\n   597→        return PromptResult(\n   598→            success=True,\n   599→            output=result.stdout.strip(),\n   600→            error=None,\n   601→        )\n   602→\n   603→    def execute_prompt_passthrough(\n   604→        self,\n   605→        prompt: str,\n   606→        *,\n   607→        model: str,\n   608→        tools: list[str] | None,\n   609→        cwd: Path,\n   610→        dangerous: bool,\n   611→    ) -> int:\n   612→        \"\"\"Execute prompt with output streaming directly to terminal.\n   613→\n   614→        Implementation details:\n   615→        - Uses subprocess.run with stdin=subprocess.DEVNULL to prevent interactive prompts\n   616→        - Passes --print, --model, --output-format stream-json, --verbose\n   617→        - Optionally passes --allowedTools when tools is provided\n   618→        - Optionally passes --dangerously-skip-permissions when dangerous=True\n   619→        - Output streams directly to terminal (stdout/stderr not captured)\n   620→        \"\"\"\n   621→        cmd = [\n   622→            \"claude\",\n   623→            \"--print\",\n   624→            \"--no-session-persistence\",\n   625→            \"--model\",\n   626→            model,\n   627→            \"--output-format\",\n   628→            \"stream-json\",\n   629→            \"--verbose\",\n   630→        ]\n   631→        if tools is not None:\n   632→            cmd.extend([\"--allowedTools\", \",\".join(tools)])\n   633→        if dangerous:\n   634→            cmd.append(\"--dangerously-skip-permissions\")\n   635→        cmd.append(prompt)\n   636→\n   637→        result = subprocess.run(\n   638→            cmd,\n   639→            cwd=cwd,\n   640→            stdin=subprocess.DEVNULL,\n   641→            check=False,\n   642→            env=self._subprocess_env(),\n   643→        )\n   644→        return result.returncode\n   645→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"13a63dae-3076-4010-826d-dc7c4f2cd8fe","timestamp":"2026-02-22T14:37:34.694Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/core/prompt_executor.py","content":"\"\"\"Claude CLI prompt execution implementation.\n\nThis module provides the ClaudePromptExecutor implementation and re-exports\nABC and types from erk_shared.core.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport threading\nfrom collections.abc import Iterator\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from erk_shared.context.types import PermissionMode\n\nfrom erk_shared.context.types import permission_mode_to_claude\nfrom erk_shared.core.prompt_executor import (\n    CommandResult,  # noqa: F401 - re-exported for erk.cli.output\n    ErrorEvent,\n    ExecutorEvent,\n    IssueNumberEvent,\n    NoOutputEvent,\n    NoTurnsEvent,\n    PrNumberEvent,\n    ProcessErrorEvent,\n    PromptExecutor,\n    PromptResult,\n    PrTitleEvent,\n    PrUrlEvent,\n    SpinnerUpdateEvent,\n    TextEvent,\n    ToolEvent,\n)\nfrom erk_shared.gateway.console.abc import Console\nfrom erk_shared.gateway.console.real import InteractiveConsole\nfrom erk_shared.subprocess_utils import build_claude_subprocess_env\n\n# Constants for process execution\nPROCESS_TIMEOUT_SECONDS = 600  # 10 minutes\nSTDERR_JOIN_TIMEOUT = 5.0  # 5 seconds (increased from 1.0)\n\nlogger = logging.getLogger(__name__)\n\n\ndef format_prompt_error(\n    *,\n    returncode: int,\n    stderr: str,\n    stdout: str,\n) -> str:\n    \"\"\"Format error message for failed prompt execution.\n\n    Constructs a structured error message from subprocess failure details.\n\n    Args:\n        returncode: Process exit code\n        stderr: Standard error output\n        stdout: Standard output (truncated to 500 characters)\n\n    Returns:\n        Formatted error string like \"Exit code 1 | stderr: ... | stdout: ...\"\n    \"\"\"\n    error_parts = [f\"Exit code {returncode}\"]\n    if stderr and stderr.strip():\n        error_parts.append(f\"stderr: {stderr.strip()}\")\n    if stdout and stdout.strip():\n        stdout_preview = stdout.strip()[:500]\n        error_parts.append(f\"stdout: {stdout_preview}\")\n    return \" | \".join(error_parts)\n\n\nclass ClaudePromptExecutor(PromptExecutor):\n    \"\"\"Production implementation using subprocess and Claude CLI.\"\"\"\n\n    def __init__(self, console: Console | None) -> None:\n        \"\"\"Initialize ClaudePromptExecutor with Console dependency.\n\n        Args:\n            console: Console gateway for TTY detection.\n                If None, creates an InteractiveConsole instance.\n        \"\"\"\n        self._console = console if console is not None else InteractiveConsole()\n\n    def is_available(self) -> bool:\n        \"\"\"Check if Claude CLI is in PATH using shutil.which.\"\"\"\n        return shutil.which(\"claude\") is not None\n\n    @staticmethod\n    def _subprocess_env() -> dict[str, str]:\n        \"\"\"Build environment for claude subprocess with nested session guard removed.\"\"\"\n        return build_claude_subprocess_env()\n\n    def execute_command_streaming(\n        self,\n        *,\n        command: str,\n        worktree_path: Path,\n        dangerous: bool,\n        verbose: bool = False,\n        debug: bool = False,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n        allow_dangerous: bool = False,\n    ) -> Iterator[ExecutorEvent]:\n        \"\"\"Execute Claude CLI command and yield typed events in real-time.\n\n        Implementation details:\n        - Uses subprocess.Popen() for streaming stdout line-by-line\n        - Passes --permission-mode with the provided mode, --output-format stream-json\n        - Optionally passes --dangerously-skip-permissions when dangerous=True\n        - Optionally passes --allow-dangerously-skip-permissions when allow_dangerous=True\n        - Optionally passes --model when model is specified\n        - In verbose mode: streams output to terminal (no parsing, no events yielded)\n        - In filtered mode: parses stream-json and yields events in real-time\n        - In debug mode: emits additional debug information to stderr\n        \"\"\"\n        # Map generic permission_mode to Claude-specific permission_mode\n        claude_permission_mode = permission_mode_to_claude(permission_mode)\n\n        cmd_args = [\n            \"claude\",\n            \"--print\",\n            \"--no-session-persistence\",\n            \"--verbose\",\n            \"--permission-mode\",\n            claude_permission_mode,\n            \"--output-format\",\n            \"stream-json\",\n        ]\n        if dangerous:\n            cmd_args.append(\"--dangerously-skip-permissions\")\n        if allow_dangerous:\n            cmd_args.append(\"--allow-dangerously-skip-permissions\")\n        if model is not None:\n            cmd_args.extend([\"--model\", model])\n        cmd_args.append(command)\n\n        if verbose:\n            # Verbose mode - stream to terminal, no parsing, no events\n            result = subprocess.run(\n                cmd_args, cwd=worktree_path, check=False, env=self._subprocess_env()\n            )\n\n            if result.returncode != 0:\n                error_msg = f\"Claude command {command} failed with exit code {result.returncode}\"\n                yield ErrorEvent(message=error_msg)\n            return\n\n        # Filtered mode - streaming with real-time parsing\n        if debug:\n            print(f\"[DEBUG executor] Starting Popen with args: {cmd_args}\", file=sys.stderr)\n            print(f\"[DEBUG executor] cwd: {worktree_path}\", file=sys.stderr)\n            sys.stderr.flush()\n\n        # Handle Popen errors (e.g., claude not found, permission denied)\n        try:\n            process = subprocess.Popen(\n                cmd_args,\n                cwd=worktree_path,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n                bufsize=1,  # Line buffered\n                env=self._subprocess_env(),\n            )\n        except OSError as e:\n            yield ProcessErrorEvent(\n                message=f\"Failed to start Claude CLI: {e}\\nCommand: {' '.join(cmd_args)}\"\n            )\n            return\n\n        if debug:\n            print(f\"[DEBUG executor] Popen started, pid={process.pid}\", file=sys.stderr)\n            sys.stderr.flush()\n\n        stderr_output: list[str] = []\n\n        # Capture stderr in background thread\n        def capture_stderr() -> None:\n            if process.stderr:\n                for line in process.stderr:\n                    stderr_output.append(line)\n\n        stderr_thread = threading.Thread(target=capture_stderr, daemon=True)\n        stderr_thread.start()\n\n        # Process stdout line by line in real-time\n        line_count = 0\n        if debug:\n            print(\"[DEBUG executor] Starting to read stdout...\", file=sys.stderr)\n            sys.stderr.flush()\n        if process.stdout:\n            for line in process.stdout:\n                line_count += 1\n                if debug:\n                    print(\n                        f\"[DEBUG executor] Line #{line_count}: {line[:100]!r}...\", file=sys.stderr\n                    )\n                    sys.stderr.flush()\n                if not line.strip():\n                    continue\n\n                # Try to parse as JSON\n                parsed = self._parse_stream_json_line(line, worktree_path, command)\n                if parsed is None:\n                    if debug:\n                        print(\n                            f\"[DEBUG executor] Line #{line_count} parsed to None\", file=sys.stderr\n                        )\n                        sys.stderr.flush()\n                    continue\n\n                if debug:\n                    print(f\"[DEBUG executor] Line #{line_count} parsed: {parsed}\", file=sys.stderr)\n                    sys.stderr.flush()\n\n                # Yield text content and extract metadata from it\n                text_content = parsed.get(\"text_content\")\n                if text_content is not None and isinstance(text_content, str):\n                    yield TextEvent(content=text_content)\n\n                    # Also try to extract PR metadata from text (simpler than nested JSON)\n                    from erk.core.output_filter import extract_pr_metadata_from_text\n\n                    text_metadata = extract_pr_metadata_from_text(text_content)\n                    text_pr_url = text_metadata.get(\"pr_url\")\n                    if text_pr_url is not None:\n                        yield PrUrlEvent(url=str(text_pr_url))\n                    text_pr_number = text_metadata.get(\"pr_number\")\n                    if text_pr_number is not None:\n                        yield PrNumberEvent(number=int(text_pr_number))\n                    text_pr_title = text_metadata.get(\"pr_title\")\n                    if text_pr_title is not None:\n                        yield PrTitleEvent(title=str(text_pr_title))\n                    text_issue_number = text_metadata.get(\"issue_number\")\n                    if text_issue_number is not None:\n                        yield IssueNumberEvent(number=int(text_issue_number))\n\n                # Yield tool summaries\n                tool_summary = parsed.get(\"tool_summary\")\n                if tool_summary is not None and isinstance(tool_summary, str):\n                    yield ToolEvent(summary=tool_summary)\n\n                # Yield spinner updates\n                spinner_text = parsed.get(\"spinner_update\")\n                if spinner_text is not None and isinstance(spinner_text, str):\n                    yield SpinnerUpdateEvent(status=spinner_text)\n\n                # Yield PR URL\n                pr_url_value = parsed.get(\"pr_url\")\n                if pr_url_value is not None:\n                    yield PrUrlEvent(url=str(pr_url_value))\n\n                # Yield PR number\n                pr_number_value = parsed.get(\"pr_number\")\n                if pr_number_value is not None:\n                    yield PrNumberEvent(number=int(pr_number_value))\n\n                # Yield PR title\n                pr_title_value = parsed.get(\"pr_title\")\n                if pr_title_value is not None:\n                    yield PrTitleEvent(title=str(pr_title_value))\n\n                # Yield issue number\n                issue_number_value = parsed.get(\"issue_number\")\n                if issue_number_value is not None:\n                    yield IssueNumberEvent(number=int(issue_number_value))\n\n                # Detect zero-turn completions (hook blocking)\n                num_turns = parsed.get(\"num_turns\")\n                if num_turns is not None and num_turns == 0:\n                    diag = f\"Claude command {command} completed without processing\"\n                    diag += \"\\n  This usually means a hook blocked the command\"\n                    diag += \"\\n  Run 'claude' directly to see hook error messages\"\n                    diag += f\"\\n  Working directory: {worktree_path}\"\n                    yield NoTurnsEvent(diagnostic=diag)\n\n        if debug:\n            print(\n                f\"[DEBUG executor] stdout reading complete, total lines: {line_count}\",\n                file=sys.stderr,\n            )\n            sys.stderr.flush()\n\n        # Wait for process to complete with timeout\n        try:\n            returncode = process.wait(timeout=PROCESS_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            process.kill()\n            process.wait()\n            timeout_minutes = PROCESS_TIMEOUT_SECONDS // 60\n            yield ProcessErrorEvent(\n                message=f\"Claude command {command} timed out after {timeout_minutes} minutes\"\n            )\n            return\n\n        # Wait for stderr thread to finish with increased timeout\n        stderr_thread.join(timeout=STDERR_JOIN_TIMEOUT)\n\n        # Detect no output condition - yield before checking exit code\n        if line_count == 0:\n            diag = f\"Claude command {command} completed but produced no output\"\n            diag += f\"\\n  Exit code: {returncode}\"\n            diag += f\"\\n  Working directory: {worktree_path}\"\n            if stderr_output:\n                diag += \"\\n  Stderr:\\n\" + \"\".join(stderr_output)\n            yield NoOutputEvent(diagnostic=diag)\n\n            if returncode != 0:\n                yield ErrorEvent(message=f\"Exit code {returncode}\")\n            return\n\n        # Enhanced error messages for non-zero exit codes\n        if returncode != 0:\n            error_msg = f\"Claude command {command} failed\"\n            error_msg += f\"\\n  Exit code: {returncode}\"\n            error_msg += f\"\\n  Lines processed: {line_count}\"\n            if stderr_output:\n                error_msg += \"\\n  Stderr:\\n\" + \"\".join(stderr_output).strip()\n            yield ErrorEvent(message=error_msg)\n\n        # Debug summary\n        if debug:\n            print(\"[DEBUG executor] === Summary ===\", file=sys.stderr)\n            print(f\"[DEBUG executor] Exit code: {returncode}\", file=sys.stderr)\n            print(f\"[DEBUG executor] Lines: {line_count}\", file=sys.stderr)\n            if stderr_output:\n                print(f\"[DEBUG executor] Stderr: {''.join(stderr_output)}\", file=sys.stderr)\n            sys.stderr.flush()\n\n    def _parse_stream_json_line(\n        self, line: str, worktree_path: Path, command: str\n    ) -> dict[str, str | int | bool | None] | None:\n        \"\"\"Parse a single stream-json line and extract relevant information.\n\n        Args:\n            line: JSON line from stream-json output\n            worktree_path: Path to worktree for relativizing paths\n            command: The slash command being executed\n\n        Returns:\n            Dict with text_content, tool_summary, spinner_update, pr_url, pr_number,\n            pr_title, and issue_number keys, or None if not JSON\n        \"\"\"\n        # Import here to avoid circular dependency\n        from erk.core.output_filter import (\n            determine_spinner_status,\n            extract_pr_metadata,\n            extract_text_content,\n            summarize_tool_use,\n        )\n\n        if not line.strip():\n            return None\n\n        # Parse JSON safely - JSON parsing requires exception handling\n        data: dict | None = None\n        if line.strip():\n            try:\n                parsed = json.loads(line)\n                if isinstance(parsed, dict):\n                    data = parsed\n            except json.JSONDecodeError:\n                return None\n\n        if data is None:\n            return None\n\n        result: dict[str, str | int | bool | None] = {\n            \"text_content\": None,\n            \"tool_summary\": None,\n            \"spinner_update\": None,\n            \"pr_url\": None,\n            \"pr_number\": None,\n            \"pr_title\": None,\n            \"issue_number\": None,\n            \"num_turns\": None,\n            \"is_error\": None,\n            \"result_text\": None,\n        }\n\n        # stream-json format uses \"type\": \"assistant\" with nested \"message\" object\n        # (not \"type\": \"assistant_message\" with content at top level)\n        msg_type = data.get(\"type\")\n        message = data.get(\"message\", {})\n        if not isinstance(message, dict):\n            message = {}\n\n        # Extract text from assistant messages\n        if msg_type == \"assistant\":\n            text = extract_text_content(message)\n            if text:\n                result[\"text_content\"] = text\n\n            # Extract tool summaries and spinner updates\n            content = message.get(\"content\", [])\n            if isinstance(content, list):\n                for item in content:\n                    if isinstance(item, dict) and item.get(\"type\") == \"tool_use\":\n                        summary = summarize_tool_use(item, worktree_path)\n                        if summary:\n                            result[\"tool_summary\"] = summary\n\n                        # Generate spinner update for all tools (even suppressible ones)\n                        spinner_text = determine_spinner_status(item, command, worktree_path)\n                        result[\"spinner_update\"] = spinner_text\n                        break\n\n        # Extract PR metadata from tool results\n        if msg_type == \"user\":\n            content = message.get(\"content\", [])\n            if isinstance(content, list):\n                for item in content:\n                    if isinstance(item, dict) and item.get(\"type\") == \"tool_result\":\n                        tool_content = item.get(\"content\")\n                        # Handle both string and list formats\n                        # String format: raw JSON string\n                        # List format: [{\"type\": \"text\", \"text\": \"...\"}]\n                        content_str: str | None = None\n                        if isinstance(tool_content, str):\n                            content_str = tool_content\n                        elif isinstance(tool_content, list):\n                            # Extract text from list of content items\n                            for content_item in tool_content:\n                                is_text_item = (\n                                    isinstance(content_item, dict)\n                                    and content_item.get(\"type\") == \"text\"\n                                )\n                                if is_text_item:\n                                    text = content_item.get(\"text\")\n                                    if isinstance(text, str):\n                                        content_str = text\n                                        break\n                        if content_str is not None:\n                            pr_metadata = extract_pr_metadata(content_str)\n                            if pr_metadata.get(\"pr_url\"):\n                                result[\"pr_url\"] = pr_metadata[\"pr_url\"]\n                                result[\"pr_number\"] = pr_metadata[\"pr_number\"]\n                                result[\"pr_title\"] = pr_metadata[\"pr_title\"]\n                                result[\"issue_number\"] = pr_metadata.get(\"issue_number\")\n                                break\n\n        # Parse type: result messages for num_turns (hook blocking detection)\n        if msg_type == \"result\":\n            num_turns = data.get(\"num_turns\")\n            if num_turns is not None:\n                result[\"num_turns\"] = num_turns\n            result[\"is_error\"] = data.get(\"is_error\", False)\n            result_text = data.get(\"result\")\n            if result_text is not None:\n                result[\"result_text\"] = result_text\n\n        return result\n\n    def execute_interactive(\n        self,\n        *,\n        worktree_path: Path,\n        dangerous: bool,\n        command: str,\n        target_subpath: Path | None,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n    ) -> None:\n        \"\"\"Execute Claude CLI in interactive mode by replacing current process.\n\n        Implementation details:\n        - Verifies Claude CLI is available\n        - Changes to worktree directory (and to subpath if provided)\n        - Builds command arguments with the specified command\n        - Replaces current process using os.execvp\n\n        Note:\n            This function never returns - the process is replaced by Claude CLI.\n\n            The target_subpath is trusted to exist because it was computed from\n            the source worktree's directory structure. Since the new worktree\n            shares git history with the source, the path should exist.\n        \"\"\"\n        # Verify Claude is available\n        if not self.is_available():\n            raise RuntimeError(\"Claude CLI not found\\nInstall from: https://claude.com/download\")\n\n        # Change to worktree directory (optionally to subpath)\n        # Trust the computed subpath exists - it was derived from the source worktree\n        # which has the same git history. If it doesn't exist, os.chdir will raise\n        # FileNotFoundError which is the appropriate error.\n        if target_subpath is not None:\n            target_dir = worktree_path / target_subpath\n            os.chdir(target_dir)\n        else:\n            os.chdir(worktree_path)\n\n        # Map generic permission_mode to Claude-specific permission_mode\n        claude_permission_mode = permission_mode_to_claude(permission_mode)\n\n        # Build command arguments\n        cmd_args = [\"claude\", \"--permission-mode\", claude_permission_mode]\n        if dangerous:\n            cmd_args.append(\"--dangerously-skip-permissions\")\n        if model is not None:\n            cmd_args.extend([\"--model\", model])\n        # Only append command if non-empty (allows launching Claude for planning)\n        if command:\n            cmd_args.append(command)\n\n        # Redirect stdin/stdout/stderr to /dev/tty only if they are not already TTYs.\n        # This ensures Claude gets terminal access when running as subprocess with\n        # captured stdout (e.g., shell integration), while avoiding unnecessary\n        # redirection when already running in a terminal (which can break tools\n        # like Bun that expect specific TTY capabilities).\n        if not (self._console.is_stdout_tty() and self._console.is_stderr_tty()):\n            try:\n                tty_fd = os.open(\"/dev/tty\", os.O_RDWR)\n                os.dup2(tty_fd, 0)  # stdin\n                os.dup2(tty_fd, 1)  # stdout\n                os.dup2(tty_fd, 2)  # stderr\n                os.close(tty_fd)\n            except OSError:\n                logger.debug(\n                    \"Unable to redirect stdin/stdout/stderr to /dev/tty; \"\n                    \"falling back to inherited descriptors\"\n                )\n\n        # Strip nested session guard before replacing process.\n        # Claude Code sets CLAUDECODE=1 to block nested sessions, but execvp\n        # replaces the current process entirely — no resources are shared.\n        os.environ.pop(\"CLAUDECODE\", None)\n\n        # Replace current process with Claude\n        os.execvp(\"claude\", cmd_args)\n        # Never returns - process is replaced\n\n    def execute_prompt(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path | None,\n        system_prompt: str | None,\n        dangerous: bool,\n    ) -> PromptResult:\n        \"\"\"Execute a single prompt and return the result.\n\n        Implementation details:\n        - Uses subprocess.run with --print and --output-format text\n        - When system_prompt is provided, uses --system-prompt to replace\n          Claude Code's default system prompt\n        - When dangerous is True, adds --dangerously-skip-permissions\n        - Returns PromptResult with success status and output\n        \"\"\"\n        cmd = [\n            \"claude\",\n            \"--print\",\n            \"--no-session-persistence\",\n            \"--output-format\",\n            \"text\",\n            \"--model\",\n            model,\n        ]\n        if dangerous:\n            cmd.append(\"--dangerously-skip-permissions\")\n        if system_prompt is not None:\n            cmd.extend([\"--system-prompt\", system_prompt])\n        if tools is not None:\n            cmd.extend([\"--allowedTools\", \",\".join(tools)])\n        cmd.append(prompt)\n\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            cwd=cwd,\n            check=False,\n            env=self._subprocess_env(),\n        )\n\n        if result.returncode != 0:\n            return PromptResult(\n                success=False,\n                output=\"\",\n                error=format_prompt_error(\n                    returncode=result.returncode,\n                    stderr=result.stderr,\n                    stdout=result.stdout,\n                ),\n            )\n\n        return PromptResult(\n            success=True,\n            output=result.stdout.strip(),\n            error=None,\n        )\n\n    def execute_prompt_passthrough(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path,\n        dangerous: bool,\n    ) -> int:\n        \"\"\"Execute prompt with output streaming directly to terminal.\n\n        Implementation details:\n        - Uses subprocess.run with stdin=subprocess.DEVNULL to prevent interactive prompts\n        - Passes --print, --model, --output-format stream-json, --verbose\n        - Optionally passes --allowedTools when tools is provided\n        - Optionally passes --dangerously-skip-permissions when dangerous=True\n        - Output streams directly to terminal (stdout/stderr not captured)\n        \"\"\"\n        cmd = [\n            \"claude\",\n            \"--print\",\n            \"--no-session-persistence\",\n            \"--model\",\n            model,\n            \"--output-format\",\n            \"stream-json\",\n            \"--verbose\",\n        ]\n        if tools is not None:\n            cmd.extend([\"--allowedTools\", \",\".join(tools)])\n        if dangerous:\n            cmd.append(\"--dangerously-skip-permissions\")\n        cmd.append(prompt)\n\n        result = subprocess.run(\n            cmd,\n            cwd=cwd,\n            stdin=subprocess.DEVNULL,\n            check=False,\n            env=self._subprocess_env(),\n        )\n        return result.returncode\n","numLines":645,"startLine":1,"totalLines":645}}}
{"parentUuid":"13a63dae-3076-4010-826d-dc7c4f2cd8fe","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01JGN6FEmpE3ttZemSkxv2hN","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the 5 call sites to understand the integration points:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17938,"cache_read_input_tokens":60267,"cache_creation":{"ephemeral_5m_input_tokens":17938,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3AvsnWeWuJNx8Bkmz","type":"assistant","uuid":"a497cda5-0b12-412f-a09b-661944e216d0","timestamp":"2026-02-22T14:37:37.840Z"}
{"parentUuid":"a497cda5-0b12-412f-a09b-661944e216d0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01JGN6FEmpE3ttZemSkxv2hN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016npmZCiNe6qHtfGK5NZcQa","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":17938,"cache_read_input_tokens":60267,"cache_creation":{"ephemeral_5m_input_tokens":17938,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3AvsnWeWuJNx8Bkmz","type":"assistant","uuid":"54a03bd2-45bf-438e-84d9-99fd4c5e8357","timestamp":"2026-02-22T14:37:39.704Z"}
{"parentUuid":"54a03bd2-45bf-438e-84d9-99fd4c5e8357","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016npmZCiNe6qHtfGK5NZcQa","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"4bedd67b-fb30-492b-9fe8-888ba6643033","timestamp":"2026-02-22T14:37:39.729Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]}}
{"parentUuid":"4bedd67b-fb30-492b-9fe8-888ba6643033","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012Lf5ZwTbcKbMXSLVmncRS9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LULjLpjBTn1icv6dQ3xx7e","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","limit":200},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":274,"cache_read_input_tokens":78205,"cache_creation":{"ephemeral_5m_input_tokens":274,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3YTw5jK32jhJtSD5z","type":"assistant","uuid":"96f6c40d-c837-4026-a702-ac269b1c6290","timestamp":"2026-02-22T14:37:42.831Z"}
{"parentUuid":"96f6c40d-c837-4026-a702-ac269b1c6290","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012Lf5ZwTbcKbMXSLVmncRS9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HMEAbHevayqucvFEUX2hfX","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":274,"cache_read_input_tokens":78205,"cache_creation":{"ephemeral_5m_input_tokens":274,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3YTw5jK32jhJtSD5z","type":"assistant","uuid":"65ba5038-43c2-4931-84ee-f209dce4e8c1","timestamp":"2026-02-22T14:37:43.389Z"}
{"parentUuid":"65ba5038-43c2-4931-84ee-f209dce4e8c1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012Lf5ZwTbcKbMXSLVmncRS9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DvtpkQfr6WeT4s6CBWQumK","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":274,"cache_read_input_tokens":78205,"cache_creation":{"ephemeral_5m_input_tokens":274,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3YTw5jK32jhJtSD5z","type":"assistant","uuid":"59b5b9a8-6111-4c55-a9be-7f9e01fd0f1d","timestamp":"2026-02-22T14:37:44.073Z"}
{"parentUuid":"59b5b9a8-6111-4c55-a9be-7f9e01fd0f1d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012Lf5ZwTbcKbMXSLVmncRS9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FipaH5gNtf6n4RtUNDZHJG","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":274,"cache_read_input_tokens":78205,"cache_creation":{"ephemeral_5m_input_tokens":274,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3YTw5jK32jhJtSD5z","type":"assistant","uuid":"ae8a6077-8779-4650-ba3f-d28cf11466db","timestamp":"2026-02-22T14:37:44.850Z"}
{"parentUuid":"ae8a6077-8779-4650-ba3f-d28cf11466db","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012Lf5ZwTbcKbMXSLVmncRS9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Qf4zavspxfpBmif72EjzNC","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":274,"cache_read_input_tokens":78205,"cache_creation":{"ephemeral_5m_input_tokens":274,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3YTw5jK32jhJtSD5z","type":"assistant","uuid":"035bfa1f-d872-4fc2-84f6-fdd14b01a9da","timestamp":"2026-02-22T14:37:45.689Z"}
{"parentUuid":"035bfa1f-d872-4fc2-84f6-fdd14b01a9da","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LULjLpjBTn1icv6dQ3xx7e","type":"tool_result","content":"     1→\"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n     2→\n     3→Usage:\n     4→    erk exec plan-save [OPTIONS]\n     5→\n     6→When ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR with the plan.\n     7→Otherwise delegates to the existing plan-save-to-issue logic (default).\n     8→\n     9→Options:\n    10→    --format json|display: Output format (default: json)\n    11→    --plan-file PATH: Use specific plan file (highest priority)\n    12→    --session-id ID: Session ID for scoped plan lookup\n    13→    --objective-issue INT: Link plan to parent objective\n    14→    --plan-type standard|learn: Plan type (default: standard)\n    15→    --learned-from-issue INT: Parent plan issue (for learn plans)\n    16→    --created-from-workflow-run-url URL: Workflow run URL\n    17→\n    18→Exit Codes:\n    19→    0: Success\n    20→    1: Error\n    21→    2: Validation failed\n    22→\"\"\"\n    23→\n    24→import json\n    25→from pathlib import Path\n    26→\n    27→import click\n    28→\n    29→from erk.cli.commands.exec.scripts.plan_save_to_issue import (\n    30→    plan_save_to_issue,\n    31→)\n    32→from erk.cli.commands.exec.scripts.validate_plan_content import _validate_plan_content\n    33→from erk_shared.context.helpers import (\n    34→    get_repo_identifier,\n    35→    require_branch_manager,\n    36→    require_claude_installation,\n    37→    require_cwd,\n    38→    require_git,\n    39→    require_github,\n    40→    require_issues,\n    41→    require_local_config,\n    42→    require_repo_root,\n    43→    require_time,\n    44→)\n    45→from erk_shared.gateway.claude_installation.abc import ClaudeInstallation\n    46→from erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\n    47→from erk_shared.gateway.time.real import RealTime\n    48→from erk_shared.naming import generate_draft_pr_branch_name\n    49→from erk_shared.output.next_steps import format_draft_pr_next_steps_plain\n    50→from erk_shared.plan_store import get_plan_backend\n    51→from erk_shared.plan_store.draft_pr import DraftPRPlanBackend\n    52→from erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\n    53→from erk_shared.plan_store.plan_content import extract_title_from_plan, resolve_plan_content\n    54→from erk_shared.plan_utils import get_title_tag_from_labels\n    55→from erk_shared.scratch.plan_snapshots import PlanSnapshot, snapshot_plan_for_session\n    56→from erk_shared.scratch.session_markers import (\n    57→    create_plan_saved_issue_marker,\n    58→    create_plan_saved_marker,\n    59→    get_existing_saved_issue,\n    60→)\n    61→\n    62→\n    63→def _get_snapshot_result(\n    64→    *,\n    65→    session_id: str,\n    66→    plan_file: Path | None,\n    67→    cwd: Path,\n    68→    claude_installation: ClaudeInstallation,\n    69→    repo_root: Path,\n    70→) -> PlanSnapshot | None:\n    71→    \"\"\"Archive the plan file to session-scoped scratch storage.\n    72→\n    73→    Plan snapshots preserve the original plan content at save time, creating\n    74→    an immutable record tied to the session. This enables deduplication\n    75→    (detecting if a session already saved a plan) and provides an audit trail\n    76→    (what was the plan content when it was saved).\n    77→\n    78→    Args:\n    79→        session_id: Claude session ID\n    80→        plan_file: Explicit plan file path (highest priority)\n    81→        cwd: Current working directory\n    82→        claude_installation: ClaudeInstallation gateway for plan discovery\n    83→        repo_root: Repository root for scratch directory\n    84→\n    85→    Returns:\n    86→        PlanSnapshot with archive path, or None if no plan file found.\n    87→    \"\"\"\n    88→    if plan_file is not None:\n    89→        snapshot_path = plan_file\n    90→    else:\n    91→        snapshot_path = claude_installation.find_plan_for_session(cwd, session_id)\n    92→\n    93→    if snapshot_path is None or not snapshot_path.exists():\n    94→        return None\n    95→\n    96→    return snapshot_plan_for_session(\n    97→        session_id=session_id,\n    98→        plan_file_path=snapshot_path,\n    99→        project_cwd=cwd,\n   100→        claude_installation=claude_installation,\n   101→        repo_root=repo_root,\n   102→    )\n   103→\n   104→\n   105→def _save_as_draft_pr(\n   106→    ctx: click.Context,\n   107→    *,\n   108→    plan_content: str,\n   109→    session_id: str | None,\n   110→    objective_issue: int | None,\n   111→    plan_type: str | None,\n   112→    output_format: str,\n   113→    plan_file: Path | None,\n   114→    learned_from_issue: int | None,\n   115→    created_from_workflow_run_url: str | None,\n   116→) -> None:\n   117→    \"\"\"Save plan as a draft PR.\n   118→\n   119→    Creates a branch, pushes it, then creates a draft PR with plan content.\n   120→\n   121→    Args:\n   122→        ctx: Click context\n   123→        plan_content: Validated plan content\n   124→        session_id: Session ID for markers\n   125→        objective_issue: Optional objective issue number\n   126→        plan_type: Plan type (standard or learn)\n   127→        output_format: Output format (json or display)\n   128→        plan_file: Original plan file path (for snapshot)\n   129→        learned_from_issue: Parent plan issue number (for learn plans)\n   130→        created_from_workflow_run_url: GitHub Actions workflow run URL\n   131→    \"\"\"\n   132→    repo_root = require_repo_root(ctx)\n   133→    cwd = require_cwd(ctx)\n   134→    git = require_git(ctx)\n   135→    github = require_github(ctx)\n   136→    github_issues = require_issues(ctx)\n   137→    config = require_local_config(ctx)\n   138→    claude_installation = require_claude_installation(ctx)\n   139→\n   140→    title = extract_title_from_plan(plan_content)\n   141→\n   142→    # Generate branch name\n   143→    now = require_time(ctx).now()\n   144→    branch_name = generate_draft_pr_branch_name(\n   145→        title,\n   146→        now,\n   147→        objective_id=objective_issue,\n   148→    )\n   149→\n   150→    # Create branch with Graphite tracking (handles both creation and stack metadata)\n   151→    branch_manager = require_branch_manager(ctx)\n   152→    current_branch = git.branch.get_current_branch(cwd)\n   153→    start_point = current_branch if current_branch is not None else \"HEAD\"\n   154→    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n   155→    if isinstance(create_result, BranchAlreadyExists):\n   156→        click.echo(f\"Error: {create_result.message}\", err=True)\n   157→        raise SystemExit(1) from None\n   158→\n   159→    # Detect trunk for PR base metadata\n   160→    trunk = git.branch.detect_trunk_branch(cwd)\n   161→\n   162→    # Build ref.json data\n   163→    ref_data: dict[str, str | int | None] = {\n   164→        \"provider\": \"github-draft-pr\",\n   165→        \"title\": title,\n   166→    }\n   167→    if objective_issue is not None:\n   168→        ref_data[\"objective_id\"] = objective_issue\n   169→\n   170→    # Commit plan files directly to branch (no checkout needed).\n   171→    # Uses git plumbing to avoid race conditions when multiple sessions\n   172→    # share the same worktree.\n   173→    git.commit.commit_files_to_branch(\n   174→        repo_root,\n   175→        branch=branch_name,\n   176→        files={\n   177→            f\"{IMPL_CONTEXT_DIR}/plan.md\": plan_content,\n   178→            f\"{IMPL_CONTEXT_DIR}/ref.json\": json.dumps(ref_data, indent=2),\n   179→        },\n   180→        message=f\"Add plan: {title}\",\n   181→    )\n   182→    git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n   183→\n   184→    # Build metadata\n   185→    metadata: dict[str, object] = {\"branch_name\": branch_name, \"trunk_branch\": trunk}\n   186→\n   187→    if config.plans_repo is not None:\n   188→        metadata[\"source_repo\"] = get_repo_identifier(ctx)\n   189→\n   190→    if objective_issue is not None:\n   191→        metadata[\"objective_issue\"] = objective_issue\n   192→\n   193→    if session_id is not None:\n   194→        metadata[\"created_from_session\"] = session_id\n   195→\n   196→    if learned_from_issue is not None:\n   197→        metadata[\"learned_from_issue\"] = learned_from_issue\n   198→\n   199→    if created_from_workflow_run_url is not None:\n   200→        metadata[\"created_from_workflow_run_url\"] = created_from_workflow_run_url\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e63aca99-a3d4-4341-b035-720dc472da77","timestamp":"2026-02-22T14:37:45.707Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","content":"\"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n\nUsage:\n    erk exec plan-save [OPTIONS]\n\nWhen ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR with the plan.\nOtherwise delegates to the existing plan-save-to-issue logic (default).\n\nOptions:\n    --format json|display: Output format (default: json)\n    --plan-file PATH: Use specific plan file (highest priority)\n    --session-id ID: Session ID for scoped plan lookup\n    --objective-issue INT: Link plan to parent objective\n    --plan-type standard|learn: Plan type (default: standard)\n    --learned-from-issue INT: Parent plan issue (for learn plans)\n    --created-from-workflow-run-url URL: Workflow run URL\n\nExit Codes:\n    0: Success\n    1: Error\n    2: Validation failed\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.exec.scripts.plan_save_to_issue import (\n    plan_save_to_issue,\n)\nfrom erk.cli.commands.exec.scripts.validate_plan_content import _validate_plan_content\nfrom erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.claude_installation.abc import ClaudeInstallation\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.time.real import RealTime\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.output.next_steps import format_draft_pr_next_steps_plain\nfrom erk_shared.plan_store import get_plan_backend\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.plan_content import extract_title_from_plan, resolve_plan_content\nfrom erk_shared.plan_utils import get_title_tag_from_labels\nfrom erk_shared.scratch.plan_snapshots import PlanSnapshot, snapshot_plan_for_session\nfrom erk_shared.scratch.session_markers import (\n    create_plan_saved_issue_marker,\n    create_plan_saved_marker,\n    get_existing_saved_issue,\n)\n\n\ndef _get_snapshot_result(\n    *,\n    session_id: str,\n    plan_file: Path | None,\n    cwd: Path,\n    claude_installation: ClaudeInstallation,\n    repo_root: Path,\n) -> PlanSnapshot | None:\n    \"\"\"Archive the plan file to session-scoped scratch storage.\n\n    Plan snapshots preserve the original plan content at save time, creating\n    an immutable record tied to the session. This enables deduplication\n    (detecting if a session already saved a plan) and provides an audit trail\n    (what was the plan content when it was saved).\n\n    Args:\n        session_id: Claude session ID\n        plan_file: Explicit plan file path (highest priority)\n        cwd: Current working directory\n        claude_installation: ClaudeInstallation gateway for plan discovery\n        repo_root: Repository root for scratch directory\n\n    Returns:\n        PlanSnapshot with archive path, or None if no plan file found.\n    \"\"\"\n    if plan_file is not None:\n        snapshot_path = plan_file\n    else:\n        snapshot_path = claude_installation.find_plan_for_session(cwd, session_id)\n\n    if snapshot_path is None or not snapshot_path.exists():\n        return None\n\n    return snapshot_plan_for_session(\n        session_id=session_id,\n        plan_file_path=snapshot_path,\n        project_cwd=cwd,\n        claude_installation=claude_installation,\n        repo_root=repo_root,\n    )\n\n\ndef _save_as_draft_pr(\n    ctx: click.Context,\n    *,\n    plan_content: str,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    output_format: str,\n    plan_file: Path | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Save plan as a draft PR.\n\n    Creates a branch, pushes it, then creates a draft PR with plan content.\n\n    Args:\n        ctx: Click context\n        plan_content: Validated plan content\n        session_id: Session ID for markers\n        objective_issue: Optional objective issue number\n        plan_type: Plan type (standard or learn)\n        output_format: Output format (json or display)\n        plan_file: Original plan file path (for snapshot)\n        learned_from_issue: Parent plan issue number (for learn plans)\n        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    github_issues = require_issues(ctx)\n    config = require_local_config(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )\n\n    # Create branch with Graphite tracking (handles both creation and stack metadata)\n    branch_manager = require_branch_manager(ctx)\n    current_branch = git.branch.get_current_branch(cwd)\n    start_point = current_branch if current_branch is not None else \"HEAD\"\n    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n    if isinstance(create_result, BranchAlreadyExists):\n        click.echo(f\"Error: {create_result.message}\", err=True)\n        raise SystemExit(1) from None\n\n    # Detect trunk for PR base metadata\n    trunk = git.branch.detect_trunk_branch(cwd)\n\n    # Build ref.json data\n    ref_data: dict[str, str | int | None] = {\n        \"provider\": \"github-draft-pr\",\n        \"title\": title,\n    }\n    if objective_issue is not None:\n        ref_data[\"objective_id\"] = objective_issue\n\n    # Commit plan files directly to branch (no checkout needed).\n    # Uses git plumbing to avoid race conditions when multiple sessions\n    # share the same worktree.\n    git.commit.commit_files_to_branch(\n        repo_root,\n        branch=branch_name,\n        files={\n            f\"{IMPL_CONTEXT_DIR}/plan.md\": plan_content,\n            f\"{IMPL_CONTEXT_DIR}/ref.json\": json.dumps(ref_data, indent=2),\n        },\n        message=f\"Add plan: {title}\",\n    )\n    git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n\n    # Build metadata\n    metadata: dict[str, object] = {\"branch_name\": branch_name, \"trunk_branch\": trunk}\n\n    if config.plans_repo is not None:\n        metadata[\"source_repo\"] = get_repo_identifier(ctx)\n\n    if objective_issue is not None:\n        metadata[\"objective_issue\"] = objective_issue\n\n    if session_id is not None:\n        metadata[\"created_from_session\"] = session_id\n\n    if learned_from_issue is not None:\n        metadata[\"learned_from_issue\"] = learned_from_issue\n\n    if created_from_workflow_run_url is not None:\n        metadata[\"created_from_workflow_run_url\"] = created_from_workflow_run_url","numLines":200,"startLine":1,"totalLines":445}}}
{"parentUuid":"e63aca99-a3d4-4341-b035-720dc472da77","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DvtpkQfr6WeT4s6CBWQumK","type":"tool_result","content":"     1→\"\"\"Shared dispatch logic for one-shot autonomous execution.\n     2→\n     3→Extracts the branch-create/push/PR/workflow-trigger sequence into reusable\n     4→pieces so both `erk one-shot` and `erk objective plan --one-shot` can\n     5→dispatch tasks through the same CI workflow.\n     6→\"\"\"\n     7→\n     8→import logging\n     9→from dataclasses import dataclass\n    10→from datetime import UTC\n    11→\n    12→import click\n    13→\n    14→from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\n    15→from erk.cli.ensure import Ensure\n    16→from erk.core.context import ErkContext, NoRepoSentinel, RepoContext\n    17→from erk_shared.gateway.git.remote_ops.types import PushError\n    18→from erk_shared.gateway.github.metadata.core import (\n    19→    create_submission_queued_block,\n    20→    render_erk_issue_event,\n    21→)\n    22→from erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\n    23→from erk_shared.gateway.github.parsing import construct_workflow_run_url\n    24→from erk_shared.gateway.github.plan_issues import create_plan_issue\n    25→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    26→from erk_shared.gateway.time.abc import Time\n    27→from erk_shared.naming import (\n    28→    format_branch_timestamp_suffix,\n    29→    generate_draft_pr_branch_name,\n    30→    generate_issue_branch_name,\n    31→    sanitize_worktree_name,\n    32→)\n    33→from erk_shared.output.output import user_output\n    34→from erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n    35→\n    36→logger = logging.getLogger(__name__)\n    37→\n    38→ONE_SHOT_WORKFLOW = \"one-shot.yml\"\n    39→\n    40→\n    41→@dataclass(frozen=True)\n    42→class OneShotDispatchParams:\n    43→    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n    44→\n    45→    prompt: str\n    46→    model: str | None\n    47→    extra_workflow_inputs: dict[str, str]\n    48→\n    49→\n    50→@dataclass(frozen=True)\n    51→class OneShotDispatchResult:\n    52→    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n    53→\n    54→    pr_number: int\n    55→    run_id: str\n    56→    branch_name: str\n    57→\n    58→\n    59→def generate_branch_name(\n    60→    prompt: str,\n    61→    *,\n    62→    time: Time,\n    63→    plan_issue_number: int | None,\n    64→    objective_id: int | None,\n    65→) -> str:\n    66→    \"\"\"Generate a branch name from the prompt.\n    67→\n    68→    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    69→    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n    70→\n    71→    Args:\n    72→        prompt: The task description\n    73→        time: Time gateway for deterministic timestamps\n    74→        plan_issue_number: If provided, delegate to generate_issue_branch_name\n    75→        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n    76→\n    77→    Returns:\n    78→        Branch name string\n    79→    \"\"\"\n    80→    if plan_issue_number is not None:\n    81→        return generate_issue_branch_name(\n    82→            plan_issue_number, prompt, time.now(), objective_id=objective_id\n    83→        )\n    84→    slug = sanitize_worktree_name(prompt)\n    85→    prefix = \"oneshot-\"\n    86→    max_slug_len = 31 - len(prefix)\n    87→    if len(slug) > max_slug_len:\n    88→        slug = slug[:max_slug_len].rstrip(\"-\")\n    89→    timestamp = format_branch_timestamp_suffix(time.now())\n    90→    return f\"{prefix}{slug}{timestamp}\"\n    91→\n    92→\n    93→def dispatch_one_shot(\n    94→    ctx: ErkContext,\n    95→    *,\n    96→    params: OneShotDispatchParams,\n    97→    dry_run: bool,\n    98→) -> OneShotDispatchResult | None:\n    99→    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n   100→\n   101→    Creates branch, commits prompt file directly to branch (no checkout),\n   102→    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n   103→    prints what would happen without executing.\n   104→\n   105→    Args:\n   106→        ctx: Erk context with git/github gateways\n   107→        params: Dispatch parameters\n   108→        dry_run: If True, print preview without executing\n   109→\n   110→    Returns:\n   111→        OneShotDispatchResult with pr_number, run_id, branch_name,\n   112→        or None in dry-run mode\n   113→    \"\"\"\n   114→    # Validate we're in a git repo\n   115→    Ensure.invariant(\n   116→        not isinstance(ctx.repo, NoRepoSentinel),\n   117→        \"Not in a git repository\",\n   118→    )\n   119→    assert not isinstance(ctx.repo, NoRepoSentinel)\n   120→    repo: RepoContext = ctx.repo\n   121→\n   122→    # Validate GitHub authentication\n   123→    Ensure.gh_authenticated(ctx)\n   124→\n   125→    # Get GitHub username\n   126→    _, username, _ = ctx.github.check_auth_status()\n   127→    submitted_by = username or \"unknown\"\n   128→\n   129→    # Detect trunk branch\n   130→    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n   131→\n   132→    # Build PR title\n   133→    max_title_len = 60\n   134→    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n   135→    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n   136→\n   137→    if dry_run:\n   138→        # In dry-run, show preview without creating skeleton issue\n   139→        branch_name = generate_branch_name(\n   140→            params.prompt,\n   141→            time=ctx.time,\n   142→            plan_issue_number=None,\n   143→            objective_id=None,\n   144→        )\n   145→        user_output(\n   146→            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n   147→        )\n   148→        user_output(f\"Prompt: {params.prompt}\")\n   149→        user_output(f\"Branch: {branch_name}\")\n   150→        user_output(f\"PR title: {pr_title}\")\n   151→        user_output(f\"Base branch: {trunk}\")\n   152→        user_output(f\"Submitted by: {submitted_by}\")\n   153→        if params.model is not None:\n   154→            user_output(f\"Model: {params.model}\")\n   155→        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n   156→        if params.extra_workflow_inputs:\n   157→            for key, value in params.extra_workflow_inputs.items():\n   158→                user_output(f\"Extra input: {key}={value}\")\n   159→        return None\n   160→\n   161→    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n   162→    objective_id = int(objective_issue_str) if objective_issue_str else None\n   163→\n   164→    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n   165→\n   166→    # --- Backend-conditional entity creation ---\n   167→    # github backend: create skeleton issue first for P<N>- branch naming\n   168→    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n   169→    plan_issue_number: int | None = None\n   170→    if not is_draft_pr:\n   171→        skeleton_plan_content = (\n   172→            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n   173→            f\"**Prompt:** {params.prompt}\"\n   174→        )\n   175→        skeleton_result = create_plan_issue(\n   176→            github_issues=ctx.github.issues,\n   177→            repo_root=repo.root,\n   178→            plan_content=skeleton_plan_content,\n   179→            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n   180→            extra_labels=None,\n   181→            title_tag=None,\n   182→            source_repo=None,\n   183→            objective_id=objective_id,\n   184→            created_from_session=None,\n   185→            created_from_workflow_run_url=None,\n   186→            learned_from_issue=None,\n   187→            lifecycle_stage=\"prompted\",\n   188→        )\n   189→        plan_issue_number = skeleton_result.issue_number\n   190→\n   191→    # Generate branch name\n   192→    if is_draft_pr:\n   193→        # draft_pr: planned/ prefix (no issue number needed)\n   194→        branch_name = generate_draft_pr_branch_name(\n   195→            params.prompt,\n   196→            ctx.time.now(),\n   197→            objective_id=objective_id,\n   198→        )\n   199→    else:\n   200→        # github: P<N>- prefix using skeleton issue number\n   201→        branch_name = generate_branch_name(\n   202→            params.prompt,\n   203→            time=ctx.time,\n   204→            plan_issue_number=plan_issue_number,\n   205→            objective_id=objective_id,\n   206→        )\n   207→\n   208→    # Save current branch for restoration after workflow trigger\n   209→    original_branch = ctx.git.branch.get_current_branch(repo.root)\n   210→    if original_branch is None:\n   211→        user_output(\n   212→            click.style(\"Error: \", fg=\"red\")\n   213→            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n   214→        )\n   215→        raise SystemExit(1)\n   216→\n   217→    # Create branch from trunk\n   218→    user_output(\"Creating branch...\")\n   219→    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n   220→\n   221→    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n   222→    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n   223→    # that the remote workflow copies into .impl/)\n   224→    ctx.git.commit.commit_files_to_branch(\n   225→        repo.root,\n   226→        branch=branch_name,\n   227→        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n   228→        message=f\"One-shot: {params.prompt[:60]}\",\n   229→    )\n   230→\n   231→    # Push to remote\n   232→    user_output(\"Pushing to remote...\")\n   233→    push_result = ctx.git.remote.push_to_remote(\n   234→        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n   235→    )\n   236→    if isinstance(push_result, PushError):\n   237→        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n   238→\n   239→    # --- Create draft PR ---\n   240→    user_output(\"Creating draft PR...\")\n   241→    if is_draft_pr:\n   242→        # draft_pr: create PR with plan-header metadata block\n   243→        _, username_for_header, _ = ctx.github.check_auth_status()\n   244→        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n   245→        metadata_body = format_plan_header_body(\n   246→            created_at=created_at,\n   247→            created_by=username_for_header or \"unknown\",\n   248→            worktree_name=None,\n   249→            branch_name=branch_name,\n   250→            plan_comment_id=None,\n   251→            last_dispatched_run_id=None,\n   252→            last_dispatched_node_id=None,\n   253→            last_dispatched_at=None,\n   254→            last_local_impl_at=None,\n   255→            last_local_impl_event=None,\n   256→            last_local_impl_session=None,\n   257→            last_local_impl_user=None,\n   258→            last_remote_impl_at=None,\n   259→            last_remote_impl_run_id=None,\n   260→            last_remote_impl_session_id=None,\n   261→            source_repo=None,\n   262→            objective_issue=objective_id,\n   263→            created_from_session=None,\n   264→            created_from_workflow_run_url=None,\n   265→            last_learn_session=None,\n   266→            last_learn_at=None,\n   267→            learn_status=None,\n   268→            learn_plan_issue=None,\n   269→            learn_plan_pr=None,\n   270→            learned_from_issue=None,\n   271→            lifecycle_stage=\"prompted\",\n   272→        )\n   273→        placeholder_content = (\n   274→            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n   275→            f\"**Prompt:** {params.prompt}\"\n   276→        )\n   277→        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n   278→        pr_number = ctx.github.create_pr(\n   279→            repo.root,\n   280→            branch_name,\n   281→            pr_title,\n   282→            pr_body_initial,\n   283→            trunk,\n   284→            draft=True,\n   285→        )\n   286→        # Add footer now that we have the PR number.\n   287→        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n   288→        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n   289→        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n   290→        # Add erk-plan label\n   291→        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n   292→\n   293→        # Key: set plan_issue_number = pr_number so downstream code\n   294→        # (workflow inputs, metadata writing, comments) targets the PR\n   295→        plan_issue_number = pr_number\n   296→    else:\n   297→        # github: create plain draft PR with closing reference\n   298→        closing_ref = \"\"\n   299→        if plan_issue_number is not None:\n   300→            plans_repo = ctx.local_config.plans_repo\n   301→            closing_ref = (\n   302→                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n   303→                if plans_repo\n   304→                else f\"\\n\\nCloses #{plan_issue_number}\"\n   305→            )\n   306→        pr_number = ctx.github.create_pr(\n   307→            repo.root,\n   308→            branch_name,\n   309→            pr_title,\n   310→            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n   311→            trunk,\n   312→            draft=True,\n   313→        )\n   314→    user_output(f\"Created draft PR #{pr_number}\")\n   315→\n   316→    # Build workflow inputs\n   317→    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n   318→    max_input_len = 500\n   319→    truncated_prompt = params.prompt[:max_input_len]\n   320→    if len(params.prompt) > max_input_len:\n   321→        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n   322→\n   323→    inputs: dict[str, str] = {\n   324→        \"prompt\": truncated_prompt,\n   325→        \"branch_name\": branch_name,\n   326→        \"pr_number\": str(pr_number),\n   327→        \"submitted_by\": submitted_by,\n   328→        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n   329→    }\n   330→    if params.model is not None:\n   331→        inputs[\"model_name\"] = params.model\n   332→    if plan_issue_number is not None:\n   333→        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n   334→\n   335→    # Merge extra workflow inputs\n   336→    inputs.update(params.extra_workflow_inputs)\n   337→\n   338→    # Trigger workflow\n   339→    user_output(\"Triggering one-shot workflow...\")\n   340→    run_id = ctx.github.trigger_workflow(\n   341→        repo_root=repo.root,\n   342→        workflow=ONE_SHOT_WORKFLOW,\n   343→        inputs=inputs,\n   344→    )\n   345→\n   346→    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n   347→    run_url: str | None = None\n   348→    if repo.github is not None:\n   349→        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n   350→    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n   351→\n   352→    # Update PR body with workflow run link (best-effort)\n   353→    # For github backend: rewrite with prompt + run link + closing ref\n   354→    # For draft_pr backend: skip — metadata block body should not be overwritten\n   355→    if not is_draft_pr and run_url is not None:\n   356→        try:\n   357→            closing_ref = \"\"\n   358→            if plan_issue_number is not None:\n   359→                plans_repo = ctx.local_config.plans_repo\n   360→                closing_ref = (\n   361→                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n   362→                    if plans_repo\n   363→                    else f\"\\n\\nCloses #{plan_issue_number}\"\n   364→                )\n   365→            pr_body = (\n   366→                f\"Autonomous one-shot execution.\\n\\n\"\n   367→                f\"**Prompt:** {params.prompt}\\n\\n\"\n   368→                f\"**Workflow run:** {run_url}{closing_ref}\"\n   369→            )\n   370→            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n   371→        except Exception as e:\n   372→            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n   373→\n   374→    # Write dispatch metadata and post queued comment (best-effort)\n   375→    if plan_issue_number is not None:\n   376→        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n   377→        try:\n   378→            write_dispatch_metadata(\n   379→                plan_backend=ctx.plan_backend,\n   380→                github=ctx.github,\n   381→                repo_root=repo.root,\n   382→                issue_number=plan_issue_number,\n   383→                run_id=run_id,\n   384→                dispatched_at=queued_at,\n   385→            )\n   386→            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n   387→        except Exception as e:\n   388→            user_output(\n   389→                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n   390→            )\n   391→\n   392→        # Post queued event comment to plan entity\n   393→        try:\n   394→            metadata_block = create_submission_queued_block(\n   395→                queued_at=queued_at,\n   396→                submitted_by=submitted_by,\n   397→                issue_number=plan_issue_number,\n   398→                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n   399→                expected_workflow=\"one-shot\",\n   400→            )\n   401→            comment_body = render_erk_issue_event(\n   402→                title=\"\\U0001f504 One-Shot Dispatched\",\n   403→                metadata=metadata_block,\n   404→                description=(\n   405→                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n   406→                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n   407→                    f\"**Prompt:** {params.prompt}\"\n   408→                ),\n   409→            )\n   410→            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n   411→            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n   412→        except Exception as e:\n   413→            user_output(\n   414→                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n   415→            )\n   416→\n   417→    # Display results\n   418→    user_output(\"\")\n   419→    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n   420→    if repo.github is not None and run_url is not None:\n   421→        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n   422→        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n   423→        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n   424→    else:\n   425→        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n   426→\n   427→    return OneShotDispatchResult(\n   428→        pr_number=pr_number,\n   429→        run_id=run_id,\n   430→        branch_name=branch_name,\n   431→    )\n   432→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"aa061f78-58e2-48ab-a1e2-97f68986f7f7","timestamp":"2026-02-22T14:37:45.707Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","content":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","numLines":432,"startLine":1,"totalLines":432}}}
{"parentUuid":"aa061f78-58e2-48ab-a1e2-97f68986f7f7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FipaH5gNtf6n4RtUNDZHJG","type":"tool_result","content":"     1→\"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n     2→\n     3→This exec command fetches a plan from a GitHub issue, creates a feature branch,\n     4→checks it out, and creates the .impl/ folder structure for implementation.\n     5→\n     6→Usage:\n     7→    erk exec setup-impl-from-issue <issue-number> [--session-id <id>]\n     8→\n     9→Output:\n    10→    Structured JSON output with success status and folder details\n    11→\n    12→Exit Codes:\n    13→    0: Success (.impl/ folder created, branch checked out)\n    14→    1: Error (issue not found, plan fetch failed, git operations failed)\n    15→\n    16→Examples:\n    17→    $ erk exec setup-impl-from-issue 1028\n    18→    {\"success\": true, \"impl_path\": \"/path/to/.impl\", \"issue_number\": 1028, \"branch\": \"P1028-...\"}\n    19→\"\"\"\n    20→\n    21→import json\n    22→from pathlib import Path\n    23→\n    24→import click\n    25→\n    26→from erk_shared.context.helpers import (\n    27→    require_branch_manager,\n    28→    require_cwd,\n    29→    require_git,\n    30→    require_github,\n    31→    require_plan_backend,\n    32→    require_repo_root,\n    33→    require_time,\n    34→)\n    35→from erk_shared.gateway.branch_manager.abc import BranchManager\n    36→from erk_shared.gateway.git.abc import Git\n    37→from erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\n    38→from erk_shared.gateway.git.remote_ops.types import PullRebaseError\n    39→from erk_shared.gateway.github.metadata.core import find_metadata_block\n    40→from erk_shared.gateway.github.metadata.schemas import OBJECTIVE_ISSUE\n    41→from erk_shared.gateway.github.types import PRNotFound\n    42→from erk_shared.impl_folder import create_impl_folder, read_plan_ref, save_plan_ref\n    43→from erk_shared.naming import generate_issue_branch_name\n    44→from erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR, extract_plan_content\n    45→from erk_shared.plan_store.types import PlanNotFound\n    46→\n    47→\n    48→def _get_current_branch(git: Git, cwd: Path) -> str:\n    49→    \"\"\"Get current branch via gateway, raising if detached HEAD.\"\"\"\n    50→    branch = git.branch.get_current_branch(cwd)\n    51→    if branch is None:\n    52→        msg = \"Cannot set up implementation from detached HEAD state\"\n    53→        raise click.ClickException(msg)\n    54→    return branch\n    55→\n    56→\n    57→def _checkout_plan_branch(\n    58→    *,\n    59→    git: Git,\n    60→    branch_manager: BranchManager,\n    61→    repo_root: Path,\n    62→    cwd: Path,\n    63→    current_branch: str,\n    64→    branch_name: str,\n    65→) -> None:\n    66→    \"\"\"Fetch, checkout, and sync a draft-PR plan branch.\n    67→\n    68→    Handles three cases:\n    69→    - Already on the branch: just sync\n    70→    - Branch exists locally: checkout and sync\n    71→    - Branch only on remote: create tracking branch (no sync needed)\n    72→\n    73→    Args:\n    74→        git: Git gateway\n    75→        branch_manager: BranchManager for checkout operations\n    76→        repo_root: Repository root\n    77→        cwd: Current working directory\n    78→        current_branch: Name of current branch\n    79→        branch_name: Plan branch to checkout\n    80→    \"\"\"\n    81→    git.remote.fetch_branch(repo_root, \"origin\", branch_name)\n    82→    local_branches = git.branch.list_local_branches(repo_root)\n    83→    needs_sync = True\n    84→\n    85→    if current_branch == branch_name:\n    86→        click.echo(f\"Already on plan branch '{branch_name}', syncing with remote...\", err=True)\n    87→    elif branch_name in local_branches:\n    88→        click.echo(f\"Checking out plan branch '{branch_name}'...\", err=True)\n    89→        branch_manager.checkout_branch(cwd, branch_name)\n    90→    else:\n    91→        click.echo(f\"Creating local tracking branch for '{branch_name}' from remote...\", err=True)\n    92→        branch_manager.create_tracking_branch(repo_root, branch_name, f\"origin/{branch_name}\")\n    93→        branch_manager.checkout_branch(cwd, branch_name)\n    94→        needs_sync = False\n    95→\n    96→    if needs_sync:\n    97→        pull_result = git.remote.pull_rebase(cwd, \"origin\", branch_name)\n    98→        if isinstance(pull_result, PullRebaseError):\n    99→            error_output = {\n   100→                \"success\": False,\n   101→                \"error\": \"pull_rebase_failed\",\n   102→                \"message\": (\n   103→                    f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n   104→                ),\n   105→            }\n   106→            click.echo(json.dumps(error_output), err=True)\n   107→            raise SystemExit(1)\n   108→\n   109→\n   110→def _setup_draft_pr_plan(\n   111→    ctx: click.Context,\n   112→    *,\n   113→    issue_number: int,\n   114→    no_impl: bool,\n   115→) -> dict[str, str | int | bool | None]:\n   116→    \"\"\"Set up implementation from a draft-PR plan.\n   117→\n   118→    Uses github.get_pr() for branch discovery, then reads plan content\n   119→    from .erk/impl-context/ on the branch (falling back to PR body).\n   120→\n   121→    Args:\n   122→        ctx: Click context\n   123→        issue_number: PR number for the draft-PR plan\n   124→        no_impl: Skip .impl/ folder creation\n   125→\n   126→    Returns:\n   127→        Success output dict\n   128→    \"\"\"\n   129→    cwd = require_cwd(ctx)\n   130→    git = require_git(ctx)\n   131→\n   132→    # Early exit: if .impl/ is already set up for this issue (e.g., CI pre-populated it),\n   133→    # skip branch switching. Switching to the plan branch would abandon the implementation\n   134→    # branch, causing work to land on the wrong branch.\n   135→    impl_dir = cwd / \".impl\"\n   136→    if impl_dir.exists():\n   137→        existing_ref = read_plan_ref(impl_dir)\n   138→        if existing_ref is not None and existing_ref.plan_id == str(issue_number):\n   139→            click.echo(\n   140→                f\"Found existing .impl/ for plan #{issue_number}, skipping branch setup\",\n   141→                err=True,\n   142→            )\n   143→            current_branch = _get_current_branch(git, cwd)\n   144→            impl_path_str = str(impl_dir) if not no_impl else None\n   145→            return {\n   146→                \"success\": True,\n   147→                \"impl_path\": impl_path_str,\n   148→                \"issue_number\": issue_number,\n   149→                \"issue_url\": existing_ref.url,\n   150→                \"branch\": current_branch,\n   151→                \"plan_title\": \"\",\n   152→                \"no_impl\": no_impl,\n   153→            }\n   154→\n   155→    repo_root = require_repo_root(ctx)\n   156→    github = require_github(ctx)\n   157→    branch_manager = require_branch_manager(ctx)\n   158→\n   159→    # Phase A: Lightweight PR query for branch name only\n   160→    pr_result = github.get_pr(repo_root, issue_number)\n   161→    if isinstance(pr_result, PRNotFound):\n   162→        error_output = {\n   163→            \"success\": False,\n   164→            \"error\": \"plan_not_found\",\n   165→            \"message\": f\"Could not fetch plan for PR #{issue_number}: PR not found.\",\n   166→        }\n   167→        click.echo(json.dumps(error_output), err=True)\n   168→        raise SystemExit(1)\n   169→\n   170→    branch_name = pr_result.head_ref_name\n   171→    pr_url = pr_result.url\n   172→    current_branch = _get_current_branch(git, cwd)\n   173→\n   174→    # Checkout and sync the plan branch\n   175→    _checkout_plan_branch(\n   176→        git=git,\n   177→        branch_manager=branch_manager,\n   178→        repo_root=repo_root,\n   179→        cwd=cwd,\n   180→        current_branch=current_branch,\n   181→        branch_name=branch_name,\n   182→    )\n   183→\n   184→    # Phase B: After checkout, read plan content from local files or PR body\n   185→    impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n   186→    impl_context_plan = impl_context_dir / \"plan.md\"\n   187→\n   188→    if impl_context_plan.exists():\n   189→        # Read from committed .erk/impl-context/ files\n   190→        plan_content = impl_context_plan.read_text(encoding=\"utf-8\")\n   191→        ref_json_path = impl_context_dir / \"ref.json\"\n   192→        objective_id: int | None = None\n   193→        plan_title: str = pr_result.title\n   194→        if ref_json_path.exists():\n   195→            ref_data = json.loads(ref_json_path.read_text(encoding=\"utf-8\"))\n   196→            raw_objective = ref_data.get(\"objective_id\")\n   197→            if isinstance(raw_objective, int):\n   198→                objective_id = raw_objective\n   199→            raw_title = ref_data.get(\"title\")\n   200→            if isinstance(raw_title, str):\n   201→                plan_title = raw_title\n   202→        # Do not delete here — Step 2d in plan-implement.md handles git rm + commit + push\n   203→    else:\n   204→        # Fallback: extract from PR body (legacy branch or already cleaned up)\n   205→        plan_content = extract_plan_content(pr_result.body)\n   206→        plan_title = pr_result.title\n   207→        objective_id = None\n   208→        block = find_metadata_block(pr_result.body, \"plan-header\")\n   209→        if block is not None:\n   210→            raw_objective = block.data.get(OBJECTIVE_ISSUE)\n   211→            if isinstance(raw_objective, int):\n   212→                objective_id = raw_objective\n   213→\n   214→    # Create .impl/ folder with plan content (unless --no-impl)\n   215→    impl_path_str: str | None = None\n   216→\n   217→    if not no_impl:\n   218→        impl_path = cwd / \".impl\"\n   219→        impl_path_str = str(impl_path)\n   220→\n   221→        create_impl_folder(\n   222→            worktree_path=cwd,\n   223→            plan_content=plan_content,\n   224→            overwrite=True,\n   225→        )\n   226→\n   227→        save_plan_ref(\n   228→            impl_path,\n   229→            provider=\"github-draft-pr\",\n   230→            plan_id=str(issue_number),\n   231→            url=pr_url,\n   232→            labels=(),\n   233→            objective_id=objective_id,\n   234→        )\n   235→\n   236→    return {\n   237→        \"success\": True,\n   238→        \"impl_path\": impl_path_str,\n   239→        \"issue_number\": issue_number,\n   240→        \"issue_url\": pr_url,\n   241→        \"branch\": branch_name,\n   242→        \"plan_title\": plan_title,\n   243→        \"no_impl\": no_impl,\n   244→    }\n   245→\n   246→\n   247→def _setup_issue_plan(\n   248→    ctx: click.Context,\n   249→    *,\n   250→    issue_number: int,\n   251→    no_impl: bool,\n   252→) -> dict[str, str | int | bool | None]:\n   253→    \"\"\"Set up implementation from an issue-based plan.\n   254→\n   255→    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n   256→\n   257→    Args:\n   258→        ctx: Click context\n   259→        issue_number: Issue number for the plan\n   260→        no_impl: Skip .impl/ folder creation\n   261→\n   262→    Returns:\n   263→        Success output dict\n   264→    \"\"\"\n   265→    cwd = require_cwd(ctx)\n   266→    repo_root = require_repo_root(ctx)\n   267→    git = require_git(ctx)\n   268→    plan_backend = require_plan_backend(ctx)\n   269→    time = require_time(ctx)\n   270→\n   271→    # Fetch plan from GitHub issue\n   272→    result = plan_backend.get_plan(repo_root, str(issue_number))\n   273→    if isinstance(result, PlanNotFound):\n   274→        error_output = {\n   275→            \"success\": False,\n   276→            \"error\": \"plan_not_found\",\n   277→            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n   278→            f\"Ensure issue has erk-plan label and plan content.\",\n   279→        }\n   280→        click.echo(json.dumps(error_output), err=True)\n   281→        raise SystemExit(1)\n   282→    plan = result\n   283→\n   284→    current_branch = _get_current_branch(git, cwd)\n   285→    branch_manager = require_branch_manager(ctx)\n   286→\n   287→    # Issue-based plan: generate P{issue}-... branch name\n   288→    # Check if already on a branch for this issue - reuse it\n   289→    expected_prefix = f\"P{issue_number}-\"\n   290→    if current_branch.startswith(expected_prefix):\n   291→        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n   292→        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n   293→        branch_name = current_branch\n   294→    else:\n   295→        # Generate branch name from issue\n   296→        timestamp = time.now()\n   297→        branch_name = generate_issue_branch_name(\n   298→            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n   299→        )\n   300→\n   301→        # Check if branch already exists\n   302→        local_branches = git.branch.list_local_branches(repo_root)\n   303→\n   304→        if branch_name in local_branches:\n   305→            # Branch exists - just check it out\n   306→            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)\n   307→            branch_manager.checkout_branch(cwd, branch_name)\n   308→        else:\n   309→            base_branch = current_branch\n   310→\n   311→            # Create branch using BranchManager (handles Graphite tracking automatically)\n   312→            create_result = branch_manager.create_branch(repo_root, branch_name, base_branch)\n   313→            if isinstance(create_result, BranchAlreadyExists):\n   314→                click.echo(f\"Error: {create_result.message}\", err=True)\n   315→                raise SystemExit(1) from None\n   316→            click.echo(f\"Created branch '{branch_name}' from '{base_branch}'\", err=True)\n   317→\n   318→            branch_manager.checkout_branch(cwd, branch_name)\n   319→\n   320→    # Create .impl/ folder with plan content (unless --no-impl)\n   321→    impl_path_str: str | None = None\n   322→\n   323→    if not no_impl:\n   324→        impl_path = cwd / \".impl\"\n   325→        impl_path_str = str(impl_path)\n   326→\n   327→        create_impl_folder(\n   328→            worktree_path=cwd,\n   329→            plan_content=plan.body,\n   330→            overwrite=True,\n   331→        )\n   332→\n   333→        save_plan_ref(\n   334→            impl_path,\n   335→            provider=\"github\",\n   336→            plan_id=str(issue_number),\n   337→            url=plan.url,\n   338→            labels=(),\n   339→            objective_id=plan.objective_id,\n   340→        )\n   341→\n   342→    return {\n   343→        \"success\": True,\n   344→        \"impl_path\": impl_path_str,\n   345→        \"issue_number\": issue_number,\n   346→        \"issue_url\": plan.url,\n   347→        \"branch\": branch_name,\n   348→        \"plan_title\": plan.title,\n   349→        \"no_impl\": no_impl,\n   350→    }\n   351→\n   352→\n   353→@click.command(name=\"setup-impl-from-issue\")\n   354→@click.argument(\"issue_number\", type=int)\n   355→@click.option(\n   356→    \"--session-id\",\n   357→    default=None,\n   358→    help=\"Claude session ID for marker creation\",\n   359→)\n   360→@click.option(\n   361→    \"--no-impl\",\n   362→    is_flag=True,\n   363→    help=\"Skip .impl/ folder creation (for local execution without file overhead)\",\n   364→)\n   365→@click.pass_context\n   366→def setup_impl_from_issue(\n   367→    ctx: click.Context,\n   368→    issue_number: int,\n   369→    session_id: str | None,\n   370→    no_impl: bool,\n   371→) -> None:\n   372→    \"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n   373→\n   374→    Fetches plan content from GitHub issue, creates/checks out a feature branch,\n   375→    and creates .impl/ folder structure with plan.md, progress.md, and issue.json.\n   376→\n   377→    ISSUE_NUMBER: GitHub issue number containing the plan\n   378→\n   379→    The command:\n   380→    1. Fetches the plan from the GitHub issue or draft PR\n   381→    2. Creates a feature branch from current branch (stacked) or trunk\n   382→    3. Checks out the new branch in the current worktree\n   383→    4. Creates .impl/ folder with plan content\n   384→    5. Saves issue reference for PR linking\n   385→    \"\"\"\n   386→    plan_backend = require_plan_backend(ctx)\n   387→\n   388→    # Dispatch based on plan backend\n   389→    if plan_backend.get_provider_name() == \"github-draft-pr\":\n   390→        output = _setup_draft_pr_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n   391→    else:\n   392→        output = _setup_issue_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n   393→\n   394→    click.echo(json.dumps(output))\n   395→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cc104904-1e35-4158-ab00-e6b6b9995e7a","timestamp":"2026-02-22T14:37:45.707Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","content":"\"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\nThis exec command fetches a plan from a GitHub issue, creates a feature branch,\nchecks it out, and creates the .impl/ folder structure for implementation.\n\nUsage:\n    erk exec setup-impl-from-issue <issue-number> [--session-id <id>]\n\nOutput:\n    Structured JSON output with success status and folder details\n\nExit Codes:\n    0: Success (.impl/ folder created, branch checked out)\n    1: Error (issue not found, plan fetch failed, git operations failed)\n\nExamples:\n    $ erk exec setup-impl-from-issue 1028\n    {\"success\": true, \"impl_path\": \"/path/to/.impl\", \"issue_number\": 1028, \"branch\": \"P1028-...\"}\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.branch_manager.abc import BranchManager\nfrom erk_shared.gateway.git.abc import Git\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError\nfrom erk_shared.gateway.github.metadata.core import find_metadata_block\nfrom erk_shared.gateway.github.metadata.schemas import OBJECTIVE_ISSUE\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.impl_folder import create_impl_folder, read_plan_ref, save_plan_ref\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR, extract_plan_content\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _get_current_branch(git: Git, cwd: Path) -> str:\n    \"\"\"Get current branch via gateway, raising if detached HEAD.\"\"\"\n    branch = git.branch.get_current_branch(cwd)\n    if branch is None:\n        msg = \"Cannot set up implementation from detached HEAD state\"\n        raise click.ClickException(msg)\n    return branch\n\n\ndef _checkout_plan_branch(\n    *,\n    git: Git,\n    branch_manager: BranchManager,\n    repo_root: Path,\n    cwd: Path,\n    current_branch: str,\n    branch_name: str,\n) -> None:\n    \"\"\"Fetch, checkout, and sync a draft-PR plan branch.\n\n    Handles three cases:\n    - Already on the branch: just sync\n    - Branch exists locally: checkout and sync\n    - Branch only on remote: create tracking branch (no sync needed)\n\n    Args:\n        git: Git gateway\n        branch_manager: BranchManager for checkout operations\n        repo_root: Repository root\n        cwd: Current working directory\n        current_branch: Name of current branch\n        branch_name: Plan branch to checkout\n    \"\"\"\n    git.remote.fetch_branch(repo_root, \"origin\", branch_name)\n    local_branches = git.branch.list_local_branches(repo_root)\n    needs_sync = True\n\n    if current_branch == branch_name:\n        click.echo(f\"Already on plan branch '{branch_name}', syncing with remote...\", err=True)\n    elif branch_name in local_branches:\n        click.echo(f\"Checking out plan branch '{branch_name}'...\", err=True)\n        branch_manager.checkout_branch(cwd, branch_name)\n    else:\n        click.echo(f\"Creating local tracking branch for '{branch_name}' from remote...\", err=True)\n        branch_manager.create_tracking_branch(repo_root, branch_name, f\"origin/{branch_name}\")\n        branch_manager.checkout_branch(cwd, branch_name)\n        needs_sync = False\n\n    if needs_sync:\n        pull_result = git.remote.pull_rebase(cwd, \"origin\", branch_name)\n        if isinstance(pull_result, PullRebaseError):\n            error_output = {\n                \"success\": False,\n                \"error\": \"pull_rebase_failed\",\n                \"message\": (\n                    f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n                ),\n            }\n            click.echo(json.dumps(error_output), err=True)\n            raise SystemExit(1)\n\n\ndef _setup_draft_pr_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from a draft-PR plan.\n\n    Uses github.get_pr() for branch discovery, then reads plan content\n    from .erk/impl-context/ on the branch (falling back to PR body).\n\n    Args:\n        ctx: Click context\n        issue_number: PR number for the draft-PR plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n\n    # Early exit: if .impl/ is already set up for this issue (e.g., CI pre-populated it),\n    # skip branch switching. Switching to the plan branch would abandon the implementation\n    # branch, causing work to land on the wrong branch.\n    impl_dir = cwd / \".impl\"\n    if impl_dir.exists():\n        existing_ref = read_plan_ref(impl_dir)\n        if existing_ref is not None and existing_ref.plan_id == str(issue_number):\n            click.echo(\n                f\"Found existing .impl/ for plan #{issue_number}, skipping branch setup\",\n                err=True,\n            )\n            current_branch = _get_current_branch(git, cwd)\n            impl_path_str = str(impl_dir) if not no_impl else None\n            return {\n                \"success\": True,\n                \"impl_path\": impl_path_str,\n                \"issue_number\": issue_number,\n                \"issue_url\": existing_ref.url,\n                \"branch\": current_branch,\n                \"plan_title\": \"\",\n                \"no_impl\": no_impl,\n            }\n\n    repo_root = require_repo_root(ctx)\n    github = require_github(ctx)\n    branch_manager = require_branch_manager(ctx)\n\n    # Phase A: Lightweight PR query for branch name only\n    pr_result = github.get_pr(repo_root, issue_number)\n    if isinstance(pr_result, PRNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for PR #{issue_number}: PR not found.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n\n    branch_name = pr_result.head_ref_name\n    pr_url = pr_result.url\n    current_branch = _get_current_branch(git, cwd)\n\n    # Checkout and sync the plan branch\n    _checkout_plan_branch(\n        git=git,\n        branch_manager=branch_manager,\n        repo_root=repo_root,\n        cwd=cwd,\n        current_branch=current_branch,\n        branch_name=branch_name,\n    )\n\n    # Phase B: After checkout, read plan content from local files or PR body\n    impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n    impl_context_plan = impl_context_dir / \"plan.md\"\n\n    if impl_context_plan.exists():\n        # Read from committed .erk/impl-context/ files\n        plan_content = impl_context_plan.read_text(encoding=\"utf-8\")\n        ref_json_path = impl_context_dir / \"ref.json\"\n        objective_id: int | None = None\n        plan_title: str = pr_result.title\n        if ref_json_path.exists():\n            ref_data = json.loads(ref_json_path.read_text(encoding=\"utf-8\"))\n            raw_objective = ref_data.get(\"objective_id\")\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n            raw_title = ref_data.get(\"title\")\n            if isinstance(raw_title, str):\n                plan_title = raw_title\n        # Do not delete here — Step 2d in plan-implement.md handles git rm + commit + push\n    else:\n        # Fallback: extract from PR body (legacy branch or already cleaned up)\n        plan_content = extract_plan_content(pr_result.body)\n        plan_title = pr_result.title\n        objective_id = None\n        block = find_metadata_block(pr_result.body, \"plan-header\")\n        if block is not None:\n            raw_objective = block.data.get(OBJECTIVE_ISSUE)\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan_content,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github-draft-pr\",\n            plan_id=str(issue_number),\n            url=pr_url,\n            labels=(),\n            objective_id=objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": pr_url,\n        \"branch\": branch_name,\n        \"plan_title\": plan_title,\n        \"no_impl\": no_impl,\n    }\n\n\ndef _setup_issue_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from an issue-based plan.\n\n    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n\n    Args:\n        ctx: Click context\n        issue_number: Issue number for the plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    repo_root = require_repo_root(ctx)\n    git = require_git(ctx)\n    plan_backend = require_plan_backend(ctx)\n    time = require_time(ctx)\n\n    # Fetch plan from GitHub issue\n    result = plan_backend.get_plan(repo_root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n            f\"Ensure issue has erk-plan label and plan content.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n    plan = result\n\n    current_branch = _get_current_branch(git, cwd)\n    branch_manager = require_branch_manager(ctx)\n\n    # Issue-based plan: generate P{issue}-... branch name\n    # Check if already on a branch for this issue - reuse it\n    expected_prefix = f\"P{issue_number}-\"\n    if current_branch.startswith(expected_prefix):\n        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n        branch_name = current_branch\n    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )\n\n        # Check if branch already exists\n        local_branches = git.branch.list_local_branches(repo_root)\n\n        if branch_name in local_branches:\n            # Branch exists - just check it out\n            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)\n            branch_manager.checkout_branch(cwd, branch_name)\n        else:\n            base_branch = current_branch\n\n            # Create branch using BranchManager (handles Graphite tracking automatically)\n            create_result = branch_manager.create_branch(repo_root, branch_name, base_branch)\n            if isinstance(create_result, BranchAlreadyExists):\n                click.echo(f\"Error: {create_result.message}\", err=True)\n                raise SystemExit(1) from None\n            click.echo(f\"Created branch '{branch_name}' from '{base_branch}'\", err=True)\n\n            branch_manager.checkout_branch(cwd, branch_name)\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan.body,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github\",\n            plan_id=str(issue_number),\n            url=plan.url,\n            labels=(),\n            objective_id=plan.objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": plan.url,\n        \"branch\": branch_name,\n        \"plan_title\": plan.title,\n        \"no_impl\": no_impl,\n    }\n\n\n@click.command(name=\"setup-impl-from-issue\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--session-id\",\n    default=None,\n    help=\"Claude session ID for marker creation\",\n)\n@click.option(\n    \"--no-impl\",\n    is_flag=True,\n    help=\"Skip .impl/ folder creation (for local execution without file overhead)\",\n)\n@click.pass_context\ndef setup_impl_from_issue(\n    ctx: click.Context,\n    issue_number: int,\n    session_id: str | None,\n    no_impl: bool,\n) -> None:\n    \"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\n    Fetches plan content from GitHub issue, creates/checks out a feature branch,\n    and creates .impl/ folder structure with plan.md, progress.md, and issue.json.\n\n    ISSUE_NUMBER: GitHub issue number containing the plan\n\n    The command:\n    1. Fetches the plan from the GitHub issue or draft PR\n    2. Creates a feature branch from current branch (stacked) or trunk\n    3. Checks out the new branch in the current worktree\n    4. Creates .impl/ folder with plan content\n    5. Saves issue reference for PR linking\n    \"\"\"\n    plan_backend = require_plan_backend(ctx)\n\n    # Dispatch based on plan backend\n    if plan_backend.get_provider_name() == \"github-draft-pr\":\n        output = _setup_draft_pr_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n    else:\n        output = _setup_issue_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n\n    click.echo(json.dumps(output))\n","numLines":395,"startLine":1,"totalLines":395}}}
{"parentUuid":"cc104904-1e35-4158-ab00-e6b6b9995e7a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Qf4zavspxfpBmif72EjzNC","type":"tool_result","content":"     1→\"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n     2→\n     3→Reads an existing erk-plan GitHub issue, creates a draft PR using the\n     4→draft_pr backend, then closes the original issue with a migration notice.\n     5→\n     6→Usage:\n     7→    erk exec plan-migrate-to-draft-pr <issue_number>\n     8→    erk exec plan-migrate-to-draft-pr <issue_number> --dry-run\n     9→    erk exec plan-migrate-to-draft-pr <issue_number> --format display\n    10→\n    11→Options:\n    12→    --dry-run: Preview the migration without making any changes\n    13→    --format json|display: Output format (default: json)\n    14→\n    15→Exit Codes:\n    16→    0: Success\n    17→    1: Error (issue not found, not an erk-plan, etc.)\n    18→\"\"\"\n    19→\n    20→import json\n    21→\n    22→import click\n    23→\n    24→from erk_shared.context.helpers import (\n    25→    require_cwd,\n    26→    require_git,\n    27→    require_github,\n    28→    require_issues,\n    29→    require_repo_root,\n    30→    require_time,\n    31→)\n    32→from erk_shared.naming import generate_draft_pr_branch_name\n    33→from erk_shared.plan_store.draft_pr import DraftPRPlanBackend\n    34→from erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\n    35→from erk_shared.plan_store.github import GitHubPlanStore\n    36→from erk_shared.plan_store.types import PlanNotFound\n    37→\n    38→\n    39→def _output_error(output_format: str, message: str, error_type: str) -> None:\n    40→    \"\"\"Emit an error in the requested format.\"\"\"\n    41→    if output_format == \"display\":\n    42→        click.echo(f\"Error: {message}\", err=True)\n    43→    else:\n    44→        click.echo(\n    45→            json.dumps(\n    46→                {\n    47→                    \"success\": False,\n    48→                    \"error\": error_type,\n    49→                    \"message\": message,\n    50→                }\n    51→            )\n    52→        )\n    53→\n    54→\n    55→def _output_dry_run(\n    56→    output_format: str,\n    57→    *,\n    58→    issue_number: int,\n    59→    title: str,\n    60→    branch_name: str,\n    61→    trunk: str,\n    62→) -> None:\n    63→    \"\"\"Emit dry-run preview in the requested format.\"\"\"\n    64→    if output_format == \"display\":\n    65→        click.echo(f\"[dry-run] Would migrate issue #{issue_number}: {title}\")\n    66→        click.echo(f\"[dry-run] Would create branch: {branch_name} from {trunk}\")\n    67→        click.echo(\"[dry-run] Would create draft PR from branch\")\n    68→        click.echo(f\"[dry-run] Would close issue #{issue_number}\")\n    69→    else:\n    70→        click.echo(\n    71→            json.dumps(\n    72→                {\n    73→                    \"success\": True,\n    74→                    \"dry_run\": True,\n    75→                    \"original_issue_number\": issue_number,\n    76→                    \"title\": title,\n    77→                    \"branch_name\": branch_name,\n    78→                    \"trunk\": trunk,\n    79→                }\n    80→            )\n    81→        )\n    82→\n    83→\n    84→@click.command(name=\"plan-migrate-to-draft-pr\")\n    85→@click.argument(\"issue_number\", type=int)\n    86→@click.option(\n    87→    \"--dry-run\",\n    88→    is_flag=True,\n    89→    default=False,\n    90→    help=\"Preview the migration without making any changes\",\n    91→)\n    92→@click.option(\n    93→    \"--format\",\n    94→    \"output_format\",\n    95→    type=click.Choice([\"json\", \"display\"]),\n    96→    default=\"json\",\n    97→    help=\"Output format: json (default) or display (formatted text)\",\n    98→)\n    99→@click.pass_context\n   100→def plan_migrate_to_draft_pr(\n   101→    ctx: click.Context,\n   102→    issue_number: int,\n   103→    *,\n   104→    dry_run: bool,\n   105→    output_format: str,\n   106→) -> None:\n   107→    \"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n   108→\n   109→    Reads the plan from the specified GitHub issue, creates a new draft PR\n   110→    with the same content and metadata, then closes the original issue with\n   111→    a migration notice pointing to the new draft PR.\n   112→\n   113→    Preserves: title, plan content, labels (including erk-learn), objective\n   114→    link, and created_from_session from the original issue.\n   115→    \"\"\"\n   116→    repo_root = require_repo_root(ctx)\n   117→    cwd = require_cwd(ctx)\n   118→    git = require_git(ctx)\n   119→    github = require_github(ctx)\n   120→    issues = require_issues(ctx)\n   121→    now = require_time(ctx).now()\n   122→\n   123→    # Fetch the issue plan via GitHubPlanStore\n   124→    issue_store = GitHubPlanStore(issues)\n   125→    plan = issue_store.get_plan(repo_root, str(issue_number))\n   126→    if isinstance(plan, PlanNotFound):\n   127→        _output_error(\n   128→            output_format,\n   129→            f\"Issue #{issue_number} not found\",\n   130→            \"issue_not_found\",\n   131→        )\n   132→        raise SystemExit(1)\n   133→\n   134→    # Validate it has the erk-plan label\n   135→    if \"erk-plan\" not in plan.labels:\n   136→        _output_error(\n   137→            output_format,\n   138→            f\"Issue #{issue_number} does not have the 'erk-plan' label\",\n   139→            \"not_an_erk_plan\",\n   140→        )\n   141→        raise SystemExit(1)\n   142→\n   143→    # Generate draft-PR branch name from trunk\n   144→    trunk = git.branch.detect_trunk_branch(cwd)\n   145→    branch_name = generate_draft_pr_branch_name(\n   146→        plan.title,\n   147→        now,\n   148→        objective_id=plan.objective_id,\n   149→    )\n   150→\n   151→    if dry_run:\n   152→        _output_dry_run(\n   153→            output_format,\n   154→            issue_number=issue_number,\n   155→            title=plan.title,\n   156→            branch_name=branch_name,\n   157→            trunk=trunk,\n   158→        )\n   159→        return\n   160→\n   161→    # Save current branch so we can restore after checkout dance\n   162→    current_branch = git.branch.get_current_branch(cwd)\n   163→    restore_branch = current_branch or \"HEAD\"\n   164→\n   165→    # Create branch from trunk, commit plan file, push\n   166→    git.branch.create_branch(cwd, branch_name, trunk, force=False)\n   167→    git.branch.checkout_branch(cwd, branch_name)\n   168→    try:\n   169→        impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n   170→        impl_context_dir.mkdir(parents=True, exist_ok=True)\n   171→        plan_file = impl_context_dir / \"plan.md\"\n   172→        plan_file.write_text(plan.body, encoding=\"utf-8\")\n   173→        git.commit.stage_files(repo_root, [f\"{IMPL_CONTEXT_DIR}/plan.md\"])\n   174→        git.commit.commit(repo_root, f\"Add plan: {plan.title}\")\n   175→        git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n   176→    finally:\n   177→        git.branch.checkout_branch(cwd, restore_branch)\n   178→\n   179→    # Build metadata for draft PR, preserving key fields from original issue\n   180→    created_from_session = plan.header_fields.get(\"created_from_session\")\n   181→    metadata: dict[str, object] = {\n   182→        k: v\n   183→        for k, v in {\n   184→            \"branch_name\": branch_name,\n   185→            \"trunk_branch\": trunk,\n   186→            \"objective_issue\": plan.objective_id,\n   187→            \"created_from_session\": created_from_session,\n   188→        }.items()\n   189→        if v is not None\n   190→    }\n   191→\n   192→    # Create draft PR via DraftPRPlanBackend\n   193→    draft_backend = DraftPRPlanBackend(github, issues, time=require_time(ctx))\n   194→    result = draft_backend.create_plan(\n   195→        repo_root=repo_root,\n   196→        title=plan.title,\n   197→        content=plan.body,\n   198→        labels=tuple(plan.labels),\n   199→        metadata=metadata,\n   200→    )\n   201→    pr_number = int(result.plan_id)\n   202→    pr_url = result.url\n   203→\n   204→    # Carry over operational metadata from the source issue's plan-header.\n   205→    # create_plan sets these to None; update_metadata restores historical data.\n   206→    _FIELDS_HANDLED_BY_CREATE = {\n   207→        \"schema_version\",\n   208→        \"created_at\",\n   209→        \"created_by\",\n   210→        \"branch_name\",\n   211→        \"plan_comment_id\",\n   212→        \"source_repo\",\n   213→        \"objective_issue\",\n   214→        \"created_from_session\",\n   215→        \"created_from_workflow_run_url\",\n   216→    }\n   217→    operational_fields: dict[str, object] = {\n   218→        k: v\n   219→        for k, v in plan.header_fields.items()\n   220→        if k not in _FIELDS_HANDLED_BY_CREATE and v is not None\n   221→    }\n   222→    if operational_fields:\n   223→        draft_backend.update_metadata(repo_root, str(pr_number), operational_fields)\n   224→\n   225→    # Comment on original issue with migration notice, then close it\n   226→    migration_comment = (\n   227→        f\"Migrated to draft PR #{pr_number}: {pr_url}\\n\\n\"\n   228→        \"This issue has been superseded by the draft PR above.\"\n   229→    )\n   230→    issues.add_comment(repo_root, issue_number, migration_comment)\n   231→    issues.close_issue(repo_root, issue_number)\n   232→\n   233→    if output_format == \"display\":\n   234→        click.echo(f\"Migrated plan #{issue_number} → draft PR #{pr_number}\")\n   235→        click.echo(f\"Title: {plan.title}\")\n   236→        click.echo(f\"PR URL: {pr_url}\")\n   237→        click.echo(f\"Branch: {branch_name}\")\n   238→        click.echo(f\"Original issue #{issue_number} closed.\")\n   239→    else:\n   240→        click.echo(\n   241→            json.dumps(\n   242→                {\n   243→                    \"success\": True,\n   244→                    \"original_issue_number\": issue_number,\n   245→                    \"pr_number\": pr_number,\n   246→                    \"pr_url\": pr_url,\n   247→                    \"branch_name\": branch_name,\n   248→                }\n   249→            )\n   250→        )\n   251→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"16012ae2-af5f-45aa-9628-c538b85f7ceb","timestamp":"2026-02-22T14:37:45.708Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py","content":"\"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\nReads an existing erk-plan GitHub issue, creates a draft PR using the\ndraft_pr backend, then closes the original issue with a migration notice.\n\nUsage:\n    erk exec plan-migrate-to-draft-pr <issue_number>\n    erk exec plan-migrate-to-draft-pr <issue_number> --dry-run\n    erk exec plan-migrate-to-draft-pr <issue_number> --format display\n\nOptions:\n    --dry-run: Preview the migration without making any changes\n    --format json|display: Output format (default: json)\n\nExit Codes:\n    0: Success\n    1: Error (issue not found, not an erk-plan, etc.)\n\"\"\"\n\nimport json\n\nimport click\n\nfrom erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.github import GitHubPlanStore\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _output_error(output_format: str, message: str, error_type: str) -> None:\n    \"\"\"Emit an error in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"Error: {message}\", err=True)\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": False,\n                    \"error\": error_type,\n                    \"message\": message,\n                }\n            )\n        )\n\n\ndef _output_dry_run(\n    output_format: str,\n    *,\n    issue_number: int,\n    title: str,\n    branch_name: str,\n    trunk: str,\n) -> None:\n    \"\"\"Emit dry-run preview in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"[dry-run] Would migrate issue #{issue_number}: {title}\")\n        click.echo(f\"[dry-run] Would create branch: {branch_name} from {trunk}\")\n        click.echo(\"[dry-run] Would create draft PR from branch\")\n        click.echo(f\"[dry-run] Would close issue #{issue_number}\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"dry_run\": True,\n                    \"original_issue_number\": issue_number,\n                    \"title\": title,\n                    \"branch_name\": branch_name,\n                    \"trunk\": trunk,\n                }\n            )\n        )\n\n\n@click.command(name=\"plan-migrate-to-draft-pr\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--dry-run\",\n    is_flag=True,\n    default=False,\n    help=\"Preview the migration without making any changes\",\n)\n@click.option(\n    \"--format\",\n    \"output_format\",\n    type=click.Choice([\"json\", \"display\"]),\n    default=\"json\",\n    help=\"Output format: json (default) or display (formatted text)\",\n)\n@click.pass_context\ndef plan_migrate_to_draft_pr(\n    ctx: click.Context,\n    issue_number: int,\n    *,\n    dry_run: bool,\n    output_format: str,\n) -> None:\n    \"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\n    Reads the plan from the specified GitHub issue, creates a new draft PR\n    with the same content and metadata, then closes the original issue with\n    a migration notice pointing to the new draft PR.\n\n    Preserves: title, plan content, labels (including erk-learn), objective\n    link, and created_from_session from the original issue.\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    issues = require_issues(ctx)\n    now = require_time(ctx).now()\n\n    # Fetch the issue plan via GitHubPlanStore\n    issue_store = GitHubPlanStore(issues)\n    plan = issue_store.get_plan(repo_root, str(issue_number))\n    if isinstance(plan, PlanNotFound):\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} not found\",\n            \"issue_not_found\",\n        )\n        raise SystemExit(1)\n\n    # Validate it has the erk-plan label\n    if \"erk-plan\" not in plan.labels:\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} does not have the 'erk-plan' label\",\n            \"not_an_erk_plan\",\n        )\n        raise SystemExit(1)\n\n    # Generate draft-PR branch name from trunk\n    trunk = git.branch.detect_trunk_branch(cwd)\n    branch_name = generate_draft_pr_branch_name(\n        plan.title,\n        now,\n        objective_id=plan.objective_id,\n    )\n\n    if dry_run:\n        _output_dry_run(\n            output_format,\n            issue_number=issue_number,\n            title=plan.title,\n            branch_name=branch_name,\n            trunk=trunk,\n        )\n        return\n\n    # Save current branch so we can restore after checkout dance\n    current_branch = git.branch.get_current_branch(cwd)\n    restore_branch = current_branch or \"HEAD\"\n\n    # Create branch from trunk, commit plan file, push\n    git.branch.create_branch(cwd, branch_name, trunk, force=False)\n    git.branch.checkout_branch(cwd, branch_name)\n    try:\n        impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n        impl_context_dir.mkdir(parents=True, exist_ok=True)\n        plan_file = impl_context_dir / \"plan.md\"\n        plan_file.write_text(plan.body, encoding=\"utf-8\")\n        git.commit.stage_files(repo_root, [f\"{IMPL_CONTEXT_DIR}/plan.md\"])\n        git.commit.commit(repo_root, f\"Add plan: {plan.title}\")\n        git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n    finally:\n        git.branch.checkout_branch(cwd, restore_branch)\n\n    # Build metadata for draft PR, preserving key fields from original issue\n    created_from_session = plan.header_fields.get(\"created_from_session\")\n    metadata: dict[str, object] = {\n        k: v\n        for k, v in {\n            \"branch_name\": branch_name,\n            \"trunk_branch\": trunk,\n            \"objective_issue\": plan.objective_id,\n            \"created_from_session\": created_from_session,\n        }.items()\n        if v is not None\n    }\n\n    # Create draft PR via DraftPRPlanBackend\n    draft_backend = DraftPRPlanBackend(github, issues, time=require_time(ctx))\n    result = draft_backend.create_plan(\n        repo_root=repo_root,\n        title=plan.title,\n        content=plan.body,\n        labels=tuple(plan.labels),\n        metadata=metadata,\n    )\n    pr_number = int(result.plan_id)\n    pr_url = result.url\n\n    # Carry over operational metadata from the source issue's plan-header.\n    # create_plan sets these to None; update_metadata restores historical data.\n    _FIELDS_HANDLED_BY_CREATE = {\n        \"schema_version\",\n        \"created_at\",\n        \"created_by\",\n        \"branch_name\",\n        \"plan_comment_id\",\n        \"source_repo\",\n        \"objective_issue\",\n        \"created_from_session\",\n        \"created_from_workflow_run_url\",\n    }\n    operational_fields: dict[str, object] = {\n        k: v\n        for k, v in plan.header_fields.items()\n        if k not in _FIELDS_HANDLED_BY_CREATE and v is not None\n    }\n    if operational_fields:\n        draft_backend.update_metadata(repo_root, str(pr_number), operational_fields)\n\n    # Comment on original issue with migration notice, then close it\n    migration_comment = (\n        f\"Migrated to draft PR #{pr_number}: {pr_url}\\n\\n\"\n        \"This issue has been superseded by the draft PR above.\"\n    )\n    issues.add_comment(repo_root, issue_number, migration_comment)\n    issues.close_issue(repo_root, issue_number)\n\n    if output_format == \"display\":\n        click.echo(f\"Migrated plan #{issue_number} → draft PR #{pr_number}\")\n        click.echo(f\"Title: {plan.title}\")\n        click.echo(f\"PR URL: {pr_url}\")\n        click.echo(f\"Branch: {branch_name}\")\n        click.echo(f\"Original issue #{issue_number} closed.\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"original_issue_number\": issue_number,\n                    \"pr_number\": pr_number,\n                    \"pr_url\": pr_url,\n                    \"branch_name\": branch_name,\n                }\n            )\n        )\n","numLines":251,"startLine":1,"totalLines":251}}}
{"parentUuid":"16012ae2-af5f-45aa-9628-c538b85f7ceb","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HMEAbHevayqucvFEUX2hfX","type":"tool_result","content":"     1→\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n     2→\n     3→import logging\n     4→import tomllib\n     5→from collections.abc import Iterator\n     6→from contextlib import contextmanager\n     7→from dataclasses import dataclass\n     8→from datetime import UTC, datetime\n     9→from pathlib import Path\n    10→\n    11→import click\n    12→\n    13→from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\n    14→from erk.cli.commands.slot.common import is_placeholder_branch\n    15→from erk.cli.commands.submit_helpers import ensure_trunk_synced\n    16→from erk.cli.constants import (\n    17→    DISPATCH_WORKFLOW_METADATA_NAME,\n    18→    DISPATCH_WORKFLOW_NAME,\n    19→    ERK_PLAN_LABEL,\n    20→    ERK_PLAN_TITLE_PREFIX,\n    21→    PLAN_HEADING_PREFIX,\n    22→    PLANNED_PR_TITLE_PREFIX,\n    23→)\n    24→from erk.cli.core import discover_repo_context\n    25→from erk.cli.ensure import Ensure, UserFacingCliError\n    26→from erk.core.context import ErkContext\n    27→from erk.core.repo_discovery import RepoContext\n    28→from erk_shared.gateway.branch_manager.types import SubmitBranchError\n    29→from erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\n    30→from erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\n    31→from erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\n    32→from erk_shared.gateway.github.metadata.core import (\n    33→    create_submission_queued_block,\n    34→    render_erk_issue_event,\n    35→)\n    36→from erk_shared.gateway.github.parsing import (\n    37→    construct_pr_url,\n    38→    construct_workflow_run_url,\n    39→    extract_owner_repo_from_github_url,\n    40→)\n    41→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    42→from erk_shared.gateway.github.types import PRNotFound\n    43→from erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\n    44→from erk_shared.naming import generate_issue_branch_name\n    45→from erk_shared.output.output import user_output\n    46→from erk_shared.plan_store.types import PlanNotFound\n    47→from erk_shared.worker_impl_folder import (\n    48→    create_worker_impl_folder,\n    49→    remove_worker_impl_folder,\n    50→    worker_impl_folder_exists,\n    51→)\n    52→\n    53→logger = logging.getLogger(__name__)\n    54→\n    55→\n    56→def _format_issue_ref(issue_number: int, plans_repo: str | None) -> str:\n    57→    \"\"\"Format issue reference for PR body.\n    58→\n    59→    Args:\n    60→        issue_number: The issue number\n    61→        plans_repo: Target repo in \"owner/repo\" format, or None for same repo\n    62→\n    63→    Returns:\n    64→        \"#N\" for same-repo, \"owner/repo#N\" for cross-repo\n    65→    \"\"\"\n    66→    if plans_repo is None:\n    67→        return f\"#{issue_number}\"\n    68→    return f\"{plans_repo}#{issue_number}\"\n    69→\n    70→\n    71→@contextmanager\n    72→def branch_rollback(ctx: ErkContext, repo_root: Path, original_branch: str) -> Iterator[None]:\n    73→    \"\"\"Context manager that restores original branch on exception.\n    74→\n    75→    On success, does nothing (caller handles cleanup).\n    76→    On exception, checks out original_branch and re-raises.\n    77→    \"\"\"\n    78→    try:\n    79→        yield\n    80→    except Exception:\n    81→        user_output(\n    82→            click.style(\"Error: \", fg=\"red\") + \"Operation failed, restoring original branch...\"\n    83→        )\n    84→        ctx.branch_manager.checkout_branch(repo_root, original_branch)\n    85→        raise\n    86→\n    87→\n    88→def is_issue_learn_plan(labels: list[str]) -> bool:\n    89→    \"\"\"Check if an issue is a learn plan by checking for erk-learn label.\n    90→\n    91→    Args:\n    92→        labels: The issue's labels\n    93→\n    94→    Returns:\n    95→        True if the issue has the erk-learn label, False otherwise\n    96→    \"\"\"\n    97→    return \"erk-learn\" in labels\n    98→\n    99→\n   100→def _find_existing_branches_for_issue(\n   101→    ctx: ErkContext,\n   102→    repo_root: Path,\n   103→    issue_number: int,\n   104→) -> list[str]:\n   105→    \"\"\"Find local branches matching P{issue_number}-* pattern.\"\"\"\n   106→    local_branches = ctx.git.branch.list_local_branches(repo_root)\n   107→    prefix = f\"P{issue_number}-\"\n   108→    return sorted([b for b in local_branches if b.startswith(prefix)])\n   109→\n   110→\n   111→def _prompt_existing_branch_action(\n   112→    ctx: ErkContext,\n   113→    repo_root: Path,\n   114→    existing_branches: list[str],\n   115→    new_branch_name: str,\n   116→    *,\n   117→    force: bool,\n   118→) -> str | None:\n   119→    \"\"\"Prompt user to decide what to do with existing branch(es).\n   120→\n   121→    Args:\n   122→        ctx: ErkContext with git operations\n   123→        repo_root: Repository root path\n   124→        existing_branches: List of existing branch names matching the issue pattern\n   125→        new_branch_name: Name for new branch if creating fresh\n   126→        force: If True, delete existing branches without prompting\n   127→\n   128→    Returns:\n   129→        - Branch name to use (existing branch)\n   130→        - None to signal \"create new\" (after deleting existing)\n   131→    \"\"\"\n   132→    if force:\n   133→        user_output(f\"\\nDeleting {len(existing_branches)} existing branch(es) (--force mode):\")\n   134→        for branch in existing_branches:\n   135→            ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n   136→            user_output(f\"  Deleted: {branch}\")\n   137→        return None  # Signal \"create new branch\"\n   138→\n   139→    user_output(\"\\nFound existing local branch(es) for this issue:\")\n   140→    for branch in existing_branches:\n   141→        user_output(f\"  • {branch}\")\n   142→    user_output(f\"\\nNew branch would be: {click.style(new_branch_name, fg='cyan')}\")\n   143→    user_output(\"\")\n   144→\n   145→    # Use newest branch (latest timestamp = last alphabetically)\n   146→    branch_to_use = existing_branches[-1]\n   147→\n   148→    # Single binary prompt\n   149→    reuse = ctx.console.confirm(\n   150→        f\"Reuse existing branch '{branch_to_use}'? \"\n   151→        \"If not, a new branch and PR will be created (old draft PR will be closed)\",\n   152→        default=True,\n   153→    )\n   154→\n   155→    if reuse:\n   156→        return branch_to_use\n   157→\n   158→    # Delete existing branches and signal \"create new\"\n   159→    for branch in existing_branches:\n   160→        ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n   161→        user_output(f\"Deleted branch: {branch}\")\n   162→    return None\n   163→\n   164→\n   165→def get_learn_plan_parent_branch(ctx: ErkContext, repo_root: Path, plan_id: str) -> str | None:\n   166→    \"\"\"Get the parent branch for a learn plan.\n   167→\n   168→    Learn plans should stack on their parent plan's branch.\n   169→    Extracts learned_from_issue via plan_backend, fetches parent's branch_name.\n   170→\n   171→    Args:\n   172→        ctx: ErkContext with plan_backend\n   173→        repo_root: Repository root path\n   174→        plan_id: Plan identifier\n   175→\n   176→    Returns:\n   177→        Parent plan's branch_name if found, None otherwise\n   178→    \"\"\"\n   179→    learned_from = ctx.plan_backend.get_metadata_field(repo_root, plan_id, \"learned_from_issue\")\n   180→    if isinstance(learned_from, PlanNotFound) or learned_from is None:\n   181→        return None\n   182→\n   183→    branch_name = ctx.plan_backend.get_metadata_field(repo_root, str(learned_from), \"branch_name\")\n   184→    if isinstance(branch_name, PlanNotFound) or branch_name is None:\n   185→        return None\n   186→    return str(branch_name)\n   187→\n   188→\n   189→def load_workflow_config(repo_root: Path, workflow_name: str) -> dict[str, str]:\n   190→    \"\"\"Load workflow config from .erk/config.toml [workflows.<name>] section.\n   191→\n   192→    Args:\n   193→        repo_root: Repository root path\n   194→        workflow_name: Workflow filename (with or without .yml/.yaml extension).\n   195→            Only the basename is used for config lookup.\n   196→\n   197→    Returns:\n   198→        Dict of string key-value pairs for workflow inputs.\n   199→        Returns empty dict if config file or section doesn't exist.\n   200→\n   201→    Example:\n   202→        For workflow_name=\"plan-implement.yml\", reads from:\n   203→        .erk/config.toml -> [workflows.plan-implement] section\n   204→    \"\"\"\n   205→    config_path = repo_root / \".erk\" / \"config.toml\"\n   206→\n   207→    if not config_path.exists():\n   208→        return {}\n   209→\n   210→    with open(config_path, \"rb\") as f:\n   211→        data = tomllib.load(f)\n   212→\n   213→    # Extract basename and strip .yml/.yaml extension\n   214→    basename = Path(workflow_name).name\n   215→    config_name = basename.removesuffix(\".yml\").removesuffix(\".yaml\")\n   216→\n   217→    # Get [workflows.<name>] section\n   218→    workflows_section = data.get(\"workflows\", {})\n   219→    workflow_config = workflows_section.get(config_name, {})\n   220→\n   221→    # Convert all values to strings (workflow inputs are always strings)\n   222→    return {k: str(v) for k, v in workflow_config.items()}\n   223→\n   224→\n   225→@dataclass(frozen=True)\n   226→class ValidatedIssue:\n   227→    \"\"\"Issue that passed all validation checks.\"\"\"\n   228→\n   229→    number: int\n   230→    issue: IssueInfo\n   231→    branch_name: str\n   232→    branch_exists: bool\n   233→    pr_number: int | None\n   234→    is_learn_origin: bool\n   235→\n   236→\n   237→@dataclass(frozen=True)\n   238→class SubmitResult:\n   239→    \"\"\"Result of submitting a single issue.\"\"\"\n   240→\n   241→    issue_number: int\n   242→    issue_title: str\n   243→    issue_url: str\n   244→    pr_number: int | None\n   245→    pr_url: str | None\n   246→    workflow_run_id: str\n   247→    workflow_url: str\n   248→\n   249→\n   250→def _build_workflow_run_url(issue_url: str, run_id: str) -> str:\n   251→    \"\"\"Construct GitHub Actions workflow run URL from issue URL and run ID.\n   252→\n   253→    Args:\n   254→        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n   255→        run_id: Workflow run ID\n   256→\n   257→    Returns:\n   258→        Workflow run URL (e.g., https://github.com/owner/repo/actions/runs/1234567890)\n   259→    \"\"\"\n   260→    owner_repo = extract_owner_repo_from_github_url(issue_url)\n   261→    if owner_repo is not None:\n   262→        owner, repo = owner_repo\n   263→        return construct_workflow_run_url(owner, repo, run_id)\n   264→    return f\"https://github.com/actions/runs/{run_id}\"\n   265→\n   266→\n   267→def _strip_plan_markers(title: str) -> str:\n   268→    \"\"\"Strip '[erk-plan]' prefix and 'Plan:' prefix from issue title for use as PR title.\"\"\"\n   269→    result = title\n   270→    # Strip \"[erk-plan] \" prefix if present\n   271→    if result.startswith(ERK_PLAN_TITLE_PREFIX):\n   272→        result = result[len(ERK_PLAN_TITLE_PREFIX) :]\n   273→    # Strip \"Plan: \" prefix if present\n   274→    if result.startswith(PLAN_HEADING_PREFIX):\n   275→        result = result[len(PLAN_HEADING_PREFIX) :]\n   276→    return result\n   277→\n   278→\n   279→def _add_planned_prefix(title: str) -> str:\n   280→    \"\"\"Prepend 'planned/' prefix to PR title (idempotent).\n   281→\n   282→    Args:\n   283→        title: The PR title to prefix\n   284→\n   285→    Returns:\n   286→        The title with 'planned/' prefix, skipping if already prefixed\n   287→    \"\"\"\n   288→    if title.startswith(PLANNED_PR_TITLE_PREFIX):\n   289→        return title\n   290→    return f\"{PLANNED_PR_TITLE_PREFIX}{title}\"\n   291→\n   292→\n   293→def _build_pr_url(issue_url: str, pr_number: int) -> str:\n   294→    \"\"\"Construct GitHub PR URL from issue URL and PR number.\n   295→\n   296→    Args:\n   297→        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n   298→        pr_number: PR number\n   299→\n   300→    Returns:\n   301→        PR URL (e.g., https://github.com/owner/repo/pull/456)\n   302→    \"\"\"\n   303→    owner_repo = extract_owner_repo_from_github_url(issue_url)\n   304→    if owner_repo is not None:\n   305→        owner, repo = owner_repo\n   306→        return construct_pr_url(owner, repo, pr_number)\n   307→    return f\"https://github.com/pull/{pr_number}\"\n   308→\n   309→\n   310→def _close_orphaned_draft_prs(\n   311→    ctx: ErkContext,\n   312→    repo_root: Path,\n   313→    issue_number: int,\n   314→    keep_pr_number: int,\n   315→) -> list[int]:\n   316→    \"\"\"Close old draft PRs linked to an issue, keeping the specified one.\n   317→\n   318→    Returns list of PR numbers that were closed.\n   319→    \"\"\"\n   320→    linked_prs = ctx.issues.get_prs_referencing_issue(repo_root, issue_number)\n   321→\n   322→    closed_prs: list[int] = []\n   323→    for pr in linked_prs:\n   324→        # Close orphaned drafts: draft PRs that are OPEN and not the one we just created\n   325→        # Any draft PR linked to an erk-plan issue is fair game to close\n   326→        if pr.is_draft and pr.state == \"OPEN\" and pr.number != keep_pr_number:\n   327→            ctx.github.close_pr(repo_root, pr.number)\n   328→            closed_prs.append(pr.number)\n   329→\n   330→    return closed_prs\n   331→\n   332→\n   333→@dataclass(frozen=True)\n   334→class ValidatedDraftPR:\n   335→    \"\"\"Draft PR that passed all validation checks.\"\"\"\n   336→\n   337→    number: int\n   338→    title: str\n   339→    url: str\n   340→    branch_name: str\n   341→\n   342→\n   343→def _validate_draft_pr_for_submit(\n   344→    ctx: ErkContext,\n   345→    repo: RepoContext,\n   346→    plan_number: int,\n   347→) -> ValidatedDraftPR:\n   348→    \"\"\"Validate a draft PR plan for submission.\n   349→\n   350→    Fetches the PR, validates it has the erk-plan label and is OPEN.\n   351→\n   352→    Args:\n   353→        ctx: ErkContext with git operations\n   354→        repo: Repository context\n   355→        plan_number: PR number to validate\n   356→\n   357→    Raises:\n   358→        SystemExit: If PR doesn't exist, missing label, or not OPEN.\n   359→    \"\"\"\n   360→    pr_result = ctx.github.get_pr(repo.root, plan_number)\n   361→    if isinstance(pr_result, PRNotFound):\n   362→        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} not found\")\n   363→        raise SystemExit(1)\n   364→\n   365→    # Validate: must have erk-plan label\n   366→    if ERK_PLAN_LABEL not in pr_result.labels:\n   367→        user_output(\n   368→            click.style(\"Error: \", fg=\"red\")\n   369→            + f\"PR #{plan_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n   370→            \"Cannot submit non-plan PRs for automated implementation.\"\n   371→        )\n   372→        raise SystemExit(1)\n   373→\n   374→    # Validate: must be OPEN\n   375→    if pr_result.state != \"OPEN\":\n   376→        user_output(\n   377→            click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} is {pr_result.state}\\n\\n\"\n   378→            \"Cannot submit closed PRs for automated implementation.\"\n   379→        )\n   380→        raise SystemExit(1)\n   381→\n   382→    return ValidatedDraftPR(\n   383→        number=plan_number,\n   384→        title=pr_result.title,\n   385→        url=pr_result.url,\n   386→        branch_name=pr_result.head_ref_name,\n   387→    )\n   388→\n   389→\n   390→def _submit_draft_pr_plan(\n   391→    ctx: ErkContext,\n   392→    *,\n   393→    repo: RepoContext,\n   394→    validated: ValidatedDraftPR,\n   395→    submitted_by: str,\n   396→    original_branch: str,\n   397→    base_branch: str,\n   398→) -> SubmitResult:\n   399→    \"\"\"Submit a validated draft-PR plan for implementation.\n   400→\n   401→    For draft-PR plans, the branch and PR already exist. This function:\n   402→    - Fetches and checks out the existing plan branch\n   403→    - Creates .worker-impl/ with provider=\"github-draft-pr\"\n   404→    - Commits and pushes .worker-impl/ to existing branch\n   405→    - Triggers the workflow with plan_backend=\"draft_pr\"\n   406→\n   407→    Args:\n   408→        ctx: ErkContext with git operations\n   409→        repo: Repository context\n   410→        validated: Validated draft PR information\n   411→        submitted_by: GitHub username of submitter\n   412→        original_branch: Original branch name (to restore after)\n   413→        base_branch: Base branch for PR\n   414→\n   415→    Returns:\n   416→        SubmitResult with URLs and identifiers.\n   417→    \"\"\"\n   418→    plan_number = validated.number\n   419→    branch_name = validated.branch_name\n   420→\n   421→    # Fetch plan content via PlanBackend\n   422→    user_output(\"Fetching plan content...\")\n   423→    result = ctx.plan_store.get_plan(repo.root, str(plan_number))\n   424→    if isinstance(result, PlanNotFound):\n   425→        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number}: plan content not found\")\n   426→        raise SystemExit(1)\n   427→    plan = result\n   428→\n   429→    # Fetch and checkout the existing plan branch\n   430→    user_output(f\"Checking out existing plan branch: {click.style(branch_name, fg='cyan')}\")\n   431→    ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n   432→\n   433→    local_branches = ctx.git.branch.list_local_branches(repo.root)\n   434→    if branch_name not in local_branches:\n   435→        remote_ref = f\"origin/{branch_name}\"\n   436→        ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n   437→\n   438→    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n   439→\n   440→    # Sync local branch with remote (may be behind from prior submission or CI)\n   441→    pull_result = ctx.git.remote.pull_rebase(repo.root, \"origin\", branch_name)\n   442→    if isinstance(pull_result, PullRebaseError):\n   443→        raise UserFacingCliError(\n   444→            f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n   445→        )\n   446→\n   447→    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n   448→    if worker_impl_folder_exists(repo.root):\n   449→        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n   450→        remove_worker_impl_folder(repo.root)\n   451→\n   452→    # Create .worker-impl/ with draft-PR provider\n   453→    user_output(\"Creating .worker-impl/ folder...\")\n   454→    create_worker_impl_folder(\n   455→        plan_content=plan.body,\n   456→        plan_id=str(plan_number),\n   457→        url=validated.url,\n   458→        repo_root=repo.root,\n   459→        provider=\"github-draft-pr\",\n   460→        objective_id=plan.objective_id,\n   461→    )\n   462→\n   463→    # Stage, commit, and push\n   464→    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n   465→    ctx.git.commit.commit(repo.root, f\"Add plan for PR #{plan_number}\")\n   466→    push_result = ctx.git.remote.push_to_remote(\n   467→        repo.root, \"origin\", branch_name, set_upstream=False, force=False\n   468→    )\n   469→    if isinstance(push_result, PushError):\n   470→        raise UserFacingCliError(push_result.message)\n   471→    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n   472→\n   473→    # Switch back to original branch\n   474→    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n   475→\n   476→    # Gather submission metadata\n   477→    queued_at = datetime.now(UTC).isoformat()\n   478→\n   479→    # Load workflow-specific config\n   480→    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n   481→\n   482→    # Build inputs dict with plan_backend=\"draft_pr\"\n   483→    user_output(\"\")\n   484→    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n   485→\n   486→    inputs = {\n   487→        \"plan_id\": str(plan_number),\n   488→        \"submitted_by\": submitted_by,\n   489→        \"plan_title\": validated.title,\n   490→        \"branch_name\": branch_name,\n   491→        \"pr_number\": str(plan_number),\n   492→        \"base_branch\": base_branch,\n   493→        \"plan_backend\": \"draft_pr\",\n   494→        **workflow_config,\n   495→    }\n   496→\n   497→    run_id = ctx.github.trigger_workflow(\n   498→        repo_root=repo.root,\n   499→        workflow=DISPATCH_WORKFLOW_NAME,\n   500→        inputs=inputs,\n   501→    )\n   502→    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n   503→\n   504→    # Compute workflow URL\n   505→    workflow_url = _build_workflow_run_url(validated.url, run_id)\n   506→\n   507→    # Write dispatch metadata FIRST (before any PR body modification)\n   508→    try:\n   509→        write_dispatch_metadata(\n   510→            plan_backend=ctx.plan_backend,\n   511→            github=ctx.github,\n   512→            repo_root=repo.root,\n   513→            issue_number=plan_number,\n   514→            run_id=run_id,\n   515→            dispatched_at=queued_at,\n   516→        )\n   517→        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written\")\n   518→    except Exception as e:\n   519→        user_output(\n   520→            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n   521→        )\n   522→\n   523→    # Update PR body with workflow run link (best-effort)\n   524→    # Guard: only append if body is non-empty to avoid overwriting metadata block\n   525→    try:\n   526→        pr_details = ctx.github.get_pr(repo.root, plan_number)\n   527→        if not isinstance(pr_details, PRNotFound) and pr_details.body:\n   528→            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n   529→            ctx.github.update_pr_body(repo.root, plan_number, updated_body)\n   530→    except Exception as e:\n   531→        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n   532→\n   533→    # Post queued event comment via PlanBackend\n   534→    try:\n   535→        validation_results = {\n   536→            \"pr_is_open\": True,\n   537→            \"has_erk_plan_label\": True,\n   538→        }\n   539→\n   540→        metadata_block = create_submission_queued_block(\n   541→            queued_at=queued_at,\n   542→            submitted_by=submitted_by,\n   543→            issue_number=plan_number,\n   544→            validation_results=validation_results,\n   545→            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n   546→        )\n   547→\n   548→        comment_body = render_erk_issue_event(\n   549→            title=\"🔄 Plan Queued for Implementation\",\n   550→            metadata=metadata_block,\n   551→            description=(\n   552→                f\"Plan submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n   553→                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n   554→                f\"triggered via direct dispatch.\\n\\n\"\n   555→                f\"**Workflow run:** {workflow_url}\"\n   556→            ),\n   557→        )\n   558→\n   559→        user_output(\"Posting queued event comment...\")\n   560→        ctx.plan_backend.add_comment(repo.root, str(plan_number), comment_body)\n   561→        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n   562→    except Exception as e:\n   563→        user_output(\n   564→            click.style(\"Warning: \", fg=\"yellow\")\n   565→            + f\"Failed to post queued comment: {e}\\n\"\n   566→            + \"Workflow is already running.\"\n   567→        )\n   568→\n   569→    pr_url = _build_pr_url(validated.url, plan_number)\n   570→\n   571→    return SubmitResult(\n   572→        issue_number=plan_number,\n   573→        issue_title=validated.title,\n   574→        issue_url=validated.url,\n   575→        pr_number=plan_number,\n   576→        pr_url=pr_url,\n   577→        workflow_run_id=run_id,\n   578→        workflow_url=workflow_url,\n   579→    )\n   580→\n   581→\n   582→def _validate_issue_for_submit(\n   583→    ctx: ErkContext,\n   584→    repo: RepoContext,\n   585→    issue_number: int,\n   586→    base_branch: str,\n   587→    *,\n   588→    force: bool,\n   589→) -> ValidatedIssue:\n   590→    \"\"\"Validate a single issue for submission.\n   591→\n   592→    Fetches the issue, validates constraints, derives branch name, and checks\n   593→    if branch/PR already exist.\n   594→\n   595→    Args:\n   596→        ctx: ErkContext with git operations\n   597→        repo: Repository context\n   598→        issue_number: GitHub issue number to validate\n   599→        base_branch: Base branch for PR (trunk or custom feature branch)\n   600→\n   601→    Raises:\n   602→        SystemExit: If issue doesn't exist, missing label, or closed.\n   603→    \"\"\"\n   604→    # Fetch issue from GitHub\n   605→    issue = ctx.issues.get_issue(repo.root, issue_number)\n   606→    if isinstance(issue, IssueNotFound):\n   607→        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue.issue_number} not found\")\n   608→        raise SystemExit(1)\n   609→\n   610→    # Validate: must have erk-plan label\n   611→    if ERK_PLAN_LABEL not in issue.labels:\n   612→        user_output(\n   613→            click.style(\"Error: \", fg=\"red\")\n   614→            + f\"Issue #{issue_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n   615→            \"Cannot submit non-plan issues for automated implementation.\\n\"\n   616→            \"To create a plan, use Plan Mode then /erk:plan-save\"\n   617→        )\n   618→        raise SystemExit(1)\n   619→\n   620→    # Validate: must be OPEN\n   621→    if issue.state != \"OPEN\":\n   622→        user_output(\n   623→            click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} is {issue.state}\\n\\n\"\n   624→            \"Cannot submit closed issues for automated implementation.\"\n   625→        )\n   626→        raise SystemExit(1)\n   627→\n   628→    # Use provided base_branch instead of detecting trunk\n   629→    logger.debug(\"base_branch=%s\", base_branch)\n   630→\n   631→    # Check for existing local branches BEFORE computing new name\n   632→    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n   633→\n   634→    # Compute branch name using canonical naming function\n   635→    objective_id_raw = ctx.plan_backend.get_metadata_field(\n   636→        repo.root, str(issue_number), \"objective_issue\"\n   637→    )\n   638→    objective_id: int | None = None\n   639→    if isinstance(objective_id_raw, int):\n   640→        objective_id = objective_id_raw\n   641→    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n   642→        objective_id = int(objective_id_raw)\n   643→    new_branch_name = generate_issue_branch_name(\n   644→        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n   645→    )\n   646→\n   647→    if existing_branches:\n   648→        chosen = _prompt_existing_branch_action(\n   649→            ctx, repo.root, existing_branches, new_branch_name, force=force\n   650→        )\n   651→        branch_name = chosen if chosen is not None else new_branch_name\n   652→    else:\n   653→        branch_name = new_branch_name\n   654→\n   655→    logger.debug(\"branch_name=%s\", branch_name)\n   656→    user_output(f\"Computed branch: {click.style(branch_name, fg='cyan')}\")\n   657→\n   658→    # Check if branch already exists on remote and has a PR\n   659→    branch_exists = ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", branch_name)\n   660→    logger.debug(\"branch_exists_on_remote(%s)=%s\", branch_name, branch_exists)\n   661→\n   662→    pr_number: int | None = None\n   663→    if branch_exists:\n   664→        pr_details = ctx.github.get_pr_for_branch(repo.root, branch_name)\n   665→        if not isinstance(pr_details, PRNotFound):\n   666→            pr_number = pr_details.number\n   667→\n   668→    # Check if this issue is a learn plan\n   669→    is_learn_origin = is_issue_learn_plan(issue.labels)\n   670→\n   671→    return ValidatedIssue(\n   672→        number=issue_number,\n   673→        issue=issue,\n   674→        branch_name=branch_name,\n   675→        branch_exists=branch_exists,\n   676→        pr_number=pr_number,\n   677→        is_learn_origin=is_learn_origin,\n   678→    )\n   679→\n   680→\n   681→def _create_branch_and_pr(\n   682→    ctx: ErkContext,\n   683→    *,\n   684→    repo: RepoContext,\n   685→    validated: ValidatedIssue,\n   686→    branch_name: str,\n   687→    base_branch: str,\n   688→    submitted_by: str,\n   689→    original_branch: str,\n   690→) -> int:\n   691→    \"\"\"Create branch, commit, push, and create draft PR.\n   692→\n   693→    This function is called within the branch_rollback context manager.\n   694→    On any exception, the context manager will restore the original branch.\n   695→\n   696→    Args:\n   697→        ctx: ErkContext with git operations\n   698→        repo: Repository context\n   699→        validated: Validated issue information\n   700→        branch_name: Name of branch to create\n   701→        base_branch: Base branch for PR\n   702→        submitted_by: GitHub username of submitter\n   703→        original_branch: Original branch name (for cleanup on success)\n   704→\n   705→    Returns:\n   706→        PR number of the created draft PR.\n   707→    \"\"\"\n   708→    issue = validated.issue\n   709→    issue_number = validated.number\n   710→\n   711→    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n   712→\n   713→    # Get plan content and create .worker-impl/ folder\n   714→    user_output(\"Fetching plan content...\")\n   715→    result = ctx.plan_store.get_plan(repo.root, str(issue_number))\n   716→    if isinstance(result, PlanNotFound):\n   717→        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} not found\")\n   718→        raise SystemExit(1)\n   719→    plan = result\n   720→\n   721→    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n   722→    if worker_impl_folder_exists(repo.root):\n   723→        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n   724→        remove_worker_impl_folder(repo.root)\n   725→\n   726→    user_output(\"Creating .worker-impl/ folder...\")\n   727→    create_worker_impl_folder(\n   728→        plan_content=plan.body,\n   729→        plan_id=str(issue_number),\n   730→        url=issue.url,\n   731→        repo_root=repo.root,\n   732→        provider=\"github\",\n   733→        objective_id=plan.objective_id,\n   734→    )\n   735→\n   736→    # Stage, commit, and push\n   737→    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n   738→    ctx.git.commit.commit(repo.root, f\"Add plan for issue #{issue_number}\")\n   739→    push_result = ctx.git.remote.push_to_remote(\n   740→        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n   741→    )\n   742→    if isinstance(push_result, PushError):\n   743→        raise UserFacingCliError(push_result.message)\n   744→    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n   745→\n   746→    # Create draft PR\n   747→    # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n   748→    # MUST be in the initial body passed to create_pr(), NOT added via update.\n   749→    # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n   750→    # updated when the body is edited afterward.\n   751→    user_output(\"Creating draft PR...\")\n   752→    plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n   753→    issue_ref = _format_issue_ref(issue_number, plans_repo)\n   754→    pr_body = (\n   755→        f\"**Author:** @{submitted_by}\\n\"\n   756→        f\"**Plan:** {issue_ref}\\n\\n\"\n   757→        f\"**Status:** Queued for implementation\\n\\n\"\n   758→        f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n   759→        f\"## Implementation Plan\\n\\n\"\n   760→        f\"<details>\\n\"\n   761→        f\"<summary><strong>Implementation Plan</strong> (Issue #{issue_number})</summary>\\n\\n\"\n   762→        f\"{plan.body}\\n\\n\"\n   763→        f\"</details>\\n\\n\"\n   764→        f\"---\\n\\n\"\n   765→        f\"Closes {issue_ref}\"\n   766→    )\n   767→    pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n   768→    pr_number = ctx.github.create_pr(\n   769→        repo_root=repo.root,\n   770→        branch=branch_name,\n   771→        title=pr_title,\n   772→        body=pr_body,\n   773→        base=base_branch,\n   774→        draft=True,\n   775→    )\n   776→    user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n   777→\n   778→    # Update PR body with checkout command footer\n   779→    footer = build_pr_body_footer(\n   780→        pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n   781→    )\n   782→    ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n   783→\n   784→    # Add extraction skip label if this is a learn plan\n   785→    if validated.is_learn_origin:\n   786→        ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n   787→        # FUTURE ENHANCEMENT: When a learn plan issue gets a PR, update the parent\n   788→        # plan's learn_status from \"completed_with_plan\" to track the PR number.\n   789→        # Currently, the parent only gets updated when the learn plan's PR lands\n   790→        # (in land_cmd._update_parent_learn_status_if_learn_plan). Adding an\n   791→        # intermediate state here would let the TUI show the PR number (e.g.,\n   792→        # \"🚧 #5514\") instead of the learn plan issue number (e.g., \"#5508\")\n   793→        # while the PR is still in review.\n   794→        # See: LearnStatusValue in erk_shared/github/metadata/schemas.py\n   795→\n   796→    # Link PR with Graphite (if enabled)\n   797→    if ctx.branch_manager.is_graphite_managed():\n   798→        user_output(\"Linking PR with Graphite...\")\n   799→        submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n   800→        if isinstance(submit_result, SubmitBranchError):\n   801→            user_output(\n   802→                click.style(\"✗\", fg=\"red\")\n   803→                + f\" Failed to link PR with Graphite: {submit_result.message}\"\n   804→            )\n   805→        else:\n   806→            user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n   807→\n   808→    # Close any orphaned draft PRs for this issue\n   809→    closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n   810→    if closed_prs:\n   811→        user_output(\n   812→            click.style(\"✓\", fg=\"green\")\n   813→            + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n   814→            + \", \".join(f\"#{n}\" for n in closed_prs)\n   815→        )\n   816→\n   817→    # Switch back to original branch (keep the new branch for Graphite lineage)\n   818→    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n   819→\n   820→    return pr_number\n   821→\n   822→\n   823→def _submit_single_issue(\n   824→    ctx: ErkContext,\n   825→    *,\n   826→    repo: RepoContext,\n   827→    validated: ValidatedIssue,\n   828→    submitted_by: str,\n   829→    original_branch: str,\n   830→    base_branch: str,\n   831→) -> SubmitResult:\n   832→    \"\"\"Submit a single validated issue for implementation.\n   833→\n   834→    Creates branch/PR if needed and triggers workflow.\n   835→\n   836→    Args:\n   837→        ctx: ErkContext with git operations\n   838→        repo: Repository context\n   839→        validated: Validated issue information\n   840→        submitted_by: GitHub username of submitter\n   841→        original_branch: Original branch name (to restore after)\n   842→        base_branch: Base branch for PR (trunk or custom feature branch)\n   843→\n   844→    Returns:\n   845→        SubmitResult with URLs and identifiers.\n   846→    \"\"\"\n   847→    issue = validated.issue\n   848→    issue_number = validated.number\n   849→    branch_name = validated.branch_name\n   850→    branch_exists = validated.branch_exists\n   851→    pr_number = validated.pr_number\n   852→\n   853→    if branch_exists:\n   854→        if pr_number is not None:\n   855→            user_output(\n   856→                f\"PR #{pr_number} already exists for branch '{branch_name}' (state: existing)\"\n   857→            )\n   858→            user_output(\"Skipping branch/PR creation, triggering workflow...\")\n   859→        else:\n   860→            # Branch exists but no PR - need to add a commit for PR creation\n   861→            user_output(f\"Branch '{branch_name}' exists but no PR. Adding placeholder commit...\")\n   862→\n   863→            # Fetch and checkout the remote branch locally\n   864→            ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n   865→\n   866→            # Only create tracking branch if it doesn't exist locally (LBYL)\n   867→            local_branches = ctx.git.branch.list_local_branches(repo.root)\n   868→            if branch_name not in local_branches:\n   869→                remote_ref = f\"origin/{branch_name}\"\n   870→                ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n   871→\n   872→            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n   873→\n   874→            # Create empty commit as placeholder for PR creation\n   875→            ctx.git.commit.commit(\n   876→                repo.root,\n   877→                f\"[erk-plan] Initialize implementation for issue #{issue_number}\",\n   878→            )\n   879→            push_result = ctx.git.remote.push_to_remote(\n   880→                repo.root, \"origin\", branch_name, set_upstream=False, force=False\n   881→            )\n   882→            if isinstance(push_result, PushError):\n   883→                raise UserFacingCliError(push_result.message)\n   884→            user_output(click.style(\"✓\", fg=\"green\") + \" Placeholder commit pushed\")\n   885→\n   886→            # Now create the PR\n   887→            # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n   888→            # MUST be in the initial body passed to create_pr(), NOT added via update.\n   889→            # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n   890→            # updated when the body is edited afterward.\n   891→            plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n   892→            issue_ref = _format_issue_ref(issue_number, plans_repo)\n   893→            pr_body = (\n   894→                f\"**Author:** @{submitted_by}\\n\"\n   895→                f\"**Plan:** {issue_ref}\\n\\n\"\n   896→                f\"**Status:** Queued for implementation\\n\\n\"\n   897→                f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n   898→                f\"---\\n\\n\"\n   899→                f\"Closes {issue_ref}\"\n   900→            )\n   901→            pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n   902→            pr_number = ctx.github.create_pr(\n   903→                repo_root=repo.root,\n   904→                branch=branch_name,\n   905→                title=pr_title,\n   906→                body=pr_body,\n   907→                base=base_branch,\n   908→                draft=True,\n   909→            )\n   910→            user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n   911→\n   912→            # Update PR body with checkout command footer\n   913→            footer = build_pr_body_footer(\n   914→                pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n   915→            )\n   916→            ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n   917→\n   918→            # Add extraction skip label if this is a learn plan\n   919→            if validated.is_learn_origin:\n   920→                ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n   921→                # FUTURE ENHANCEMENT: See comment in _create_branch_and_pr for\n   922→                # updating parent plan's learn_status when learn plan gets a PR.\n   923→\n   924→            # Link PR with Graphite (if enabled)\n   925→            if ctx.branch_manager.is_graphite_managed():\n   926→                user_output(\"Linking PR with Graphite...\")\n   927→                submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n   928→                if isinstance(submit_result, SubmitBranchError):\n   929→                    user_output(\n   930→                        click.style(\"✗\", fg=\"red\")\n   931→                        + f\" Failed to link PR with Graphite: {submit_result.message}\"\n   932→                    )\n   933→                else:\n   934→                    user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n   935→\n   936→            # Close any orphaned draft PRs\n   937→            closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n   938→            if closed_prs:\n   939→                user_output(\n   940→                    click.style(\"✓\", fg=\"green\")\n   941→                    + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n   942→                    + \", \".join(f\"#{n}\" for n in closed_prs)\n   943→                )\n   944→\n   945→            # Switch back to original branch (keep the new branch for Graphite lineage)\n   946→            ctx.branch_manager.checkout_branch(repo.root, original_branch)\n   947→    else:\n   948→        # Check if branch exists locally (user chose to reuse existing)\n   949→        local_branches = ctx.git.branch.list_local_branches(repo.root)\n   950→        branch_exists_locally = branch_name in local_branches\n   951→\n   952→        if branch_exists_locally:\n   953→            # Reuse existing local branch\n   954→            user_output(f\"Using existing local branch: {click.style(branch_name, fg='cyan')}\")\n   955→\n   956→            # Track in Graphite if not already tracked\n   957→            if ctx.branch_manager.is_graphite_managed():\n   958→                if not ctx.graphite.is_branch_tracked(repo.root, branch_name):\n   959→                    ctx.branch_manager.track_branch(repo.root, branch_name, base_branch)\n   960→                    user_output(click.style(\"✓\", fg=\"green\") + \" Branch tracked in Graphite\")\n   961→\n   962→            # Checkout existing branch\n   963→            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n   964→\n   965→            # Use context manager to restore original branch on failure\n   966→            with branch_rollback(ctx, repo.root, original_branch):\n   967→                pr_number = _create_branch_and_pr(\n   968→                    ctx=ctx,\n   969→                    repo=repo,\n   970→                    validated=validated,\n   971→                    branch_name=branch_name,\n   972→                    base_branch=base_branch,\n   973→                    submitted_by=submitted_by,\n   974→                    original_branch=original_branch,\n   975→                )\n   976→        else:\n   977→            # Create new branch\n   978→            user_output(f\"Creating branch from origin/{base_branch}...\")\n   979→            ctx.git.remote.fetch_branch(repo.root, \"origin\", base_branch)\n   980→\n   981→            # Verify parent is tracked by Graphite (if enabled)\n   982→            if ctx.branch_manager.is_graphite_managed():\n   983→                parent_branch = base_branch.removeprefix(\"origin/\")\n   984→                if not ctx.graphite.is_branch_tracked(repo.root, parent_branch):\n   985→                    msg = (\n   986→                        f\"Cannot stack on branch '{parent_branch}' - \"\n   987→                        f\"it's not tracked by Graphite.\\n\\n\"\n   988→                        f\"To fix this:\\n\"\n   989→                        f\"  1. gt checkout {parent_branch}\\n\"\n   990→                        f\"  2. gt track --parent <parent-branch>\\n\\n\"\n   991→                        f\"Then retry your command.\"\n   992→                    )\n   993→                    user_output(click.style(\"Error: \", fg=\"red\") + msg)\n   994→                    raise SystemExit(1)\n   995→\n   996→            create_result = ctx.branch_manager.create_branch(\n   997→                repo.root, branch_name, f\"origin/{base_branch}\"\n   998→            )\n   999→            if isinstance(create_result, BranchAlreadyExists):\n  1000→                user_output(click.style(\"Error: \", fg=\"red\") + create_result.message)\n  1001→                raise SystemExit(1) from None\n  1002→            user_output(f\"Created branch: {click.style(branch_name, fg='cyan')}\")\n  1003→\n  1004→            # Use context manager to restore original branch on failure\n  1005→            with branch_rollback(ctx, repo.root, original_branch):\n  1006→                pr_number = _create_branch_and_pr(\n  1007→                    ctx=ctx,\n  1008→                    repo=repo,\n  1009→                    validated=validated,\n  1010→                    branch_name=branch_name,\n  1011→                    base_branch=base_branch,\n  1012→                    submitted_by=submitted_by,\n  1013→                    original_branch=original_branch,\n  1014→                )\n  1015→\n  1016→    # Gather submission metadata\n  1017→    queued_at = datetime.now(UTC).isoformat()\n  1018→\n  1019→    # Validate pr_number is set before workflow dispatch\n  1020→    if pr_number is None:\n  1021→        user_output(\n  1022→            click.style(\"Error: \", fg=\"red\")\n  1023→            + \"Failed to create or find PR. Cannot trigger workflow.\"\n  1024→        )\n  1025→        raise SystemExit(1)\n  1026→\n  1027→    # Load workflow-specific config\n  1028→    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n  1029→\n  1030→    # Trigger workflow via direct dispatch\n  1031→    user_output(\"\")\n  1032→    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n  1033→    user_output(f\"  Display name: {DISPATCH_WORKFLOW_METADATA_NAME}\")\n  1034→\n  1035→    # Build inputs dict, merging workflow config\n  1036→    inputs = {\n  1037→        # Required inputs (always passed)\n  1038→        \"plan_id\": str(issue_number),\n  1039→        \"submitted_by\": submitted_by,\n  1040→        \"plan_title\": issue.title,\n  1041→        \"branch_name\": branch_name,\n  1042→        \"pr_number\": str(pr_number),\n  1043→        \"base_branch\": base_branch,\n  1044→        # Config-based inputs (from .erk/workflows/)\n  1045→        **workflow_config,\n  1046→    }\n  1047→\n  1048→    run_id = ctx.github.trigger_workflow(\n  1049→        repo_root=repo.root,\n  1050→        workflow=DISPATCH_WORKFLOW_NAME,\n  1051→        inputs=inputs,\n  1052→    )\n  1053→    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n  1054→\n  1055→    # Compute workflow URL once (used for PR body update, queued comment, and result)\n  1056→    workflow_url = _build_workflow_run_url(issue.url, run_id)\n  1057→\n  1058→    # Update PR body with workflow run link (best-effort)\n  1059→    try:\n  1060→        pr_details = ctx.github.get_pr(repo.root, pr_number)\n  1061→        if not isinstance(pr_details, PRNotFound):\n  1062→            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n  1063→            ctx.github.update_pr_body(repo.root, pr_number, updated_body)\n  1064→    except Exception as e:\n  1065→        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n  1066→\n  1067→    # Write dispatch metadata synchronously to fix race condition with erk dash\n  1068→    # This ensures the issue body has the run info before we return to the user\n  1069→    try:\n  1070→        write_dispatch_metadata(\n  1071→            plan_backend=ctx.plan_backend,\n  1072→            github=ctx.github,\n  1073→            repo_root=repo.root,\n  1074→            issue_number=issue_number,\n  1075→            run_id=run_id,\n  1076→            dispatched_at=queued_at,\n  1077→        )\n  1078→        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written to issue\")\n  1079→    except Exception as e:\n  1080→        # Log warning but don't block - workflow is already triggered\n  1081→        user_output(\n  1082→            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n  1083→        )\n  1084→\n  1085→    validation_results = {\n  1086→        \"issue_is_open\": True,\n  1087→        \"has_erk_plan_label\": True,\n  1088→    }\n  1089→\n  1090→    # Create and post queued event comment\n  1091→    try:\n  1092→        metadata_block = create_submission_queued_block(\n  1093→            queued_at=queued_at,\n  1094→            submitted_by=submitted_by,\n  1095→            issue_number=issue_number,\n  1096→            validation_results=validation_results,\n  1097→            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n  1098→        )\n  1099→\n  1100→        comment_body = render_erk_issue_event(\n  1101→            title=\"🔄 Issue Queued for Implementation\",\n  1102→            metadata=metadata_block,\n  1103→            description=(\n  1104→                f\"Issue submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n  1105→                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n  1106→                f\"triggered via direct dispatch.\\n\\n\"\n  1107→                f\"**Workflow run:** {workflow_url}\\n\\n\"\n  1108→                f\"Branch and draft PR were created locally for correct commit attribution.\"\n  1109→            ),\n  1110→        )\n  1111→\n  1112→        user_output(\"Posting queued event comment...\")\n  1113→        ctx.issues.add_comment(repo.root, issue_number, comment_body)\n  1114→        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n  1115→    except Exception as e:\n  1116→        # Log warning but don't block - workflow is already triggered\n  1117→        user_output(\n  1118→            click.style(\"Warning: \", fg=\"yellow\")\n  1119→            + f\"Failed to post queued comment: {e}\\n\"\n  1120→            + \"Workflow is already running.\"\n  1121→        )\n  1122→\n  1123→    pr_url = _build_pr_url(issue.url, pr_number) if pr_number else None\n  1124→\n  1125→    return SubmitResult(\n  1126→        issue_number=issue_number,\n  1127→        issue_title=issue.title,\n  1128→        issue_url=issue.url,\n  1129→        pr_number=pr_number,\n  1130→        pr_url=pr_url,\n  1131→        workflow_run_id=run_id,\n  1132→        workflow_url=workflow_url,\n  1133→    )\n  1134→\n  1135→\n  1136→@click.command(\"submit\")\n  1137→@click.argument(\"issue_numbers\", type=int, nargs=-1, required=True)\n  1138→@click.option(\n  1139→    \"--base\",\n  1140→    type=str,\n  1141→    default=None,\n  1142→    help=\"Base branch for PR (defaults to current branch).\",\n  1143→)\n  1144→@click.option(\n  1145→    \"-f\",\n  1146→    \"--force\",\n  1147→    is_flag=True,\n  1148→    help=\"Delete existing branches and create fresh without prompting.\",\n  1149→)\n  1150→@click.pass_obj\n  1151→def submit_cmd(\n  1152→    ctx: ErkContext, issue_numbers: tuple[int, ...], base: str | None, force: bool\n  1153→) -> None:\n  1154→    \"\"\"Submit issues for remote AI implementation via GitHub Actions.\n  1155→\n  1156→    Creates branch and draft PR locally (for correct commit attribution),\n  1157→    then triggers the dispatch-erk-queue.yml GitHub Actions workflow.\n  1158→\n  1159→    Arguments:\n  1160→        ISSUE_NUMBERS: One or more GitHub issue numbers to submit\n  1161→\n  1162→    Example:\n  1163→        erk plan submit 123\n  1164→        erk plan submit 123 456 789\n  1165→        erk plan submit 123 --base master\n  1166→\n  1167→    Requires:\n  1168→        - All issues must have erk-plan label\n  1169→        - All issues must be OPEN\n  1170→        - Working directory must be clean (no uncommitted changes)\n  1171→    \"\"\"\n  1172→    # Validate GitHub CLI prerequisites upfront (LBYL)\n  1173→    Ensure.gh_authenticated(ctx)\n  1174→\n  1175→    # Get repository context\n  1176→    if isinstance(ctx.repo, RepoContext):\n  1177→        repo = ctx.repo\n  1178→    else:\n  1179→        repo = discover_repo_context(ctx, ctx.cwd)\n  1180→\n  1181→    # Ensure trunk is synced before any operations\n  1182→    ensure_trunk_synced(ctx, repo)\n  1183→\n  1184→    # Save current state (needed for both default base and restoration)\n  1185→    original_branch = ctx.git.branch.get_current_branch(repo.root)\n  1186→    if original_branch is None:\n  1187→        user_output(\n  1188→            click.style(\"Error: \", fg=\"red\")\n  1189→            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n  1190→        )\n  1191→        raise SystemExit(1)\n  1192→\n  1193→    # Validate base branch if provided, otherwise default to current branch (LBYL)\n  1194→    if base is not None:\n  1195→        if not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", base):\n  1196→            user_output(\n  1197→                click.style(\"Error: \", fg=\"red\") + f\"Base branch '{base}' does not exist on remote\"\n  1198→            )\n  1199→            raise SystemExit(1)\n  1200→        target_branch = base\n  1201→    else:\n  1202→        # If on a placeholder branch (local-only), use trunk as base\n  1203→        if is_placeholder_branch(original_branch):\n  1204→            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n  1205→        elif not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", original_branch):\n  1206→            # Current branch not pushed to remote - fall back to trunk\n  1207→            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n  1208→        else:\n  1209→            target_branch = original_branch\n  1210→\n  1211→    # For single-issue learn plan submissions, auto-detect parent branch\n  1212→    issue_number = issue_numbers[0] if len(issue_numbers) == 1 else None\n  1213→    if (\n  1214→        issue_number is not None\n  1215→        and base is None\n  1216→        and ctx.issues.issue_exists(repo.root, issue_number)\n  1217→    ):\n  1218→        issue = ctx.issues.get_issue(repo.root, issue_number)\n  1219→        # issue_exists check above ensures this won't be IssueNotFound\n  1220→        if not isinstance(issue, IssueNotFound) and is_issue_learn_plan(issue.labels):\n  1221→            parent_branch = get_learn_plan_parent_branch(ctx, repo.root, str(issue_number))\n  1222→            if parent_branch is not None and ctx.git.branch.branch_exists_on_remote(\n  1223→                repo.root, \"origin\", parent_branch\n  1224→            ):\n  1225→                target_branch = parent_branch\n  1226→                user_output(\n  1227→                    f\"Learn plan detected, stacking on parent branch: \"\n  1228→                    f\"{click.style(parent_branch, fg='cyan')}\"\n  1229→                )\n  1230→            elif parent_branch is not None:\n  1231→                user_output(\n  1232→                    click.style(\"Warning: \", fg=\"yellow\")\n  1233→                    + f\"Parent branch '{parent_branch}' not on remote, using trunk\"\n  1234→                )\n  1235→\n  1236→    # Get GitHub username (authentication already validated)\n  1237→    _, username, _ = ctx.github.check_auth_status()\n  1238→    submitted_by = username or \"unknown\"\n  1239→\n  1240→    # Detect draft-PR backend\n  1241→    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n  1242→\n  1243→    if is_draft_pr:\n  1244→        # Draft-PR path: branch and PR already exist, just validate and trigger workflow\n  1245→        user_output(f\"Validating {len(issue_numbers)} draft-PR plan(s)...\")\n  1246→        user_output(\"\")\n  1247→\n  1248→        validated_draft_prs: list[ValidatedDraftPR] = []\n  1249→        for issue_number in issue_numbers:\n  1250→            user_output(f\"Validating PR #{issue_number}...\")\n  1251→            validated_pr = _validate_draft_pr_for_submit(ctx, repo, issue_number)\n  1252→            validated_draft_prs.append(validated_pr)\n  1253→\n  1254→        user_output(\"\")\n  1255→        user_output(\n  1256→            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_draft_prs)} plan(s) validated\"\n  1257→        )\n  1258→        user_output(\"\")\n  1259→\n  1260→        for v in validated_draft_prs:\n  1261→            user_output(f\"  #{v.number}: {click.style(v.title, fg='yellow')}\")\n  1262→        user_output(\"\")\n  1263→\n  1264→        results: list[SubmitResult] = []\n  1265→        for i, v in enumerate(validated_draft_prs):\n  1266→            if len(validated_draft_prs) > 1:\n  1267→                count = len(validated_draft_prs)\n  1268→                user_output(f\"--- Submitting PR {i + 1}/{count}: #{v.number} ---\")\n  1269→            else:\n  1270→                user_output(f\"Submitting PR #{v.number}...\")\n  1271→            user_output(\"\")\n  1272→            result = _submit_draft_pr_plan(\n  1273→                ctx,\n  1274→                repo=repo,\n  1275→                validated=v,\n  1276→                submitted_by=submitted_by,\n  1277→                original_branch=original_branch,\n  1278→                base_branch=target_branch,\n  1279→            )\n  1280→            results.append(result)\n  1281→            user_output(\"\")\n  1282→    else:\n  1283→        # Issue-based path: existing flow\n  1284→        # Phase 1: Validate ALL issues upfront (atomic - fail fast before any side effects)\n  1285→        user_output(f\"Validating {len(issue_numbers)} issue(s)...\")\n  1286→        user_output(\"\")\n  1287→\n  1288→        validated_issues: list[ValidatedIssue] = []\n  1289→        for issue_number in issue_numbers:\n  1290→            user_output(f\"Validating issue #{issue_number}...\")\n  1291→            validated_issue = _validate_issue_for_submit(\n  1292→                ctx, repo, issue_number, target_branch, force=force\n  1293→            )\n  1294→            validated_issues.append(validated_issue)\n  1295→\n  1296→        user_output(\"\")\n  1297→        user_output(\n  1298→            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_issues)} issue(s) validated\"\n  1299→        )\n  1300→        user_output(\"\")\n  1301→\n  1302→        # Display validated issues\n  1303→        for v in validated_issues:\n  1304→            user_output(f\"  #{v.number}: {click.style(v.issue.title, fg='yellow')}\")\n  1305→        user_output(\"\")\n  1306→\n  1307→        # Phase 2: Submit all validated issues\n  1308→        results = []\n  1309→        for i, v in enumerate(validated_issues):\n  1310→            if len(validated_issues) > 1:\n  1311→                user_output(\n  1312→                    f\"--- Submitting issue {i + 1}/{len(validated_issues)}: #{v.number} ---\"\n  1313→                )\n  1314→            else:\n  1315→                user_output(f\"Submitting issue #{v.number}...\")\n  1316→            user_output(\"\")\n  1317→            result = _submit_single_issue(\n  1318→                ctx,\n  1319→                repo=repo,\n  1320→                validated=v,\n  1321→                submitted_by=submitted_by,\n  1322→                original_branch=original_branch,\n  1323→                base_branch=target_branch,\n  1324→            )\n  1325→            results.append(result)\n  1326→            user_output(\"\")\n  1327→\n  1328→    # Success output\n  1329→    user_output(\"\")\n  1330→    user_output(click.style(\"✓\", fg=\"green\") + f\" {len(results)} issue(s) submitted successfully!\")\n  1331→    user_output(\"\")\n  1332→    user_output(\"Submitted issues:\")\n  1333→    for r in results:\n  1334→        user_output(f\"  • #{r.issue_number}: {r.issue_title}\")\n  1335→        user_output(f\"    Issue: {r.issue_url}\")\n  1336→        if r.pr_url:\n  1337→            user_output(f\"    PR: {r.pr_url}\")\n  1338→        user_output(f\"    Workflow: {r.workflow_url}\")\n  1339→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9ac7fda4-6ab8-415d-9823-3a013b513c05","timestamp":"2026-02-22T14:37:45.911Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","content":"\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n\nimport logging\nimport tomllib\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,\n    worker_impl_folder_exists,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _format_issue_ref(issue_number: int, plans_repo: str | None) -> str:\n    \"\"\"Format issue reference for PR body.\n\n    Args:\n        issue_number: The issue number\n        plans_repo: Target repo in \"owner/repo\" format, or None for same repo\n\n    Returns:\n        \"#N\" for same-repo, \"owner/repo#N\" for cross-repo\n    \"\"\"\n    if plans_repo is None:\n        return f\"#{issue_number}\"\n    return f\"{plans_repo}#{issue_number}\"\n\n\n@contextmanager\ndef branch_rollback(ctx: ErkContext, repo_root: Path, original_branch: str) -> Iterator[None]:\n    \"\"\"Context manager that restores original branch on exception.\n\n    On success, does nothing (caller handles cleanup).\n    On exception, checks out original_branch and re-raises.\n    \"\"\"\n    try:\n        yield\n    except Exception:\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + \"Operation failed, restoring original branch...\"\n        )\n        ctx.branch_manager.checkout_branch(repo_root, original_branch)\n        raise\n\n\ndef is_issue_learn_plan(labels: list[str]) -> bool:\n    \"\"\"Check if an issue is a learn plan by checking for erk-learn label.\n\n    Args:\n        labels: The issue's labels\n\n    Returns:\n        True if the issue has the erk-learn label, False otherwise\n    \"\"\"\n    return \"erk-learn\" in labels\n\n\ndef _find_existing_branches_for_issue(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n) -> list[str]:\n    \"\"\"Find local branches matching P{issue_number}-* pattern.\"\"\"\n    local_branches = ctx.git.branch.list_local_branches(repo_root)\n    prefix = f\"P{issue_number}-\"\n    return sorted([b for b in local_branches if b.startswith(prefix)])\n\n\ndef _prompt_existing_branch_action(\n    ctx: ErkContext,\n    repo_root: Path,\n    existing_branches: list[str],\n    new_branch_name: str,\n    *,\n    force: bool,\n) -> str | None:\n    \"\"\"Prompt user to decide what to do with existing branch(es).\n\n    Args:\n        ctx: ErkContext with git operations\n        repo_root: Repository root path\n        existing_branches: List of existing branch names matching the issue pattern\n        new_branch_name: Name for new branch if creating fresh\n        force: If True, delete existing branches without prompting\n\n    Returns:\n        - Branch name to use (existing branch)\n        - None to signal \"create new\" (after deleting existing)\n    \"\"\"\n    if force:\n        user_output(f\"\\nDeleting {len(existing_branches)} existing branch(es) (--force mode):\")\n        for branch in existing_branches:\n            ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n            user_output(f\"  Deleted: {branch}\")\n        return None  # Signal \"create new branch\"\n\n    user_output(\"\\nFound existing local branch(es) for this issue:\")\n    for branch in existing_branches:\n        user_output(f\"  • {branch}\")\n    user_output(f\"\\nNew branch would be: {click.style(new_branch_name, fg='cyan')}\")\n    user_output(\"\")\n\n    # Use newest branch (latest timestamp = last alphabetically)\n    branch_to_use = existing_branches[-1]\n\n    # Single binary prompt\n    reuse = ctx.console.confirm(\n        f\"Reuse existing branch '{branch_to_use}'? \"\n        \"If not, a new branch and PR will be created (old draft PR will be closed)\",\n        default=True,\n    )\n\n    if reuse:\n        return branch_to_use\n\n    # Delete existing branches and signal \"create new\"\n    for branch in existing_branches:\n        ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n        user_output(f\"Deleted branch: {branch}\")\n    return None\n\n\ndef get_learn_plan_parent_branch(ctx: ErkContext, repo_root: Path, plan_id: str) -> str | None:\n    \"\"\"Get the parent branch for a learn plan.\n\n    Learn plans should stack on their parent plan's branch.\n    Extracts learned_from_issue via plan_backend, fetches parent's branch_name.\n\n    Args:\n        ctx: ErkContext with plan_backend\n        repo_root: Repository root path\n        plan_id: Plan identifier\n\n    Returns:\n        Parent plan's branch_name if found, None otherwise\n    \"\"\"\n    learned_from = ctx.plan_backend.get_metadata_field(repo_root, plan_id, \"learned_from_issue\")\n    if isinstance(learned_from, PlanNotFound) or learned_from is None:\n        return None\n\n    branch_name = ctx.plan_backend.get_metadata_field(repo_root, str(learned_from), \"branch_name\")\n    if isinstance(branch_name, PlanNotFound) or branch_name is None:\n        return None\n    return str(branch_name)\n\n\ndef load_workflow_config(repo_root: Path, workflow_name: str) -> dict[str, str]:\n    \"\"\"Load workflow config from .erk/config.toml [workflows.<name>] section.\n\n    Args:\n        repo_root: Repository root path\n        workflow_name: Workflow filename (with or without .yml/.yaml extension).\n            Only the basename is used for config lookup.\n\n    Returns:\n        Dict of string key-value pairs for workflow inputs.\n        Returns empty dict if config file or section doesn't exist.\n\n    Example:\n        For workflow_name=\"plan-implement.yml\", reads from:\n        .erk/config.toml -> [workflows.plan-implement] section\n    \"\"\"\n    config_path = repo_root / \".erk\" / \"config.toml\"\n\n    if not config_path.exists():\n        return {}\n\n    with open(config_path, \"rb\") as f:\n        data = tomllib.load(f)\n\n    # Extract basename and strip .yml/.yaml extension\n    basename = Path(workflow_name).name\n    config_name = basename.removesuffix(\".yml\").removesuffix(\".yaml\")\n\n    # Get [workflows.<name>] section\n    workflows_section = data.get(\"workflows\", {})\n    workflow_config = workflows_section.get(config_name, {})\n\n    # Convert all values to strings (workflow inputs are always strings)\n    return {k: str(v) for k, v in workflow_config.items()}\n\n\n@dataclass(frozen=True)\nclass ValidatedIssue:\n    \"\"\"Issue that passed all validation checks.\"\"\"\n\n    number: int\n    issue: IssueInfo\n    branch_name: str\n    branch_exists: bool\n    pr_number: int | None\n    is_learn_origin: bool\n\n\n@dataclass(frozen=True)\nclass SubmitResult:\n    \"\"\"Result of submitting a single issue.\"\"\"\n\n    issue_number: int\n    issue_title: str\n    issue_url: str\n    pr_number: int | None\n    pr_url: str | None\n    workflow_run_id: str\n    workflow_url: str\n\n\ndef _build_workflow_run_url(issue_url: str, run_id: str) -> str:\n    \"\"\"Construct GitHub Actions workflow run URL from issue URL and run ID.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        run_id: Workflow run ID\n\n    Returns:\n        Workflow run URL (e.g., https://github.com/owner/repo/actions/runs/1234567890)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_workflow_run_url(owner, repo, run_id)\n    return f\"https://github.com/actions/runs/{run_id}\"\n\n\ndef _strip_plan_markers(title: str) -> str:\n    \"\"\"Strip '[erk-plan]' prefix and 'Plan:' prefix from issue title for use as PR title.\"\"\"\n    result = title\n    # Strip \"[erk-plan] \" prefix if present\n    if result.startswith(ERK_PLAN_TITLE_PREFIX):\n        result = result[len(ERK_PLAN_TITLE_PREFIX) :]\n    # Strip \"Plan: \" prefix if present\n    if result.startswith(PLAN_HEADING_PREFIX):\n        result = result[len(PLAN_HEADING_PREFIX) :]\n    return result\n\n\ndef _add_planned_prefix(title: str) -> str:\n    \"\"\"Prepend 'planned/' prefix to PR title (idempotent).\n\n    Args:\n        title: The PR title to prefix\n\n    Returns:\n        The title with 'planned/' prefix, skipping if already prefixed\n    \"\"\"\n    if title.startswith(PLANNED_PR_TITLE_PREFIX):\n        return title\n    return f\"{PLANNED_PR_TITLE_PREFIX}{title}\"\n\n\ndef _build_pr_url(issue_url: str, pr_number: int) -> str:\n    \"\"\"Construct GitHub PR URL from issue URL and PR number.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        pr_number: PR number\n\n    Returns:\n        PR URL (e.g., https://github.com/owner/repo/pull/456)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_pr_url(owner, repo, pr_number)\n    return f\"https://github.com/pull/{pr_number}\"\n\n\ndef _close_orphaned_draft_prs(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n    keep_pr_number: int,\n) -> list[int]:\n    \"\"\"Close old draft PRs linked to an issue, keeping the specified one.\n\n    Returns list of PR numbers that were closed.\n    \"\"\"\n    linked_prs = ctx.issues.get_prs_referencing_issue(repo_root, issue_number)\n\n    closed_prs: list[int] = []\n    for pr in linked_prs:\n        # Close orphaned drafts: draft PRs that are OPEN and not the one we just created\n        # Any draft PR linked to an erk-plan issue is fair game to close\n        if pr.is_draft and pr.state == \"OPEN\" and pr.number != keep_pr_number:\n            ctx.github.close_pr(repo_root, pr.number)\n            closed_prs.append(pr.number)\n\n    return closed_prs\n\n\n@dataclass(frozen=True)\nclass ValidatedDraftPR:\n    \"\"\"Draft PR that passed all validation checks.\"\"\"\n\n    number: int\n    title: str\n    url: str\n    branch_name: str\n\n\ndef _validate_draft_pr_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    plan_number: int,\n) -> ValidatedDraftPR:\n    \"\"\"Validate a draft PR plan for submission.\n\n    Fetches the PR, validates it has the erk-plan label and is OPEN.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        plan_number: PR number to validate\n\n    Raises:\n        SystemExit: If PR doesn't exist, missing label, or not OPEN.\n    \"\"\"\n    pr_result = ctx.github.get_pr(repo.root, plan_number)\n    if isinstance(pr_result, PRNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in pr_result.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"PR #{plan_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if pr_result.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} is {pr_result.state}\\n\\n\"\n            \"Cannot submit closed PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    return ValidatedDraftPR(\n        number=plan_number,\n        title=pr_result.title,\n        url=pr_result.url,\n        branch_name=pr_result.head_ref_name,\n    )\n\n\ndef _submit_draft_pr_plan(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedDraftPR,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a validated draft-PR plan for implementation.\n\n    For draft-PR plans, the branch and PR already exist. This function:\n    - Fetches and checks out the existing plan branch\n    - Creates .worker-impl/ with provider=\"github-draft-pr\"\n    - Commits and pushes .worker-impl/ to existing branch\n    - Triggers the workflow with plan_backend=\"draft_pr\"\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated draft PR information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    plan_number = validated.number\n    branch_name = validated.branch_name\n\n    # Fetch plan content via PlanBackend\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(plan_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number}: plan content not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Fetch and checkout the existing plan branch\n    user_output(f\"Checking out existing plan branch: {click.style(branch_name, fg='cyan')}\")\n    ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n    local_branches = ctx.git.branch.list_local_branches(repo.root)\n    if branch_name not in local_branches:\n        remote_ref = f\"origin/{branch_name}\"\n        ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Sync local branch with remote (may be behind from prior submission or CI)\n    pull_result = ctx.git.remote.pull_rebase(repo.root, \"origin\", branch_name)\n    if isinstance(pull_result, PullRebaseError):\n        raise UserFacingCliError(\n            f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n        )\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    # Create .worker-impl/ with draft-PR provider\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(plan_number),\n        url=validated.url,\n        repo_root=repo.root,\n        provider=\"github-draft-pr\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for PR #{plan_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=False, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Switch back to original branch\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Build inputs dict with plan_backend=\"draft_pr\"\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n\n    inputs = {\n        \"plan_id\": str(plan_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": validated.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(plan_number),\n        \"base_branch\": base_branch,\n        \"plan_backend\": \"draft_pr\",\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL\n    workflow_url = _build_workflow_run_url(validated.url, run_id)\n\n    # Write dispatch metadata FIRST (before any PR body modification)\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=plan_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    # Update PR body with workflow run link (best-effort)\n    # Guard: only append if body is non-empty to avoid overwriting metadata block\n    try:\n        pr_details = ctx.github.get_pr(repo.root, plan_number)\n        if not isinstance(pr_details, PRNotFound) and pr_details.body:\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, plan_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Post queued event comment via PlanBackend\n    try:\n        validation_results = {\n            \"pr_is_open\": True,\n            \"has_erk_plan_label\": True,\n        }\n\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=plan_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Plan Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Plan submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.plan_backend.add_comment(repo.root, str(plan_number), comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(validated.url, plan_number)\n\n    return SubmitResult(\n        issue_number=plan_number,\n        issue_title=validated.title,\n        issue_url=validated.url,\n        pr_number=plan_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\ndef _validate_issue_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    issue_number: int,\n    base_branch: str,\n    *,\n    force: bool,\n) -> ValidatedIssue:\n    \"\"\"Validate a single issue for submission.\n\n    Fetches the issue, validates constraints, derives branch name, and checks\n    if branch/PR already exist.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        issue_number: GitHub issue number to validate\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Raises:\n        SystemExit: If issue doesn't exist, missing label, or closed.\n    \"\"\"\n    # Fetch issue from GitHub\n    issue = ctx.issues.get_issue(repo.root, issue_number)\n    if isinstance(issue, IssueNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue.issue_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in issue.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"Issue #{issue_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan issues for automated implementation.\\n\"\n            \"To create a plan, use Plan Mode then /erk:plan-save\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if issue.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} is {issue.state}\\n\\n\"\n            \"Cannot submit closed issues for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Use provided base_branch instead of detecting trunk\n    logger.debug(\"base_branch=%s\", base_branch)\n\n    # Check for existing local branches BEFORE computing new name\n    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n\n    # Compute branch name using canonical naming function\n    objective_id_raw = ctx.plan_backend.get_metadata_field(\n        repo.root, str(issue_number), \"objective_issue\"\n    )\n    objective_id: int | None = None\n    if isinstance(objective_id_raw, int):\n        objective_id = objective_id_raw\n    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n        objective_id = int(objective_id_raw)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )\n\n    if existing_branches:\n        chosen = _prompt_existing_branch_action(\n            ctx, repo.root, existing_branches, new_branch_name, force=force\n        )\n        branch_name = chosen if chosen is not None else new_branch_name\n    else:\n        branch_name = new_branch_name\n\n    logger.debug(\"branch_name=%s\", branch_name)\n    user_output(f\"Computed branch: {click.style(branch_name, fg='cyan')}\")\n\n    # Check if branch already exists on remote and has a PR\n    branch_exists = ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", branch_name)\n    logger.debug(\"branch_exists_on_remote(%s)=%s\", branch_name, branch_exists)\n\n    pr_number: int | None = None\n    if branch_exists:\n        pr_details = ctx.github.get_pr_for_branch(repo.root, branch_name)\n        if not isinstance(pr_details, PRNotFound):\n            pr_number = pr_details.number\n\n    # Check if this issue is a learn plan\n    is_learn_origin = is_issue_learn_plan(issue.labels)\n\n    return ValidatedIssue(\n        number=issue_number,\n        issue=issue,\n        branch_name=branch_name,\n        branch_exists=branch_exists,\n        pr_number=pr_number,\n        is_learn_origin=is_learn_origin,\n    )\n\n\ndef _create_branch_and_pr(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    branch_name: str,\n    base_branch: str,\n    submitted_by: str,\n    original_branch: str,\n) -> int:\n    \"\"\"Create branch, commit, push, and create draft PR.\n\n    This function is called within the branch_rollback context manager.\n    On any exception, the context manager will restore the original branch.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        branch_name: Name of branch to create\n        base_branch: Base branch for PR\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (for cleanup on success)\n\n    Returns:\n        PR number of the created draft PR.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Get plan content and create .worker-impl/ folder\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(issue_number),\n        url=issue.url,\n        repo_root=repo.root,\n        provider=\"github\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for issue #{issue_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Create draft PR\n    # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n    # MUST be in the initial body passed to create_pr(), NOT added via update.\n    # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n    # updated when the body is edited afterward.\n    user_output(\"Creating draft PR...\")\n    plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n    issue_ref = _format_issue_ref(issue_number, plans_repo)\n    pr_body = (\n        f\"**Author:** @{submitted_by}\\n\"\n        f\"**Plan:** {issue_ref}\\n\\n\"\n        f\"**Status:** Queued for implementation\\n\\n\"\n        f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n        f\"## Implementation Plan\\n\\n\"\n        f\"<details>\\n\"\n        f\"<summary><strong>Implementation Plan</strong> (Issue #{issue_number})</summary>\\n\\n\"\n        f\"{plan.body}\\n\\n\"\n        f\"</details>\\n\\n\"\n        f\"---\\n\\n\"\n        f\"Closes {issue_ref}\"\n    )\n    pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n    pr_number = ctx.github.create_pr(\n        repo_root=repo.root,\n        branch=branch_name,\n        title=pr_title,\n        body=pr_body,\n        base=base_branch,\n        draft=True,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n    # Update PR body with checkout command footer\n    footer = build_pr_body_footer(\n        pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n    )\n    ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n    # Add extraction skip label if this is a learn plan\n    if validated.is_learn_origin:\n        ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n        # FUTURE ENHANCEMENT: When a learn plan issue gets a PR, update the parent\n        # plan's learn_status from \"completed_with_plan\" to track the PR number.\n        # Currently, the parent only gets updated when the learn plan's PR lands\n        # (in land_cmd._update_parent_learn_status_if_learn_plan). Adding an\n        # intermediate state here would let the TUI show the PR number (e.g.,\n        # \"🚧 #5514\") instead of the learn plan issue number (e.g., \"#5508\")\n        # while the PR is still in review.\n        # See: LearnStatusValue in erk_shared/github/metadata/schemas.py\n\n    # Link PR with Graphite (if enabled)\n    if ctx.branch_manager.is_graphite_managed():\n        user_output(\"Linking PR with Graphite...\")\n        submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n        if isinstance(submit_result, SubmitBranchError):\n            user_output(\n                click.style(\"✗\", fg=\"red\")\n                + f\" Failed to link PR with Graphite: {submit_result.message}\"\n            )\n        else:\n            user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n    # Close any orphaned draft PRs for this issue\n    closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n    if closed_prs:\n        user_output(\n            click.style(\"✓\", fg=\"green\")\n            + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n            + \", \".join(f\"#{n}\" for n in closed_prs)\n        )\n\n    # Switch back to original branch (keep the new branch for Graphite lineage)\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    return pr_number\n\n\ndef _submit_single_issue(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a single validated issue for implementation.\n\n    Creates branch/PR if needed and triggers workflow.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n    branch_name = validated.branch_name\n    branch_exists = validated.branch_exists\n    pr_number = validated.pr_number\n\n    if branch_exists:\n        if pr_number is not None:\n            user_output(\n                f\"PR #{pr_number} already exists for branch '{branch_name}' (state: existing)\"\n            )\n            user_output(\"Skipping branch/PR creation, triggering workflow...\")\n        else:\n            # Branch exists but no PR - need to add a commit for PR creation\n            user_output(f\"Branch '{branch_name}' exists but no PR. Adding placeholder commit...\")\n\n            # Fetch and checkout the remote branch locally\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n            # Only create tracking branch if it doesn't exist locally (LBYL)\n            local_branches = ctx.git.branch.list_local_branches(repo.root)\n            if branch_name not in local_branches:\n                remote_ref = f\"origin/{branch_name}\"\n                ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Create empty commit as placeholder for PR creation\n            ctx.git.commit.commit(\n                repo.root,\n                f\"[erk-plan] Initialize implementation for issue #{issue_number}\",\n            )\n            push_result = ctx.git.remote.push_to_remote(\n                repo.root, \"origin\", branch_name, set_upstream=False, force=False\n            )\n            if isinstance(push_result, PushError):\n                raise UserFacingCliError(push_result.message)\n            user_output(click.style(\"✓\", fg=\"green\") + \" Placeholder commit pushed\")\n\n            # Now create the PR\n            # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n            # MUST be in the initial body passed to create_pr(), NOT added via update.\n            # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n            # updated when the body is edited afterward.\n            plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n            issue_ref = _format_issue_ref(issue_number, plans_repo)\n            pr_body = (\n                f\"**Author:** @{submitted_by}\\n\"\n                f\"**Plan:** {issue_ref}\\n\\n\"\n                f\"**Status:** Queued for implementation\\n\\n\"\n                f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n                f\"---\\n\\n\"\n                f\"Closes {issue_ref}\"\n            )\n            pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n            pr_number = ctx.github.create_pr(\n                repo_root=repo.root,\n                branch=branch_name,\n                title=pr_title,\n                body=pr_body,\n                base=base_branch,\n                draft=True,\n            )\n            user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n            # Update PR body with checkout command footer\n            footer = build_pr_body_footer(\n                pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n            # Add extraction skip label if this is a learn plan\n            if validated.is_learn_origin:\n                ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n                # FUTURE ENHANCEMENT: See comment in _create_branch_and_pr for\n                # updating parent plan's learn_status when learn plan gets a PR.\n\n            # Link PR with Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                user_output(\"Linking PR with Graphite...\")\n                submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n                if isinstance(submit_result, SubmitBranchError):\n                    user_output(\n                        click.style(\"✗\", fg=\"red\")\n                        + f\" Failed to link PR with Graphite: {submit_result.message}\"\n                    )\n                else:\n                    user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n            # Close any orphaned draft PRs\n            closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n            if closed_prs:\n                user_output(\n                    click.style(\"✓\", fg=\"green\")\n                    + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n                    + \", \".join(f\"#{n}\" for n in closed_prs)\n                )\n\n            # Switch back to original branch (keep the new branch for Graphite lineage)\n            ctx.branch_manager.checkout_branch(repo.root, original_branch)\n    else:\n        # Check if branch exists locally (user chose to reuse existing)\n        local_branches = ctx.git.branch.list_local_branches(repo.root)\n        branch_exists_locally = branch_name in local_branches\n\n        if branch_exists_locally:\n            # Reuse existing local branch\n            user_output(f\"Using existing local branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Track in Graphite if not already tracked\n            if ctx.branch_manager.is_graphite_managed():\n                if not ctx.graphite.is_branch_tracked(repo.root, branch_name):\n                    ctx.branch_manager.track_branch(repo.root, branch_name, base_branch)\n                    user_output(click.style(\"✓\", fg=\"green\") + \" Branch tracked in Graphite\")\n\n            # Checkout existing branch\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n        else:\n            # Create new branch\n            user_output(f\"Creating branch from origin/{base_branch}...\")\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", base_branch)\n\n            # Verify parent is tracked by Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                parent_branch = base_branch.removeprefix(\"origin/\")\n                if not ctx.graphite.is_branch_tracked(repo.root, parent_branch):\n                    msg = (\n                        f\"Cannot stack on branch '{parent_branch}' - \"\n                        f\"it's not tracked by Graphite.\\n\\n\"\n                        f\"To fix this:\\n\"\n                        f\"  1. gt checkout {parent_branch}\\n\"\n                        f\"  2. gt track --parent <parent-branch>\\n\\n\"\n                        f\"Then retry your command.\"\n                    )\n                    user_output(click.style(\"Error: \", fg=\"red\") + msg)\n                    raise SystemExit(1)\n\n            create_result = ctx.branch_manager.create_branch(\n                repo.root, branch_name, f\"origin/{base_branch}\"\n            )\n            if isinstance(create_result, BranchAlreadyExists):\n                user_output(click.style(\"Error: \", fg=\"red\") + create_result.message)\n                raise SystemExit(1) from None\n            user_output(f\"Created branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Validate pr_number is set before workflow dispatch\n    if pr_number is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Failed to create or find PR. Cannot trigger workflow.\"\n        )\n        raise SystemExit(1)\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Trigger workflow via direct dispatch\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n    user_output(f\"  Display name: {DISPATCH_WORKFLOW_METADATA_NAME}\")\n\n    # Build inputs dict, merging workflow config\n    inputs = {\n        # Required inputs (always passed)\n        \"plan_id\": str(issue_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": issue.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"base_branch\": base_branch,\n        # Config-based inputs (from .erk/workflows/)\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL once (used for PR body update, queued comment, and result)\n    workflow_url = _build_workflow_run_url(issue.url, run_id)\n\n    # Update PR body with workflow run link (best-effort)\n    try:\n        pr_details = ctx.github.get_pr(repo.root, pr_number)\n        if not isinstance(pr_details, PRNotFound):\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, pr_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata synchronously to fix race condition with erk dash\n    # This ensures the issue body has the run info before we return to the user\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=issue_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written to issue\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    validation_results = {\n        \"issue_is_open\": True,\n        \"has_erk_plan_label\": True,\n    }\n\n    # Create and post queued event comment\n    try:\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=issue_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Issue Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Issue submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\\n\\n\"\n                f\"Branch and draft PR were created locally for correct commit attribution.\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.issues.add_comment(repo.root, issue_number, comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(issue.url, pr_number) if pr_number else None\n\n    return SubmitResult(\n        issue_number=issue_number,\n        issue_title=issue.title,\n        issue_url=issue.url,\n        pr_number=pr_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\n@click.command(\"submit\")\n@click.argument(\"issue_numbers\", type=int, nargs=-1, required=True)\n@click.option(\n    \"--base\",\n    type=str,\n    default=None,\n    help=\"Base branch for PR (defaults to current branch).\",\n)\n@click.option(\n    \"-f\",\n    \"--force\",\n    is_flag=True,\n    help=\"Delete existing branches and create fresh without prompting.\",\n)\n@click.pass_obj\ndef submit_cmd(\n    ctx: ErkContext, issue_numbers: tuple[int, ...], base: str | None, force: bool\n) -> None:\n    \"\"\"Submit issues for remote AI implementation via GitHub Actions.\n\n    Creates branch and draft PR locally (for correct commit attribution),\n    then triggers the dispatch-erk-queue.yml GitHub Actions workflow.\n\n    Arguments:\n        ISSUE_NUMBERS: One or more GitHub issue numbers to submit\n\n    Example:\n        erk plan submit 123\n        erk plan submit 123 456 789\n        erk plan submit 123 --base master\n\n    Requires:\n        - All issues must have erk-plan label\n        - All issues must be OPEN\n        - Working directory must be clean (no uncommitted changes)\n    \"\"\"\n    # Validate GitHub CLI prerequisites upfront (LBYL)\n    Ensure.gh_authenticated(ctx)\n\n    # Get repository context\n    if isinstance(ctx.repo, RepoContext):\n        repo = ctx.repo\n    else:\n        repo = discover_repo_context(ctx, ctx.cwd)\n\n    # Ensure trunk is synced before any operations\n    ensure_trunk_synced(ctx, repo)\n\n    # Save current state (needed for both default base and restoration)\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Validate base branch if provided, otherwise default to current branch (LBYL)\n    if base is not None:\n        if not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", base):\n            user_output(\n                click.style(\"Error: \", fg=\"red\") + f\"Base branch '{base}' does not exist on remote\"\n            )\n            raise SystemExit(1)\n        target_branch = base\n    else:\n        # If on a placeholder branch (local-only), use trunk as base\n        if is_placeholder_branch(original_branch):\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        elif not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", original_branch):\n            # Current branch not pushed to remote - fall back to trunk\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        else:\n            target_branch = original_branch\n\n    # For single-issue learn plan submissions, auto-detect parent branch\n    issue_number = issue_numbers[0] if len(issue_numbers) == 1 else None\n    if (\n        issue_number is not None\n        and base is None\n        and ctx.issues.issue_exists(repo.root, issue_number)\n    ):\n        issue = ctx.issues.get_issue(repo.root, issue_number)\n        # issue_exists check above ensures this won't be IssueNotFound\n        if not isinstance(issue, IssueNotFound) and is_issue_learn_plan(issue.labels):\n            parent_branch = get_learn_plan_parent_branch(ctx, repo.root, str(issue_number))\n            if parent_branch is not None and ctx.git.branch.branch_exists_on_remote(\n                repo.root, \"origin\", parent_branch\n            ):\n                target_branch = parent_branch\n                user_output(\n                    f\"Learn plan detected, stacking on parent branch: \"\n                    f\"{click.style(parent_branch, fg='cyan')}\"\n                )\n            elif parent_branch is not None:\n                user_output(\n                    click.style(\"Warning: \", fg=\"yellow\")\n                    + f\"Parent branch '{parent_branch}' not on remote, using trunk\"\n                )\n\n    # Get GitHub username (authentication already validated)\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect draft-PR backend\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    if is_draft_pr:\n        # Draft-PR path: branch and PR already exist, just validate and trigger workflow\n        user_output(f\"Validating {len(issue_numbers)} draft-PR plan(s)...\")\n        user_output(\"\")\n\n        validated_draft_prs: list[ValidatedDraftPR] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating PR #{issue_number}...\")\n            validated_pr = _validate_draft_pr_for_submit(ctx, repo, issue_number)\n            validated_draft_prs.append(validated_pr)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_draft_prs)} plan(s) validated\"\n        )\n        user_output(\"\")\n\n        for v in validated_draft_prs:\n            user_output(f\"  #{v.number}: {click.style(v.title, fg='yellow')}\")\n        user_output(\"\")\n\n        results: list[SubmitResult] = []\n        for i, v in enumerate(validated_draft_prs):\n            if len(validated_draft_prs) > 1:\n                count = len(validated_draft_prs)\n                user_output(f\"--- Submitting PR {i + 1}/{count}: #{v.number} ---\")\n            else:\n                user_output(f\"Submitting PR #{v.number}...\")\n            user_output(\"\")\n            result = _submit_draft_pr_plan(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n    else:\n        # Issue-based path: existing flow\n        # Phase 1: Validate ALL issues upfront (atomic - fail fast before any side effects)\n        user_output(f\"Validating {len(issue_numbers)} issue(s)...\")\n        user_output(\"\")\n\n        validated_issues: list[ValidatedIssue] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating issue #{issue_number}...\")\n            validated_issue = _validate_issue_for_submit(\n                ctx, repo, issue_number, target_branch, force=force\n            )\n            validated_issues.append(validated_issue)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_issues)} issue(s) validated\"\n        )\n        user_output(\"\")\n\n        # Display validated issues\n        for v in validated_issues:\n            user_output(f\"  #{v.number}: {click.style(v.issue.title, fg='yellow')}\")\n        user_output(\"\")\n\n        # Phase 2: Submit all validated issues\n        results = []\n        for i, v in enumerate(validated_issues):\n            if len(validated_issues) > 1:\n                user_output(\n                    f\"--- Submitting issue {i + 1}/{len(validated_issues)}: #{v.number} ---\"\n                )\n            else:\n                user_output(f\"Submitting issue #{v.number}...\")\n            user_output(\"\")\n            result = _submit_single_issue(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n\n    # Success output\n    user_output(\"\")\n    user_output(click.style(\"✓\", fg=\"green\") + f\" {len(results)} issue(s) submitted successfully!\")\n    user_output(\"\")\n    user_output(\"Submitted issues:\")\n    for r in results:\n        user_output(f\"  • #{r.issue_number}: {r.issue_title}\")\n        user_output(f\"    Issue: {r.issue_url}\")\n        if r.pr_url:\n            user_output(f\"    PR: {r.pr_url}\")\n        user_output(f\"    Workflow: {r.workflow_url}\")\n","numLines":1339,"startLine":1,"totalLines":1339}}}
{"parentUuid":"9ac7fda4-6ab8-415d-9823-3a013b513c05","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Wq5C7pAutYPTHtimkTAk79","type":"message","role":"assistant","content":[{"type":"text","text":"I now have a clear picture of all 5 call sites and the pattern to follow. Let me also check for PromptResult:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14790,"cache_creation_input_tokens":22169,"cache_read_input_tokens":78479,"cache_creation":{"ephemeral_5m_input_tokens":22169,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3ztAiG2Rn4qAc3rSX","type":"assistant","uuid":"f4e2f27f-dff8-4156-bb19-96b8c377de11","timestamp":"2026-02-22T14:37:49.378Z"}
{"parentUuid":"f4e2f27f-dff8-4156-bb19-96b8c377de11","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Wq5C7pAutYPTHtimkTAk79","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VCgVaLx1A24Dm11VGkqFRs","name":"Grep","input":{"pattern":"class PromptResult","path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/core/prompt_executor.py","output_mode":"content","-A":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":14790,"cache_creation_input_tokens":22169,"cache_read_input_tokens":78479,"cache_creation":{"ephemeral_5m_input_tokens":22169,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH3ztAiG2Rn4qAc3rSX","type":"assistant","uuid":"c3f1b8c0-04ae-4784-9fca-6e56916c763c","timestamp":"2026-02-22T14:37:50.818Z"}
{"parentUuid":"c3f1b8c0-04ae-4784-9fca-6e56916c763c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VCgVaLx1A24Dm11VGkqFRs","type":"tool_result","content":"118:class PromptResult:\n119-    \"\"\"Result of executing a single prompt.\n120-\n121-    Attributes:\n122-        success: Whether the prompt completed successfully\n123-        output: The output text from Claude\n124-        error: Error message if command failed, None otherwise\n125-    \"\"\"\n126-\n127-    success: bool\n128-    output: str"}]},"uuid":"b4465766-b7e6-460d-99bb-2c4d9c78ae13","timestamp":"2026-02-22T14:37:51.241Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"118:class PromptResult:\n119-    \"\"\"Result of executing a single prompt.\n120-\n121-    Attributes:\n122-        success: Whether the prompt completed successfully\n123-        output: The output text from Claude\n124-        error: Error message if command failed, None otherwise\n125-    \"\"\"\n126-\n127-    success: bool\n128-    output: str","numLines":11}}
{"parentUuid":"b4465766-b7e6-460d-99bb-2c4d9c78ae13","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01FTL8PG2mi4dWuPTVgVWfdJ","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me check the existing test directory structure:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":15254,"cache_read_input_tokens":100648,"cache_creation":{"ephemeral_5m_input_tokens":15254,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH4PedUjCk4yoMb1p5o","type":"assistant","uuid":"2d582239-446d-4e4c-8839-4f7837433e16","timestamp":"2026-02-22T14:37:53.987Z"}
{"parentUuid":"2d582239-446d-4e4c-8839-4f7837433e16","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01FTL8PG2mi4dWuPTVgVWfdJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Gb8DRJhZCRD1PvyWd2bdwT","name":"Bash","input":{"command":"ls /home/runner/work/erk/erk/tests/core/ 2>/dev/null || echo \"No tests/core/ directory\"","description":"Check test directory structure"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":15254,"cache_read_input_tokens":100648,"cache_creation":{"ephemeral_5m_input_tokens":15254,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH4PedUjCk4yoMb1p5o","type":"assistant","uuid":"abec3c42-c81c-4820-af89-f4d3b3158c94","timestamp":"2026-02-22T14:37:55.059Z"}
{"parentUuid":"abec3c42-c81c-4820-af89-f4d3b3158c94","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Gb8DRJhZCRD1PvyWd2bdwT","type":"tool_result","content":"AGENTS.md\nCLAUDE.md\n__init__.py\nconfig\ndetection\nfoundation\ngithub\nimplementation_queue\noperations\ntest_cli_output.py\ntest_commit_message_generator.py\ntest_health_checks.py\ntest_impl_folder.py\ntest_impl_issue_wt_workflow.py\ntest_markers.py\ntest_output_filter.py\ntest_plan_context_provider.py\ntest_prompt_executor.py\ntest_script_result_output.py\nutils","is_error":false}]},"uuid":"ec165348-3c2b-4172-af48-6a85d7026055","timestamp":"2026-02-22T14:37:55.415Z","toolUseResult":{"stdout":"AGENTS.md\nCLAUDE.md\n__init__.py\nconfig\ndetection\nfoundation\ngithub\nimplementation_queue\noperations\ntest_cli_output.py\ntest_commit_message_generator.py\ntest_health_checks.py\ntest_impl_folder.py\ntest_impl_issue_wt_workflow.py\ntest_markers.py\ntest_output_filter.py\ntest_plan_context_provider.py\ntest_prompt_executor.py\ntest_script_result_output.py\nutils","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"ec165348-3c2b-4172-af48-6a85d7026055","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_0149VvxrfF3TpfhWAVXmQDgb","type":"message","role":"assistant","content":[{"type":"text","text":"Good. Now I have all the context I need. Let me create the branch slug generator module:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":247,"cache_read_input_tokens":115902,"cache_creation":{"ephemeral_5m_input_tokens":247,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH4hXR9HwQZWJXLYL33","type":"assistant","uuid":"76fdaa86-346f-4373-9872-8bc9317ec19d","timestamp":"2026-02-22T14:37:58.472Z"}
{"parentUuid":"76fdaa86-346f-4373-9872-8bc9317ec19d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_0149VvxrfF3TpfhWAVXmQDgb","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011UFRugNRRvEsjgMmuj7kP2","name":"Write","input":{"file_path":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","content":"\"\"\"Branch slug generation via LLM inference.\n\nThis module provides branch name slug generation using a fast LLM call\nto distill plan/issue titles into meaningful 2-4 word slugs before they\nenter the branch naming pipeline.\n\nFollows the CommitMessageGenerator pattern from src/erk/core/commit_message_generator.py.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom dataclasses import dataclass\n\nfrom erk_shared.core.prompt_executor import PromptExecutor, PromptResult\nfrom erk_shared.naming import sanitize_worktree_name\n\nBRANCH_SLUG_SYSTEM_PROMPT = \"\"\"\\\nYou are a branch name slug generator. Given a title, return ONLY a concise\n2-4 word slug using lowercase letters and hyphens. No explanation.\n\nRules:\n- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n- Capture the distinctive essence, not generic words\n- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n- Never exceed 30 characters total\n- Output ONLY the slug, nothing else\"\"\"\n\n\n@dataclass(frozen=True)\nclass BranchSlugResult:\n    \"\"\"Result of branch slug generation.\n\n    Attributes:\n        success: Whether generation succeeded\n        slug: The generated slug if successful\n        error_message: Error description if generation failed\n    \"\"\"\n\n    success: bool\n    slug: str | None\n    error_message: str | None\n\n\nclass BranchSlugGenerator:\n    \"\"\"Generates branch name slugs via LLM inference.\n\n    This is a concrete class (not ABC) that uses PromptExecutor for\n    testability. In tests, inject FakePromptExecutor with simulated prompt output.\n    \"\"\"\n\n    def __init__(self, executor: PromptExecutor) -> None:\n        self._executor = executor\n\n    def generate(self, title: str) -> BranchSlugResult:\n        \"\"\"Generate a branch slug from a title.\n\n        Sends the title to an LLM with the branch slug system prompt,\n        then validates the output meets slug requirements.\n\n        Args:\n            title: Plan or issue title to distill into a slug\n\n        Returns:\n            BranchSlugResult with success status and slug or error\n        \"\"\"\n        result = self._executor.execute_prompt(\n            title,\n            model=\"haiku\",\n            tools=None,\n            cwd=None,\n            system_prompt=BRANCH_SLUG_SYSTEM_PROMPT,\n            dangerous=False,\n        )\n\n        if not result.success:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=result.error or \"LLM execution failed\",\n            )\n\n        slug = _postprocess_slug(result.output)\n        if slug is None:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=f\"Invalid LLM output: {result.output!r}\",\n            )\n\n        return BranchSlugResult(\n            success=True,\n            slug=slug,\n            error_message=None,\n        )\n\n\ndef _postprocess_slug(raw_output: str) -> str | None:\n    \"\"\"Clean and validate LLM slug output.\n\n    Post-processing steps:\n    1. Strip whitespace\n    2. Strip surrounding quotes and backticks\n    3. Run through sanitize_worktree_name as safety net\n    4. Validate: must have 2+ hyphenated words\n    5. Validate: max 30 characters\n\n    Args:\n        raw_output: Raw LLM output string\n\n    Returns:\n        Validated slug string, or None if invalid\n    \"\"\"\n    stripped = raw_output.strip()\n\n    # Strip surrounding quotes and backticks\n    stripped = stripped.strip(\"\\\"'`\")\n\n    # Run through sanitize_worktree_name as safety net\n    sanitized = sanitize_worktree_name(stripped)\n\n    # Validate: must have 2+ hyphenated words\n    words = sanitized.split(\"-\")\n    if len(words) < 2:\n        return None\n\n    # Validate: max 30 characters\n    if len(sanitized) > 30:\n        return None\n\n    return sanitized\n\n\ndef generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str:\n    \"\"\"Generate a slug from title, falling back to raw title on failure.\n\n    Convenience function that returns the LLM slug on success,\n    or the raw title on failure (so sanitize_worktree_name handles it downstream).\n\n    Args:\n        executor: PromptExecutor for LLM inference\n        title: Plan or issue title\n\n    Returns:\n        LLM-generated slug on success, raw title on failure\n    \"\"\"\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(title)\n    if result.success and result.slug is not None:\n        return result.slug\n    return title\n"},"caller":{"type":"direct"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":247,"cache_read_input_tokens":115902,"cache_creation":{"ephemeral_5m_input_tokens":247,"ephemeral_1h_input_tokens":0},"output_tokens":1352,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH4hXR9HwQZWJXLYL33","type":"assistant","uuid":"214552e5-f5ed-4722-9505-8468e8e32bcf","timestamp":"2026-02-22T14:38:17.395Z"}
{"parentUuid":"214552e5-f5ed-4722-9505-8468e8e32bcf","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011UFRugNRRvEsjgMmuj7kP2","type":"tool_result","content":"File created successfully at: /home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py"}]},"uuid":"5b8c3a1e-861c-44d6-b600-e349e8fb100e","timestamp":"2026-02-22T14:38:18.953Z","toolUseResult":{"type":"create","filePath":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","content":"\"\"\"Branch slug generation via LLM inference.\n\nThis module provides branch name slug generation using a fast LLM call\nto distill plan/issue titles into meaningful 2-4 word slugs before they\nenter the branch naming pipeline.\n\nFollows the CommitMessageGenerator pattern from src/erk/core/commit_message_generator.py.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom dataclasses import dataclass\n\nfrom erk_shared.core.prompt_executor import PromptExecutor, PromptResult\nfrom erk_shared.naming import sanitize_worktree_name\n\nBRANCH_SLUG_SYSTEM_PROMPT = \"\"\"\\\nYou are a branch name slug generator. Given a title, return ONLY a concise\n2-4 word slug using lowercase letters and hyphens. No explanation.\n\nRules:\n- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n- Capture the distinctive essence, not generic words\n- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n- Never exceed 30 characters total\n- Output ONLY the slug, nothing else\"\"\"\n\n\n@dataclass(frozen=True)\nclass BranchSlugResult:\n    \"\"\"Result of branch slug generation.\n\n    Attributes:\n        success: Whether generation succeeded\n        slug: The generated slug if successful\n        error_message: Error description if generation failed\n    \"\"\"\n\n    success: bool\n    slug: str | None\n    error_message: str | None\n\n\nclass BranchSlugGenerator:\n    \"\"\"Generates branch name slugs via LLM inference.\n\n    This is a concrete class (not ABC) that uses PromptExecutor for\n    testability. In tests, inject FakePromptExecutor with simulated prompt output.\n    \"\"\"\n\n    def __init__(self, executor: PromptExecutor) -> None:\n        self._executor = executor\n\n    def generate(self, title: str) -> BranchSlugResult:\n        \"\"\"Generate a branch slug from a title.\n\n        Sends the title to an LLM with the branch slug system prompt,\n        then validates the output meets slug requirements.\n\n        Args:\n            title: Plan or issue title to distill into a slug\n\n        Returns:\n            BranchSlugResult with success status and slug or error\n        \"\"\"\n        result = self._executor.execute_prompt(\n            title,\n            model=\"haiku\",\n            tools=None,\n            cwd=None,\n            system_prompt=BRANCH_SLUG_SYSTEM_PROMPT,\n            dangerous=False,\n        )\n\n        if not result.success:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=result.error or \"LLM execution failed\",\n            )\n\n        slug = _postprocess_slug(result.output)\n        if slug is None:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=f\"Invalid LLM output: {result.output!r}\",\n            )\n\n        return BranchSlugResult(\n            success=True,\n            slug=slug,\n            error_message=None,\n        )\n\n\ndef _postprocess_slug(raw_output: str) -> str | None:\n    \"\"\"Clean and validate LLM slug output.\n\n    Post-processing steps:\n    1. Strip whitespace\n    2. Strip surrounding quotes and backticks\n    3. Run through sanitize_worktree_name as safety net\n    4. Validate: must have 2+ hyphenated words\n    5. Validate: max 30 characters\n\n    Args:\n        raw_output: Raw LLM output string\n\n    Returns:\n        Validated slug string, or None if invalid\n    \"\"\"\n    stripped = raw_output.strip()\n\n    # Strip surrounding quotes and backticks\n    stripped = stripped.strip(\"\\\"'`\")\n\n    # Run through sanitize_worktree_name as safety net\n    sanitized = sanitize_worktree_name(stripped)\n\n    # Validate: must have 2+ hyphenated words\n    words = sanitized.split(\"-\")\n    if len(words) < 2:\n        return None\n\n    # Validate: max 30 characters\n    if len(sanitized) > 30:\n        return None\n\n    return sanitized\n\n\ndef generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str:\n    \"\"\"Generate a slug from title, falling back to raw title on failure.\n\n    Convenience function that returns the LLM slug on success,\n    or the raw title on failure (so sanitize_worktree_name handles it downstream).\n\n    Args:\n        executor: PromptExecutor for LLM inference\n        title: Plan or issue title\n\n    Returns:\n        LLM-generated slug on success, raw title on failure\n    \"\"\"\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(title)\n    if result.success and result.slug is not None:\n        return result.slug\n    return title\n","structuredPatch":[],"originalFile":null}}
{"parentUuid":"5b8c3a1e-861c-44d6-b600-e349e8fb100e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Mwe7JwCmiWgsCJU9A8FRyd","type":"message","role":"assistant","content":[{"type":"text","text":"I notice I imported `re` but don't use it. Let me fix that:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1588,"cache_read_input_tokens":116149,"cache_creation":{"ephemeral_5m_input_tokens":1588,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH6SDUNpetRAwVfWQ3w","type":"assistant","uuid":"87ace417-e24a-4ef1-b64f-5c9fa3901c9c","timestamp":"2026-02-22T14:38:21.624Z"}
{"parentUuid":"87ace417-e24a-4ef1-b64f-5c9fa3901c9c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Mwe7JwCmiWgsCJU9A8FRyd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011DzjazrdWgqy44XhUpGzAU","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","old_string":"import re\nfrom dataclasses import dataclass","new_string":"from dataclasses import dataclass"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1588,"cache_read_input_tokens":116149,"cache_creation":{"ephemeral_5m_input_tokens":1588,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH6SDUNpetRAwVfWQ3w","type":"assistant","uuid":"74e73107-2bf0-4fa8-97ba-6ca441745a04","timestamp":"2026-02-22T14:38:22.563Z"}
{"parentUuid":"74e73107-2bf0-4fa8-97ba-6ca441745a04","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011DzjazrdWgqy44XhUpGzAU","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py has been updated successfully."}]},"uuid":"cf5b79d5-b1bb-4ca4-973f-99efbded23aa","timestamp":"2026-02-22T14:38:23.241Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","oldString":"import re\nfrom dataclasses import dataclass","newString":"from dataclasses import dataclass","originalFile":"\"\"\"Branch slug generation via LLM inference.\n\nThis module provides branch name slug generation using a fast LLM call\nto distill plan/issue titles into meaningful 2-4 word slugs before they\nenter the branch naming pipeline.\n\nFollows the CommitMessageGenerator pattern from src/erk/core/commit_message_generator.py.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport re\nfrom dataclasses import dataclass\n\nfrom erk_shared.core.prompt_executor import PromptExecutor, PromptResult\nfrom erk_shared.naming import sanitize_worktree_name\n\nBRANCH_SLUG_SYSTEM_PROMPT = \"\"\"\\\nYou are a branch name slug generator. Given a title, return ONLY a concise\n2-4 word slug using lowercase letters and hyphens. No explanation.\n\nRules:\n- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n- Capture the distinctive essence, not generic words\n- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n- Never exceed 30 characters total\n- Output ONLY the slug, nothing else\"\"\"\n\n\n@dataclass(frozen=True)\nclass BranchSlugResult:\n    \"\"\"Result of branch slug generation.\n\n    Attributes:\n        success: Whether generation succeeded\n        slug: The generated slug if successful\n        error_message: Error description if generation failed\n    \"\"\"\n\n    success: bool\n    slug: str | None\n    error_message: str | None\n\n\nclass BranchSlugGenerator:\n    \"\"\"Generates branch name slugs via LLM inference.\n\n    This is a concrete class (not ABC) that uses PromptExecutor for\n    testability. In tests, inject FakePromptExecutor with simulated prompt output.\n    \"\"\"\n\n    def __init__(self, executor: PromptExecutor) -> None:\n        self._executor = executor\n\n    def generate(self, title: str) -> BranchSlugResult:\n        \"\"\"Generate a branch slug from a title.\n\n        Sends the title to an LLM with the branch slug system prompt,\n        then validates the output meets slug requirements.\n\n        Args:\n            title: Plan or issue title to distill into a slug\n\n        Returns:\n            BranchSlugResult with success status and slug or error\n        \"\"\"\n        result = self._executor.execute_prompt(\n            title,\n            model=\"haiku\",\n            tools=None,\n            cwd=None,\n            system_prompt=BRANCH_SLUG_SYSTEM_PROMPT,\n            dangerous=False,\n        )\n\n        if not result.success:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=result.error or \"LLM execution failed\",\n            )\n\n        slug = _postprocess_slug(result.output)\n        if slug is None:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=f\"Invalid LLM output: {result.output!r}\",\n            )\n\n        return BranchSlugResult(\n            success=True,\n            slug=slug,\n            error_message=None,\n        )\n\n\ndef _postprocess_slug(raw_output: str) -> str | None:\n    \"\"\"Clean and validate LLM slug output.\n\n    Post-processing steps:\n    1. Strip whitespace\n    2. Strip surrounding quotes and backticks\n    3. Run through sanitize_worktree_name as safety net\n    4. Validate: must have 2+ hyphenated words\n    5. Validate: max 30 characters\n\n    Args:\n        raw_output: Raw LLM output string\n\n    Returns:\n        Validated slug string, or None if invalid\n    \"\"\"\n    stripped = raw_output.strip()\n\n    # Strip surrounding quotes and backticks\n    stripped = stripped.strip(\"\\\"'`\")\n\n    # Run through sanitize_worktree_name as safety net\n    sanitized = sanitize_worktree_name(stripped)\n\n    # Validate: must have 2+ hyphenated words\n    words = sanitized.split(\"-\")\n    if len(words) < 2:\n        return None\n\n    # Validate: max 30 characters\n    if len(sanitized) > 30:\n        return None\n\n    return sanitized\n\n\ndef generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str:\n    \"\"\"Generate a slug from title, falling back to raw title on failure.\n\n    Convenience function that returns the LLM slug on success,\n    or the raw title on failure (so sanitize_worktree_name handles it downstream).\n\n    Args:\n        executor: PromptExecutor for LLM inference\n        title: Plan or issue title\n\n    Returns:\n        LLM-generated slug on success, raw title on failure\n    \"\"\"\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(title)\n    if result.success and result.slug is not None:\n        return result.slug\n    return title\n","structuredPatch":[{"oldStart":9,"oldLines":7,"newStart":9,"newLines":6,"lines":[" "," from __future__ import annotations"," ","-import re"," from dataclasses import dataclass"," "," from erk_shared.core.prompt_executor import PromptExecutor, PromptResult"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"cf5b79d5-b1bb-4ca4-973f-99efbded23aa","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01BpDz6Yd1WNwwy3CFyaLLst","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018ThrSkdjqgruyihcHM8jDZ","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":196,"cache_read_input_tokens":117737,"cache_creation":{"ephemeral_5m_input_tokens":196,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH6kWoUxfjjHUAnULpc","type":"assistant","uuid":"6a4f2074-8af3-4782-8771-a92af8301bb7","timestamp":"2026-02-22T14:38:28.038Z"}
{"parentUuid":"6a4f2074-8af3-4782-8771-a92af8301bb7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018ThrSkdjqgruyihcHM8jDZ","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"e4313e3c-6908-43bf-b4cf-aba9b8a24e0f","timestamp":"2026-02-22T14:38:28.092Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"pending","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]}}
{"parentUuid":"e4313e3c-6908-43bf-b4cf-aba9b8a24e0f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01DwoTvoTK3Y2um7i5ZfA4ZX","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me create the tests. Let me first check the test for commit_message_generator to see the pattern:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":257,"cache_read_input_tokens":117933,"cache_creation":{"ephemeral_5m_input_tokens":257,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH77EFKjAmthWEdX75R","type":"assistant","uuid":"1f4d8162-91e5-4b58-8b95-cd22e9104d46","timestamp":"2026-02-22T14:38:31.259Z"}
{"parentUuid":"1f4d8162-91e5-4b58-8b95-cd22e9104d46","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01DwoTvoTK3Y2um7i5ZfA4ZX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WQXSWHqNSDRhSnpqC2sUa8","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/core/test_commit_message_generator.py","limit":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":257,"cache_read_input_tokens":117933,"cache_creation":{"ephemeral_5m_input_tokens":257,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH77EFKjAmthWEdX75R","type":"assistant","uuid":"4633cf41-e5c9-4c2a-b1f9-f139c305955b","timestamp":"2026-02-22T14:38:32.071Z"}
{"parentUuid":"4633cf41-e5c9-4c2a-b1f9-f139c305955b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WQXSWHqNSDRhSnpqC2sUa8","type":"tool_result","content":"     1→\"\"\"Tests for CommitMessageGenerator.\"\"\"\n     2→\n     3→from pathlib import Path\n     4→\n     5→from erk.core.commit_message_generator import (\n     6→    CommitMessageGenerator,\n     7→    CommitMessageRequest,\n     8→    CommitMessageResult,\n     9→)\n    10→from erk.core.plan_context_provider import PlanContext\n    11→from erk_shared.gateway.gt.events import CompletionEvent, ProgressEvent\n    12→from tests.fakes.prompt_executor import FakePromptExecutor\n    13→\n    14→\n    15→def _consume_generator(\n    16→    generator: CommitMessageGenerator, request: CommitMessageRequest\n    17→) -> tuple[CommitMessageResult, list[ProgressEvent]]:\n    18→    \"\"\"Consume generator and return result with collected progress events.\"\"\"\n    19→    progress_events: list[ProgressEvent] = []\n    20→    result: CommitMessageResult | None = None\n    21→\n    22→    for event in generator.generate(request):\n    23→        if isinstance(event, ProgressEvent):\n    24→            progress_events.append(event)\n    25→        elif isinstance(event, CompletionEvent):\n    26→            result = event.result\n    27→\n    28→    if result is None:\n    29→        raise AssertionError(\"Generator did not yield CompletionEvent\")\n    30→\n    31→    return result, progress_events\n    32→\n    33→\n    34→def test_generate_success(tmp_path: Path) -> None:\n    35→    \"\"\"Test successful commit message generation.\"\"\"\n    36→    # Arrange\n    37→    diff_file = tmp_path / \"test.diff\"\n    38→    diff_file.write_text(\"diff --git a/file.py b/file.py\\n-old\\n+new\", encoding=\"utf-8\")\n    39→\n    40→    executor = FakePromptExecutor(\n    41→        available=True,\n    42→        simulated_prompt_output=\"Add new feature\\n\\nThis adds a new feature to the codebase.\",\n    43→    )\n    44→    generator = CommitMessageGenerator(executor)\n    45→    request = CommitMessageRequest(\n    46→        diff_file=diff_file,\n    47→        repo_root=tmp_path,\n    48→        current_branch=\"feature-branch\",\n    49→        parent_branch=\"main\",\n    50→        commit_messages=None,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"c00aa875-1e15-42c7-ad11-fe93a6d0a80c","timestamp":"2026-02-22T14:38:32.209Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/core/test_commit_message_generator.py","content":"\"\"\"Tests for CommitMessageGenerator.\"\"\"\n\nfrom pathlib import Path\n\nfrom erk.core.commit_message_generator import (\n    CommitMessageGenerator,\n    CommitMessageRequest,\n    CommitMessageResult,\n)\nfrom erk.core.plan_context_provider import PlanContext\nfrom erk_shared.gateway.gt.events import CompletionEvent, ProgressEvent\nfrom tests.fakes.prompt_executor import FakePromptExecutor\n\n\ndef _consume_generator(\n    generator: CommitMessageGenerator, request: CommitMessageRequest\n) -> tuple[CommitMessageResult, list[ProgressEvent]]:\n    \"\"\"Consume generator and return result with collected progress events.\"\"\"\n    progress_events: list[ProgressEvent] = []\n    result: CommitMessageResult | None = None\n\n    for event in generator.generate(request):\n        if isinstance(event, ProgressEvent):\n            progress_events.append(event)\n        elif isinstance(event, CompletionEvent):\n            result = event.result\n\n    if result is None:\n        raise AssertionError(\"Generator did not yield CompletionEvent\")\n\n    return result, progress_events\n\n\ndef test_generate_success(tmp_path: Path) -> None:\n    \"\"\"Test successful commit message generation.\"\"\"\n    # Arrange\n    diff_file = tmp_path / \"test.diff\"\n    diff_file.write_text(\"diff --git a/file.py b/file.py\\n-old\\n+new\", encoding=\"utf-8\")\n\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"Add new feature\\n\\nThis adds a new feature to the codebase.\",\n    )\n    generator = CommitMessageGenerator(executor)\n    request = CommitMessageRequest(\n        diff_file=diff_file,\n        repo_root=tmp_path,\n        current_branch=\"feature-branch\",\n        parent_branch=\"main\",\n        commit_messages=None,","numLines":50,"startLine":1,"totalLines":530}}}
{"parentUuid":"c00aa875-1e15-42c7-ad11-fe93a6d0a80c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014nQTmyfiLsuTompbDFqMpn","type":"message","role":"assistant","content":[{"type":"text","text":"Interesting, there's a separate `tests/fakes/prompt_executor.py`. Let me check that:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":836,"cache_read_input_tokens":118190,"cache_creation":{"ephemeral_5m_input_tokens":836,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH7QpuVtNP1ATSH2FCw","type":"assistant","uuid":"1593fbeb-014a-48c8-906a-1b06a39ba4a6","timestamp":"2026-02-22T14:38:34.606Z"}
{"parentUuid":"1593fbeb-014a-48c8-906a-1b06a39ba4a6","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014nQTmyfiLsuTompbDFqMpn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MrX3oqRd9HF9YaXRQN1CSX","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/fakes/prompt_executor.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":836,"cache_read_input_tokens":118190,"cache_creation":{"ephemeral_5m_input_tokens":836,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH7QpuVtNP1ATSH2FCw","type":"assistant","uuid":"a5ec4ae4-070d-436a-927c-dc5fc7d6f8ce","timestamp":"2026-02-22T14:38:35.071Z"}
{"parentUuid":"a5ec4ae4-070d-436a-927c-dc5fc7d6f8ce","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MrX3oqRd9HF9YaXRQN1CSX","type":"tool_result","content":"     1→\"\"\"Fake implementation of PromptExecutor for testing.\n     2→\n     3→This fake enables testing prompt execution without\n     4→requiring the actual Claude CLI or using subprocess mocks.\n     5→\"\"\"\n     6→\n     7→from __future__ import annotations\n     8→\n     9→from collections.abc import Iterator\n    10→from pathlib import Path\n    11→from typing import TYPE_CHECKING\n    12→\n    13→if TYPE_CHECKING:\n    14→    from erk_shared.context.types import PermissionMode\n    15→\n    16→from erk_shared.core.prompt_executor import (\n    17→    CommandResult,\n    18→    ErrorEvent,\n    19→    ExecutorEvent,\n    20→    IssueNumberEvent,\n    21→    NoOutputEvent,\n    22→    NoTurnsEvent,\n    23→    PrNumberEvent,\n    24→    ProcessErrorEvent,\n    25→    PromptExecutor,\n    26→    PromptResult,\n    27→    PrTitleEvent,\n    28→    PrUrlEvent,\n    29→    SpinnerUpdateEvent,\n    30→    TextEvent,\n    31→    ToolEvent,\n    32→)\n    33→\n    34→\n    35→class FakePromptExecutor(PromptExecutor):\n    36→    \"\"\"In-memory fake implementation of prompt execution.\n    37→\n    38→    Constructor Injection:\n    39→    - All state is provided via constructor parameters\n    40→    - Mutations are tracked in read-only properties\n    41→\n    42→    When to Use:\n    43→    - Testing commands that execute prompts (e.g., erk implement --no-interactive)\n    44→    - Simulating executor availability\n    45→    - Verifying command execution without actual subprocess calls\n    46→\n    47→    Examples:\n    48→        # Test with executor available and successful execution\n    49→        >>> executor = FakePromptExecutor(available=True)\n    50→        >>> executor.execute_command(\"/erk:plan-implement\", Path(\"/repo\"), False)\n    51→        >>> assert len(executor.executed_commands) == 1\n    52→\n    53→        # Test with executor not available\n    54→        >>> executor = FakePromptExecutor(available=False)\n    55→        >>> assert not executor.is_available()\n    56→\n    57→        # Test command failure\n    58→        >>> executor = FakePromptExecutor(command_should_fail=True)\n    59→        >>> try:\n    60→        ...     executor.execute_command(\"/bad-command\", Path(\"/repo\"), False)\n    61→        ... except RuntimeError:\n    62→        ...     print(\"Command failed as expected\")\n    63→\n    64→        # Test interactive execution\n    65→        >>> executor = FakePromptExecutor(available=True)\n    66→        >>> executor.execute_interactive(Path(\"/repo\"), dangerous=False)\n    67→        >>> assert len(executor.interactive_calls) == 1\n    68→    \"\"\"\n    69→\n    70→    def __init__(\n    71→        self,\n    72→        *,\n    73→        available: bool = True,\n    74→        command_should_fail: bool = False,\n    75→        simulated_pr_url: str | None = None,\n    76→        simulated_pr_number: int | None = None,\n    77→        simulated_pr_title: str | None = None,\n    78→        simulated_issue_number: int | None = None,\n    79→        simulated_tool_events: list[str] | None = None,\n    80→        simulated_no_output: bool = False,\n    81→        simulated_zero_turns: bool = False,\n    82→        simulated_process_error: str | None = None,\n    83→        simulated_prompt_output: str | None = None,\n    84→        simulated_prompt_error: str | None = None,\n    85→        simulated_no_work_events: bool = False,\n    86→        simulated_passthrough_exit_code: int = 0,\n    87→    ) -> None:\n    88→        \"\"\"Initialize fake with predetermined behavior.\n    89→\n    90→        Args:\n    91→            available: Whether the executor should appear available\n    92→            command_should_fail: Whether execute_command should raise RuntimeError\n    93→            simulated_pr_url: PR URL to return in CommandResult (simulates successful PR creation)\n    94→            simulated_pr_number: PR number to return (simulates PR metadata)\n    95→            simulated_pr_title: PR title to return (simulates PR metadata)\n    96→            simulated_issue_number: Issue number to return (simulates linked issue)\n    97→            simulated_tool_events: Tool event contents to emit (e.g., \"Using...\")\n    98→            simulated_no_output: Whether to simulate Claude CLI producing no output\n    99→            simulated_zero_turns: Whether to simulate Claude completing with num_turns=0\n   100→                (hook blocking scenario)\n   101→            simulated_process_error: Error message to simulate process startup failure\n   102→            simulated_prompt_output: Output to return from execute_prompt() on success.\n   103→                If None, defaults to \"Test Title\\n\\nTest body\"\n   104→            simulated_prompt_error: Error message to return from execute_prompt() on failure.\n   105→                If set, execute_prompt() will return a failure result.\n   106→            simulated_no_work_events: Whether to simulate Claude completing successfully\n   107→                but without emitting any work events (TextEvent or ToolEvent). This\n   108→                tests the \"empty response\" failure mode where Claude produces JSON\n   109→                but no actual work output.\n   110→            simulated_passthrough_exit_code: Exit code to return from execute_prompt_passthrough().\n   111→                Defaults to 0 (success).\n   112→        \"\"\"\n   113→        self._available = available\n   114→        self._command_should_fail = command_should_fail\n   115→        self._simulated_pr_url = simulated_pr_url\n   116→        self._simulated_pr_number = simulated_pr_number\n   117→        self._simulated_pr_title = simulated_pr_title\n   118→        self._simulated_issue_number = simulated_issue_number\n   119→        self._simulated_tool_events = simulated_tool_events or []\n   120→        self._simulated_no_output = simulated_no_output\n   121→        self._simulated_zero_turns = simulated_zero_turns\n   122→        self._simulated_process_error = simulated_process_error\n   123→        self._simulated_prompt_output = simulated_prompt_output\n   124→        self._simulated_prompt_error = simulated_prompt_error\n   125→        self._simulated_no_work_events = simulated_no_work_events\n   126→        self._simulated_passthrough_exit_code = simulated_passthrough_exit_code\n   127→        self._executed_commands: list[tuple[str, Path, bool, bool, str | None]] = []\n   128→        self._interactive_calls: list[tuple[Path, bool, str, Path | None, str | None, str]] = []\n   129→        self._prompt_calls: list[tuple[str, str | None]] = []\n   130→        self._passthrough_calls: list[tuple[str, str, list[str] | None, Path, bool]] = []\n   131→\n   132→    def is_available(self) -> bool:\n   133→        \"\"\"Return the availability configured at construction time.\"\"\"\n   134→        return self._available\n   135→\n   136→    def execute_command_streaming(\n   137→        self,\n   138→        *,\n   139→        command: str,\n   140→        worktree_path: Path,\n   141→        dangerous: bool,\n   142→        verbose: bool = False,\n   143→        debug: bool = False,\n   144→        model: str | None = None,\n   145→        permission_mode: PermissionMode,\n   146→        allow_dangerous: bool = False,\n   147→    ) -> Iterator[ExecutorEvent]:\n   148→        \"\"\"Track command execution and yield simulated typed events.\n   149→\n   150→        This method records the call parameters for test assertions.\n   151→        It does not execute any actual subprocess operations.\n   152→\n   153→        Args:\n   154→            command: The slash command to execute\n   155→            worktree_path: Path to worktree directory\n   156→            dangerous: Whether to skip permission prompts\n   157→            verbose: Whether to show raw output or filtered output\n   158→            debug: Whether to emit debug output for stream parsing\n   159→            model: Optional model name (haiku, sonnet, opus) - recorded but not used\n   160→            permission_mode: Claude CLI permission mode - recorded but not used\n   161→            allow_dangerous: Whether --allow-dangerously-skip-permissions - recorded but not used\n   162→\n   163→        Yields:\n   164→            ExecutorEvent objects simulating command execution\n   165→\n   166→        Raises:\n   167→            RuntimeError: If command_should_fail was set to True\n   168→        \"\"\"\n   169→        self._executed_commands.append((command, worktree_path, dangerous, verbose, model))\n   170→\n   171→        # Process error takes precedence (simulates Popen failure)\n   172→        if self._simulated_process_error is not None:\n   173→            yield ProcessErrorEvent(message=self._simulated_process_error)\n   174→            return\n   175→\n   176→        # No output simulation (simulates Claude CLI producing no output)\n   177→        if self._simulated_no_output:\n   178→            yield NoOutputEvent(\n   179→                diagnostic=f\"Claude command {command} completed but produced no output\"\n   180→            )\n   181→            return\n   182→\n   183→        # Zero turns simulation (simulates hook blocking)\n   184→        if self._simulated_zero_turns:\n   185→            diag = f\"Claude command {command} completed without processing\"\n   186→            diag += \"\\n  This usually means a hook blocked the command\"\n   187→            diag += \"\\n  Run 'claude' directly to see hook error messages\"\n   188→            diag += f\"\\n  Working directory: {worktree_path}\"\n   189→            yield NoTurnsEvent(diagnostic=diag)\n   190→            return\n   191→\n   192→        if self._command_should_fail:\n   193→            yield ErrorEvent(message=f\"Claude command {command} failed (simulated failure)\")\n   194→            return\n   195→\n   196→        # No work events simulation: emits only non-work events (spinner, metadata)\n   197→        # This tests the scenario where Claude completes but produces no output\n   198→        if self._simulated_no_work_events:\n   199→            yield SpinnerUpdateEvent(status=f\"Running {command}...\")\n   200→            yield SpinnerUpdateEvent(status=\"Completed\")\n   201→            # Note: no TextEvent or ToolEvent emitted\n   202→            return\n   203→\n   204→        # Simulate some basic streaming events\n   205→        yield TextEvent(content=\"Starting execution...\")\n   206→        yield SpinnerUpdateEvent(status=f\"Running {command}...\")\n   207→\n   208→        # Yield any configured tool events\n   209→        for tool_event in self._simulated_tool_events:\n   210→            yield ToolEvent(summary=tool_event)\n   211→\n   212→        yield TextEvent(content=\"Execution complete\")\n   213→\n   214→        # Yield PR metadata if configured\n   215→        if self._simulated_pr_url is not None:\n   216→            yield PrUrlEvent(url=self._simulated_pr_url)\n   217→        if self._simulated_pr_number is not None:\n   218→            yield PrNumberEvent(number=self._simulated_pr_number)\n   219→        if self._simulated_pr_title is not None:\n   220→            yield PrTitleEvent(title=self._simulated_pr_title)\n   221→        if self._simulated_issue_number is not None:\n   222→            yield IssueNumberEvent(number=self._simulated_issue_number)\n   223→\n   224→    def execute_command(\n   225→        self,\n   226→        *,\n   227→        command: str,\n   228→        worktree_path: Path,\n   229→        dangerous: bool,\n   230→        verbose: bool = False,\n   231→        model: str | None = None,\n   232→        permission_mode: PermissionMode,\n   233→        allow_dangerous: bool = False,\n   234→    ) -> CommandResult:\n   235→        \"\"\"Track command execution without running subprocess.\n   236→\n   237→        This method records the call parameters for test assertions.\n   238→        It does not execute any actual subprocess operations.\n   239→\n   240→        Args:\n   241→            command: The slash command to execute\n   242→            worktree_path: Path to worktree directory\n   243→            dangerous: Whether to skip permission prompts\n   244→            verbose: Whether to show raw output or filtered output\n   245→            model: Optional model name (ignored in fake)\n   246→\n   247→        Returns:\n   248→            CommandResult with success status\n   249→\n   250→        Raises:\n   251→            RuntimeError: If command_should_fail was set to True\n   252→        \"\"\"\n   253→        self._executed_commands.append((command, worktree_path, dangerous, verbose, model))\n   254→\n   255→        if self._command_should_fail:\n   256→            return CommandResult(\n   257→                success=False,\n   258→                pr_url=None,\n   259→                pr_number=None,\n   260→                pr_title=None,\n   261→                issue_number=None,\n   262→                duration_seconds=0.0,\n   263→                error_message=f\"Claude command {command} failed (simulated failure)\",\n   264→                filtered_messages=[],\n   265→            )\n   266→\n   267→        return CommandResult(\n   268→            success=True,\n   269→            pr_url=self._simulated_pr_url,\n   270→            pr_number=self._simulated_pr_number,\n   271→            pr_title=self._simulated_pr_title,\n   272→            issue_number=self._simulated_issue_number,\n   273→            duration_seconds=0.0,\n   274→            error_message=None,\n   275→            filtered_messages=[],\n   276→        )\n   277→\n   278→    def execute_interactive(\n   279→        self,\n   280→        *,\n   281→        worktree_path: Path,\n   282→        dangerous: bool,\n   283→        command: str,\n   284→        target_subpath: Path | None,\n   285→        model: str | None = None,\n   286→        permission_mode: PermissionMode,\n   287→    ) -> None:\n   288→        \"\"\"Track interactive execution without replacing process.\n   289→\n   290→        This method records the call parameters for test assertions.\n   291→        Unlike RealPromptExecutor, this does not use os.execvp and returns\n   292→        normally to allow tests to continue.\n   293→\n   294→        Raises:\n   295→            RuntimeError: If Claude CLI is not available\n   296→        \"\"\"\n   297→        if not self._available:\n   298→            raise RuntimeError(\"Claude CLI not found\\nInstall from: https://claude.com/download\")\n   299→\n   300→        self._interactive_calls.append(\n   301→            (worktree_path, dangerous, command, target_subpath, model, permission_mode)\n   302→        )\n   303→\n   304→    @property\n   305→    def executed_commands(self) -> list[tuple[str, Path, bool, bool, str | None]]:\n   306→        \"\"\"Get the list of execute_command() calls that were made.\n   307→\n   308→        Returns list of (command, worktree_path, dangerous, verbose, model) tuples.\n   309→\n   310→        This property is for test assertions only.\n   311→        \"\"\"\n   312→        return self._executed_commands.copy()\n   313→\n   314→    @property\n   315→    def interactive_calls(\n   316→        self,\n   317→    ) -> list[tuple[Path, bool, str, Path | None, str | None, str]]:\n   318→        \"\"\"Get the list of execute_interactive() calls that were made.\n   319→\n   320→        Returns list of tuples:\n   321→        (worktree_path, dangerous, command, target_subpath, model, permission_mode)\n   322→\n   323→        This property is for test assertions only.\n   324→        \"\"\"\n   325→        return self._interactive_calls.copy()\n   326→\n   327→    def execute_prompt(\n   328→        self,\n   329→        prompt: str,\n   330→        *,\n   331→        model: str,\n   332→        tools: list[str] | None,\n   333→        cwd: Path | None,\n   334→        system_prompt: str | None,\n   335→        dangerous: bool,\n   336→    ) -> PromptResult:\n   337→        \"\"\"Track prompt execution and return simulated result.\n   338→\n   339→        This method records the prompt, system_prompt, and dangerous flag for test assertions.\n   340→        It does not execute any actual subprocess operations.\n   341→\n   342→        Args:\n   343→            prompt: The prompt text to send\n   344→            model: Model to use (ignored in fake)\n   345→            tools: Optional list of allowed tools (ignored in fake)\n   346→            cwd: Optional working directory (ignored in fake)\n   347→            system_prompt: Optional system prompt (tracked for test assertions)\n   348→            dangerous: Whether --dangerously-skip-permissions was requested\n   349→                (tracked for test assertions)\n   350→\n   351→        Returns:\n   352→            PromptResult with simulated output or error\n   353→        \"\"\"\n   354→        self._prompt_calls.append((prompt, system_prompt, dangerous))\n   355→\n   356→        if self._simulated_prompt_error is not None:\n   357→            return PromptResult(\n   358→                success=False,\n   359→                output=\"\",\n   360→                error=self._simulated_prompt_error,\n   361→            )\n   362→\n   363→        # Default output if none specified\n   364→        output = self._simulated_prompt_output\n   365→        if output is None:\n   366→            output = \"Test Title\\n\\nTest body\"\n   367→\n   368→        return PromptResult(\n   369→            success=True,\n   370→            output=output,\n   371→            error=None,\n   372→        )\n   373→\n   374→    @property\n   375→    def prompt_calls(self) -> list[tuple[str, str | None, bool]]:\n   376→        \"\"\"Get the list of execute_prompt() calls that were made.\n   377→\n   378→        Returns list of (prompt, system_prompt, dangerous) tuples.\n   379→\n   380→        This property is for test assertions only.\n   381→        \"\"\"\n   382→        return self._prompt_calls.copy()\n   383→\n   384→    def execute_prompt_passthrough(\n   385→        self,\n   386→        prompt: str,\n   387→        *,\n   388→        model: str,\n   389→        tools: list[str] | None,\n   390→        cwd: Path,\n   391→        dangerous: bool,\n   392→    ) -> int:\n   393→        \"\"\"Track passthrough execution and return configured exit code.\n   394→\n   395→        This method records the call parameters for test assertions.\n   396→        It does not execute any actual subprocess operations.\n   397→\n   398→        Args:\n   399→            prompt: The prompt text to send\n   400→            model: Model to use (recorded for assertions)\n   401→            tools: Optional list of allowed tools (recorded for assertions)\n   402→            cwd: Working directory (recorded for assertions)\n   403→            dangerous: Whether dangerous mode is enabled (recorded for assertions)\n   404→\n   405→        Returns:\n   406→            The simulated exit code configured at construction time\n   407→        \"\"\"\n   408→        self._passthrough_calls.append((prompt, model, tools, cwd, dangerous))\n   409→        return self._simulated_passthrough_exit_code\n   410→\n   411→    @property\n   412→    def passthrough_calls(self) -> list[tuple[str, str, list[str] | None, Path, bool]]:\n   413→        \"\"\"Get the list of execute_prompt_passthrough() calls that were made.\n   414→\n   415→        Returns list of (prompt, model, tools, cwd, dangerous) tuples.\n   416→\n   417→        This property is for test assertions only.\n   418→        \"\"\"\n   419→        return self._passthrough_calls.copy()\n   420→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b0295ce6-152a-4ecd-9f87-147c5c00e23b","timestamp":"2026-02-22T14:38:35.084Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/fakes/prompt_executor.py","content":"\"\"\"Fake implementation of PromptExecutor for testing.\n\nThis fake enables testing prompt execution without\nrequiring the actual Claude CLI or using subprocess mocks.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Iterator\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from erk_shared.context.types import PermissionMode\n\nfrom erk_shared.core.prompt_executor import (\n    CommandResult,\n    ErrorEvent,\n    ExecutorEvent,\n    IssueNumberEvent,\n    NoOutputEvent,\n    NoTurnsEvent,\n    PrNumberEvent,\n    ProcessErrorEvent,\n    PromptExecutor,\n    PromptResult,\n    PrTitleEvent,\n    PrUrlEvent,\n    SpinnerUpdateEvent,\n    TextEvent,\n    ToolEvent,\n)\n\n\nclass FakePromptExecutor(PromptExecutor):\n    \"\"\"In-memory fake implementation of prompt execution.\n\n    Constructor Injection:\n    - All state is provided via constructor parameters\n    - Mutations are tracked in read-only properties\n\n    When to Use:\n    - Testing commands that execute prompts (e.g., erk implement --no-interactive)\n    - Simulating executor availability\n    - Verifying command execution without actual subprocess calls\n\n    Examples:\n        # Test with executor available and successful execution\n        >>> executor = FakePromptExecutor(available=True)\n        >>> executor.execute_command(\"/erk:plan-implement\", Path(\"/repo\"), False)\n        >>> assert len(executor.executed_commands) == 1\n\n        # Test with executor not available\n        >>> executor = FakePromptExecutor(available=False)\n        >>> assert not executor.is_available()\n\n        # Test command failure\n        >>> executor = FakePromptExecutor(command_should_fail=True)\n        >>> try:\n        ...     executor.execute_command(\"/bad-command\", Path(\"/repo\"), False)\n        ... except RuntimeError:\n        ...     print(\"Command failed as expected\")\n\n        # Test interactive execution\n        >>> executor = FakePromptExecutor(available=True)\n        >>> executor.execute_interactive(Path(\"/repo\"), dangerous=False)\n        >>> assert len(executor.interactive_calls) == 1\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        available: bool = True,\n        command_should_fail: bool = False,\n        simulated_pr_url: str | None = None,\n        simulated_pr_number: int | None = None,\n        simulated_pr_title: str | None = None,\n        simulated_issue_number: int | None = None,\n        simulated_tool_events: list[str] | None = None,\n        simulated_no_output: bool = False,\n        simulated_zero_turns: bool = False,\n        simulated_process_error: str | None = None,\n        simulated_prompt_output: str | None = None,\n        simulated_prompt_error: str | None = None,\n        simulated_no_work_events: bool = False,\n        simulated_passthrough_exit_code: int = 0,\n    ) -> None:\n        \"\"\"Initialize fake with predetermined behavior.\n\n        Args:\n            available: Whether the executor should appear available\n            command_should_fail: Whether execute_command should raise RuntimeError\n            simulated_pr_url: PR URL to return in CommandResult (simulates successful PR creation)\n            simulated_pr_number: PR number to return (simulates PR metadata)\n            simulated_pr_title: PR title to return (simulates PR metadata)\n            simulated_issue_number: Issue number to return (simulates linked issue)\n            simulated_tool_events: Tool event contents to emit (e.g., \"Using...\")\n            simulated_no_output: Whether to simulate Claude CLI producing no output\n            simulated_zero_turns: Whether to simulate Claude completing with num_turns=0\n                (hook blocking scenario)\n            simulated_process_error: Error message to simulate process startup failure\n            simulated_prompt_output: Output to return from execute_prompt() on success.\n                If None, defaults to \"Test Title\\n\\nTest body\"\n            simulated_prompt_error: Error message to return from execute_prompt() on failure.\n                If set, execute_prompt() will return a failure result.\n            simulated_no_work_events: Whether to simulate Claude completing successfully\n                but without emitting any work events (TextEvent or ToolEvent). This\n                tests the \"empty response\" failure mode where Claude produces JSON\n                but no actual work output.\n            simulated_passthrough_exit_code: Exit code to return from execute_prompt_passthrough().\n                Defaults to 0 (success).\n        \"\"\"\n        self._available = available\n        self._command_should_fail = command_should_fail\n        self._simulated_pr_url = simulated_pr_url\n        self._simulated_pr_number = simulated_pr_number\n        self._simulated_pr_title = simulated_pr_title\n        self._simulated_issue_number = simulated_issue_number\n        self._simulated_tool_events = simulated_tool_events or []\n        self._simulated_no_output = simulated_no_output\n        self._simulated_zero_turns = simulated_zero_turns\n        self._simulated_process_error = simulated_process_error\n        self._simulated_prompt_output = simulated_prompt_output\n        self._simulated_prompt_error = simulated_prompt_error\n        self._simulated_no_work_events = simulated_no_work_events\n        self._simulated_passthrough_exit_code = simulated_passthrough_exit_code\n        self._executed_commands: list[tuple[str, Path, bool, bool, str | None]] = []\n        self._interactive_calls: list[tuple[Path, bool, str, Path | None, str | None, str]] = []\n        self._prompt_calls: list[tuple[str, str | None]] = []\n        self._passthrough_calls: list[tuple[str, str, list[str] | None, Path, bool]] = []\n\n    def is_available(self) -> bool:\n        \"\"\"Return the availability configured at construction time.\"\"\"\n        return self._available\n\n    def execute_command_streaming(\n        self,\n        *,\n        command: str,\n        worktree_path: Path,\n        dangerous: bool,\n        verbose: bool = False,\n        debug: bool = False,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n        allow_dangerous: bool = False,\n    ) -> Iterator[ExecutorEvent]:\n        \"\"\"Track command execution and yield simulated typed events.\n\n        This method records the call parameters for test assertions.\n        It does not execute any actual subprocess operations.\n\n        Args:\n            command: The slash command to execute\n            worktree_path: Path to worktree directory\n            dangerous: Whether to skip permission prompts\n            verbose: Whether to show raw output or filtered output\n            debug: Whether to emit debug output for stream parsing\n            model: Optional model name (haiku, sonnet, opus) - recorded but not used\n            permission_mode: Claude CLI permission mode - recorded but not used\n            allow_dangerous: Whether --allow-dangerously-skip-permissions - recorded but not used\n\n        Yields:\n            ExecutorEvent objects simulating command execution\n\n        Raises:\n            RuntimeError: If command_should_fail was set to True\n        \"\"\"\n        self._executed_commands.append((command, worktree_path, dangerous, verbose, model))\n\n        # Process error takes precedence (simulates Popen failure)\n        if self._simulated_process_error is not None:\n            yield ProcessErrorEvent(message=self._simulated_process_error)\n            return\n\n        # No output simulation (simulates Claude CLI producing no output)\n        if self._simulated_no_output:\n            yield NoOutputEvent(\n                diagnostic=f\"Claude command {command} completed but produced no output\"\n            )\n            return\n\n        # Zero turns simulation (simulates hook blocking)\n        if self._simulated_zero_turns:\n            diag = f\"Claude command {command} completed without processing\"\n            diag += \"\\n  This usually means a hook blocked the command\"\n            diag += \"\\n  Run 'claude' directly to see hook error messages\"\n            diag += f\"\\n  Working directory: {worktree_path}\"\n            yield NoTurnsEvent(diagnostic=diag)\n            return\n\n        if self._command_should_fail:\n            yield ErrorEvent(message=f\"Claude command {command} failed (simulated failure)\")\n            return\n\n        # No work events simulation: emits only non-work events (spinner, metadata)\n        # This tests the scenario where Claude completes but produces no output\n        if self._simulated_no_work_events:\n            yield SpinnerUpdateEvent(status=f\"Running {command}...\")\n            yield SpinnerUpdateEvent(status=\"Completed\")\n            # Note: no TextEvent or ToolEvent emitted\n            return\n\n        # Simulate some basic streaming events\n        yield TextEvent(content=\"Starting execution...\")\n        yield SpinnerUpdateEvent(status=f\"Running {command}...\")\n\n        # Yield any configured tool events\n        for tool_event in self._simulated_tool_events:\n            yield ToolEvent(summary=tool_event)\n\n        yield TextEvent(content=\"Execution complete\")\n\n        # Yield PR metadata if configured\n        if self._simulated_pr_url is not None:\n            yield PrUrlEvent(url=self._simulated_pr_url)\n        if self._simulated_pr_number is not None:\n            yield PrNumberEvent(number=self._simulated_pr_number)\n        if self._simulated_pr_title is not None:\n            yield PrTitleEvent(title=self._simulated_pr_title)\n        if self._simulated_issue_number is not None:\n            yield IssueNumberEvent(number=self._simulated_issue_number)\n\n    def execute_command(\n        self,\n        *,\n        command: str,\n        worktree_path: Path,\n        dangerous: bool,\n        verbose: bool = False,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n        allow_dangerous: bool = False,\n    ) -> CommandResult:\n        \"\"\"Track command execution without running subprocess.\n\n        This method records the call parameters for test assertions.\n        It does not execute any actual subprocess operations.\n\n        Args:\n            command: The slash command to execute\n            worktree_path: Path to worktree directory\n            dangerous: Whether to skip permission prompts\n            verbose: Whether to show raw output or filtered output\n            model: Optional model name (ignored in fake)\n\n        Returns:\n            CommandResult with success status\n\n        Raises:\n            RuntimeError: If command_should_fail was set to True\n        \"\"\"\n        self._executed_commands.append((command, worktree_path, dangerous, verbose, model))\n\n        if self._command_should_fail:\n            return CommandResult(\n                success=False,\n                pr_url=None,\n                pr_number=None,\n                pr_title=None,\n                issue_number=None,\n                duration_seconds=0.0,\n                error_message=f\"Claude command {command} failed (simulated failure)\",\n                filtered_messages=[],\n            )\n\n        return CommandResult(\n            success=True,\n            pr_url=self._simulated_pr_url,\n            pr_number=self._simulated_pr_number,\n            pr_title=self._simulated_pr_title,\n            issue_number=self._simulated_issue_number,\n            duration_seconds=0.0,\n            error_message=None,\n            filtered_messages=[],\n        )\n\n    def execute_interactive(\n        self,\n        *,\n        worktree_path: Path,\n        dangerous: bool,\n        command: str,\n        target_subpath: Path | None,\n        model: str | None = None,\n        permission_mode: PermissionMode,\n    ) -> None:\n        \"\"\"Track interactive execution without replacing process.\n\n        This method records the call parameters for test assertions.\n        Unlike RealPromptExecutor, this does not use os.execvp and returns\n        normally to allow tests to continue.\n\n        Raises:\n            RuntimeError: If Claude CLI is not available\n        \"\"\"\n        if not self._available:\n            raise RuntimeError(\"Claude CLI not found\\nInstall from: https://claude.com/download\")\n\n        self._interactive_calls.append(\n            (worktree_path, dangerous, command, target_subpath, model, permission_mode)\n        )\n\n    @property\n    def executed_commands(self) -> list[tuple[str, Path, bool, bool, str | None]]:\n        \"\"\"Get the list of execute_command() calls that were made.\n\n        Returns list of (command, worktree_path, dangerous, verbose, model) tuples.\n\n        This property is for test assertions only.\n        \"\"\"\n        return self._executed_commands.copy()\n\n    @property\n    def interactive_calls(\n        self,\n    ) -> list[tuple[Path, bool, str, Path | None, str | None, str]]:\n        \"\"\"Get the list of execute_interactive() calls that were made.\n\n        Returns list of tuples:\n        (worktree_path, dangerous, command, target_subpath, model, permission_mode)\n\n        This property is for test assertions only.\n        \"\"\"\n        return self._interactive_calls.copy()\n\n    def execute_prompt(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path | None,\n        system_prompt: str | None,\n        dangerous: bool,\n    ) -> PromptResult:\n        \"\"\"Track prompt execution and return simulated result.\n\n        This method records the prompt, system_prompt, and dangerous flag for test assertions.\n        It does not execute any actual subprocess operations.\n\n        Args:\n            prompt: The prompt text to send\n            model: Model to use (ignored in fake)\n            tools: Optional list of allowed tools (ignored in fake)\n            cwd: Optional working directory (ignored in fake)\n            system_prompt: Optional system prompt (tracked for test assertions)\n            dangerous: Whether --dangerously-skip-permissions was requested\n                (tracked for test assertions)\n\n        Returns:\n            PromptResult with simulated output or error\n        \"\"\"\n        self._prompt_calls.append((prompt, system_prompt, dangerous))\n\n        if self._simulated_prompt_error is not None:\n            return PromptResult(\n                success=False,\n                output=\"\",\n                error=self._simulated_prompt_error,\n            )\n\n        # Default output if none specified\n        output = self._simulated_prompt_output\n        if output is None:\n            output = \"Test Title\\n\\nTest body\"\n\n        return PromptResult(\n            success=True,\n            output=output,\n            error=None,\n        )\n\n    @property\n    def prompt_calls(self) -> list[tuple[str, str | None, bool]]:\n        \"\"\"Get the list of execute_prompt() calls that were made.\n\n        Returns list of (prompt, system_prompt, dangerous) tuples.\n\n        This property is for test assertions only.\n        \"\"\"\n        return self._prompt_calls.copy()\n\n    def execute_prompt_passthrough(\n        self,\n        prompt: str,\n        *,\n        model: str,\n        tools: list[str] | None,\n        cwd: Path,\n        dangerous: bool,\n    ) -> int:\n        \"\"\"Track passthrough execution and return configured exit code.\n\n        This method records the call parameters for test assertions.\n        It does not execute any actual subprocess operations.\n\n        Args:\n            prompt: The prompt text to send\n            model: Model to use (recorded for assertions)\n            tools: Optional list of allowed tools (recorded for assertions)\n            cwd: Working directory (recorded for assertions)\n            dangerous: Whether dangerous mode is enabled (recorded for assertions)\n\n        Returns:\n            The simulated exit code configured at construction time\n        \"\"\"\n        self._passthrough_calls.append((prompt, model, tools, cwd, dangerous))\n        return self._simulated_passthrough_exit_code\n\n    @property\n    def passthrough_calls(self) -> list[tuple[str, str, list[str] | None, Path, bool]]:\n        \"\"\"Get the list of execute_prompt_passthrough() calls that were made.\n\n        Returns list of (prompt, model, tools, cwd, dangerous) tuples.\n\n        This property is for test assertions only.\n        \"\"\"\n        return self._passthrough_calls.copy()\n","numLines":420,"startLine":1,"totalLines":420}}}
{"parentUuid":"b0295ce6-152a-4ecd-9f87-147c5c00e23b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HJ5QTP2qTrEbfD5rjw84Wn","type":"message","role":"assistant","content":[{"type":"text","text":"Good. I see there are two different FakePromptExecutors. The one in `tests/fakes/` records `(prompt, system_prompt, dangerous)` tuples for prompt_calls. The one in `erk_shared/core/fakes.py` records `PromptCall` named tuples. For the test file I'll use the `tests/fakes/` one since that's what the commit message generator tests use. Now let me write the tests:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5525,"cache_read_input_tokens":119026,"cache_creation":{"ephemeral_5m_input_tokens":5525,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH7dA55M3P5JqYJyuGT","type":"assistant","uuid":"19936e6e-b490-4899-b50d-5f72e4672822","timestamp":"2026-02-22T14:38:40.558Z"}
{"parentUuid":"19936e6e-b490-4899-b50d-5f72e4672822","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HJ5QTP2qTrEbfD5rjw84Wn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01T33ENCuZEFsPo9k5YLDwgD","name":"Write","input":{"file_path":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","content":"\"\"\"Tests for BranchSlugGenerator.\"\"\"\n\nfrom erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)\nfrom tests.fakes.prompt_executor import FakePromptExecutor\n\n\ndef test_successful_slug_generation() -> None:\n    \"\"\"Test successful slug generation from a plan title.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"objective-marker-fallback\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Objective Context Marker Fallback\")\n\n    assert result.success is True\n    assert result.slug == \"objective-marker-fallback\"\n    assert result.error_message is None\n\n\ndef test_strips_quotes_from_output() -> None:\n    \"\"\"Test that surrounding quotes are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output='\"fix-auth-session\"',\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Authentication Session Handling\")\n\n    assert result.success is True\n    assert result.slug == \"fix-auth-session\"\n\n\ndef test_strips_backticks_from_output() -> None:\n    \"\"\"Test that surrounding backticks are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"`add-plan-validation`\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Plan Validation Gate\")\n\n    assert result.success is True\n    assert result.slug == \"add-plan-validation\"\n\n\ndef test_falls_back_on_executor_failure() -> None:\n    \"\"\"Test that executor failure returns error result.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"Claude CLI not available\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert result.error_message is not None\n\n\ndef test_rejects_single_word_output() -> None:\n    \"\"\"Test that single-word output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"refactor\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Refactor the Gateway Layer\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_rejects_too_long_output() -> None:\n    \"\"\"Test that output exceeding 30 characters is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"this-is-a-very-long-branch-name-that-exceeds-limit\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Very Long Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_generate_slug_or_fallback_returns_slug_on_success() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns slug on success.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug in Login\")\n\n    assert result == \"fix-auth-bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_failure() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title on failure.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"LLM unavailable\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_invalid_output() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title when LLM output is invalid.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"singleword\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_uses_haiku_model() -> None:\n    \"\"\"Test that the generator uses the haiku model.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    generator = BranchSlugGenerator(executor)\n    generator.generate(\"Fix Auth Bug\")\n\n    assert len(executor.prompt_calls) == 1\n    # prompt_calls records (prompt, system_prompt, dangerous)\n    prompt, system_prompt, dangerous = executor.prompt_calls[0]\n    assert prompt == \"Fix Auth Bug\"\n    assert system_prompt is not None\n    assert dangerous is False\n\n\ndef test_sanitizes_special_characters() -> None:\n    \"\"\"Test that special characters in LLM output are sanitized.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix auth-bug!\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Auth Bug!\")\n\n    assert result.success is True\n    # sanitize_worktree_name handles the special chars\n    assert result.slug == \"fix-auth-bug\"\n\n\ndef test_empty_output_rejected() -> None:\n    \"\"\"Test that empty LLM output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":5525,"cache_read_input_tokens":119026,"cache_creation":{"ephemeral_5m_input_tokens":5525,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH7dA55M3P5JqYJyuGT","type":"assistant","uuid":"b111892b-fa26-479b-b302-3142aa5d271d","timestamp":"2026-02-22T14:38:59.090Z"}
{"parentUuid":"b111892b-fa26-479b-b302-3142aa5d271d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01T33ENCuZEFsPo9k5YLDwgD","type":"tool_result","content":"File created successfully at: /home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py"}]},"uuid":"e87a8ec0-6681-44b9-a97c-fc3bbedd8935","timestamp":"2026-02-22T14:38:59.769Z","toolUseResult":{"type":"create","filePath":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","content":"\"\"\"Tests for BranchSlugGenerator.\"\"\"\n\nfrom erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)\nfrom tests.fakes.prompt_executor import FakePromptExecutor\n\n\ndef test_successful_slug_generation() -> None:\n    \"\"\"Test successful slug generation from a plan title.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"objective-marker-fallback\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Objective Context Marker Fallback\")\n\n    assert result.success is True\n    assert result.slug == \"objective-marker-fallback\"\n    assert result.error_message is None\n\n\ndef test_strips_quotes_from_output() -> None:\n    \"\"\"Test that surrounding quotes are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output='\"fix-auth-session\"',\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Authentication Session Handling\")\n\n    assert result.success is True\n    assert result.slug == \"fix-auth-session\"\n\n\ndef test_strips_backticks_from_output() -> None:\n    \"\"\"Test that surrounding backticks are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"`add-plan-validation`\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Plan Validation Gate\")\n\n    assert result.success is True\n    assert result.slug == \"add-plan-validation\"\n\n\ndef test_falls_back_on_executor_failure() -> None:\n    \"\"\"Test that executor failure returns error result.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"Claude CLI not available\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert result.error_message is not None\n\n\ndef test_rejects_single_word_output() -> None:\n    \"\"\"Test that single-word output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"refactor\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Refactor the Gateway Layer\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_rejects_too_long_output() -> None:\n    \"\"\"Test that output exceeding 30 characters is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"this-is-a-very-long-branch-name-that-exceeds-limit\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Very Long Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_generate_slug_or_fallback_returns_slug_on_success() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns slug on success.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug in Login\")\n\n    assert result == \"fix-auth-bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_failure() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title on failure.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"LLM unavailable\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_invalid_output() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title when LLM output is invalid.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"singleword\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_uses_haiku_model() -> None:\n    \"\"\"Test that the generator uses the haiku model.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    generator = BranchSlugGenerator(executor)\n    generator.generate(\"Fix Auth Bug\")\n\n    assert len(executor.prompt_calls) == 1\n    # prompt_calls records (prompt, system_prompt, dangerous)\n    prompt, system_prompt, dangerous = executor.prompt_calls[0]\n    assert prompt == \"Fix Auth Bug\"\n    assert system_prompt is not None\n    assert dangerous is False\n\n\ndef test_sanitizes_special_characters() -> None:\n    \"\"\"Test that special characters in LLM output are sanitized.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix auth-bug!\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Auth Bug!\")\n\n    assert result.success is True\n    # sanitize_worktree_name handles the special chars\n    assert result.slug == \"fix-auth-bug\"\n\n\ndef test_empty_output_rejected() -> None:\n    \"\"\"Test that empty LLM output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n","structuredPatch":[],"originalFile":null}}
{"parentUuid":"e87a8ec0-6681-44b9-a97c-fc3bbedd8935","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01AD2enSM4h3oraB9JA83zm7","type":"message","role":"assistant","content":[{"type":"text","text":"Let me run the tests to make sure they pass:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1966,"cache_read_input_tokens":124551,"cache_creation":{"ephemeral_5m_input_tokens":1966,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH9ShKtCaVNK9PD1EW2","type":"assistant","uuid":"b570dc5e-c5c7-44c7-9626-cf7789881581","timestamp":"2026-02-22T14:39:02.356Z"}
{"parentUuid":"b570dc5e-c5c7-44c7-9626-cf7789881581","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01AD2enSM4h3oraB9JA83zm7","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01A9eHh8GddoVGf9FvofxnMm","name":"Task","input":{"description":"Run branch slug generator tests","prompt":"Run pytest tests/core/test_branch_slug_generator.py and report the results. Do NOT fix any errors - just report them.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1966,"cache_read_input_tokens":124551,"cache_creation":{"ephemeral_5m_input_tokens":1966,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPH9ShKtCaVNK9PD1EW2","type":"assistant","uuid":"1e21c95f-bf62-4980-bf13-4937e42d89fa","timestamp":"2026-02-22T14:39:03.743Z"}
{"parentUuid":"1e21c95f-bf62-4980-bf13-4937e42d89fa","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01A9eHh8GddoVGf9FvofxnMm","type":"tool_result","content":[{"type":"text","text":"pytest passed: 12 tests passed in 1.30s\n\nAll tests in `tests/core/test_branch_slug_generator.py` are passing successfully.\n\n**Results Summary:**\n- Total tests: 12\n- Passed: 12\n- Failed: 0\n- Duration: 1.30s"},{"type":"text","text":"agentId: aa83cbf (for resuming to continue this agent's work if needed)"}]}]},"uuid":"b782034f-326c-4b44-aead-37f5244d8553","timestamp":"2026-02-22T14:39:23.995Z","toolUseResult":{"status":"completed","prompt":"Run pytest tests/core/test_branch_slug_generator.py and report the results. Do NOT fix any errors - just report them.","agentId":"aa83cbf","content":[{"type":"text","text":"pytest passed: 12 tests passed in 1.30s\n\nAll tests in `tests/core/test_branch_slug_generator.py` are passing successfully.\n\n**Results Summary:**\n- Total tests: 12\n- Passed: 12\n- Failed: 0\n- Duration: 1.30s"}],"totalDurationMs":20221,"totalTokens":12929,"totalToolUseCount":1,"usage":{"input_tokens":6,"cache_creation_input_tokens":548,"cache_read_input_tokens":12301,"cache_creation":{"ephemeral_5m_input_tokens":548,"ephemeral_1h_input_tokens":0},"output_tokens":74,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"b782034f-326c-4b44-aead-37f5244d8553","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01LewfiYc6abGSsyHPNaGjdJ","type":"message","role":"assistant","content":[{"type":"text","text":"All 12 tests pass. Let me move on to integrating at the 5 call sites:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":236,"cache_read_input_tokens":126517,"cache_creation":{"ephemeral_5m_input_tokens":236,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHBEGXNpK3KCbMSjJHK","type":"assistant","uuid":"ec4e5304-6553-4aa5-b622-d3b1164ef74e","timestamp":"2026-02-22T14:39:26.832Z"}
{"parentUuid":"ec4e5304-6553-4aa5-b622-d3b1164ef74e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01LewfiYc6abGSsyHPNaGjdJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RXBhTxYDAj6GT4eiArmys6","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"in_progress","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":236,"cache_read_input_tokens":126517,"cache_creation":{"ephemeral_5m_input_tokens":236,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHBEGXNpK3KCbMSjJHK","type":"assistant","uuid":"8fb689dc-e538-4c17-ab83-ef5ce96f5c10","timestamp":"2026-02-22T14:39:28.771Z"}
{"parentUuid":"8fb689dc-e538-4c17-ab83-ef5ce96f5c10","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RXBhTxYDAj6GT4eiArmys6","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"2a292bb6-6118-4c51-a200-339a7856d337","timestamp":"2026-02-22T14:39:28.798Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"in_progress","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"pending","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"in_progress","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]}}
{"parentUuid":"2a292bb6-6118-4c51-a200-339a7856d337","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01T8a3jhHdQLHMJnBbs9tfh2","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me integrate at the 5 call sites. Let me re-read the plan's integration table:\n\n1. `plan_save.py` ~L140 - `save_plan_as_draft_pr` - `planned/` branch\n2. `submit.py` - `_validate_issue_for_submit` - `P{issue}-` branch\n3. `one_shot_dispatch.py` ~L60 - `generate_branch_name` - `P{issue}-` or `oneshot-` branch\n4. `setup_impl_from_issue.py` - `setup_impl_from_issue` - `P{issue}-` branch\n5. `plan_migrate_to_draft_pr.py` - migration flow - `planned/` branch\n\nThe pattern at each site:\n```python\nexecutor = require_prompt_executor(ctx)\nslug = generate_slug_or_fallback(executor, title)\nbranch_name = generate_*_branch_name(slug, ...)\n```\n\nLet me do all 5 integrations:\n\n**Site 1: plan_save.py**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":126753,"cache_creation":{"ephemeral_5m_input_tokens":280,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHBaonvKCK98D7rAPnV","type":"assistant","uuid":"84cd6f20-c870-40f0-89bc-6d0bdc563218","timestamp":"2026-02-22T14:39:37.091Z"}
{"parentUuid":"84cd6f20-c870-40f0-89bc-6d0bdc563218","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01T8a3jhHdQLHMJnBbs9tfh2","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EPuo63aAqCVCKN5y4zeaVb","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","offset":130,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":126753,"cache_creation":{"ephemeral_5m_input_tokens":280,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHBaonvKCK98D7rAPnV","type":"assistant","uuid":"8bc76438-a96d-4543-a4aa-154a38ce843c","timestamp":"2026-02-22T14:39:38.046Z"}
{"parentUuid":"8bc76438-a96d-4543-a4aa-154a38ce843c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EPuo63aAqCVCKN5y4zeaVb","type":"tool_result","content":"   130→        created_from_workflow_run_url: GitHub Actions workflow run URL\n   131→    \"\"\"\n   132→    repo_root = require_repo_root(ctx)\n   133→    cwd = require_cwd(ctx)\n   134→    git = require_git(ctx)\n   135→    github = require_github(ctx)\n   136→    github_issues = require_issues(ctx)\n   137→    config = require_local_config(ctx)\n   138→    claude_installation = require_claude_installation(ctx)\n   139→\n   140→    title = extract_title_from_plan(plan_content)\n   141→\n   142→    # Generate branch name\n   143→    now = require_time(ctx).now()\n   144→    branch_name = generate_draft_pr_branch_name(\n   145→        title,\n   146→        now,\n   147→        objective_id=objective_issue,\n   148→    )\n   149→\n   150→    # Create branch with Graphite tracking (handles both creation and stack metadata)\n   151→    branch_manager = require_branch_manager(ctx)\n   152→    current_branch = git.branch.get_current_branch(cwd)\n   153→    start_point = current_branch if current_branch is not None else \"HEAD\"\n   154→    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n   155→    if isinstance(create_result, BranchAlreadyExists):\n   156→        click.echo(f\"Error: {create_result.message}\", err=True)\n   157→        raise SystemExit(1) from None\n   158→\n   159→    # Detect trunk for PR base metadata\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2afef581-1485-411f-9180-741aa839acf6","timestamp":"2026-02-22T14:39:38.057Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","content":"        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    github_issues = require_issues(ctx)\n    config = require_local_config(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )\n\n    # Create branch with Graphite tracking (handles both creation and stack metadata)\n    branch_manager = require_branch_manager(ctx)\n    current_branch = git.branch.get_current_branch(cwd)\n    start_point = current_branch if current_branch is not None else \"HEAD\"\n    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n    if isinstance(create_result, BranchAlreadyExists):\n        click.echo(f\"Error: {create_result.message}\", err=True)\n        raise SystemExit(1) from None\n\n    # Detect trunk for PR base metadata","numLines":30,"startLine":130,"totalLines":445}}}
{"parentUuid":"2afef581-1485-411f-9180-741aa839acf6","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NjnUUJrueZbB1dGa6fYPx3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LGMS8H8CDZjWUxL4xphm3T","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","old_string":"from erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_repo_root,\n    require_time,\n)","new_string":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":890,"cache_read_input_tokens":127033,"cache_creation":{"ephemeral_5m_input_tokens":890,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHCGPYiusL1co9FGiRX","type":"assistant","uuid":"4fad4429-8dba-4cdc-87d7-1e79ba669882","timestamp":"2026-02-22T14:39:44.130Z"}
{"parentUuid":"4fad4429-8dba-4cdc-87d7-1e79ba669882","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LGMS8H8CDZjWUxL4xphm3T","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py has been updated successfully."}]},"uuid":"5a72cec9-3a93-4be7-91af-ba62fa5885d1","timestamp":"2026-02-22T14:39:44.820Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","oldString":"from erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_repo_root,\n    require_time,\n)","newString":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)","originalFile":"\"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n\nUsage:\n    erk exec plan-save [OPTIONS]\n\nWhen ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR with the plan.\nOtherwise delegates to the existing plan-save-to-issue logic (default).\n\nOptions:\n    --format json|display: Output format (default: json)\n    --plan-file PATH: Use specific plan file (highest priority)\n    --session-id ID: Session ID for scoped plan lookup\n    --objective-issue INT: Link plan to parent objective\n    --plan-type standard|learn: Plan type (default: standard)\n    --learned-from-issue INT: Parent plan issue (for learn plans)\n    --created-from-workflow-run-url URL: Workflow run URL\n\nExit Codes:\n    0: Success\n    1: Error\n    2: Validation failed\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.exec.scripts.plan_save_to_issue import (\n    plan_save_to_issue,\n)\nfrom erk.cli.commands.exec.scripts.validate_plan_content import _validate_plan_content\nfrom erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.claude_installation.abc import ClaudeInstallation\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.time.real import RealTime\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.output.next_steps import format_draft_pr_next_steps_plain\nfrom erk_shared.plan_store import get_plan_backend\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.plan_content import extract_title_from_plan, resolve_plan_content\nfrom erk_shared.plan_utils import get_title_tag_from_labels\nfrom erk_shared.scratch.plan_snapshots import PlanSnapshot, snapshot_plan_for_session\nfrom erk_shared.scratch.session_markers import (\n    create_plan_saved_issue_marker,\n    create_plan_saved_marker,\n    get_existing_saved_issue,\n)\n\n\ndef _get_snapshot_result(\n    *,\n    session_id: str,\n    plan_file: Path | None,\n    cwd: Path,\n    claude_installation: ClaudeInstallation,\n    repo_root: Path,\n) -> PlanSnapshot | None:\n    \"\"\"Archive the plan file to session-scoped scratch storage.\n\n    Plan snapshots preserve the original plan content at save time, creating\n    an immutable record tied to the session. This enables deduplication\n    (detecting if a session already saved a plan) and provides an audit trail\n    (what was the plan content when it was saved).\n\n    Args:\n        session_id: Claude session ID\n        plan_file: Explicit plan file path (highest priority)\n        cwd: Current working directory\n        claude_installation: ClaudeInstallation gateway for plan discovery\n        repo_root: Repository root for scratch directory\n\n    Returns:\n        PlanSnapshot with archive path, or None if no plan file found.\n    \"\"\"\n    if plan_file is not None:\n        snapshot_path = plan_file\n    else:\n        snapshot_path = claude_installation.find_plan_for_session(cwd, session_id)\n\n    if snapshot_path is None or not snapshot_path.exists():\n        return None\n\n    return snapshot_plan_for_session(\n        session_id=session_id,\n        plan_file_path=snapshot_path,\n        project_cwd=cwd,\n        claude_installation=claude_installation,\n        repo_root=repo_root,\n    )\n\n\ndef _save_as_draft_pr(\n    ctx: click.Context,\n    *,\n    plan_content: str,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    output_format: str,\n    plan_file: Path | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Save plan as a draft PR.\n\n    Creates a branch, pushes it, then creates a draft PR with plan content.\n\n    Args:\n        ctx: Click context\n        plan_content: Validated plan content\n        session_id: Session ID for markers\n        objective_issue: Optional objective issue number\n        plan_type: Plan type (standard or learn)\n        output_format: Output format (json or display)\n        plan_file: Original plan file path (for snapshot)\n        learned_from_issue: Parent plan issue number (for learn plans)\n        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    github_issues = require_issues(ctx)\n    config = require_local_config(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )\n\n    # Create branch with Graphite tracking (handles both creation and stack metadata)\n    branch_manager = require_branch_manager(ctx)\n    current_branch = git.branch.get_current_branch(cwd)\n    start_point = current_branch if current_branch is not None else \"HEAD\"\n    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n    if isinstance(create_result, BranchAlreadyExists):\n        click.echo(f\"Error: {create_result.message}\", err=True)\n        raise SystemExit(1) from None\n\n    # Detect trunk for PR base metadata\n    trunk = git.branch.detect_trunk_branch(cwd)\n\n    # Build ref.json data\n    ref_data: dict[str, str | int | None] = {\n        \"provider\": \"github-draft-pr\",\n        \"title\": title,\n    }\n    if objective_issue is not None:\n        ref_data[\"objective_id\"] = objective_issue\n\n    # Commit plan files directly to branch (no checkout needed).\n    # Uses git plumbing to avoid race conditions when multiple sessions\n    # share the same worktree.\n    git.commit.commit_files_to_branch(\n        repo_root,\n        branch=branch_name,\n        files={\n            f\"{IMPL_CONTEXT_DIR}/plan.md\": plan_content,\n            f\"{IMPL_CONTEXT_DIR}/ref.json\": json.dumps(ref_data, indent=2),\n        },\n        message=f\"Add plan: {title}\",\n    )\n    git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n\n    # Build metadata\n    metadata: dict[str, object] = {\"branch_name\": branch_name, \"trunk_branch\": trunk}\n\n    if config.plans_repo is not None:\n        metadata[\"source_repo\"] = get_repo_identifier(ctx)\n\n    if objective_issue is not None:\n        metadata[\"objective_issue\"] = objective_issue\n\n    if session_id is not None:\n        metadata[\"created_from_session\"] = session_id\n\n    if learned_from_issue is not None:\n        metadata[\"learned_from_issue\"] = learned_from_issue\n\n    if created_from_workflow_run_url is not None:\n        metadata[\"created_from_workflow_run_url\"] = created_from_workflow_run_url\n\n    # Build labels\n    labels = [\"erk-plan\"]\n    if plan_type == \"learn\":\n        labels.append(\"erk-learn\")\n\n    # Prefix title with [erk-plan] or [erk-learn] for GitHub visibility\n    title_tag = get_title_tag_from_labels(labels)\n    prefixed_title = f\"{title_tag} {title}\"\n\n    # Create draft PR via backend\n    backend = DraftPRPlanBackend(github, github_issues, time=RealTime())\n    result = backend.create_plan(\n        repo_root=repo_root,\n        title=prefixed_title,\n        content=plan_content,\n        labels=tuple(labels),\n        metadata=metadata,\n    )\n\n    if not result.plan_id.isdigit():\n        msg = f\"Expected numeric plan_id from draft PR creation, got: {result.plan_id!r}\"\n        raise RuntimeError(msg)\n    plan_number = int(result.plan_id)\n\n    # Create markers and snapshot\n    snapshot_result: PlanSnapshot | None = None\n    if session_id is not None:\n        create_plan_saved_marker(session_id, repo_root)\n        create_plan_saved_issue_marker(session_id, repo_root, plan_number)\n\n        snapshot_result = _get_snapshot_result(\n            session_id=session_id,\n            plan_file=plan_file,\n            cwd=cwd,\n            claude_installation=claude_installation,\n            repo_root=repo_root,\n        )\n\n    # Output\n    if output_format == \"display\":\n        click.echo(f\"Plan saved as draft PR #{plan_number}\")\n        click.echo(f\"Title: {prefixed_title}\")\n        click.echo(f\"URL: {result.url}\")\n        click.echo(f\"Branch: {branch_name}\")\n        if snapshot_result is not None:\n            click.echo(f\"Archived: {snapshot_result.snapshot_dir}\")\n        click.echo()\n        click.echo(format_draft_pr_next_steps_plain(plan_number, branch_name=branch_name))\n    else:\n        output_data: dict[str, str | int | bool | None] = {\n            \"success\": True,\n            \"issue_number\": plan_number,\n            \"issue_url\": result.url,\n            \"title\": prefixed_title,\n            \"branch_name\": branch_name,\n            \"plan_backend\": \"draft_pr\",\n        }\n        if snapshot_result is not None:\n            output_data[\"archived_to\"] = str(snapshot_result.snapshot_dir)\n        click.echo(json.dumps(output_data))\n\n\ndef _save_plan_via_draft_pr(\n    ctx: click.Context,\n    *,\n    output_format: str,\n    plan_file: Path | None,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Handle draft-PR backend: dedup check, plan extraction, validation, and save.\n\n    Args:\n        ctx: Click context\n        output_format: Output format (json or display)\n        plan_file: Explicit plan file path (highest priority)\n        session_id: Session ID for dedup and markers\n        objective_issue: Optional objective issue number\n        plan_type: Plan type (standard or learn)\n        learned_from_issue: Parent plan issue number (for learn plans)\n        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    # Session deduplication check\n    if session_id is not None:\n        existing_issue = get_existing_saved_issue(session_id, repo_root)\n        if existing_issue is not None:\n            if output_format == \"display\":\n                click.echo(\n                    f\"This session already saved plan #{existing_issue}. \"\n                    \"Skipping duplicate creation.\",\n                    err=True,\n                )\n            else:\n                click.echo(\n                    json.dumps(\n                        {\n                            \"success\": True,\n                            \"issue_number\": existing_issue,\n                            \"skipped_duplicate\": True,\n                            \"message\": f\"Session already saved plan #{existing_issue}\",\n                        }\n                    )\n                )\n            return\n\n    # Extract plan content (same priority as plan-save-to-issue)\n    plan = resolve_plan_content(\n        plan_file=plan_file,\n        session_id=session_id,\n        repo_root=repo_root,\n        claude_installation=claude_installation,\n        cwd=cwd,\n    )\n\n    if not plan:\n        if output_format == \"display\":\n            click.echo(\"Error: No plan found in ~/.claude/plans/\", err=True)\n        else:\n            click.echo(json.dumps({\"success\": False, \"error\": \"No plan found in ~/.claude/plans/\"}))\n        raise SystemExit(1)\n\n    # Validate plan content\n    valid, error, details = _validate_plan_content(plan)\n    if not valid:\n        if output_format == \"display\":\n            click.echo(f\"Error: Plan validation failed: {error}\", err=True)\n        else:\n            click.echo(\n                json.dumps(\n                    {\n                        \"success\": False,\n                        \"error\": f\"Plan validation failed: {error}\",\n                        \"error_type\": \"validation_failed\",\n                        \"details\": details,\n                    }\n                )\n            )\n        raise SystemExit(2)\n\n    _save_as_draft_pr(\n        ctx,\n        plan_content=plan,\n        session_id=session_id,\n        objective_issue=objective_issue,\n        plan_type=plan_type,\n        output_format=output_format,\n        plan_file=plan_file,\n        learned_from_issue=learned_from_issue,\n        created_from_workflow_run_url=created_from_workflow_run_url,\n    )\n\n\n@click.command(name=\"plan-save\")\n@click.option(\n    \"--format\",\n    \"output_format\",\n    type=click.Choice([\"json\", \"display\"]),\n    default=\"json\",\n    help=\"Output format: json (default) or display (formatted text)\",\n)\n@click.option(\n    \"--plan-file\",\n    type=click.Path(exists=True, path_type=Path),\n    default=None,\n    help=\"Path to specific plan file (highest priority)\",\n)\n@click.option(\n    \"--session-id\",\n    default=None,\n    help=\"Session ID for scoped plan lookup\",\n)\n@click.option(\n    \"--objective-issue\",\n    type=int,\n    default=None,\n    help=\"Link plan to parent objective issue number\",\n)\n@click.option(\n    \"--plan-type\",\n    type=click.Choice([\"standard\", \"learn\"]),\n    default=None,\n    help=\"Plan type: standard (default) or learn\",\n)\n@click.option(\n    \"--learned-from-issue\",\n    type=int,\n    default=None,\n    help=\"Parent plan issue number (for learn plans)\",\n)\n@click.option(\n    \"--created-from-workflow-run-url\",\n    default=None,\n    help=\"GitHub Actions workflow run URL\",\n)\n@click.pass_context\ndef plan_save(\n    ctx: click.Context,\n    *,\n    output_format: str,\n    plan_file: Path | None,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n\n    When ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR.\n    Otherwise delegates to plan-save-to-issue.\n    \"\"\"\n    # PLAN_BACKEND_SPLIT: dispatches to issue-based save or draft-PR save based on config/env\n    # Default backend: delegate to issue-based save\n    if get_plan_backend() != \"draft_pr\":\n        ctx.invoke(\n            plan_save_to_issue,\n            output_format=output_format,\n            plan_file=plan_file,\n            session_id=session_id,\n            objective_issue=objective_issue,\n            plan_type=plan_type,\n            learned_from_issue=learned_from_issue,\n            created_from_workflow_run_url=created_from_workflow_run_url,\n        )\n        return\n\n    _save_plan_via_draft_pr(\n        ctx,\n        output_format=output_format,\n        plan_file=plan_file,\n        session_id=session_id,\n        objective_issue=objective_issue,\n        plan_type=plan_type,\n        learned_from_issue=learned_from_issue,\n        created_from_workflow_run_url=created_from_workflow_run_url,\n    )\n","structuredPatch":[{"oldStart":30,"oldLines":6,"newStart":30,"newLines":7,"lines":["     plan_save_to_issue,"," )"," from erk.cli.commands.exec.scripts.validate_plan_content import _validate_plan_content","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk_shared.context.helpers import (","     get_repo_identifier,","     require_branch_manager,"]},{"oldStart":39,"oldLines":6,"newStart":40,"newLines":7,"lines":["     require_github,","     require_issues,","     require_local_config,","+    require_prompt_executor,","     require_repo_root,","     require_time,"," )"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"5a72cec9-3a93-4be7-91af-ba62fa5885d1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01VGRpJRdKnw7FC4b87uRTDN","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the branch name generation to use slug:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":363,"cache_read_input_tokens":127923,"cache_creation":{"ephemeral_5m_input_tokens":363,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHCmJboi9px2pr5s115","type":"assistant","uuid":"b31f1c72-236c-4669-bbb2-9a802f569f76","timestamp":"2026-02-22T14:39:47.314Z"}
{"parentUuid":"b31f1c72-236c-4669-bbb2-9a802f569f76","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01VGRpJRdKnw7FC4b87uRTDN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GKzdUbGdmr4hhma3FwS7H2","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","old_string":"    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )","new_string":"    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name with LLM-generated slug\n    executor = require_prompt_executor(ctx)\n    slug = generate_slug_or_fallback(executor, title)\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        slug,\n        now,\n        objective_id=objective_issue,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":363,"cache_read_input_tokens":127923,"cache_creation":{"ephemeral_5m_input_tokens":363,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHCmJboi9px2pr5s115","type":"assistant","uuid":"1b918393-485f-40c7-87f0-45e128d3673d","timestamp":"2026-02-22T14:39:49.514Z"}
{"parentUuid":"1b918393-485f-40c7-87f0-45e128d3673d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GKzdUbGdmr4hhma3FwS7H2","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py has been updated successfully."}]},"uuid":"b3f3fa1a-bcca-4fe8-9dd0-f3a70c5429ac","timestamp":"2026-02-22T14:39:50.204Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_save.py","oldString":"    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )","newString":"    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name with LLM-generated slug\n    executor = require_prompt_executor(ctx)\n    slug = generate_slug_or_fallback(executor, title)\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        slug,\n        now,\n        objective_id=objective_issue,\n    )","originalFile":"\"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n\nUsage:\n    erk exec plan-save [OPTIONS]\n\nWhen ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR with the plan.\nOtherwise delegates to the existing plan-save-to-issue logic (default).\n\nOptions:\n    --format json|display: Output format (default: json)\n    --plan-file PATH: Use specific plan file (highest priority)\n    --session-id ID: Session ID for scoped plan lookup\n    --objective-issue INT: Link plan to parent objective\n    --plan-type standard|learn: Plan type (default: standard)\n    --learned-from-issue INT: Parent plan issue (for learn plans)\n    --created-from-workflow-run-url URL: Workflow run URL\n\nExit Codes:\n    0: Success\n    1: Error\n    2: Validation failed\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.exec.scripts.plan_save_to_issue import (\n    plan_save_to_issue,\n)\nfrom erk.cli.commands.exec.scripts.validate_plan_content import _validate_plan_content\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    get_repo_identifier,\n    require_branch_manager,\n    require_claude_installation,\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_local_config,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.claude_installation.abc import ClaudeInstallation\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.time.real import RealTime\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.output.next_steps import format_draft_pr_next_steps_plain\nfrom erk_shared.plan_store import get_plan_backend\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.plan_content import extract_title_from_plan, resolve_plan_content\nfrom erk_shared.plan_utils import get_title_tag_from_labels\nfrom erk_shared.scratch.plan_snapshots import PlanSnapshot, snapshot_plan_for_session\nfrom erk_shared.scratch.session_markers import (\n    create_plan_saved_issue_marker,\n    create_plan_saved_marker,\n    get_existing_saved_issue,\n)\n\n\ndef _get_snapshot_result(\n    *,\n    session_id: str,\n    plan_file: Path | None,\n    cwd: Path,\n    claude_installation: ClaudeInstallation,\n    repo_root: Path,\n) -> PlanSnapshot | None:\n    \"\"\"Archive the plan file to session-scoped scratch storage.\n\n    Plan snapshots preserve the original plan content at save time, creating\n    an immutable record tied to the session. This enables deduplication\n    (detecting if a session already saved a plan) and provides an audit trail\n    (what was the plan content when it was saved).\n\n    Args:\n        session_id: Claude session ID\n        plan_file: Explicit plan file path (highest priority)\n        cwd: Current working directory\n        claude_installation: ClaudeInstallation gateway for plan discovery\n        repo_root: Repository root for scratch directory\n\n    Returns:\n        PlanSnapshot with archive path, or None if no plan file found.\n    \"\"\"\n    if plan_file is not None:\n        snapshot_path = plan_file\n    else:\n        snapshot_path = claude_installation.find_plan_for_session(cwd, session_id)\n\n    if snapshot_path is None or not snapshot_path.exists():\n        return None\n\n    return snapshot_plan_for_session(\n        session_id=session_id,\n        plan_file_path=snapshot_path,\n        project_cwd=cwd,\n        claude_installation=claude_installation,\n        repo_root=repo_root,\n    )\n\n\ndef _save_as_draft_pr(\n    ctx: click.Context,\n    *,\n    plan_content: str,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    output_format: str,\n    plan_file: Path | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Save plan as a draft PR.\n\n    Creates a branch, pushes it, then creates a draft PR with plan content.\n\n    Args:\n        ctx: Click context\n        plan_content: Validated plan content\n        session_id: Session ID for markers\n        objective_issue: Optional objective issue number\n        plan_type: Plan type (standard or learn)\n        output_format: Output format (json or display)\n        plan_file: Original plan file path (for snapshot)\n        learned_from_issue: Parent plan issue number (for learn plans)\n        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    github_issues = require_issues(ctx)\n    config = require_local_config(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    title = extract_title_from_plan(plan_content)\n\n    # Generate branch name\n    now = require_time(ctx).now()\n    branch_name = generate_draft_pr_branch_name(\n        title,\n        now,\n        objective_id=objective_issue,\n    )\n\n    # Create branch with Graphite tracking (handles both creation and stack metadata)\n    branch_manager = require_branch_manager(ctx)\n    current_branch = git.branch.get_current_branch(cwd)\n    start_point = current_branch if current_branch is not None else \"HEAD\"\n    create_result = branch_manager.create_branch(repo_root, branch_name, start_point)\n    if isinstance(create_result, BranchAlreadyExists):\n        click.echo(f\"Error: {create_result.message}\", err=True)\n        raise SystemExit(1) from None\n\n    # Detect trunk for PR base metadata\n    trunk = git.branch.detect_trunk_branch(cwd)\n\n    # Build ref.json data\n    ref_data: dict[str, str | int | None] = {\n        \"provider\": \"github-draft-pr\",\n        \"title\": title,\n    }\n    if objective_issue is not None:\n        ref_data[\"objective_id\"] = objective_issue\n\n    # Commit plan files directly to branch (no checkout needed).\n    # Uses git plumbing to avoid race conditions when multiple sessions\n    # share the same worktree.\n    git.commit.commit_files_to_branch(\n        repo_root,\n        branch=branch_name,\n        files={\n            f\"{IMPL_CONTEXT_DIR}/plan.md\": plan_content,\n            f\"{IMPL_CONTEXT_DIR}/ref.json\": json.dumps(ref_data, indent=2),\n        },\n        message=f\"Add plan: {title}\",\n    )\n    git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n\n    # Build metadata\n    metadata: dict[str, object] = {\"branch_name\": branch_name, \"trunk_branch\": trunk}\n\n    if config.plans_repo is not None:\n        metadata[\"source_repo\"] = get_repo_identifier(ctx)\n\n    if objective_issue is not None:\n        metadata[\"objective_issue\"] = objective_issue\n\n    if session_id is not None:\n        metadata[\"created_from_session\"] = session_id\n\n    if learned_from_issue is not None:\n        metadata[\"learned_from_issue\"] = learned_from_issue\n\n    if created_from_workflow_run_url is not None:\n        metadata[\"created_from_workflow_run_url\"] = created_from_workflow_run_url\n\n    # Build labels\n    labels = [\"erk-plan\"]\n    if plan_type == \"learn\":\n        labels.append(\"erk-learn\")\n\n    # Prefix title with [erk-plan] or [erk-learn] for GitHub visibility\n    title_tag = get_title_tag_from_labels(labels)\n    prefixed_title = f\"{title_tag} {title}\"\n\n    # Create draft PR via backend\n    backend = DraftPRPlanBackend(github, github_issues, time=RealTime())\n    result = backend.create_plan(\n        repo_root=repo_root,\n        title=prefixed_title,\n        content=plan_content,\n        labels=tuple(labels),\n        metadata=metadata,\n    )\n\n    if not result.plan_id.isdigit():\n        msg = f\"Expected numeric plan_id from draft PR creation, got: {result.plan_id!r}\"\n        raise RuntimeError(msg)\n    plan_number = int(result.plan_id)\n\n    # Create markers and snapshot\n    snapshot_result: PlanSnapshot | None = None\n    if session_id is not None:\n        create_plan_saved_marker(session_id, repo_root)\n        create_plan_saved_issue_marker(session_id, repo_root, plan_number)\n\n        snapshot_result = _get_snapshot_result(\n            session_id=session_id,\n            plan_file=plan_file,\n            cwd=cwd,\n            claude_installation=claude_installation,\n            repo_root=repo_root,\n        )\n\n    # Output\n    if output_format == \"display\":\n        click.echo(f\"Plan saved as draft PR #{plan_number}\")\n        click.echo(f\"Title: {prefixed_title}\")\n        click.echo(f\"URL: {result.url}\")\n        click.echo(f\"Branch: {branch_name}\")\n        if snapshot_result is not None:\n            click.echo(f\"Archived: {snapshot_result.snapshot_dir}\")\n        click.echo()\n        click.echo(format_draft_pr_next_steps_plain(plan_number, branch_name=branch_name))\n    else:\n        output_data: dict[str, str | int | bool | None] = {\n            \"success\": True,\n            \"issue_number\": plan_number,\n            \"issue_url\": result.url,\n            \"title\": prefixed_title,\n            \"branch_name\": branch_name,\n            \"plan_backend\": \"draft_pr\",\n        }\n        if snapshot_result is not None:\n            output_data[\"archived_to\"] = str(snapshot_result.snapshot_dir)\n        click.echo(json.dumps(output_data))\n\n\ndef _save_plan_via_draft_pr(\n    ctx: click.Context,\n    *,\n    output_format: str,\n    plan_file: Path | None,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Handle draft-PR backend: dedup check, plan extraction, validation, and save.\n\n    Args:\n        ctx: Click context\n        output_format: Output format (json or display)\n        plan_file: Explicit plan file path (highest priority)\n        session_id: Session ID for dedup and markers\n        objective_issue: Optional objective issue number\n        plan_type: Plan type (standard or learn)\n        learned_from_issue: Parent plan issue number (for learn plans)\n        created_from_workflow_run_url: GitHub Actions workflow run URL\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    claude_installation = require_claude_installation(ctx)\n\n    # Session deduplication check\n    if session_id is not None:\n        existing_issue = get_existing_saved_issue(session_id, repo_root)\n        if existing_issue is not None:\n            if output_format == \"display\":\n                click.echo(\n                    f\"This session already saved plan #{existing_issue}. \"\n                    \"Skipping duplicate creation.\",\n                    err=True,\n                )\n            else:\n                click.echo(\n                    json.dumps(\n                        {\n                            \"success\": True,\n                            \"issue_number\": existing_issue,\n                            \"skipped_duplicate\": True,\n                            \"message\": f\"Session already saved plan #{existing_issue}\",\n                        }\n                    )\n                )\n            return\n\n    # Extract plan content (same priority as plan-save-to-issue)\n    plan = resolve_plan_content(\n        plan_file=plan_file,\n        session_id=session_id,\n        repo_root=repo_root,\n        claude_installation=claude_installation,\n        cwd=cwd,\n    )\n\n    if not plan:\n        if output_format == \"display\":\n            click.echo(\"Error: No plan found in ~/.claude/plans/\", err=True)\n        else:\n            click.echo(json.dumps({\"success\": False, \"error\": \"No plan found in ~/.claude/plans/\"}))\n        raise SystemExit(1)\n\n    # Validate plan content\n    valid, error, details = _validate_plan_content(plan)\n    if not valid:\n        if output_format == \"display\":\n            click.echo(f\"Error: Plan validation failed: {error}\", err=True)\n        else:\n            click.echo(\n                json.dumps(\n                    {\n                        \"success\": False,\n                        \"error\": f\"Plan validation failed: {error}\",\n                        \"error_type\": \"validation_failed\",\n                        \"details\": details,\n                    }\n                )\n            )\n        raise SystemExit(2)\n\n    _save_as_draft_pr(\n        ctx,\n        plan_content=plan,\n        session_id=session_id,\n        objective_issue=objective_issue,\n        plan_type=plan_type,\n        output_format=output_format,\n        plan_file=plan_file,\n        learned_from_issue=learned_from_issue,\n        created_from_workflow_run_url=created_from_workflow_run_url,\n    )\n\n\n@click.command(name=\"plan-save\")\n@click.option(\n    \"--format\",\n    \"output_format\",\n    type=click.Choice([\"json\", \"display\"]),\n    default=\"json\",\n    help=\"Output format: json (default) or display (formatted text)\",\n)\n@click.option(\n    \"--plan-file\",\n    type=click.Path(exists=True, path_type=Path),\n    default=None,\n    help=\"Path to specific plan file (highest priority)\",\n)\n@click.option(\n    \"--session-id\",\n    default=None,\n    help=\"Session ID for scoped plan lookup\",\n)\n@click.option(\n    \"--objective-issue\",\n    type=int,\n    default=None,\n    help=\"Link plan to parent objective issue number\",\n)\n@click.option(\n    \"--plan-type\",\n    type=click.Choice([\"standard\", \"learn\"]),\n    default=None,\n    help=\"Plan type: standard (default) or learn\",\n)\n@click.option(\n    \"--learned-from-issue\",\n    type=int,\n    default=None,\n    help=\"Parent plan issue number (for learn plans)\",\n)\n@click.option(\n    \"--created-from-workflow-run-url\",\n    default=None,\n    help=\"GitHub Actions workflow run URL\",\n)\n@click.pass_context\ndef plan_save(\n    ctx: click.Context,\n    *,\n    output_format: str,\n    plan_file: Path | None,\n    session_id: str | None,\n    objective_issue: int | None,\n    plan_type: str | None,\n    learned_from_issue: int | None,\n    created_from_workflow_run_url: str | None,\n) -> None:\n    \"\"\"Backend-aware plan save: dispatches to issue or draft-PR based on constant.\n\n    When ERK_PLAN_BACKEND is \"draft_pr\", creates a draft PR.\n    Otherwise delegates to plan-save-to-issue.\n    \"\"\"\n    # PLAN_BACKEND_SPLIT: dispatches to issue-based save or draft-PR save based on config/env\n    # Default backend: delegate to issue-based save\n    if get_plan_backend() != \"draft_pr\":\n        ctx.invoke(\n            plan_save_to_issue,\n            output_format=output_format,\n            plan_file=plan_file,\n            session_id=session_id,\n            objective_issue=objective_issue,\n            plan_type=plan_type,\n            learned_from_issue=learned_from_issue,\n            created_from_workflow_run_url=created_from_workflow_run_url,\n        )\n        return\n\n    _save_plan_via_draft_pr(\n        ctx,\n        output_format=output_format,\n        plan_file=plan_file,\n        session_id=session_id,\n        objective_issue=objective_issue,\n        plan_type=plan_type,\n        learned_from_issue=learned_from_issue,\n        created_from_workflow_run_url=created_from_workflow_run_url,\n    )\n","structuredPatch":[{"oldStart":141,"oldLines":10,"newStart":141,"newLines":12,"lines":[" ","     title = extract_title_from_plan(plan_content)"," ","-    # Generate branch name","+    # Generate branch name with LLM-generated slug","+    executor = require_prompt_executor(ctx)","+    slug = generate_slug_or_fallback(executor, title)","     now = require_time(ctx).now()","     branch_name = generate_draft_pr_branch_name(","-        title,","+        slug,","         now,","         objective_id=objective_issue,","     )"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"b3f3fa1a-bcca-4fe8-9dd0-f3a70c5429ac","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Sbk7ipgBhU7pYVKcNnRAAn","type":"message","role":"assistant","content":[{"type":"text","text":"**Site 2: submit.py** - `_validate_issue_for_submit`"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":355,"cache_read_input_tokens":128286,"cache_creation":{"ephemeral_5m_input_tokens":355,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHDAKh8xC3qzn9G6JjM","type":"assistant","uuid":"e82c8691-e5d5-4369-9807-e1c936f14515","timestamp":"2026-02-22T14:39:53.036Z"}
{"parentUuid":"e82c8691-e5d5-4369-9807-e1c936f14515","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Sbk7ipgBhU7pYVKcNnRAAn","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GufAjUXN5GGE6LgrWbBqwG","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","old_string":"from erk_shared.naming import generate_issue_branch_name","new_string":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":355,"cache_read_input_tokens":128286,"cache_creation":{"ephemeral_5m_input_tokens":355,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHDAKh8xC3qzn9G6JjM","type":"assistant","uuid":"e449735e-9eab-4729-80ea-2b4a432da142","timestamp":"2026-02-22T14:39:54.589Z"}
{"parentUuid":"e449735e-9eab-4729-80ea-2b4a432da142","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File has not been read yet. Read it first before writing to it.</tool_use_error>","is_error":true,"tool_use_id":"toolu_01GufAjUXN5GGE6LgrWbBqwG"}]},"uuid":"affc6168-7a74-4160-9a5e-527c3f7e3dc1","timestamp":"2026-02-22T14:39:54.606Z","toolUseResult":"Error: File has not been read yet. Read it first before writing to it."}
{"parentUuid":"affc6168-7a74-4160-9a5e-527c3f7e3dc1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01R5NTsf3jC5B6AoUiFG7Vwe","type":"message","role":"assistant","content":[{"type":"text","text":"I already read submit.py earlier, but let me re-read the specific section:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":424,"cache_read_input_tokens":128641,"cache_creation":{"ephemeral_5m_input_tokens":424,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHDV9HNJNWY1aNDMjap","type":"assistant","uuid":"9d8754dd-5830-4933-a634-11cf334350e8","timestamp":"2026-02-22T14:39:57.033Z"}
{"parentUuid":"9d8754dd-5830-4933-a634-11cf334350e8","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01R5NTsf3jC5B6AoUiFG7Vwe","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MipmdALX27hfZPFBPPmxDu","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","offset":40,"limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":424,"cache_read_input_tokens":128641,"cache_creation":{"ephemeral_5m_input_tokens":424,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHDV9HNJNWY1aNDMjap","type":"assistant","uuid":"323ce015-b724-4b66-b2c6-0fba41edf03b","timestamp":"2026-02-22T14:39:57.808Z"}
{"parentUuid":"323ce015-b724-4b66-b2c6-0fba41edf03b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MipmdALX27hfZPFBPPmxDu","type":"tool_result","content":"    40→)\n    41→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    42→from erk_shared.gateway.github.types import PRNotFound\n    43→from erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\n    44→from erk_shared.naming import generate_issue_branch_name\n    45→from erk_shared.output.output import user_output\n    46→from erk_shared.plan_store.types import PlanNotFound\n    47→from erk_shared.worker_impl_folder import (\n    48→    create_worker_impl_folder,\n    49→    remove_worker_impl_folder,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"820f8453-c34f-42c1-adf3-144be34b878c","timestamp":"2026-02-22T14:39:57.837Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","content":")\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,","numLines":10,"startLine":40,"totalLines":1339}}}
{"parentUuid":"820f8453-c34f-42c1-adf3-144be34b878c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_016oRC3aczHe3MWotwGbCjXA","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011vKmjRi6Ya3k7Yn57QcnDr","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","old_string":"from erk_shared.naming import generate_issue_branch_name","new_string":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":399,"cache_read_input_tokens":129065,"cache_creation":{"ephemeral_5m_input_tokens":399,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHDiwVqFrcn1aQ9pCM3","type":"assistant","uuid":"6d25797a-831a-4087-934e-4a710a825089","timestamp":"2026-02-22T14:40:01.457Z"}
{"parentUuid":"6d25797a-831a-4087-934e-4a710a825089","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011vKmjRi6Ya3k7Yn57QcnDr","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/submit.py has been updated successfully."}]},"uuid":"28926137-374b-4d4d-afa2-4c5d87bb8cc1","timestamp":"2026-02-22T14:40:02.179Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","oldString":"from erk_shared.naming import generate_issue_branch_name","newString":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name","originalFile":"\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n\nimport logging\nimport tomllib\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,\n    worker_impl_folder_exists,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _format_issue_ref(issue_number: int, plans_repo: str | None) -> str:\n    \"\"\"Format issue reference for PR body.\n\n    Args:\n        issue_number: The issue number\n        plans_repo: Target repo in \"owner/repo\" format, or None for same repo\n\n    Returns:\n        \"#N\" for same-repo, \"owner/repo#N\" for cross-repo\n    \"\"\"\n    if plans_repo is None:\n        return f\"#{issue_number}\"\n    return f\"{plans_repo}#{issue_number}\"\n\n\n@contextmanager\ndef branch_rollback(ctx: ErkContext, repo_root: Path, original_branch: str) -> Iterator[None]:\n    \"\"\"Context manager that restores original branch on exception.\n\n    On success, does nothing (caller handles cleanup).\n    On exception, checks out original_branch and re-raises.\n    \"\"\"\n    try:\n        yield\n    except Exception:\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + \"Operation failed, restoring original branch...\"\n        )\n        ctx.branch_manager.checkout_branch(repo_root, original_branch)\n        raise\n\n\ndef is_issue_learn_plan(labels: list[str]) -> bool:\n    \"\"\"Check if an issue is a learn plan by checking for erk-learn label.\n\n    Args:\n        labels: The issue's labels\n\n    Returns:\n        True if the issue has the erk-learn label, False otherwise\n    \"\"\"\n    return \"erk-learn\" in labels\n\n\ndef _find_existing_branches_for_issue(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n) -> list[str]:\n    \"\"\"Find local branches matching P{issue_number}-* pattern.\"\"\"\n    local_branches = ctx.git.branch.list_local_branches(repo_root)\n    prefix = f\"P{issue_number}-\"\n    return sorted([b for b in local_branches if b.startswith(prefix)])\n\n\ndef _prompt_existing_branch_action(\n    ctx: ErkContext,\n    repo_root: Path,\n    existing_branches: list[str],\n    new_branch_name: str,\n    *,\n    force: bool,\n) -> str | None:\n    \"\"\"Prompt user to decide what to do with existing branch(es).\n\n    Args:\n        ctx: ErkContext with git operations\n        repo_root: Repository root path\n        existing_branches: List of existing branch names matching the issue pattern\n        new_branch_name: Name for new branch if creating fresh\n        force: If True, delete existing branches without prompting\n\n    Returns:\n        - Branch name to use (existing branch)\n        - None to signal \"create new\" (after deleting existing)\n    \"\"\"\n    if force:\n        user_output(f\"\\nDeleting {len(existing_branches)} existing branch(es) (--force mode):\")\n        for branch in existing_branches:\n            ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n            user_output(f\"  Deleted: {branch}\")\n        return None  # Signal \"create new branch\"\n\n    user_output(\"\\nFound existing local branch(es) for this issue:\")\n    for branch in existing_branches:\n        user_output(f\"  • {branch}\")\n    user_output(f\"\\nNew branch would be: {click.style(new_branch_name, fg='cyan')}\")\n    user_output(\"\")\n\n    # Use newest branch (latest timestamp = last alphabetically)\n    branch_to_use = existing_branches[-1]\n\n    # Single binary prompt\n    reuse = ctx.console.confirm(\n        f\"Reuse existing branch '{branch_to_use}'? \"\n        \"If not, a new branch and PR will be created (old draft PR will be closed)\",\n        default=True,\n    )\n\n    if reuse:\n        return branch_to_use\n\n    # Delete existing branches and signal \"create new\"\n    for branch in existing_branches:\n        ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n        user_output(f\"Deleted branch: {branch}\")\n    return None\n\n\ndef get_learn_plan_parent_branch(ctx: ErkContext, repo_root: Path, plan_id: str) -> str | None:\n    \"\"\"Get the parent branch for a learn plan.\n\n    Learn plans should stack on their parent plan's branch.\n    Extracts learned_from_issue via plan_backend, fetches parent's branch_name.\n\n    Args:\n        ctx: ErkContext with plan_backend\n        repo_root: Repository root path\n        plan_id: Plan identifier\n\n    Returns:\n        Parent plan's branch_name if found, None otherwise\n    \"\"\"\n    learned_from = ctx.plan_backend.get_metadata_field(repo_root, plan_id, \"learned_from_issue\")\n    if isinstance(learned_from, PlanNotFound) or learned_from is None:\n        return None\n\n    branch_name = ctx.plan_backend.get_metadata_field(repo_root, str(learned_from), \"branch_name\")\n    if isinstance(branch_name, PlanNotFound) or branch_name is None:\n        return None\n    return str(branch_name)\n\n\ndef load_workflow_config(repo_root: Path, workflow_name: str) -> dict[str, str]:\n    \"\"\"Load workflow config from .erk/config.toml [workflows.<name>] section.\n\n    Args:\n        repo_root: Repository root path\n        workflow_name: Workflow filename (with or without .yml/.yaml extension).\n            Only the basename is used for config lookup.\n\n    Returns:\n        Dict of string key-value pairs for workflow inputs.\n        Returns empty dict if config file or section doesn't exist.\n\n    Example:\n        For workflow_name=\"plan-implement.yml\", reads from:\n        .erk/config.toml -> [workflows.plan-implement] section\n    \"\"\"\n    config_path = repo_root / \".erk\" / \"config.toml\"\n\n    if not config_path.exists():\n        return {}\n\n    with open(config_path, \"rb\") as f:\n        data = tomllib.load(f)\n\n    # Extract basename and strip .yml/.yaml extension\n    basename = Path(workflow_name).name\n    config_name = basename.removesuffix(\".yml\").removesuffix(\".yaml\")\n\n    # Get [workflows.<name>] section\n    workflows_section = data.get(\"workflows\", {})\n    workflow_config = workflows_section.get(config_name, {})\n\n    # Convert all values to strings (workflow inputs are always strings)\n    return {k: str(v) for k, v in workflow_config.items()}\n\n\n@dataclass(frozen=True)\nclass ValidatedIssue:\n    \"\"\"Issue that passed all validation checks.\"\"\"\n\n    number: int\n    issue: IssueInfo\n    branch_name: str\n    branch_exists: bool\n    pr_number: int | None\n    is_learn_origin: bool\n\n\n@dataclass(frozen=True)\nclass SubmitResult:\n    \"\"\"Result of submitting a single issue.\"\"\"\n\n    issue_number: int\n    issue_title: str\n    issue_url: str\n    pr_number: int | None\n    pr_url: str | None\n    workflow_run_id: str\n    workflow_url: str\n\n\ndef _build_workflow_run_url(issue_url: str, run_id: str) -> str:\n    \"\"\"Construct GitHub Actions workflow run URL from issue URL and run ID.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        run_id: Workflow run ID\n\n    Returns:\n        Workflow run URL (e.g., https://github.com/owner/repo/actions/runs/1234567890)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_workflow_run_url(owner, repo, run_id)\n    return f\"https://github.com/actions/runs/{run_id}\"\n\n\ndef _strip_plan_markers(title: str) -> str:\n    \"\"\"Strip '[erk-plan]' prefix and 'Plan:' prefix from issue title for use as PR title.\"\"\"\n    result = title\n    # Strip \"[erk-plan] \" prefix if present\n    if result.startswith(ERK_PLAN_TITLE_PREFIX):\n        result = result[len(ERK_PLAN_TITLE_PREFIX) :]\n    # Strip \"Plan: \" prefix if present\n    if result.startswith(PLAN_HEADING_PREFIX):\n        result = result[len(PLAN_HEADING_PREFIX) :]\n    return result\n\n\ndef _add_planned_prefix(title: str) -> str:\n    \"\"\"Prepend 'planned/' prefix to PR title (idempotent).\n\n    Args:\n        title: The PR title to prefix\n\n    Returns:\n        The title with 'planned/' prefix, skipping if already prefixed\n    \"\"\"\n    if title.startswith(PLANNED_PR_TITLE_PREFIX):\n        return title\n    return f\"{PLANNED_PR_TITLE_PREFIX}{title}\"\n\n\ndef _build_pr_url(issue_url: str, pr_number: int) -> str:\n    \"\"\"Construct GitHub PR URL from issue URL and PR number.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        pr_number: PR number\n\n    Returns:\n        PR URL (e.g., https://github.com/owner/repo/pull/456)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_pr_url(owner, repo, pr_number)\n    return f\"https://github.com/pull/{pr_number}\"\n\n\ndef _close_orphaned_draft_prs(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n    keep_pr_number: int,\n) -> list[int]:\n    \"\"\"Close old draft PRs linked to an issue, keeping the specified one.\n\n    Returns list of PR numbers that were closed.\n    \"\"\"\n    linked_prs = ctx.issues.get_prs_referencing_issue(repo_root, issue_number)\n\n    closed_prs: list[int] = []\n    for pr in linked_prs:\n        # Close orphaned drafts: draft PRs that are OPEN and not the one we just created\n        # Any draft PR linked to an erk-plan issue is fair game to close\n        if pr.is_draft and pr.state == \"OPEN\" and pr.number != keep_pr_number:\n            ctx.github.close_pr(repo_root, pr.number)\n            closed_prs.append(pr.number)\n\n    return closed_prs\n\n\n@dataclass(frozen=True)\nclass ValidatedDraftPR:\n    \"\"\"Draft PR that passed all validation checks.\"\"\"\n\n    number: int\n    title: str\n    url: str\n    branch_name: str\n\n\ndef _validate_draft_pr_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    plan_number: int,\n) -> ValidatedDraftPR:\n    \"\"\"Validate a draft PR plan for submission.\n\n    Fetches the PR, validates it has the erk-plan label and is OPEN.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        plan_number: PR number to validate\n\n    Raises:\n        SystemExit: If PR doesn't exist, missing label, or not OPEN.\n    \"\"\"\n    pr_result = ctx.github.get_pr(repo.root, plan_number)\n    if isinstance(pr_result, PRNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in pr_result.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"PR #{plan_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if pr_result.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} is {pr_result.state}\\n\\n\"\n            \"Cannot submit closed PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    return ValidatedDraftPR(\n        number=plan_number,\n        title=pr_result.title,\n        url=pr_result.url,\n        branch_name=pr_result.head_ref_name,\n    )\n\n\ndef _submit_draft_pr_plan(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedDraftPR,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a validated draft-PR plan for implementation.\n\n    For draft-PR plans, the branch and PR already exist. This function:\n    - Fetches and checks out the existing plan branch\n    - Creates .worker-impl/ with provider=\"github-draft-pr\"\n    - Commits and pushes .worker-impl/ to existing branch\n    - Triggers the workflow with plan_backend=\"draft_pr\"\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated draft PR information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    plan_number = validated.number\n    branch_name = validated.branch_name\n\n    # Fetch plan content via PlanBackend\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(plan_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number}: plan content not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Fetch and checkout the existing plan branch\n    user_output(f\"Checking out existing plan branch: {click.style(branch_name, fg='cyan')}\")\n    ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n    local_branches = ctx.git.branch.list_local_branches(repo.root)\n    if branch_name not in local_branches:\n        remote_ref = f\"origin/{branch_name}\"\n        ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Sync local branch with remote (may be behind from prior submission or CI)\n    pull_result = ctx.git.remote.pull_rebase(repo.root, \"origin\", branch_name)\n    if isinstance(pull_result, PullRebaseError):\n        raise UserFacingCliError(\n            f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n        )\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    # Create .worker-impl/ with draft-PR provider\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(plan_number),\n        url=validated.url,\n        repo_root=repo.root,\n        provider=\"github-draft-pr\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for PR #{plan_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=False, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Switch back to original branch\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Build inputs dict with plan_backend=\"draft_pr\"\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n\n    inputs = {\n        \"plan_id\": str(plan_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": validated.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(plan_number),\n        \"base_branch\": base_branch,\n        \"plan_backend\": \"draft_pr\",\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL\n    workflow_url = _build_workflow_run_url(validated.url, run_id)\n\n    # Write dispatch metadata FIRST (before any PR body modification)\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=plan_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    # Update PR body with workflow run link (best-effort)\n    # Guard: only append if body is non-empty to avoid overwriting metadata block\n    try:\n        pr_details = ctx.github.get_pr(repo.root, plan_number)\n        if not isinstance(pr_details, PRNotFound) and pr_details.body:\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, plan_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Post queued event comment via PlanBackend\n    try:\n        validation_results = {\n            \"pr_is_open\": True,\n            \"has_erk_plan_label\": True,\n        }\n\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=plan_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Plan Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Plan submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.plan_backend.add_comment(repo.root, str(plan_number), comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(validated.url, plan_number)\n\n    return SubmitResult(\n        issue_number=plan_number,\n        issue_title=validated.title,\n        issue_url=validated.url,\n        pr_number=plan_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\ndef _validate_issue_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    issue_number: int,\n    base_branch: str,\n    *,\n    force: bool,\n) -> ValidatedIssue:\n    \"\"\"Validate a single issue for submission.\n\n    Fetches the issue, validates constraints, derives branch name, and checks\n    if branch/PR already exist.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        issue_number: GitHub issue number to validate\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Raises:\n        SystemExit: If issue doesn't exist, missing label, or closed.\n    \"\"\"\n    # Fetch issue from GitHub\n    issue = ctx.issues.get_issue(repo.root, issue_number)\n    if isinstance(issue, IssueNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue.issue_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in issue.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"Issue #{issue_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan issues for automated implementation.\\n\"\n            \"To create a plan, use Plan Mode then /erk:plan-save\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if issue.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} is {issue.state}\\n\\n\"\n            \"Cannot submit closed issues for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Use provided base_branch instead of detecting trunk\n    logger.debug(\"base_branch=%s\", base_branch)\n\n    # Check for existing local branches BEFORE computing new name\n    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n\n    # Compute branch name using canonical naming function\n    objective_id_raw = ctx.plan_backend.get_metadata_field(\n        repo.root, str(issue_number), \"objective_issue\"\n    )\n    objective_id: int | None = None\n    if isinstance(objective_id_raw, int):\n        objective_id = objective_id_raw\n    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n        objective_id = int(objective_id_raw)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )\n\n    if existing_branches:\n        chosen = _prompt_existing_branch_action(\n            ctx, repo.root, existing_branches, new_branch_name, force=force\n        )\n        branch_name = chosen if chosen is not None else new_branch_name\n    else:\n        branch_name = new_branch_name\n\n    logger.debug(\"branch_name=%s\", branch_name)\n    user_output(f\"Computed branch: {click.style(branch_name, fg='cyan')}\")\n\n    # Check if branch already exists on remote and has a PR\n    branch_exists = ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", branch_name)\n    logger.debug(\"branch_exists_on_remote(%s)=%s\", branch_name, branch_exists)\n\n    pr_number: int | None = None\n    if branch_exists:\n        pr_details = ctx.github.get_pr_for_branch(repo.root, branch_name)\n        if not isinstance(pr_details, PRNotFound):\n            pr_number = pr_details.number\n\n    # Check if this issue is a learn plan\n    is_learn_origin = is_issue_learn_plan(issue.labels)\n\n    return ValidatedIssue(\n        number=issue_number,\n        issue=issue,\n        branch_name=branch_name,\n        branch_exists=branch_exists,\n        pr_number=pr_number,\n        is_learn_origin=is_learn_origin,\n    )\n\n\ndef _create_branch_and_pr(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    branch_name: str,\n    base_branch: str,\n    submitted_by: str,\n    original_branch: str,\n) -> int:\n    \"\"\"Create branch, commit, push, and create draft PR.\n\n    This function is called within the branch_rollback context manager.\n    On any exception, the context manager will restore the original branch.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        branch_name: Name of branch to create\n        base_branch: Base branch for PR\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (for cleanup on success)\n\n    Returns:\n        PR number of the created draft PR.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Get plan content and create .worker-impl/ folder\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(issue_number),\n        url=issue.url,\n        repo_root=repo.root,\n        provider=\"github\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for issue #{issue_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Create draft PR\n    # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n    # MUST be in the initial body passed to create_pr(), NOT added via update.\n    # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n    # updated when the body is edited afterward.\n    user_output(\"Creating draft PR...\")\n    plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n    issue_ref = _format_issue_ref(issue_number, plans_repo)\n    pr_body = (\n        f\"**Author:** @{submitted_by}\\n\"\n        f\"**Plan:** {issue_ref}\\n\\n\"\n        f\"**Status:** Queued for implementation\\n\\n\"\n        f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n        f\"## Implementation Plan\\n\\n\"\n        f\"<details>\\n\"\n        f\"<summary><strong>Implementation Plan</strong> (Issue #{issue_number})</summary>\\n\\n\"\n        f\"{plan.body}\\n\\n\"\n        f\"</details>\\n\\n\"\n        f\"---\\n\\n\"\n        f\"Closes {issue_ref}\"\n    )\n    pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n    pr_number = ctx.github.create_pr(\n        repo_root=repo.root,\n        branch=branch_name,\n        title=pr_title,\n        body=pr_body,\n        base=base_branch,\n        draft=True,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n    # Update PR body with checkout command footer\n    footer = build_pr_body_footer(\n        pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n    )\n    ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n    # Add extraction skip label if this is a learn plan\n    if validated.is_learn_origin:\n        ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n        # FUTURE ENHANCEMENT: When a learn plan issue gets a PR, update the parent\n        # plan's learn_status from \"completed_with_plan\" to track the PR number.\n        # Currently, the parent only gets updated when the learn plan's PR lands\n        # (in land_cmd._update_parent_learn_status_if_learn_plan). Adding an\n        # intermediate state here would let the TUI show the PR number (e.g.,\n        # \"🚧 #5514\") instead of the learn plan issue number (e.g., \"#5508\")\n        # while the PR is still in review.\n        # See: LearnStatusValue in erk_shared/github/metadata/schemas.py\n\n    # Link PR with Graphite (if enabled)\n    if ctx.branch_manager.is_graphite_managed():\n        user_output(\"Linking PR with Graphite...\")\n        submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n        if isinstance(submit_result, SubmitBranchError):\n            user_output(\n                click.style(\"✗\", fg=\"red\")\n                + f\" Failed to link PR with Graphite: {submit_result.message}\"\n            )\n        else:\n            user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n    # Close any orphaned draft PRs for this issue\n    closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n    if closed_prs:\n        user_output(\n            click.style(\"✓\", fg=\"green\")\n            + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n            + \", \".join(f\"#{n}\" for n in closed_prs)\n        )\n\n    # Switch back to original branch (keep the new branch for Graphite lineage)\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    return pr_number\n\n\ndef _submit_single_issue(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a single validated issue for implementation.\n\n    Creates branch/PR if needed and triggers workflow.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n    branch_name = validated.branch_name\n    branch_exists = validated.branch_exists\n    pr_number = validated.pr_number\n\n    if branch_exists:\n        if pr_number is not None:\n            user_output(\n                f\"PR #{pr_number} already exists for branch '{branch_name}' (state: existing)\"\n            )\n            user_output(\"Skipping branch/PR creation, triggering workflow...\")\n        else:\n            # Branch exists but no PR - need to add a commit for PR creation\n            user_output(f\"Branch '{branch_name}' exists but no PR. Adding placeholder commit...\")\n\n            # Fetch and checkout the remote branch locally\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n            # Only create tracking branch if it doesn't exist locally (LBYL)\n            local_branches = ctx.git.branch.list_local_branches(repo.root)\n            if branch_name not in local_branches:\n                remote_ref = f\"origin/{branch_name}\"\n                ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Create empty commit as placeholder for PR creation\n            ctx.git.commit.commit(\n                repo.root,\n                f\"[erk-plan] Initialize implementation for issue #{issue_number}\",\n            )\n            push_result = ctx.git.remote.push_to_remote(\n                repo.root, \"origin\", branch_name, set_upstream=False, force=False\n            )\n            if isinstance(push_result, PushError):\n                raise UserFacingCliError(push_result.message)\n            user_output(click.style(\"✓\", fg=\"green\") + \" Placeholder commit pushed\")\n\n            # Now create the PR\n            # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n            # MUST be in the initial body passed to create_pr(), NOT added via update.\n            # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n            # updated when the body is edited afterward.\n            plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n            issue_ref = _format_issue_ref(issue_number, plans_repo)\n            pr_body = (\n                f\"**Author:** @{submitted_by}\\n\"\n                f\"**Plan:** {issue_ref}\\n\\n\"\n                f\"**Status:** Queued for implementation\\n\\n\"\n                f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n                f\"---\\n\\n\"\n                f\"Closes {issue_ref}\"\n            )\n            pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n            pr_number = ctx.github.create_pr(\n                repo_root=repo.root,\n                branch=branch_name,\n                title=pr_title,\n                body=pr_body,\n                base=base_branch,\n                draft=True,\n            )\n            user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n            # Update PR body with checkout command footer\n            footer = build_pr_body_footer(\n                pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n            # Add extraction skip label if this is a learn plan\n            if validated.is_learn_origin:\n                ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n                # FUTURE ENHANCEMENT: See comment in _create_branch_and_pr for\n                # updating parent plan's learn_status when learn plan gets a PR.\n\n            # Link PR with Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                user_output(\"Linking PR with Graphite...\")\n                submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n                if isinstance(submit_result, SubmitBranchError):\n                    user_output(\n                        click.style(\"✗\", fg=\"red\")\n                        + f\" Failed to link PR with Graphite: {submit_result.message}\"\n                    )\n                else:\n                    user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n            # Close any orphaned draft PRs\n            closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n            if closed_prs:\n                user_output(\n                    click.style(\"✓\", fg=\"green\")\n                    + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n                    + \", \".join(f\"#{n}\" for n in closed_prs)\n                )\n\n            # Switch back to original branch (keep the new branch for Graphite lineage)\n            ctx.branch_manager.checkout_branch(repo.root, original_branch)\n    else:\n        # Check if branch exists locally (user chose to reuse existing)\n        local_branches = ctx.git.branch.list_local_branches(repo.root)\n        branch_exists_locally = branch_name in local_branches\n\n        if branch_exists_locally:\n            # Reuse existing local branch\n            user_output(f\"Using existing local branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Track in Graphite if not already tracked\n            if ctx.branch_manager.is_graphite_managed():\n                if not ctx.graphite.is_branch_tracked(repo.root, branch_name):\n                    ctx.branch_manager.track_branch(repo.root, branch_name, base_branch)\n                    user_output(click.style(\"✓\", fg=\"green\") + \" Branch tracked in Graphite\")\n\n            # Checkout existing branch\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n        else:\n            # Create new branch\n            user_output(f\"Creating branch from origin/{base_branch}...\")\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", base_branch)\n\n            # Verify parent is tracked by Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                parent_branch = base_branch.removeprefix(\"origin/\")\n                if not ctx.graphite.is_branch_tracked(repo.root, parent_branch):\n                    msg = (\n                        f\"Cannot stack on branch '{parent_branch}' - \"\n                        f\"it's not tracked by Graphite.\\n\\n\"\n                        f\"To fix this:\\n\"\n                        f\"  1. gt checkout {parent_branch}\\n\"\n                        f\"  2. gt track --parent <parent-branch>\\n\\n\"\n                        f\"Then retry your command.\"\n                    )\n                    user_output(click.style(\"Error: \", fg=\"red\") + msg)\n                    raise SystemExit(1)\n\n            create_result = ctx.branch_manager.create_branch(\n                repo.root, branch_name, f\"origin/{base_branch}\"\n            )\n            if isinstance(create_result, BranchAlreadyExists):\n                user_output(click.style(\"Error: \", fg=\"red\") + create_result.message)\n                raise SystemExit(1) from None\n            user_output(f\"Created branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Validate pr_number is set before workflow dispatch\n    if pr_number is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Failed to create or find PR. Cannot trigger workflow.\"\n        )\n        raise SystemExit(1)\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Trigger workflow via direct dispatch\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n    user_output(f\"  Display name: {DISPATCH_WORKFLOW_METADATA_NAME}\")\n\n    # Build inputs dict, merging workflow config\n    inputs = {\n        # Required inputs (always passed)\n        \"plan_id\": str(issue_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": issue.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"base_branch\": base_branch,\n        # Config-based inputs (from .erk/workflows/)\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL once (used for PR body update, queued comment, and result)\n    workflow_url = _build_workflow_run_url(issue.url, run_id)\n\n    # Update PR body with workflow run link (best-effort)\n    try:\n        pr_details = ctx.github.get_pr(repo.root, pr_number)\n        if not isinstance(pr_details, PRNotFound):\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, pr_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata synchronously to fix race condition with erk dash\n    # This ensures the issue body has the run info before we return to the user\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=issue_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written to issue\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    validation_results = {\n        \"issue_is_open\": True,\n        \"has_erk_plan_label\": True,\n    }\n\n    # Create and post queued event comment\n    try:\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=issue_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Issue Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Issue submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\\n\\n\"\n                f\"Branch and draft PR were created locally for correct commit attribution.\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.issues.add_comment(repo.root, issue_number, comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(issue.url, pr_number) if pr_number else None\n\n    return SubmitResult(\n        issue_number=issue_number,\n        issue_title=issue.title,\n        issue_url=issue.url,\n        pr_number=pr_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\n@click.command(\"submit\")\n@click.argument(\"issue_numbers\", type=int, nargs=-1, required=True)\n@click.option(\n    \"--base\",\n    type=str,\n    default=None,\n    help=\"Base branch for PR (defaults to current branch).\",\n)\n@click.option(\n    \"-f\",\n    \"--force\",\n    is_flag=True,\n    help=\"Delete existing branches and create fresh without prompting.\",\n)\n@click.pass_obj\ndef submit_cmd(\n    ctx: ErkContext, issue_numbers: tuple[int, ...], base: str | None, force: bool\n) -> None:\n    \"\"\"Submit issues for remote AI implementation via GitHub Actions.\n\n    Creates branch and draft PR locally (for correct commit attribution),\n    then triggers the dispatch-erk-queue.yml GitHub Actions workflow.\n\n    Arguments:\n        ISSUE_NUMBERS: One or more GitHub issue numbers to submit\n\n    Example:\n        erk plan submit 123\n        erk plan submit 123 456 789\n        erk plan submit 123 --base master\n\n    Requires:\n        - All issues must have erk-plan label\n        - All issues must be OPEN\n        - Working directory must be clean (no uncommitted changes)\n    \"\"\"\n    # Validate GitHub CLI prerequisites upfront (LBYL)\n    Ensure.gh_authenticated(ctx)\n\n    # Get repository context\n    if isinstance(ctx.repo, RepoContext):\n        repo = ctx.repo\n    else:\n        repo = discover_repo_context(ctx, ctx.cwd)\n\n    # Ensure trunk is synced before any operations\n    ensure_trunk_synced(ctx, repo)\n\n    # Save current state (needed for both default base and restoration)\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Validate base branch if provided, otherwise default to current branch (LBYL)\n    if base is not None:\n        if not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", base):\n            user_output(\n                click.style(\"Error: \", fg=\"red\") + f\"Base branch '{base}' does not exist on remote\"\n            )\n            raise SystemExit(1)\n        target_branch = base\n    else:\n        # If on a placeholder branch (local-only), use trunk as base\n        if is_placeholder_branch(original_branch):\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        elif not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", original_branch):\n            # Current branch not pushed to remote - fall back to trunk\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        else:\n            target_branch = original_branch\n\n    # For single-issue learn plan submissions, auto-detect parent branch\n    issue_number = issue_numbers[0] if len(issue_numbers) == 1 else None\n    if (\n        issue_number is not None\n        and base is None\n        and ctx.issues.issue_exists(repo.root, issue_number)\n    ):\n        issue = ctx.issues.get_issue(repo.root, issue_number)\n        # issue_exists check above ensures this won't be IssueNotFound\n        if not isinstance(issue, IssueNotFound) and is_issue_learn_plan(issue.labels):\n            parent_branch = get_learn_plan_parent_branch(ctx, repo.root, str(issue_number))\n            if parent_branch is not None and ctx.git.branch.branch_exists_on_remote(\n                repo.root, \"origin\", parent_branch\n            ):\n                target_branch = parent_branch\n                user_output(\n                    f\"Learn plan detected, stacking on parent branch: \"\n                    f\"{click.style(parent_branch, fg='cyan')}\"\n                )\n            elif parent_branch is not None:\n                user_output(\n                    click.style(\"Warning: \", fg=\"yellow\")\n                    + f\"Parent branch '{parent_branch}' not on remote, using trunk\"\n                )\n\n    # Get GitHub username (authentication already validated)\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect draft-PR backend\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    if is_draft_pr:\n        # Draft-PR path: branch and PR already exist, just validate and trigger workflow\n        user_output(f\"Validating {len(issue_numbers)} draft-PR plan(s)...\")\n        user_output(\"\")\n\n        validated_draft_prs: list[ValidatedDraftPR] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating PR #{issue_number}...\")\n            validated_pr = _validate_draft_pr_for_submit(ctx, repo, issue_number)\n            validated_draft_prs.append(validated_pr)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_draft_prs)} plan(s) validated\"\n        )\n        user_output(\"\")\n\n        for v in validated_draft_prs:\n            user_output(f\"  #{v.number}: {click.style(v.title, fg='yellow')}\")\n        user_output(\"\")\n\n        results: list[SubmitResult] = []\n        for i, v in enumerate(validated_draft_prs):\n            if len(validated_draft_prs) > 1:\n                count = len(validated_draft_prs)\n                user_output(f\"--- Submitting PR {i + 1}/{count}: #{v.number} ---\")\n            else:\n                user_output(f\"Submitting PR #{v.number}...\")\n            user_output(\"\")\n            result = _submit_draft_pr_plan(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n    else:\n        # Issue-based path: existing flow\n        # Phase 1: Validate ALL issues upfront (atomic - fail fast before any side effects)\n        user_output(f\"Validating {len(issue_numbers)} issue(s)...\")\n        user_output(\"\")\n\n        validated_issues: list[ValidatedIssue] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating issue #{issue_number}...\")\n            validated_issue = _validate_issue_for_submit(\n                ctx, repo, issue_number, target_branch, force=force\n            )\n            validated_issues.append(validated_issue)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_issues)} issue(s) validated\"\n        )\n        user_output(\"\")\n\n        # Display validated issues\n        for v in validated_issues:\n            user_output(f\"  #{v.number}: {click.style(v.issue.title, fg='yellow')}\")\n        user_output(\"\")\n\n        # Phase 2: Submit all validated issues\n        results = []\n        for i, v in enumerate(validated_issues):\n            if len(validated_issues) > 1:\n                user_output(\n                    f\"--- Submitting issue {i + 1}/{len(validated_issues)}: #{v.number} ---\"\n                )\n            else:\n                user_output(f\"Submitting issue #{v.number}...\")\n            user_output(\"\")\n            result = _submit_single_issue(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n\n    # Success output\n    user_output(\"\")\n    user_output(click.style(\"✓\", fg=\"green\") + f\" {len(results)} issue(s) submitted successfully!\")\n    user_output(\"\")\n    user_output(\"Submitted issues:\")\n    for r in results:\n        user_output(f\"  • #{r.issue_number}: {r.issue_title}\")\n        user_output(f\"    Issue: {r.issue_url}\")\n        if r.pr_url:\n            user_output(f\"    PR: {r.pr_url}\")\n        user_output(f\"    Workflow: {r.workflow_url}\")\n","structuredPatch":[{"oldStart":41,"oldLines":6,"newStart":41,"newLines":7,"lines":[" from erk_shared.gateway.github.pr_footer import build_pr_body_footer"," from erk_shared.gateway.github.types import PRNotFound"," from erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk_shared.naming import generate_issue_branch_name"," from erk_shared.output.output import user_output"," from erk_shared.plan_store.types import PlanNotFound"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"28926137-374b-4d4d-afa2-4c5d87bb8cc1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_018rio13Zk4poPt9sMtTNkxJ","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the `_validate_issue_for_submit` function to use the slug. I need to read the relevant section to find the exact usage:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":400,"cache_read_input_tokens":129464,"cache_creation":{"ephemeral_5m_input_tokens":400,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHE3cu1dZTQtj7xCESm","type":"assistant","uuid":"9da1d006-936c-4656-a727-263af28773a5","timestamp":"2026-02-22T14:40:04.693Z"}
{"parentUuid":"9da1d006-936c-4656-a727-263af28773a5","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_018rio13Zk4poPt9sMtTNkxJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011f8aVysBTZV3VHYzKE6ktM","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","offset":630,"limit":20},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":400,"cache_read_input_tokens":129464,"cache_creation":{"ephemeral_5m_input_tokens":400,"ephemeral_1h_input_tokens":0},"output_tokens":4,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHE3cu1dZTQtj7xCESm","type":"assistant","uuid":"d9eadfc6-5539-4c40-9585-d07cb6fb10b3","timestamp":"2026-02-22T14:40:05.496Z"}
{"parentUuid":"d9eadfc6-5539-4c40-9585-d07cb6fb10b3","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011f8aVysBTZV3VHYzKE6ktM","type":"tool_result","content":"   630→    logger.debug(\"base_branch=%s\", base_branch)\n   631→\n   632→    # Check for existing local branches BEFORE computing new name\n   633→    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n   634→\n   635→    # Compute branch name using canonical naming function\n   636→    objective_id_raw = ctx.plan_backend.get_metadata_field(\n   637→        repo.root, str(issue_number), \"objective_issue\"\n   638→    )\n   639→    objective_id: int | None = None\n   640→    if isinstance(objective_id_raw, int):\n   641→        objective_id = objective_id_raw\n   642→    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n   643→        objective_id = int(objective_id_raw)\n   644→    new_branch_name = generate_issue_branch_name(\n   645→        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n   646→    )\n   647→\n   648→    if existing_branches:\n   649→        chosen = _prompt_existing_branch_action(\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f413998f-54f6-4d54-a23d-3f32756b54a5","timestamp":"2026-02-22T14:40:05.538Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","content":"    logger.debug(\"base_branch=%s\", base_branch)\n\n    # Check for existing local branches BEFORE computing new name\n    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n\n    # Compute branch name using canonical naming function\n    objective_id_raw = ctx.plan_backend.get_metadata_field(\n        repo.root, str(issue_number), \"objective_issue\"\n    )\n    objective_id: int | None = None\n    if isinstance(objective_id_raw, int):\n        objective_id = objective_id_raw\n    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n        objective_id = int(objective_id_raw)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )\n\n    if existing_branches:\n        chosen = _prompt_existing_branch_action(","numLines":20,"startLine":630,"totalLines":1340}}}
{"parentUuid":"f413998f-54f6-4d54-a23d-3f32756b54a5","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01XTfb4CGqg1AFg3p5t8f1fZ","type":"message","role":"assistant","content":[{"type":"text","text":"Now I need to pass the slug through. The `_validate_issue_for_submit` function takes an `ErkContext`, not a `click.Context`. Let me check how to get the prompt executor from `ErkContext`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":540,"cache_read_input_tokens":129864,"cache_creation":{"ephemeral_5m_input_tokens":540,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHEHstt1pYg2vhkXQ6H","type":"assistant","uuid":"2781bbbe-ac85-4149-8f0b-5e9dea9a4f9a","timestamp":"2026-02-22T14:40:08.904Z"}
{"parentUuid":"2781bbbe-ac85-4149-8f0b-5e9dea9a4f9a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01XTfb4CGqg1AFg3p5t8f1fZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LG5wQPqU2cwbggL76vsH56","name":"Grep","input":{"pattern":"prompt_executor","path":"/home/runner/work/erk/erk/src/erk/core/context.py","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":540,"cache_read_input_tokens":129864,"cache_creation":{"ephemeral_5m_input_tokens":540,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHEHstt1pYg2vhkXQ6H","type":"assistant","uuid":"81dba849-3c7c-48f9-9f5b-97e0934f7d93","timestamp":"2026-02-22T14:40:09.864Z"}
{"parentUuid":"81dba849-3c7c-48f9-9f5b-97e0934f7d93","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LG5wQPqU2cwbggL76vsH56","type":"tool_result","content":"19:from erk.core.codex_prompt_executor import CodexPromptExecutor\n21:from erk.core.prompt_executor import ClaudePromptExecutor\n40:from erk_shared.core.prompt_executor import PromptExecutor\n87:def create_prompt_executor(\n127:    from tests.fakes.prompt_executor import FakePromptExecutor\n181:        prompt_executor=FakePromptExecutor(),\n213:    prompt_executor: PromptExecutor | None = None,\n244:        prompt_executor: Optional PromptExecutor. If None, creates FakePromptExecutor.\n256:    from tests.fakes.prompt_executor import FakePromptExecutor\n373:    if prompt_executor is None:\n374:        prompt_executor = FakePromptExecutor()\n422:        prompt_executor=prompt_executor,\n643:    prompt_executor = create_prompt_executor(\n676:        prompt_executor=prompt_executor,"}]},"uuid":"a7d67284-acf3-45a1-9b2e-073897ee3d1a","timestamp":"2026-02-22T14:40:10.289Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"19:from erk.core.codex_prompt_executor import CodexPromptExecutor\n21:from erk.core.prompt_executor import ClaudePromptExecutor\n40:from erk_shared.core.prompt_executor import PromptExecutor\n87:def create_prompt_executor(\n127:    from tests.fakes.prompt_executor import FakePromptExecutor\n181:        prompt_executor=FakePromptExecutor(),\n213:    prompt_executor: PromptExecutor | None = None,\n244:        prompt_executor: Optional PromptExecutor. If None, creates FakePromptExecutor.\n256:    from tests.fakes.prompt_executor import FakePromptExecutor\n373:    if prompt_executor is None:\n374:        prompt_executor = FakePromptExecutor()\n422:        prompt_executor=prompt_executor,\n643:    prompt_executor = create_prompt_executor(\n676:        prompt_executor=prompt_executor,","numLines":14}}
{"parentUuid":"a7d67284-acf3-45a1-9b2e-073897ee3d1a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Lhnijx3dosZhn3AWS7EqKH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FHytPHXMmW1Pw7eaHB9JgW","name":"Grep","input":{"pattern":"class ErkContext","path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context","output_mode":"content","-A":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":601,"cache_read_input_tokens":130404,"cache_creation":{"ephemeral_5m_input_tokens":601,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHEmV4vvYCUNAdfUvmm","type":"assistant","uuid":"34ba98d7-ec2d-4765-a0bf-868dfae7990a","timestamp":"2026-02-22T14:40:16.275Z"}
{"parentUuid":"34ba98d7-ec2d-4765-a0bf-868dfae7990a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FHytPHXMmW1Pw7eaHB9JgW","type":"tool_result","content":"packages/erk-shared/src/erk_shared/context/context.py:57:class ErkContext:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-58-    \"\"\"Immutable context holding all dependencies for erk and erk-kits operations.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-59-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-60-    Created at CLI entry point and threaded through the application via Click's\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-61-    context system. Frozen to prevent accidental modification at runtime.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-62-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-63-    This unified context combines functionality that was previously split across\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-64-    multiple context types (erk.core.context.ErkContext and erk_kits.context).\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-65-\npackages/erk-shared/src/erk_shared/context/context.py-66-    Note:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-67-    - global_config may be None only during init command before config is created.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-68-      All other commands should have a valid GlobalConfig.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-69-\npackages/erk-shared/src/erk_shared/context/context.py-70-    Field naming conventions:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-71-    - github_issues property -> issues (renamed for consistency)\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-72-    - repo_root property -> repo.root (access via repo property or require_repo_root helper)\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-73-    \"\"\"\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-74-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-75-    # Gateway integrations (from erk_shared)\npackages/erk-shared/src/erk_shared/context/context.py-76-    git: Git  # Note: branch ops accessed via git.branch subgateway\npackages/erk-shared/src/erk_shared/context/context.py-77-    github: GitHub  # Note: issues accessed via github.issues property\npackages/erk-shared/src/erk_shared/context/context.py-78-    github_admin: GitHubAdmin  # GitHub Actions admin operations\npackages/erk-shared/src/erk_shared/context/context.py-79-    graphite: Graphite\npackages/erk-shared/src/erk_shared/context/context.py-80-    graphite_branch_ops: GraphiteBranchOps | None  # None when Graphite disabled\npackages/erk-shared/src/erk_shared/context/context.py-81-    console: Console  # TTY detection, user feedback, and confirmation prompts\npackages/erk-shared/src/erk_shared/context/context.py-82-    time: Time\npackages/erk-shared/src/erk_shared/context/context.py-83-    erk_installation: ErkInstallation  # ~/.erk/ installation data (config, pool state)\npackages/erk-shared/src/erk_shared/context/context.py-84-    claude_installation: ClaudeInstallation  # ~/.claude/ installation data (sessions, settings)\npackages/erk-shared/src/erk_shared/context/context.py-85-    agent_docs: AgentDocs  # docs/learned/ file access\npackages/erk-shared/src/erk_shared/context/context.py-86-    plan_store: PlanStore\npackages/erk-shared/src/erk_shared/context/context.py-87-    prompt_executor: PromptExecutor"}]},"uuid":"f403f19e-b570-4406-b898-5e0e2437595d","timestamp":"2026-02-22T14:40:16.861Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"packages/erk-shared/src/erk_shared/context/context.py:57:class ErkContext:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-58-    \"\"\"Immutable context holding all dependencies for erk and erk-kits operations.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-59-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-60-    Created at CLI entry point and threaded through the application via Click's\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-61-    context system. Frozen to prevent accidental modification at runtime.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-62-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-63-    This unified context combines functionality that was previously split across\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-64-    multiple context types (erk.core.context.ErkContext and erk_kits.context).\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-65-\npackages/erk-shared/src/erk_shared/context/context.py-66-    Note:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-67-    - global_config may be None only during init command before config is created.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-68-      All other commands should have a valid GlobalConfig.\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-69-\npackages/erk-shared/src/erk_shared/context/context.py-70-    Field naming conventions:\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-71-    - github_issues property -> issues (renamed for consistency)\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-72-    - repo_root property -> repo.root (access via repo property or require_repo_root helper)\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-73-    \"\"\"\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-74-\n/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/context.py-75-    # Gateway integrations (from erk_shared)\npackages/erk-shared/src/erk_shared/context/context.py-76-    git: Git  # Note: branch ops accessed via git.branch subgateway\npackages/erk-shared/src/erk_shared/context/context.py-77-    github: GitHub  # Note: issues accessed via github.issues property\npackages/erk-shared/src/erk_shared/context/context.py-78-    github_admin: GitHubAdmin  # GitHub Actions admin operations\npackages/erk-shared/src/erk_shared/context/context.py-79-    graphite: Graphite\npackages/erk-shared/src/erk_shared/context/context.py-80-    graphite_branch_ops: GraphiteBranchOps | None  # None when Graphite disabled\npackages/erk-shared/src/erk_shared/context/context.py-81-    console: Console  # TTY detection, user feedback, and confirmation prompts\npackages/erk-shared/src/erk_shared/context/context.py-82-    time: Time\npackages/erk-shared/src/erk_shared/context/context.py-83-    erk_installation: ErkInstallation  # ~/.erk/ installation data (config, pool state)\npackages/erk-shared/src/erk_shared/context/context.py-84-    claude_installation: ClaudeInstallation  # ~/.claude/ installation data (sessions, settings)\npackages/erk-shared/src/erk_shared/context/context.py-85-    agent_docs: AgentDocs  # docs/learned/ file access\npackages/erk-shared/src/erk_shared/context/context.py-86-    plan_store: PlanStore\npackages/erk-shared/src/erk_shared/context/context.py-87-    prompt_executor: PromptExecutor","numLines":31}}
{"parentUuid":"f403f19e-b570-4406-b898-5e0e2437595d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NqF37qcC96AjwDHEeUUNVH","type":"message","role":"assistant","content":[{"type":"text","text":"`ErkContext` has a `prompt_executor` field directly. Now update the submit.py call site:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1427,"cache_read_input_tokens":131005,"cache_creation":{"ephemeral_5m_input_tokens":1427,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHF8Hxe3gFvNoJpLf1X","type":"assistant","uuid":"5319605c-f838-492f-9248-13f740c4e176","timestamp":"2026-02-22T14:40:20.195Z"}
{"parentUuid":"5319605c-f838-492f-9248-13f740c4e176","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01NqF37qcC96AjwDHEeUUNVH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TE42GXGYzC2vE1pda6BLFk","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","old_string":"    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )","new_string":"    slug = generate_slug_or_fallback(ctx.prompt_executor, issue.title)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, slug, ctx.time.now(), objective_id=objective_id\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1427,"cache_read_input_tokens":131005,"cache_creation":{"ephemeral_5m_input_tokens":1427,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHF8Hxe3gFvNoJpLf1X","type":"assistant","uuid":"5ab89a81-7ec6-4c8c-966a-0708819eecda","timestamp":"2026-02-22T14:40:21.712Z"}
{"parentUuid":"5ab89a81-7ec6-4c8c-966a-0708819eecda","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TE42GXGYzC2vE1pda6BLFk","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/submit.py has been updated successfully."}]},"uuid":"021c2d3f-e271-4ffd-ae7b-f114ad6acce1","timestamp":"2026-02-22T14:40:22.393Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","oldString":"    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )","newString":"    slug = generate_slug_or_fallback(ctx.prompt_executor, issue.title)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, slug, ctx.time.now(), objective_id=objective_id\n    )","originalFile":"\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n\nimport logging\nimport tomllib\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,\n    worker_impl_folder_exists,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _format_issue_ref(issue_number: int, plans_repo: str | None) -> str:\n    \"\"\"Format issue reference for PR body.\n\n    Args:\n        issue_number: The issue number\n        plans_repo: Target repo in \"owner/repo\" format, or None for same repo\n\n    Returns:\n        \"#N\" for same-repo, \"owner/repo#N\" for cross-repo\n    \"\"\"\n    if plans_repo is None:\n        return f\"#{issue_number}\"\n    return f\"{plans_repo}#{issue_number}\"\n\n\n@contextmanager\ndef branch_rollback(ctx: ErkContext, repo_root: Path, original_branch: str) -> Iterator[None]:\n    \"\"\"Context manager that restores original branch on exception.\n\n    On success, does nothing (caller handles cleanup).\n    On exception, checks out original_branch and re-raises.\n    \"\"\"\n    try:\n        yield\n    except Exception:\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + \"Operation failed, restoring original branch...\"\n        )\n        ctx.branch_manager.checkout_branch(repo_root, original_branch)\n        raise\n\n\ndef is_issue_learn_plan(labels: list[str]) -> bool:\n    \"\"\"Check if an issue is a learn plan by checking for erk-learn label.\n\n    Args:\n        labels: The issue's labels\n\n    Returns:\n        True if the issue has the erk-learn label, False otherwise\n    \"\"\"\n    return \"erk-learn\" in labels\n\n\ndef _find_existing_branches_for_issue(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n) -> list[str]:\n    \"\"\"Find local branches matching P{issue_number}-* pattern.\"\"\"\n    local_branches = ctx.git.branch.list_local_branches(repo_root)\n    prefix = f\"P{issue_number}-\"\n    return sorted([b for b in local_branches if b.startswith(prefix)])\n\n\ndef _prompt_existing_branch_action(\n    ctx: ErkContext,\n    repo_root: Path,\n    existing_branches: list[str],\n    new_branch_name: str,\n    *,\n    force: bool,\n) -> str | None:\n    \"\"\"Prompt user to decide what to do with existing branch(es).\n\n    Args:\n        ctx: ErkContext with git operations\n        repo_root: Repository root path\n        existing_branches: List of existing branch names matching the issue pattern\n        new_branch_name: Name for new branch if creating fresh\n        force: If True, delete existing branches without prompting\n\n    Returns:\n        - Branch name to use (existing branch)\n        - None to signal \"create new\" (after deleting existing)\n    \"\"\"\n    if force:\n        user_output(f\"\\nDeleting {len(existing_branches)} existing branch(es) (--force mode):\")\n        for branch in existing_branches:\n            ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n            user_output(f\"  Deleted: {branch}\")\n        return None  # Signal \"create new branch\"\n\n    user_output(\"\\nFound existing local branch(es) for this issue:\")\n    for branch in existing_branches:\n        user_output(f\"  • {branch}\")\n    user_output(f\"\\nNew branch would be: {click.style(new_branch_name, fg='cyan')}\")\n    user_output(\"\")\n\n    # Use newest branch (latest timestamp = last alphabetically)\n    branch_to_use = existing_branches[-1]\n\n    # Single binary prompt\n    reuse = ctx.console.confirm(\n        f\"Reuse existing branch '{branch_to_use}'? \"\n        \"If not, a new branch and PR will be created (old draft PR will be closed)\",\n        default=True,\n    )\n\n    if reuse:\n        return branch_to_use\n\n    # Delete existing branches and signal \"create new\"\n    for branch in existing_branches:\n        ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n        user_output(f\"Deleted branch: {branch}\")\n    return None\n\n\ndef get_learn_plan_parent_branch(ctx: ErkContext, repo_root: Path, plan_id: str) -> str | None:\n    \"\"\"Get the parent branch for a learn plan.\n\n    Learn plans should stack on their parent plan's branch.\n    Extracts learned_from_issue via plan_backend, fetches parent's branch_name.\n\n    Args:\n        ctx: ErkContext with plan_backend\n        repo_root: Repository root path\n        plan_id: Plan identifier\n\n    Returns:\n        Parent plan's branch_name if found, None otherwise\n    \"\"\"\n    learned_from = ctx.plan_backend.get_metadata_field(repo_root, plan_id, \"learned_from_issue\")\n    if isinstance(learned_from, PlanNotFound) or learned_from is None:\n        return None\n\n    branch_name = ctx.plan_backend.get_metadata_field(repo_root, str(learned_from), \"branch_name\")\n    if isinstance(branch_name, PlanNotFound) or branch_name is None:\n        return None\n    return str(branch_name)\n\n\ndef load_workflow_config(repo_root: Path, workflow_name: str) -> dict[str, str]:\n    \"\"\"Load workflow config from .erk/config.toml [workflows.<name>] section.\n\n    Args:\n        repo_root: Repository root path\n        workflow_name: Workflow filename (with or without .yml/.yaml extension).\n            Only the basename is used for config lookup.\n\n    Returns:\n        Dict of string key-value pairs for workflow inputs.\n        Returns empty dict if config file or section doesn't exist.\n\n    Example:\n        For workflow_name=\"plan-implement.yml\", reads from:\n        .erk/config.toml -> [workflows.plan-implement] section\n    \"\"\"\n    config_path = repo_root / \".erk\" / \"config.toml\"\n\n    if not config_path.exists():\n        return {}\n\n    with open(config_path, \"rb\") as f:\n        data = tomllib.load(f)\n\n    # Extract basename and strip .yml/.yaml extension\n    basename = Path(workflow_name).name\n    config_name = basename.removesuffix(\".yml\").removesuffix(\".yaml\")\n\n    # Get [workflows.<name>] section\n    workflows_section = data.get(\"workflows\", {})\n    workflow_config = workflows_section.get(config_name, {})\n\n    # Convert all values to strings (workflow inputs are always strings)\n    return {k: str(v) for k, v in workflow_config.items()}\n\n\n@dataclass(frozen=True)\nclass ValidatedIssue:\n    \"\"\"Issue that passed all validation checks.\"\"\"\n\n    number: int\n    issue: IssueInfo\n    branch_name: str\n    branch_exists: bool\n    pr_number: int | None\n    is_learn_origin: bool\n\n\n@dataclass(frozen=True)\nclass SubmitResult:\n    \"\"\"Result of submitting a single issue.\"\"\"\n\n    issue_number: int\n    issue_title: str\n    issue_url: str\n    pr_number: int | None\n    pr_url: str | None\n    workflow_run_id: str\n    workflow_url: str\n\n\ndef _build_workflow_run_url(issue_url: str, run_id: str) -> str:\n    \"\"\"Construct GitHub Actions workflow run URL from issue URL and run ID.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        run_id: Workflow run ID\n\n    Returns:\n        Workflow run URL (e.g., https://github.com/owner/repo/actions/runs/1234567890)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_workflow_run_url(owner, repo, run_id)\n    return f\"https://github.com/actions/runs/{run_id}\"\n\n\ndef _strip_plan_markers(title: str) -> str:\n    \"\"\"Strip '[erk-plan]' prefix and 'Plan:' prefix from issue title for use as PR title.\"\"\"\n    result = title\n    # Strip \"[erk-plan] \" prefix if present\n    if result.startswith(ERK_PLAN_TITLE_PREFIX):\n        result = result[len(ERK_PLAN_TITLE_PREFIX) :]\n    # Strip \"Plan: \" prefix if present\n    if result.startswith(PLAN_HEADING_PREFIX):\n        result = result[len(PLAN_HEADING_PREFIX) :]\n    return result\n\n\ndef _add_planned_prefix(title: str) -> str:\n    \"\"\"Prepend 'planned/' prefix to PR title (idempotent).\n\n    Args:\n        title: The PR title to prefix\n\n    Returns:\n        The title with 'planned/' prefix, skipping if already prefixed\n    \"\"\"\n    if title.startswith(PLANNED_PR_TITLE_PREFIX):\n        return title\n    return f\"{PLANNED_PR_TITLE_PREFIX}{title}\"\n\n\ndef _build_pr_url(issue_url: str, pr_number: int) -> str:\n    \"\"\"Construct GitHub PR URL from issue URL and PR number.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        pr_number: PR number\n\n    Returns:\n        PR URL (e.g., https://github.com/owner/repo/pull/456)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_pr_url(owner, repo, pr_number)\n    return f\"https://github.com/pull/{pr_number}\"\n\n\ndef _close_orphaned_draft_prs(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n    keep_pr_number: int,\n) -> list[int]:\n    \"\"\"Close old draft PRs linked to an issue, keeping the specified one.\n\n    Returns list of PR numbers that were closed.\n    \"\"\"\n    linked_prs = ctx.issues.get_prs_referencing_issue(repo_root, issue_number)\n\n    closed_prs: list[int] = []\n    for pr in linked_prs:\n        # Close orphaned drafts: draft PRs that are OPEN and not the one we just created\n        # Any draft PR linked to an erk-plan issue is fair game to close\n        if pr.is_draft and pr.state == \"OPEN\" and pr.number != keep_pr_number:\n            ctx.github.close_pr(repo_root, pr.number)\n            closed_prs.append(pr.number)\n\n    return closed_prs\n\n\n@dataclass(frozen=True)\nclass ValidatedDraftPR:\n    \"\"\"Draft PR that passed all validation checks.\"\"\"\n\n    number: int\n    title: str\n    url: str\n    branch_name: str\n\n\ndef _validate_draft_pr_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    plan_number: int,\n) -> ValidatedDraftPR:\n    \"\"\"Validate a draft PR plan for submission.\n\n    Fetches the PR, validates it has the erk-plan label and is OPEN.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        plan_number: PR number to validate\n\n    Raises:\n        SystemExit: If PR doesn't exist, missing label, or not OPEN.\n    \"\"\"\n    pr_result = ctx.github.get_pr(repo.root, plan_number)\n    if isinstance(pr_result, PRNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in pr_result.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"PR #{plan_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if pr_result.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} is {pr_result.state}\\n\\n\"\n            \"Cannot submit closed PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    return ValidatedDraftPR(\n        number=plan_number,\n        title=pr_result.title,\n        url=pr_result.url,\n        branch_name=pr_result.head_ref_name,\n    )\n\n\ndef _submit_draft_pr_plan(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedDraftPR,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a validated draft-PR plan for implementation.\n\n    For draft-PR plans, the branch and PR already exist. This function:\n    - Fetches and checks out the existing plan branch\n    - Creates .worker-impl/ with provider=\"github-draft-pr\"\n    - Commits and pushes .worker-impl/ to existing branch\n    - Triggers the workflow with plan_backend=\"draft_pr\"\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated draft PR information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    plan_number = validated.number\n    branch_name = validated.branch_name\n\n    # Fetch plan content via PlanBackend\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(plan_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number}: plan content not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Fetch and checkout the existing plan branch\n    user_output(f\"Checking out existing plan branch: {click.style(branch_name, fg='cyan')}\")\n    ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n    local_branches = ctx.git.branch.list_local_branches(repo.root)\n    if branch_name not in local_branches:\n        remote_ref = f\"origin/{branch_name}\"\n        ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Sync local branch with remote (may be behind from prior submission or CI)\n    pull_result = ctx.git.remote.pull_rebase(repo.root, \"origin\", branch_name)\n    if isinstance(pull_result, PullRebaseError):\n        raise UserFacingCliError(\n            f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n        )\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    # Create .worker-impl/ with draft-PR provider\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(plan_number),\n        url=validated.url,\n        repo_root=repo.root,\n        provider=\"github-draft-pr\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for PR #{plan_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=False, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Switch back to original branch\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Build inputs dict with plan_backend=\"draft_pr\"\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n\n    inputs = {\n        \"plan_id\": str(plan_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": validated.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(plan_number),\n        \"base_branch\": base_branch,\n        \"plan_backend\": \"draft_pr\",\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL\n    workflow_url = _build_workflow_run_url(validated.url, run_id)\n\n    # Write dispatch metadata FIRST (before any PR body modification)\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=plan_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    # Update PR body with workflow run link (best-effort)\n    # Guard: only append if body is non-empty to avoid overwriting metadata block\n    try:\n        pr_details = ctx.github.get_pr(repo.root, plan_number)\n        if not isinstance(pr_details, PRNotFound) and pr_details.body:\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, plan_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Post queued event comment via PlanBackend\n    try:\n        validation_results = {\n            \"pr_is_open\": True,\n            \"has_erk_plan_label\": True,\n        }\n\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=plan_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Plan Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Plan submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.plan_backend.add_comment(repo.root, str(plan_number), comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(validated.url, plan_number)\n\n    return SubmitResult(\n        issue_number=plan_number,\n        issue_title=validated.title,\n        issue_url=validated.url,\n        pr_number=plan_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\ndef _validate_issue_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    issue_number: int,\n    base_branch: str,\n    *,\n    force: bool,\n) -> ValidatedIssue:\n    \"\"\"Validate a single issue for submission.\n\n    Fetches the issue, validates constraints, derives branch name, and checks\n    if branch/PR already exist.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        issue_number: GitHub issue number to validate\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Raises:\n        SystemExit: If issue doesn't exist, missing label, or closed.\n    \"\"\"\n    # Fetch issue from GitHub\n    issue = ctx.issues.get_issue(repo.root, issue_number)\n    if isinstance(issue, IssueNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue.issue_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in issue.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"Issue #{issue_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan issues for automated implementation.\\n\"\n            \"To create a plan, use Plan Mode then /erk:plan-save\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if issue.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} is {issue.state}\\n\\n\"\n            \"Cannot submit closed issues for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Use provided base_branch instead of detecting trunk\n    logger.debug(\"base_branch=%s\", base_branch)\n\n    # Check for existing local branches BEFORE computing new name\n    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n\n    # Compute branch name using canonical naming function\n    objective_id_raw = ctx.plan_backend.get_metadata_field(\n        repo.root, str(issue_number), \"objective_issue\"\n    )\n    objective_id: int | None = None\n    if isinstance(objective_id_raw, int):\n        objective_id = objective_id_raw\n    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n        objective_id = int(objective_id_raw)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, issue.title, ctx.time.now(), objective_id=objective_id\n    )\n\n    if existing_branches:\n        chosen = _prompt_existing_branch_action(\n            ctx, repo.root, existing_branches, new_branch_name, force=force\n        )\n        branch_name = chosen if chosen is not None else new_branch_name\n    else:\n        branch_name = new_branch_name\n\n    logger.debug(\"branch_name=%s\", branch_name)\n    user_output(f\"Computed branch: {click.style(branch_name, fg='cyan')}\")\n\n    # Check if branch already exists on remote and has a PR\n    branch_exists = ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", branch_name)\n    logger.debug(\"branch_exists_on_remote(%s)=%s\", branch_name, branch_exists)\n\n    pr_number: int | None = None\n    if branch_exists:\n        pr_details = ctx.github.get_pr_for_branch(repo.root, branch_name)\n        if not isinstance(pr_details, PRNotFound):\n            pr_number = pr_details.number\n\n    # Check if this issue is a learn plan\n    is_learn_origin = is_issue_learn_plan(issue.labels)\n\n    return ValidatedIssue(\n        number=issue_number,\n        issue=issue,\n        branch_name=branch_name,\n        branch_exists=branch_exists,\n        pr_number=pr_number,\n        is_learn_origin=is_learn_origin,\n    )\n\n\ndef _create_branch_and_pr(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    branch_name: str,\n    base_branch: str,\n    submitted_by: str,\n    original_branch: str,\n) -> int:\n    \"\"\"Create branch, commit, push, and create draft PR.\n\n    This function is called within the branch_rollback context manager.\n    On any exception, the context manager will restore the original branch.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        branch_name: Name of branch to create\n        base_branch: Base branch for PR\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (for cleanup on success)\n\n    Returns:\n        PR number of the created draft PR.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Get plan content and create .worker-impl/ folder\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(issue_number),\n        url=issue.url,\n        repo_root=repo.root,\n        provider=\"github\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for issue #{issue_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Create draft PR\n    # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n    # MUST be in the initial body passed to create_pr(), NOT added via update.\n    # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n    # updated when the body is edited afterward.\n    user_output(\"Creating draft PR...\")\n    plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n    issue_ref = _format_issue_ref(issue_number, plans_repo)\n    pr_body = (\n        f\"**Author:** @{submitted_by}\\n\"\n        f\"**Plan:** {issue_ref}\\n\\n\"\n        f\"**Status:** Queued for implementation\\n\\n\"\n        f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n        f\"## Implementation Plan\\n\\n\"\n        f\"<details>\\n\"\n        f\"<summary><strong>Implementation Plan</strong> (Issue #{issue_number})</summary>\\n\\n\"\n        f\"{plan.body}\\n\\n\"\n        f\"</details>\\n\\n\"\n        f\"---\\n\\n\"\n        f\"Closes {issue_ref}\"\n    )\n    pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n    pr_number = ctx.github.create_pr(\n        repo_root=repo.root,\n        branch=branch_name,\n        title=pr_title,\n        body=pr_body,\n        base=base_branch,\n        draft=True,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n    # Update PR body with checkout command footer\n    footer = build_pr_body_footer(\n        pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n    )\n    ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n    # Add extraction skip label if this is a learn plan\n    if validated.is_learn_origin:\n        ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n        # FUTURE ENHANCEMENT: When a learn plan issue gets a PR, update the parent\n        # plan's learn_status from \"completed_with_plan\" to track the PR number.\n        # Currently, the parent only gets updated when the learn plan's PR lands\n        # (in land_cmd._update_parent_learn_status_if_learn_plan). Adding an\n        # intermediate state here would let the TUI show the PR number (e.g.,\n        # \"🚧 #5514\") instead of the learn plan issue number (e.g., \"#5508\")\n        # while the PR is still in review.\n        # See: LearnStatusValue in erk_shared/github/metadata/schemas.py\n\n    # Link PR with Graphite (if enabled)\n    if ctx.branch_manager.is_graphite_managed():\n        user_output(\"Linking PR with Graphite...\")\n        submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n        if isinstance(submit_result, SubmitBranchError):\n            user_output(\n                click.style(\"✗\", fg=\"red\")\n                + f\" Failed to link PR with Graphite: {submit_result.message}\"\n            )\n        else:\n            user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n    # Close any orphaned draft PRs for this issue\n    closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n    if closed_prs:\n        user_output(\n            click.style(\"✓\", fg=\"green\")\n            + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n            + \", \".join(f\"#{n}\" for n in closed_prs)\n        )\n\n    # Switch back to original branch (keep the new branch for Graphite lineage)\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    return pr_number\n\n\ndef _submit_single_issue(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a single validated issue for implementation.\n\n    Creates branch/PR if needed and triggers workflow.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n    branch_name = validated.branch_name\n    branch_exists = validated.branch_exists\n    pr_number = validated.pr_number\n\n    if branch_exists:\n        if pr_number is not None:\n            user_output(\n                f\"PR #{pr_number} already exists for branch '{branch_name}' (state: existing)\"\n            )\n            user_output(\"Skipping branch/PR creation, triggering workflow...\")\n        else:\n            # Branch exists but no PR - need to add a commit for PR creation\n            user_output(f\"Branch '{branch_name}' exists but no PR. Adding placeholder commit...\")\n\n            # Fetch and checkout the remote branch locally\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n            # Only create tracking branch if it doesn't exist locally (LBYL)\n            local_branches = ctx.git.branch.list_local_branches(repo.root)\n            if branch_name not in local_branches:\n                remote_ref = f\"origin/{branch_name}\"\n                ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Create empty commit as placeholder for PR creation\n            ctx.git.commit.commit(\n                repo.root,\n                f\"[erk-plan] Initialize implementation for issue #{issue_number}\",\n            )\n            push_result = ctx.git.remote.push_to_remote(\n                repo.root, \"origin\", branch_name, set_upstream=False, force=False\n            )\n            if isinstance(push_result, PushError):\n                raise UserFacingCliError(push_result.message)\n            user_output(click.style(\"✓\", fg=\"green\") + \" Placeholder commit pushed\")\n\n            # Now create the PR\n            # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n            # MUST be in the initial body passed to create_pr(), NOT added via update.\n            # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n            # updated when the body is edited afterward.\n            plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n            issue_ref = _format_issue_ref(issue_number, plans_repo)\n            pr_body = (\n                f\"**Author:** @{submitted_by}\\n\"\n                f\"**Plan:** {issue_ref}\\n\\n\"\n                f\"**Status:** Queued for implementation\\n\\n\"\n                f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n                f\"---\\n\\n\"\n                f\"Closes {issue_ref}\"\n            )\n            pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n            pr_number = ctx.github.create_pr(\n                repo_root=repo.root,\n                branch=branch_name,\n                title=pr_title,\n                body=pr_body,\n                base=base_branch,\n                draft=True,\n            )\n            user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n            # Update PR body with checkout command footer\n            footer = build_pr_body_footer(\n                pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n            # Add extraction skip label if this is a learn plan\n            if validated.is_learn_origin:\n                ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n                # FUTURE ENHANCEMENT: See comment in _create_branch_and_pr for\n                # updating parent plan's learn_status when learn plan gets a PR.\n\n            # Link PR with Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                user_output(\"Linking PR with Graphite...\")\n                submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n                if isinstance(submit_result, SubmitBranchError):\n                    user_output(\n                        click.style(\"✗\", fg=\"red\")\n                        + f\" Failed to link PR with Graphite: {submit_result.message}\"\n                    )\n                else:\n                    user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n            # Close any orphaned draft PRs\n            closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n            if closed_prs:\n                user_output(\n                    click.style(\"✓\", fg=\"green\")\n                    + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n                    + \", \".join(f\"#{n}\" for n in closed_prs)\n                )\n\n            # Switch back to original branch (keep the new branch for Graphite lineage)\n            ctx.branch_manager.checkout_branch(repo.root, original_branch)\n    else:\n        # Check if branch exists locally (user chose to reuse existing)\n        local_branches = ctx.git.branch.list_local_branches(repo.root)\n        branch_exists_locally = branch_name in local_branches\n\n        if branch_exists_locally:\n            # Reuse existing local branch\n            user_output(f\"Using existing local branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Track in Graphite if not already tracked\n            if ctx.branch_manager.is_graphite_managed():\n                if not ctx.graphite.is_branch_tracked(repo.root, branch_name):\n                    ctx.branch_manager.track_branch(repo.root, branch_name, base_branch)\n                    user_output(click.style(\"✓\", fg=\"green\") + \" Branch tracked in Graphite\")\n\n            # Checkout existing branch\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n        else:\n            # Create new branch\n            user_output(f\"Creating branch from origin/{base_branch}...\")\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", base_branch)\n\n            # Verify parent is tracked by Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                parent_branch = base_branch.removeprefix(\"origin/\")\n                if not ctx.graphite.is_branch_tracked(repo.root, parent_branch):\n                    msg = (\n                        f\"Cannot stack on branch '{parent_branch}' - \"\n                        f\"it's not tracked by Graphite.\\n\\n\"\n                        f\"To fix this:\\n\"\n                        f\"  1. gt checkout {parent_branch}\\n\"\n                        f\"  2. gt track --parent <parent-branch>\\n\\n\"\n                        f\"Then retry your command.\"\n                    )\n                    user_output(click.style(\"Error: \", fg=\"red\") + msg)\n                    raise SystemExit(1)\n\n            create_result = ctx.branch_manager.create_branch(\n                repo.root, branch_name, f\"origin/{base_branch}\"\n            )\n            if isinstance(create_result, BranchAlreadyExists):\n                user_output(click.style(\"Error: \", fg=\"red\") + create_result.message)\n                raise SystemExit(1) from None\n            user_output(f\"Created branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Validate pr_number is set before workflow dispatch\n    if pr_number is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Failed to create or find PR. Cannot trigger workflow.\"\n        )\n        raise SystemExit(1)\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Trigger workflow via direct dispatch\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n    user_output(f\"  Display name: {DISPATCH_WORKFLOW_METADATA_NAME}\")\n\n    # Build inputs dict, merging workflow config\n    inputs = {\n        # Required inputs (always passed)\n        \"plan_id\": str(issue_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": issue.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"base_branch\": base_branch,\n        # Config-based inputs (from .erk/workflows/)\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL once (used for PR body update, queued comment, and result)\n    workflow_url = _build_workflow_run_url(issue.url, run_id)\n\n    # Update PR body with workflow run link (best-effort)\n    try:\n        pr_details = ctx.github.get_pr(repo.root, pr_number)\n        if not isinstance(pr_details, PRNotFound):\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, pr_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata synchronously to fix race condition with erk dash\n    # This ensures the issue body has the run info before we return to the user\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=issue_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written to issue\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    validation_results = {\n        \"issue_is_open\": True,\n        \"has_erk_plan_label\": True,\n    }\n\n    # Create and post queued event comment\n    try:\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=issue_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Issue Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Issue submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\\n\\n\"\n                f\"Branch and draft PR were created locally for correct commit attribution.\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.issues.add_comment(repo.root, issue_number, comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(issue.url, pr_number) if pr_number else None\n\n    return SubmitResult(\n        issue_number=issue_number,\n        issue_title=issue.title,\n        issue_url=issue.url,\n        pr_number=pr_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\n@click.command(\"submit\")\n@click.argument(\"issue_numbers\", type=int, nargs=-1, required=True)\n@click.option(\n    \"--base\",\n    type=str,\n    default=None,\n    help=\"Base branch for PR (defaults to current branch).\",\n)\n@click.option(\n    \"-f\",\n    \"--force\",\n    is_flag=True,\n    help=\"Delete existing branches and create fresh without prompting.\",\n)\n@click.pass_obj\ndef submit_cmd(\n    ctx: ErkContext, issue_numbers: tuple[int, ...], base: str | None, force: bool\n) -> None:\n    \"\"\"Submit issues for remote AI implementation via GitHub Actions.\n\n    Creates branch and draft PR locally (for correct commit attribution),\n    then triggers the dispatch-erk-queue.yml GitHub Actions workflow.\n\n    Arguments:\n        ISSUE_NUMBERS: One or more GitHub issue numbers to submit\n\n    Example:\n        erk plan submit 123\n        erk plan submit 123 456 789\n        erk plan submit 123 --base master\n\n    Requires:\n        - All issues must have erk-plan label\n        - All issues must be OPEN\n        - Working directory must be clean (no uncommitted changes)\n    \"\"\"\n    # Validate GitHub CLI prerequisites upfront (LBYL)\n    Ensure.gh_authenticated(ctx)\n\n    # Get repository context\n    if isinstance(ctx.repo, RepoContext):\n        repo = ctx.repo\n    else:\n        repo = discover_repo_context(ctx, ctx.cwd)\n\n    # Ensure trunk is synced before any operations\n    ensure_trunk_synced(ctx, repo)\n\n    # Save current state (needed for both default base and restoration)\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Validate base branch if provided, otherwise default to current branch (LBYL)\n    if base is not None:\n        if not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", base):\n            user_output(\n                click.style(\"Error: \", fg=\"red\") + f\"Base branch '{base}' does not exist on remote\"\n            )\n            raise SystemExit(1)\n        target_branch = base\n    else:\n        # If on a placeholder branch (local-only), use trunk as base\n        if is_placeholder_branch(original_branch):\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        elif not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", original_branch):\n            # Current branch not pushed to remote - fall back to trunk\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        else:\n            target_branch = original_branch\n\n    # For single-issue learn plan submissions, auto-detect parent branch\n    issue_number = issue_numbers[0] if len(issue_numbers) == 1 else None\n    if (\n        issue_number is not None\n        and base is None\n        and ctx.issues.issue_exists(repo.root, issue_number)\n    ):\n        issue = ctx.issues.get_issue(repo.root, issue_number)\n        # issue_exists check above ensures this won't be IssueNotFound\n        if not isinstance(issue, IssueNotFound) and is_issue_learn_plan(issue.labels):\n            parent_branch = get_learn_plan_parent_branch(ctx, repo.root, str(issue_number))\n            if parent_branch is not None and ctx.git.branch.branch_exists_on_remote(\n                repo.root, \"origin\", parent_branch\n            ):\n                target_branch = parent_branch\n                user_output(\n                    f\"Learn plan detected, stacking on parent branch: \"\n                    f\"{click.style(parent_branch, fg='cyan')}\"\n                )\n            elif parent_branch is not None:\n                user_output(\n                    click.style(\"Warning: \", fg=\"yellow\")\n                    + f\"Parent branch '{parent_branch}' not on remote, using trunk\"\n                )\n\n    # Get GitHub username (authentication already validated)\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect draft-PR backend\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    if is_draft_pr:\n        # Draft-PR path: branch and PR already exist, just validate and trigger workflow\n        user_output(f\"Validating {len(issue_numbers)} draft-PR plan(s)...\")\n        user_output(\"\")\n\n        validated_draft_prs: list[ValidatedDraftPR] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating PR #{issue_number}...\")\n            validated_pr = _validate_draft_pr_for_submit(ctx, repo, issue_number)\n            validated_draft_prs.append(validated_pr)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_draft_prs)} plan(s) validated\"\n        )\n        user_output(\"\")\n\n        for v in validated_draft_prs:\n            user_output(f\"  #{v.number}: {click.style(v.title, fg='yellow')}\")\n        user_output(\"\")\n\n        results: list[SubmitResult] = []\n        for i, v in enumerate(validated_draft_prs):\n            if len(validated_draft_prs) > 1:\n                count = len(validated_draft_prs)\n                user_output(f\"--- Submitting PR {i + 1}/{count}: #{v.number} ---\")\n            else:\n                user_output(f\"Submitting PR #{v.number}...\")\n            user_output(\"\")\n            result = _submit_draft_pr_plan(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n    else:\n        # Issue-based path: existing flow\n        # Phase 1: Validate ALL issues upfront (atomic - fail fast before any side effects)\n        user_output(f\"Validating {len(issue_numbers)} issue(s)...\")\n        user_output(\"\")\n\n        validated_issues: list[ValidatedIssue] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating issue #{issue_number}...\")\n            validated_issue = _validate_issue_for_submit(\n                ctx, repo, issue_number, target_branch, force=force\n            )\n            validated_issues.append(validated_issue)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_issues)} issue(s) validated\"\n        )\n        user_output(\"\")\n\n        # Display validated issues\n        for v in validated_issues:\n            user_output(f\"  #{v.number}: {click.style(v.issue.title, fg='yellow')}\")\n        user_output(\"\")\n\n        # Phase 2: Submit all validated issues\n        results = []\n        for i, v in enumerate(validated_issues):\n            if len(validated_issues) > 1:\n                user_output(\n                    f\"--- Submitting issue {i + 1}/{len(validated_issues)}: #{v.number} ---\"\n                )\n            else:\n                user_output(f\"Submitting issue #{v.number}...\")\n            user_output(\"\")\n            result = _submit_single_issue(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n\n    # Success output\n    user_output(\"\")\n    user_output(click.style(\"✓\", fg=\"green\") + f\" {len(results)} issue(s) submitted successfully!\")\n    user_output(\"\")\n    user_output(\"Submitted issues:\")\n    for r in results:\n        user_output(f\"  • #{r.issue_number}: {r.issue_title}\")\n        user_output(f\"    Issue: {r.issue_url}\")\n        if r.pr_url:\n            user_output(f\"    PR: {r.pr_url}\")\n        user_output(f\"    Workflow: {r.workflow_url}\")\n","structuredPatch":[{"oldStart":641,"oldLines":8,"newStart":641,"newLines":9,"lines":["         objective_id = objective_id_raw","     elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():","         objective_id = int(objective_id_raw)","+    slug = generate_slug_or_fallback(ctx.prompt_executor, issue.title)","     new_branch_name = generate_issue_branch_name(","-        issue_number, issue.title, ctx.time.now(), objective_id=objective_id","+        issue_number, slug, ctx.time.now(), objective_id=objective_id","     )"," ","     if existing_branches:"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"021c2d3f-e271-4ffd-ae7b-f114ad6acce1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_017WLdCcfsmxPQNUGMpUVKg5","type":"message","role":"assistant","content":[{"type":"text","text":"**Site 3: one_shot_dispatch.py** - `generate_branch_name`\n\nThe plan says to add `prompt_executor: PromptExecutor | None` parameter. When `None` (dry-run), skip inference."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":477,"cache_read_input_tokens":132432,"cache_creation":{"ephemeral_5m_input_tokens":477,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHFXxkkNi3bFZwPFWe3","type":"assistant","uuid":"3b8a0362-bb2a-4059-98ff-07d565924467","timestamp":"2026-02-22T14:40:26.351Z"}
{"parentUuid":"3b8a0362-bb2a-4059-98ff-07d565924467","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_017WLdCcfsmxPQNUGMpUVKg5","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015rVe4t5V2ca4DZq2uEmpAy","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","offset":1,"limit":95},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":477,"cache_read_input_tokens":132432,"cache_creation":{"ephemeral_5m_input_tokens":477,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHFXxkkNi3bFZwPFWe3","type":"assistant","uuid":"bb3e71fb-f96f-4aee-a86f-e1dc50b4386b","timestamp":"2026-02-22T14:40:27.072Z"}
{"parentUuid":"bb3e71fb-f96f-4aee-a86f-e1dc50b4386b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015rVe4t5V2ca4DZq2uEmpAy","type":"tool_result","content":"     1→\"\"\"Shared dispatch logic for one-shot autonomous execution.\n     2→\n     3→Extracts the branch-create/push/PR/workflow-trigger sequence into reusable\n     4→pieces so both `erk one-shot` and `erk objective plan --one-shot` can\n     5→dispatch tasks through the same CI workflow.\n     6→\"\"\"\n     7→\n     8→import logging\n     9→from dataclasses import dataclass\n    10→from datetime import UTC\n    11→\n    12→import click\n    13→\n    14→from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\n    15→from erk.cli.ensure import Ensure\n    16→from erk.core.context import ErkContext, NoRepoSentinel, RepoContext\n    17→from erk_shared.gateway.git.remote_ops.types import PushError\n    18→from erk_shared.gateway.github.metadata.core import (\n    19→    create_submission_queued_block,\n    20→    render_erk_issue_event,\n    21→)\n    22→from erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\n    23→from erk_shared.gateway.github.parsing import construct_workflow_run_url\n    24→from erk_shared.gateway.github.plan_issues import create_plan_issue\n    25→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    26→from erk_shared.gateway.time.abc import Time\n    27→from erk_shared.naming import (\n    28→    format_branch_timestamp_suffix,\n    29→    generate_draft_pr_branch_name,\n    30→    generate_issue_branch_name,\n    31→    sanitize_worktree_name,\n    32→)\n    33→from erk_shared.output.output import user_output\n    34→from erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n    35→\n    36→logger = logging.getLogger(__name__)\n    37→\n    38→ONE_SHOT_WORKFLOW = \"one-shot.yml\"\n    39→\n    40→\n    41→@dataclass(frozen=True)\n    42→class OneShotDispatchParams:\n    43→    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n    44→\n    45→    prompt: str\n    46→    model: str | None\n    47→    extra_workflow_inputs: dict[str, str]\n    48→\n    49→\n    50→@dataclass(frozen=True)\n    51→class OneShotDispatchResult:\n    52→    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n    53→\n    54→    pr_number: int\n    55→    run_id: str\n    56→    branch_name: str\n    57→\n    58→\n    59→def generate_branch_name(\n    60→    prompt: str,\n    61→    *,\n    62→    time: Time,\n    63→    plan_issue_number: int | None,\n    64→    objective_id: int | None,\n    65→) -> str:\n    66→    \"\"\"Generate a branch name from the prompt.\n    67→\n    68→    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    69→    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n    70→\n    71→    Args:\n    72→        prompt: The task description\n    73→        time: Time gateway for deterministic timestamps\n    74→        plan_issue_number: If provided, delegate to generate_issue_branch_name\n    75→        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n    76→\n    77→    Returns:\n    78→        Branch name string\n    79→    \"\"\"\n    80→    if plan_issue_number is not None:\n    81→        return generate_issue_branch_name(\n    82→            plan_issue_number, prompt, time.now(), objective_id=objective_id\n    83→        )\n    84→    slug = sanitize_worktree_name(prompt)\n    85→    prefix = \"oneshot-\"\n    86→    max_slug_len = 31 - len(prefix)\n    87→    if len(slug) > max_slug_len:\n    88→        slug = slug[:max_slug_len].rstrip(\"-\")\n    89→    timestamp = format_branch_timestamp_suffix(time.now())\n    90→    return f\"{prefix}{slug}{timestamp}\"\n    91→\n    92→\n    93→def dispatch_one_shot(\n    94→    ctx: ErkContext,\n    95→    *,\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3b061db5-ffea-4551-8c80-8798b7495a8f","timestamp":"2026-02-22T14:40:27.099Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","content":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,","numLines":95,"startLine":1,"totalLines":432}}}
{"parentUuid":"3b061db5-ffea-4551-8c80-8798b7495a8f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KpCmvAJd1zscbghpLHD1eT","type":"message","role":"assistant","content":[{"type":"text","text":"I need to add the `prompt_executor` parameter and use it within the function:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1454,"cache_read_input_tokens":132909,"cache_creation":{"ephemeral_5m_input_tokens":1454,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHFt2k67FE3m7Scx9Ey","type":"assistant","uuid":"8c2f8630-380f-42b3-bfa2-ae8b57dd1433","timestamp":"2026-02-22T14:40:31.231Z"}
{"parentUuid":"8c2f8630-380f-42b3-bfa2-ae8b57dd1433","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KpCmvAJd1zscbghpLHD1eT","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DXMtMuewXKDoARH6MDvHFP","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext","new_string":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1454,"cache_read_input_tokens":132909,"cache_creation":{"ephemeral_5m_input_tokens":1454,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHFt2k67FE3m7Scx9Ey","type":"assistant","uuid":"d4fbbf5c-c64f-4ee0-a82a-f4b9d06f127b","timestamp":"2026-02-22T14:40:33.057Z"}
{"parentUuid":"d4fbbf5c-c64f-4ee0-a82a-f4b9d06f127b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DXMtMuewXKDoARH6MDvHFP","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"c94e7b0a-c30e-4266-9030-381c7ec20d6d","timestamp":"2026-02-22T14:40:33.742Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext","newString":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":13,"oldLines":6,"newStart":13,"newLines":7,"lines":[" "," from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata"," from erk.cli.ensure import Ensure","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk.core.context import ErkContext, NoRepoSentinel, RepoContext"," from erk_shared.gateway.git.remote_ops.types import PushError"," from erk_shared.gateway.github.metadata.core import ("]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"c94e7b0a-c30e-4266-9030-381c7ec20d6d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SUCtjjSPULmG4pvJyN3GXC","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the `generate_branch_name` function:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":503,"cache_read_input_tokens":134363,"cache_creation":{"ephemeral_5m_input_tokens":503,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHGNW1aLvDbx22bKL3H","type":"assistant","uuid":"1e21e564-1874-446f-96f6-ecc8a956d42d","timestamp":"2026-02-22T14:40:36.160Z"}
{"parentUuid":"1e21e564-1874-446f-96f6-ecc8a956d42d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SUCtjjSPULmG4pvJyN3GXC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KuDFH488JpUdLzzo7eYM8F","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"from erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)","new_string":"from erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":503,"cache_read_input_tokens":134363,"cache_creation":{"ephemeral_5m_input_tokens":503,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHGNW1aLvDbx22bKL3H","type":"assistant","uuid":"44b84d10-1f45-45e3-850e-99e1959710c3","timestamp":"2026-02-22T14:40:37.948Z"}
{"parentUuid":"44b84d10-1f45-45e3-850e-99e1959710c3","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KuDFH488JpUdLzzo7eYM8F","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"285a2df2-2be8-49c7-9250-32f40c927b00","timestamp":"2026-02-22T14:40:38.619Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"from erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)","newString":"from erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":25,"oldLines":6,"newStart":25,"newLines":7,"lines":[" from erk_shared.gateway.github.plan_issues import create_plan_issue"," from erk_shared.gateway.github.pr_footer import build_pr_body_footer"," from erk_shared.gateway.time.abc import Time","+from erk_shared.core.prompt_executor import PromptExecutor"," from erk_shared.naming import (","     format_branch_timestamp_suffix,","     generate_draft_pr_branch_name,"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"285a2df2-2be8-49c7-9250-32f40c927b00","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01MNzBV7fBo7Ku6hZgmpAVoB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KvLUSAHaSHfQE4EyvKqCAa","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"def generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"","new_string":"def generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n    prompt_executor: PromptExecutor | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    When prompt_executor is provided, uses LLM to generate a concise slug\n    from the prompt. When None (e.g., dry-run mode), falls back to\n    sanitize_worktree_name.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n        prompt_executor: PromptExecutor for LLM slug generation, or None to skip\n\n    Returns:\n        Branch name string\n    \"\"\"\n    title = prompt\n    if prompt_executor is not None:\n        title = generate_slug_or_fallback(prompt_executor, prompt)\n\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, title, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(title)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\""},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":70515,"cache_read_input_tokens":19598,"cache_creation":{"ephemeral_5m_input_tokens":70515,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHGjJQjGByQrTan3asu","type":"assistant","uuid":"f642a535-887a-4af5-8fd1-82216ad024a7","timestamp":"2026-02-22T14:40:54.308Z"}
{"parentUuid":"f642a535-887a-4af5-8fd1-82216ad024a7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KvLUSAHaSHfQE4EyvKqCAa","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"5199a1f3-d623-4e5d-99a3-c4678a8f10a1","timestamp":"2026-02-22T14:40:54.992Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"def generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"","newString":"def generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n    prompt_executor: PromptExecutor | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    When prompt_executor is provided, uses LLM to generate a concise slug\n    from the prompt. When None (e.g., dry-run mode), falls back to\n    sanitize_worktree_name.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n        prompt_executor: PromptExecutor for LLM slug generation, or None to skip\n\n    Returns:\n        Branch name string\n    \"\"\"\n    title = prompt\n    if prompt_executor is not None:\n        title = generate_slug_or_fallback(prompt_executor, prompt)\n\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, title, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(title)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n\n    Returns:\n        Branch name string\n    \"\"\"\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, prompt, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(prompt)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":64,"oldLines":26,"newStart":64,"newLines":36,"lines":["     time: Time,","     plan_issue_number: int | None,","     objective_id: int | None,","+    prompt_executor: PromptExecutor | None,"," ) -> str:","     \"\"\"Generate a branch name from the prompt."," ","     Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)","     when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}."," ","+    When prompt_executor is provided, uses LLM to generate a concise slug","+    from the prompt. When None (e.g., dry-run mode), falls back to","+    sanitize_worktree_name.","+","     Args:","         prompt: The task description","         time: Time gateway for deterministic timestamps","         plan_issue_number: If provided, delegate to generate_issue_branch_name","         objective_id: If provided with plan_issue_number, encode O{N} in branch name","+        prompt_executor: PromptExecutor for LLM slug generation, or None to skip"," ","     Returns:","         Branch name string","     \"\"\"","+    title = prompt","+    if prompt_executor is not None:","+        title = generate_slug_or_fallback(prompt_executor, prompt)","+","     if plan_issue_number is not None:","         return generate_issue_branch_name(","-            plan_issue_number, prompt, time.now(), objective_id=objective_id","+            plan_issue_number, title, time.now(), objective_id=objective_id","         )","-    slug = sanitize_worktree_name(prompt)","+    slug = sanitize_worktree_name(title)","     prefix = \"oneshot-\"","     max_slug_len = 31 - len(prefix)","     if len(slug) > max_slug_len:"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"5199a1f3-d623-4e5d-99a3-c4678a8f10a1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01EHyt2s1wnka3kjM3TcE7vU","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the call sites within `dispatch_one_shot`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1158,"cache_read_input_tokens":90113,"cache_creation":{"ephemeral_5m_input_tokens":1158,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHHwJFZmTJkLdzppQe1","type":"assistant","uuid":"e3ac7bde-12fa-4ba7-8b47-58751d927422","timestamp":"2026-02-22T14:40:57.646Z"}
{"parentUuid":"e3ac7bde-12fa-4ba7-8b47-58751d927422","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01EHyt2s1wnka3kjM3TcE7vU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Pfn3tbBqrmSwkcGxjTfdK1","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","offset":135,"limit":35},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1158,"cache_read_input_tokens":90113,"cache_creation":{"ephemeral_5m_input_tokens":1158,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHHwJFZmTJkLdzppQe1","type":"assistant","uuid":"cc637b04-0a41-4d59-80da-e99189a326b2","timestamp":"2026-02-22T14:40:58.494Z"}
{"parentUuid":"cc637b04-0a41-4d59-80da-e99189a326b2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Pfn3tbBqrmSwkcGxjTfdK1","type":"tool_result","content":"   135→    Ensure.gh_authenticated(ctx)\n   136→\n   137→    # Get GitHub username\n   138→    _, username, _ = ctx.github.check_auth_status()\n   139→    submitted_by = username or \"unknown\"\n   140→\n   141→    # Detect trunk branch\n   142→    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n   143→\n   144→    # Build PR title\n   145→    max_title_len = 60\n   146→    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n   147→    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n   148→\n   149→    if dry_run:\n   150→        # In dry-run, show preview without creating skeleton issue\n   151→        branch_name = generate_branch_name(\n   152→            params.prompt,\n   153→            time=ctx.time,\n   154→            plan_issue_number=None,\n   155→            objective_id=None,\n   156→        )\n   157→        user_output(\n   158→            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n   159→        )\n   160→        user_output(f\"Prompt: {params.prompt}\")\n   161→        user_output(f\"Branch: {branch_name}\")\n   162→        user_output(f\"PR title: {pr_title}\")\n   163→        user_output(f\"Base branch: {trunk}\")\n   164→        user_output(f\"Submitted by: {submitted_by}\")\n   165→        if params.model is not None:\n   166→            user_output(f\"Model: {params.model}\")\n   167→        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n   168→        if params.extra_workflow_inputs:\n   169→            for key, value in params.extra_workflow_inputs.items():\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"26beb1ef-0ce1-4320-a8e1-c7a580fcc28b","timestamp":"2026-02-22T14:40:58.532Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","content":"    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():","numLines":35,"startLine":135,"totalLines":444}}}
{"parentUuid":"26beb1ef-0ce1-4320-a8e1-c7a580fcc28b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Bj398DmiUpphxEhtKE3YH6","type":"message","role":"assistant","content":[{"type":"text","text":"Update the dry-run call (pass `None` for prompt_executor to skip LLM call):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":722,"cache_read_input_tokens":91271,"cache_creation":{"ephemeral_5m_input_tokens":722,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHJCQqzUPHizp2jvhpL","type":"assistant","uuid":"5c71e219-8a70-4f72-bd6e-254e89993dcb","timestamp":"2026-02-22T14:41:01.231Z"}
{"parentUuid":"5c71e219-8a70-4f72-bd6e-254e89993dcb","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Bj398DmiUpphxEhtKE3YH6","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Vw9mXBJUux3GkYg7iMbtE4","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )","new_string":"    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n            prompt_executor=None,\n        )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":722,"cache_read_input_tokens":91271,"cache_creation":{"ephemeral_5m_input_tokens":722,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHJCQqzUPHizp2jvhpL","type":"assistant","uuid":"07d4ac58-2bb9-4484-9c8b-b3d41e7d468d","timestamp":"2026-02-22T14:41:03.185Z"}
{"parentUuid":"07d4ac58-2bb9-4484-9c8b-b3d41e7d468d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Vw9mXBJUux3GkYg7iMbtE4","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"d3e32872-fd66-47fd-b2b9-00fcbafb9585","timestamp":"2026-02-22T14:41:03.849Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )","newString":"    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n            prompt_executor=None,\n        )","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n    prompt_executor: PromptExecutor | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    When prompt_executor is provided, uses LLM to generate a concise slug\n    from the prompt. When None (e.g., dry-run mode), falls back to\n    sanitize_worktree_name.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n        prompt_executor: PromptExecutor for LLM slug generation, or None to skip\n\n    Returns:\n        Branch name string\n    \"\"\"\n    title = prompt\n    if prompt_executor is not None:\n        title = generate_slug_or_fallback(prompt_executor, prompt)\n\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, title, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(title)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":153,"oldLines":6,"newStart":153,"newLines":7,"lines":["             time=ctx.time,","             plan_issue_number=None,","             objective_id=None,","+            prompt_executor=None,","         )","         user_output(","             click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\""]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"d3e32872-fd66-47fd-b2b9-00fcbafb9585","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Wf9WiGkKsKRCiGCrTdiLz9","type":"message","role":"assistant","content":[{"type":"text","text":"Now find the non-dry-run branch name generation calls. Let me read lines 200-215:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":522,"cache_read_input_tokens":91993,"cache_creation":{"ephemeral_5m_input_tokens":522,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHJb8q4cKTAfW7LXhKy","type":"assistant","uuid":"4e0d1d14-43bf-4320-b4d3-2154848fa7a1","timestamp":"2026-02-22T14:41:06.490Z"}
{"parentUuid":"4e0d1d14-43bf-4320-b4d3-2154848fa7a1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Wf9WiGkKsKRCiGCrTdiLz9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DX5eDijARE3NYaFGDvnMt8","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","offset":200,"limit":25},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":522,"cache_read_input_tokens":91993,"cache_creation":{"ephemeral_5m_input_tokens":522,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHJb8q4cKTAfW7LXhKy","type":"assistant","uuid":"ea2cce9c-af30-48ec-9b97-ba8daab31956","timestamp":"2026-02-22T14:41:07.228Z"}
{"parentUuid":"ea2cce9c-af30-48ec-9b97-ba8daab31956","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DX5eDijARE3NYaFGDvnMt8","type":"tool_result","content":"   200→            lifecycle_stage=\"prompted\",\n   201→        )\n   202→        plan_issue_number = skeleton_result.issue_number\n   203→\n   204→    # Generate branch name\n   205→    if is_draft_pr:\n   206→        # draft_pr: planned/ prefix (no issue number needed)\n   207→        branch_name = generate_draft_pr_branch_name(\n   208→            params.prompt,\n   209→            ctx.time.now(),\n   210→            objective_id=objective_id,\n   211→        )\n   212→    else:\n   213→        # github: P<N>- prefix using skeleton issue number\n   214→        branch_name = generate_branch_name(\n   215→            params.prompt,\n   216→            time=ctx.time,\n   217→            plan_issue_number=plan_issue_number,\n   218→            objective_id=objective_id,\n   219→        )\n   220→\n   221→    # Save current branch for restoration after workflow trigger\n   222→    original_branch = ctx.git.branch.get_current_branch(repo.root)\n   223→    if original_branch is None:\n   224→        user_output(\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"22b0734a-4bbe-44ba-9fc0-4ea537ce03ec","timestamp":"2026-02-22T14:41:07.256Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","content":"            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(","numLines":25,"startLine":200,"totalLines":445}}}
{"parentUuid":"22b0734a-4bbe-44ba-9fc0-4ea537ce03ec","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01U97BM6nUgeN6TsuYgvxdbY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TFPTHsTSQYXUXxaZNVTq3G","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )","new_string":"    # Generate branch name with LLM-generated slug\n    slug = generate_slug_or_fallback(ctx.prompt_executor, params.prompt)\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            slug,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            slug,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n            prompt_executor=None,\n        )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":526,"cache_read_input_tokens":92515,"cache_creation":{"ephemeral_5m_input_tokens":526,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHJqiBVKpEvhzr6JVHD","type":"assistant","uuid":"0ff625ac-8ced-4621-8e0d-f717bd26a220","timestamp":"2026-02-22T14:41:13.183Z"}
{"parentUuid":"0ff625ac-8ced-4621-8e0d-f717bd26a220","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TFPTHsTSQYXUXxaZNVTq3G","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"36d2cd42-4e54-4e20-bc7d-97442a5e2608","timestamp":"2026-02-22T14:41:13.861Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )","newString":"    # Generate branch name with LLM-generated slug\n    slug = generate_slug_or_fallback(ctx.prompt_executor, params.prompt)\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            slug,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            slug,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n            prompt_executor=None,\n        )","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n    prompt_executor: PromptExecutor | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    When prompt_executor is provided, uses LLM to generate a concise slug\n    from the prompt. When None (e.g., dry-run mode), falls back to\n    sanitize_worktree_name.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n        prompt_executor: PromptExecutor for LLM slug generation, or None to skip\n\n    Returns:\n        Branch name string\n    \"\"\"\n    title = prompt\n    if prompt_executor is not None:\n        title = generate_slug_or_fallback(prompt_executor, prompt)\n\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, title, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(title)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n            prompt_executor=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            params.prompt,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":201,"oldLines":21,"newStart":201,"newLines":23,"lines":["         )","         plan_issue_number = skeleton_result.issue_number"," ","-    # Generate branch name","+    # Generate branch name with LLM-generated slug","+    slug = generate_slug_or_fallback(ctx.prompt_executor, params.prompt)","     if is_draft_pr:","         # draft_pr: planned/ prefix (no issue number needed)","         branch_name = generate_draft_pr_branch_name(","-            params.prompt,","+            slug,","             ctx.time.now(),","             objective_id=objective_id,","         )","     else:","         # github: P<N>- prefix using skeleton issue number","         branch_name = generate_branch_name(","-            params.prompt,","+            slug,","             time=ctx.time,","             plan_issue_number=plan_issue_number,","             objective_id=objective_id,","+            prompt_executor=None,","         )"," ","     # Save current branch for restoration after workflow trigger"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"36d2cd42-4e54-4e20-bc7d-97442a5e2608","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Xer1mTwEG9DCJDVWj9F5Bo","type":"message","role":"assistant","content":[{"type":"text","text":"**Site 4: setup_impl_from_issue.py** - `_setup_issue_plan`"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":681,"cache_read_input_tokens":93041,"cache_creation":{"ephemeral_5m_input_tokens":681,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHKKx42YDvjQYQNmZHH","type":"assistant","uuid":"03b92016-1dd7-46f9-b5c8-cfbd43638c8a","timestamp":"2026-02-22T14:41:16.734Z"}
{"parentUuid":"03b92016-1dd7-46f9-b5c8-cfbd43638c8a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Xer1mTwEG9DCJDVWj9F5Bo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YJBg5qgR2sLUN6mHSR5P7K","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","offset":247,"limit":60},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":681,"cache_read_input_tokens":93041,"cache_creation":{"ephemeral_5m_input_tokens":681,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHKKx42YDvjQYQNmZHH","type":"assistant","uuid":"34571a1d-50b9-4335-b4c1-36d3c24ae78b","timestamp":"2026-02-22T14:41:17.683Z"}
{"parentUuid":"34571a1d-50b9-4335-b4c1-36d3c24ae78b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YJBg5qgR2sLUN6mHSR5P7K","type":"tool_result","content":"   247→def _setup_issue_plan(\n   248→    ctx: click.Context,\n   249→    *,\n   250→    issue_number: int,\n   251→    no_impl: bool,\n   252→) -> dict[str, str | int | bool | None]:\n   253→    \"\"\"Set up implementation from an issue-based plan.\n   254→\n   255→    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n   256→\n   257→    Args:\n   258→        ctx: Click context\n   259→        issue_number: Issue number for the plan\n   260→        no_impl: Skip .impl/ folder creation\n   261→\n   262→    Returns:\n   263→        Success output dict\n   264→    \"\"\"\n   265→    cwd = require_cwd(ctx)\n   266→    repo_root = require_repo_root(ctx)\n   267→    git = require_git(ctx)\n   268→    plan_backend = require_plan_backend(ctx)\n   269→    time = require_time(ctx)\n   270→\n   271→    # Fetch plan from GitHub issue\n   272→    result = plan_backend.get_plan(repo_root, str(issue_number))\n   273→    if isinstance(result, PlanNotFound):\n   274→        error_output = {\n   275→            \"success\": False,\n   276→            \"error\": \"plan_not_found\",\n   277→            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n   278→            f\"Ensure issue has erk-plan label and plan content.\",\n   279→        }\n   280→        click.echo(json.dumps(error_output), err=True)\n   281→        raise SystemExit(1)\n   282→    plan = result\n   283→\n   284→    current_branch = _get_current_branch(git, cwd)\n   285→    branch_manager = require_branch_manager(ctx)\n   286→\n   287→    # Issue-based plan: generate P{issue}-... branch name\n   288→    # Check if already on a branch for this issue - reuse it\n   289→    expected_prefix = f\"P{issue_number}-\"\n   290→    if current_branch.startswith(expected_prefix):\n   291→        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n   292→        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n   293→        branch_name = current_branch\n   294→    else:\n   295→        # Generate branch name from issue\n   296→        timestamp = time.now()\n   297→        branch_name = generate_issue_branch_name(\n   298→            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n   299→        )\n   300→\n   301→        # Check if branch already exists\n   302→        local_branches = git.branch.list_local_branches(repo_root)\n   303→\n   304→        if branch_name in local_branches:\n   305→            # Branch exists - just check it out\n   306→            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"68b0230f-f1a4-4e7b-8007-84d4c7e45b24","timestamp":"2026-02-22T14:41:17.704Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","content":"def _setup_issue_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from an issue-based plan.\n\n    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n\n    Args:\n        ctx: Click context\n        issue_number: Issue number for the plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    repo_root = require_repo_root(ctx)\n    git = require_git(ctx)\n    plan_backend = require_plan_backend(ctx)\n    time = require_time(ctx)\n\n    # Fetch plan from GitHub issue\n    result = plan_backend.get_plan(repo_root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n            f\"Ensure issue has erk-plan label and plan content.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n    plan = result\n\n    current_branch = _get_current_branch(git, cwd)\n    branch_manager = require_branch_manager(ctx)\n\n    # Issue-based plan: generate P{issue}-... branch name\n    # Check if already on a branch for this issue - reuse it\n    expected_prefix = f\"P{issue_number}-\"\n    if current_branch.startswith(expected_prefix):\n        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n        branch_name = current_branch\n    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )\n\n        # Check if branch already exists\n        local_branches = git.branch.list_local_branches(repo_root)\n\n        if branch_name in local_branches:\n            # Branch exists - just check it out\n            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)","numLines":60,"startLine":247,"totalLines":395}}}
{"parentUuid":"68b0230f-f1a4-4e7b-8007-84d4c7e45b24","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01TEu2CTwxccJ6WUaWbEABf1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016DEdRGcQZk1h2QNjWG4aCS","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","old_string":"from erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_repo_root,\n    require_time,\n)","new_string":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1042,"cache_read_input_tokens":93722,"cache_creation":{"ephemeral_5m_input_tokens":1042,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHKcPGk3rp43pLs5hEq","type":"assistant","uuid":"8cf58554-59fa-4a1d-8dd1-1ad00dd1df81","timestamp":"2026-02-22T14:41:22.196Z"}
{"parentUuid":"8cf58554-59fa-4a1d-8dd1-1ad00dd1df81","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016DEdRGcQZk1h2QNjWG4aCS","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py has been updated successfully."}]},"uuid":"1f2db4f4-4cce-4eae-965c-53cea208764d","timestamp":"2026-02-22T14:41:22.877Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","oldString":"from erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_repo_root,\n    require_time,\n)","newString":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)","originalFile":"\"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\nThis exec command fetches a plan from a GitHub issue, creates a feature branch,\nchecks it out, and creates the .impl/ folder structure for implementation.\n\nUsage:\n    erk exec setup-impl-from-issue <issue-number> [--session-id <id>]\n\nOutput:\n    Structured JSON output with success status and folder details\n\nExit Codes:\n    0: Success (.impl/ folder created, branch checked out)\n    1: Error (issue not found, plan fetch failed, git operations failed)\n\nExamples:\n    $ erk exec setup-impl-from-issue 1028\n    {\"success\": true, \"impl_path\": \"/path/to/.impl\", \"issue_number\": 1028, \"branch\": \"P1028-...\"}\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.branch_manager.abc import BranchManager\nfrom erk_shared.gateway.git.abc import Git\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError\nfrom erk_shared.gateway.github.metadata.core import find_metadata_block\nfrom erk_shared.gateway.github.metadata.schemas import OBJECTIVE_ISSUE\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.impl_folder import create_impl_folder, read_plan_ref, save_plan_ref\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR, extract_plan_content\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _get_current_branch(git: Git, cwd: Path) -> str:\n    \"\"\"Get current branch via gateway, raising if detached HEAD.\"\"\"\n    branch = git.branch.get_current_branch(cwd)\n    if branch is None:\n        msg = \"Cannot set up implementation from detached HEAD state\"\n        raise click.ClickException(msg)\n    return branch\n\n\ndef _checkout_plan_branch(\n    *,\n    git: Git,\n    branch_manager: BranchManager,\n    repo_root: Path,\n    cwd: Path,\n    current_branch: str,\n    branch_name: str,\n) -> None:\n    \"\"\"Fetch, checkout, and sync a draft-PR plan branch.\n\n    Handles three cases:\n    - Already on the branch: just sync\n    - Branch exists locally: checkout and sync\n    - Branch only on remote: create tracking branch (no sync needed)\n\n    Args:\n        git: Git gateway\n        branch_manager: BranchManager for checkout operations\n        repo_root: Repository root\n        cwd: Current working directory\n        current_branch: Name of current branch\n        branch_name: Plan branch to checkout\n    \"\"\"\n    git.remote.fetch_branch(repo_root, \"origin\", branch_name)\n    local_branches = git.branch.list_local_branches(repo_root)\n    needs_sync = True\n\n    if current_branch == branch_name:\n        click.echo(f\"Already on plan branch '{branch_name}', syncing with remote...\", err=True)\n    elif branch_name in local_branches:\n        click.echo(f\"Checking out plan branch '{branch_name}'...\", err=True)\n        branch_manager.checkout_branch(cwd, branch_name)\n    else:\n        click.echo(f\"Creating local tracking branch for '{branch_name}' from remote...\", err=True)\n        branch_manager.create_tracking_branch(repo_root, branch_name, f\"origin/{branch_name}\")\n        branch_manager.checkout_branch(cwd, branch_name)\n        needs_sync = False\n\n    if needs_sync:\n        pull_result = git.remote.pull_rebase(cwd, \"origin\", branch_name)\n        if isinstance(pull_result, PullRebaseError):\n            error_output = {\n                \"success\": False,\n                \"error\": \"pull_rebase_failed\",\n                \"message\": (\n                    f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n                ),\n            }\n            click.echo(json.dumps(error_output), err=True)\n            raise SystemExit(1)\n\n\ndef _setup_draft_pr_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from a draft-PR plan.\n\n    Uses github.get_pr() for branch discovery, then reads plan content\n    from .erk/impl-context/ on the branch (falling back to PR body).\n\n    Args:\n        ctx: Click context\n        issue_number: PR number for the draft-PR plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n\n    # Early exit: if .impl/ is already set up for this issue (e.g., CI pre-populated it),\n    # skip branch switching. Switching to the plan branch would abandon the implementation\n    # branch, causing work to land on the wrong branch.\n    impl_dir = cwd / \".impl\"\n    if impl_dir.exists():\n        existing_ref = read_plan_ref(impl_dir)\n        if existing_ref is not None and existing_ref.plan_id == str(issue_number):\n            click.echo(\n                f\"Found existing .impl/ for plan #{issue_number}, skipping branch setup\",\n                err=True,\n            )\n            current_branch = _get_current_branch(git, cwd)\n            impl_path_str = str(impl_dir) if not no_impl else None\n            return {\n                \"success\": True,\n                \"impl_path\": impl_path_str,\n                \"issue_number\": issue_number,\n                \"issue_url\": existing_ref.url,\n                \"branch\": current_branch,\n                \"plan_title\": \"\",\n                \"no_impl\": no_impl,\n            }\n\n    repo_root = require_repo_root(ctx)\n    github = require_github(ctx)\n    branch_manager = require_branch_manager(ctx)\n\n    # Phase A: Lightweight PR query for branch name only\n    pr_result = github.get_pr(repo_root, issue_number)\n    if isinstance(pr_result, PRNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for PR #{issue_number}: PR not found.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n\n    branch_name = pr_result.head_ref_name\n    pr_url = pr_result.url\n    current_branch = _get_current_branch(git, cwd)\n\n    # Checkout and sync the plan branch\n    _checkout_plan_branch(\n        git=git,\n        branch_manager=branch_manager,\n        repo_root=repo_root,\n        cwd=cwd,\n        current_branch=current_branch,\n        branch_name=branch_name,\n    )\n\n    # Phase B: After checkout, read plan content from local files or PR body\n    impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n    impl_context_plan = impl_context_dir / \"plan.md\"\n\n    if impl_context_plan.exists():\n        # Read from committed .erk/impl-context/ files\n        plan_content = impl_context_plan.read_text(encoding=\"utf-8\")\n        ref_json_path = impl_context_dir / \"ref.json\"\n        objective_id: int | None = None\n        plan_title: str = pr_result.title\n        if ref_json_path.exists():\n            ref_data = json.loads(ref_json_path.read_text(encoding=\"utf-8\"))\n            raw_objective = ref_data.get(\"objective_id\")\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n            raw_title = ref_data.get(\"title\")\n            if isinstance(raw_title, str):\n                plan_title = raw_title\n        # Do not delete here — Step 2d in plan-implement.md handles git rm + commit + push\n    else:\n        # Fallback: extract from PR body (legacy branch or already cleaned up)\n        plan_content = extract_plan_content(pr_result.body)\n        plan_title = pr_result.title\n        objective_id = None\n        block = find_metadata_block(pr_result.body, \"plan-header\")\n        if block is not None:\n            raw_objective = block.data.get(OBJECTIVE_ISSUE)\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan_content,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github-draft-pr\",\n            plan_id=str(issue_number),\n            url=pr_url,\n            labels=(),\n            objective_id=objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": pr_url,\n        \"branch\": branch_name,\n        \"plan_title\": plan_title,\n        \"no_impl\": no_impl,\n    }\n\n\ndef _setup_issue_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from an issue-based plan.\n\n    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n\n    Args:\n        ctx: Click context\n        issue_number: Issue number for the plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    repo_root = require_repo_root(ctx)\n    git = require_git(ctx)\n    plan_backend = require_plan_backend(ctx)\n    time = require_time(ctx)\n\n    # Fetch plan from GitHub issue\n    result = plan_backend.get_plan(repo_root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n            f\"Ensure issue has erk-plan label and plan content.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n    plan = result\n\n    current_branch = _get_current_branch(git, cwd)\n    branch_manager = require_branch_manager(ctx)\n\n    # Issue-based plan: generate P{issue}-... branch name\n    # Check if already on a branch for this issue - reuse it\n    expected_prefix = f\"P{issue_number}-\"\n    if current_branch.startswith(expected_prefix):\n        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n        branch_name = current_branch\n    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )\n\n        # Check if branch already exists\n        local_branches = git.branch.list_local_branches(repo_root)\n\n        if branch_name in local_branches:\n            # Branch exists - just check it out\n            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)\n            branch_manager.checkout_branch(cwd, branch_name)\n        else:\n            base_branch = current_branch\n\n            # Create branch using BranchManager (handles Graphite tracking automatically)\n            create_result = branch_manager.create_branch(repo_root, branch_name, base_branch)\n            if isinstance(create_result, BranchAlreadyExists):\n                click.echo(f\"Error: {create_result.message}\", err=True)\n                raise SystemExit(1) from None\n            click.echo(f\"Created branch '{branch_name}' from '{base_branch}'\", err=True)\n\n            branch_manager.checkout_branch(cwd, branch_name)\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan.body,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github\",\n            plan_id=str(issue_number),\n            url=plan.url,\n            labels=(),\n            objective_id=plan.objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": plan.url,\n        \"branch\": branch_name,\n        \"plan_title\": plan.title,\n        \"no_impl\": no_impl,\n    }\n\n\n@click.command(name=\"setup-impl-from-issue\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--session-id\",\n    default=None,\n    help=\"Claude session ID for marker creation\",\n)\n@click.option(\n    \"--no-impl\",\n    is_flag=True,\n    help=\"Skip .impl/ folder creation (for local execution without file overhead)\",\n)\n@click.pass_context\ndef setup_impl_from_issue(\n    ctx: click.Context,\n    issue_number: int,\n    session_id: str | None,\n    no_impl: bool,\n) -> None:\n    \"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\n    Fetches plan content from GitHub issue, creates/checks out a feature branch,\n    and creates .impl/ folder structure with plan.md, progress.md, and issue.json.\n\n    ISSUE_NUMBER: GitHub issue number containing the plan\n\n    The command:\n    1. Fetches the plan from the GitHub issue or draft PR\n    2. Creates a feature branch from current branch (stacked) or trunk\n    3. Checks out the new branch in the current worktree\n    4. Creates .impl/ folder with plan content\n    5. Saves issue reference for PR linking\n    \"\"\"\n    plan_backend = require_plan_backend(ctx)\n\n    # Dispatch based on plan backend\n    if plan_backend.get_provider_name() == \"github-draft-pr\":\n        output = _setup_draft_pr_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n    else:\n        output = _setup_issue_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n\n    click.echo(json.dumps(output))\n","structuredPatch":[{"oldStart":23,"oldLines":12,"newStart":23,"newLines":14,"lines":[" "," import click"," ","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk_shared.context.helpers import (","     require_branch_manager,","     require_cwd,","     require_git,","     require_github,","     require_plan_backend,","+    require_prompt_executor,","     require_repo_root,","     require_time,"," )"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"1f2db4f4-4cce-4eae-965c-53cea208764d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Q7ouqDDtkNbjni9VkgXWuq","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the branch name generation:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":520,"cache_read_input_tokens":94764,"cache_creation":{"ephemeral_5m_input_tokens":520,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHKzWHhzow8KQcridfd","type":"assistant","uuid":"155b50a5-1795-458c-ab5c-843e43e51f2d","timestamp":"2026-02-22T14:41:24.930Z"}
{"parentUuid":"155b50a5-1795-458c-ab5c-843e43e51f2d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Q7ouqDDtkNbjni9VkgXWuq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LZmfJsewHw32pYWHgMbQoV","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","old_string":"    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )","new_string":"    else:\n        # Generate branch name from issue with LLM-generated slug\n        executor = require_prompt_executor(ctx)\n        slug = generate_slug_or_fallback(executor, plan.title)\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, slug, timestamp, objective_id=plan.objective_id\n        )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":520,"cache_read_input_tokens":94764,"cache_creation":{"ephemeral_5m_input_tokens":520,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHKzWHhzow8KQcridfd","type":"assistant","uuid":"8341204f-419a-40f2-a7e7-cd52dae38ead","timestamp":"2026-02-22T14:41:27.004Z"}
{"parentUuid":"8341204f-419a-40f2-a7e7-cd52dae38ead","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LZmfJsewHw32pYWHgMbQoV","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py has been updated successfully."}]},"uuid":"f7cc0ab7-d046-4678-905f-cb074cbf5dcd","timestamp":"2026-02-22T14:41:27.695Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py","oldString":"    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )","newString":"    else:\n        # Generate branch name from issue with LLM-generated slug\n        executor = require_prompt_executor(ctx)\n        slug = generate_slug_or_fallback(executor, plan.title)\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, slug, timestamp, objective_id=plan.objective_id\n        )","originalFile":"\"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\nThis exec command fetches a plan from a GitHub issue, creates a feature branch,\nchecks it out, and creates the .impl/ folder structure for implementation.\n\nUsage:\n    erk exec setup-impl-from-issue <issue-number> [--session-id <id>]\n\nOutput:\n    Structured JSON output with success status and folder details\n\nExit Codes:\n    0: Success (.impl/ folder created, branch checked out)\n    1: Error (issue not found, plan fetch failed, git operations failed)\n\nExamples:\n    $ erk exec setup-impl-from-issue 1028\n    {\"success\": true, \"impl_path\": \"/path/to/.impl\", \"issue_number\": 1028, \"branch\": \"P1028-...\"}\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport click\n\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_branch_manager,\n    require_cwd,\n    require_git,\n    require_github,\n    require_plan_backend,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.gateway.branch_manager.abc import BranchManager\nfrom erk_shared.gateway.git.abc import Git\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError\nfrom erk_shared.gateway.github.metadata.core import find_metadata_block\nfrom erk_shared.gateway.github.metadata.schemas import OBJECTIVE_ISSUE\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.impl_folder import create_impl_folder, read_plan_ref, save_plan_ref\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR, extract_plan_content\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _get_current_branch(git: Git, cwd: Path) -> str:\n    \"\"\"Get current branch via gateway, raising if detached HEAD.\"\"\"\n    branch = git.branch.get_current_branch(cwd)\n    if branch is None:\n        msg = \"Cannot set up implementation from detached HEAD state\"\n        raise click.ClickException(msg)\n    return branch\n\n\ndef _checkout_plan_branch(\n    *,\n    git: Git,\n    branch_manager: BranchManager,\n    repo_root: Path,\n    cwd: Path,\n    current_branch: str,\n    branch_name: str,\n) -> None:\n    \"\"\"Fetch, checkout, and sync a draft-PR plan branch.\n\n    Handles three cases:\n    - Already on the branch: just sync\n    - Branch exists locally: checkout and sync\n    - Branch only on remote: create tracking branch (no sync needed)\n\n    Args:\n        git: Git gateway\n        branch_manager: BranchManager for checkout operations\n        repo_root: Repository root\n        cwd: Current working directory\n        current_branch: Name of current branch\n        branch_name: Plan branch to checkout\n    \"\"\"\n    git.remote.fetch_branch(repo_root, \"origin\", branch_name)\n    local_branches = git.branch.list_local_branches(repo_root)\n    needs_sync = True\n\n    if current_branch == branch_name:\n        click.echo(f\"Already on plan branch '{branch_name}', syncing with remote...\", err=True)\n    elif branch_name in local_branches:\n        click.echo(f\"Checking out plan branch '{branch_name}'...\", err=True)\n        branch_manager.checkout_branch(cwd, branch_name)\n    else:\n        click.echo(f\"Creating local tracking branch for '{branch_name}' from remote...\", err=True)\n        branch_manager.create_tracking_branch(repo_root, branch_name, f\"origin/{branch_name}\")\n        branch_manager.checkout_branch(cwd, branch_name)\n        needs_sync = False\n\n    if needs_sync:\n        pull_result = git.remote.pull_rebase(cwd, \"origin\", branch_name)\n        if isinstance(pull_result, PullRebaseError):\n            error_output = {\n                \"success\": False,\n                \"error\": \"pull_rebase_failed\",\n                \"message\": (\n                    f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n                ),\n            }\n            click.echo(json.dumps(error_output), err=True)\n            raise SystemExit(1)\n\n\ndef _setup_draft_pr_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from a draft-PR plan.\n\n    Uses github.get_pr() for branch discovery, then reads plan content\n    from .erk/impl-context/ on the branch (falling back to PR body).\n\n    Args:\n        ctx: Click context\n        issue_number: PR number for the draft-PR plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n\n    # Early exit: if .impl/ is already set up for this issue (e.g., CI pre-populated it),\n    # skip branch switching. Switching to the plan branch would abandon the implementation\n    # branch, causing work to land on the wrong branch.\n    impl_dir = cwd / \".impl\"\n    if impl_dir.exists():\n        existing_ref = read_plan_ref(impl_dir)\n        if existing_ref is not None and existing_ref.plan_id == str(issue_number):\n            click.echo(\n                f\"Found existing .impl/ for plan #{issue_number}, skipping branch setup\",\n                err=True,\n            )\n            current_branch = _get_current_branch(git, cwd)\n            impl_path_str = str(impl_dir) if not no_impl else None\n            return {\n                \"success\": True,\n                \"impl_path\": impl_path_str,\n                \"issue_number\": issue_number,\n                \"issue_url\": existing_ref.url,\n                \"branch\": current_branch,\n                \"plan_title\": \"\",\n                \"no_impl\": no_impl,\n            }\n\n    repo_root = require_repo_root(ctx)\n    github = require_github(ctx)\n    branch_manager = require_branch_manager(ctx)\n\n    # Phase A: Lightweight PR query for branch name only\n    pr_result = github.get_pr(repo_root, issue_number)\n    if isinstance(pr_result, PRNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for PR #{issue_number}: PR not found.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n\n    branch_name = pr_result.head_ref_name\n    pr_url = pr_result.url\n    current_branch = _get_current_branch(git, cwd)\n\n    # Checkout and sync the plan branch\n    _checkout_plan_branch(\n        git=git,\n        branch_manager=branch_manager,\n        repo_root=repo_root,\n        cwd=cwd,\n        current_branch=current_branch,\n        branch_name=branch_name,\n    )\n\n    # Phase B: After checkout, read plan content from local files or PR body\n    impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n    impl_context_plan = impl_context_dir / \"plan.md\"\n\n    if impl_context_plan.exists():\n        # Read from committed .erk/impl-context/ files\n        plan_content = impl_context_plan.read_text(encoding=\"utf-8\")\n        ref_json_path = impl_context_dir / \"ref.json\"\n        objective_id: int | None = None\n        plan_title: str = pr_result.title\n        if ref_json_path.exists():\n            ref_data = json.loads(ref_json_path.read_text(encoding=\"utf-8\"))\n            raw_objective = ref_data.get(\"objective_id\")\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n            raw_title = ref_data.get(\"title\")\n            if isinstance(raw_title, str):\n                plan_title = raw_title\n        # Do not delete here — Step 2d in plan-implement.md handles git rm + commit + push\n    else:\n        # Fallback: extract from PR body (legacy branch or already cleaned up)\n        plan_content = extract_plan_content(pr_result.body)\n        plan_title = pr_result.title\n        objective_id = None\n        block = find_metadata_block(pr_result.body, \"plan-header\")\n        if block is not None:\n            raw_objective = block.data.get(OBJECTIVE_ISSUE)\n            if isinstance(raw_objective, int):\n                objective_id = raw_objective\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan_content,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github-draft-pr\",\n            plan_id=str(issue_number),\n            url=pr_url,\n            labels=(),\n            objective_id=objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": pr_url,\n        \"branch\": branch_name,\n        \"plan_title\": plan_title,\n        \"no_impl\": no_impl,\n    }\n\n\ndef _setup_issue_plan(\n    ctx: click.Context,\n    *,\n    issue_number: int,\n    no_impl: bool,\n) -> dict[str, str | int | bool | None]:\n    \"\"\"Set up implementation from an issue-based plan.\n\n    Uses plan_backend.get_plan() to fetch plan content from a GitHub issue.\n\n    Args:\n        ctx: Click context\n        issue_number: Issue number for the plan\n        no_impl: Skip .impl/ folder creation\n\n    Returns:\n        Success output dict\n    \"\"\"\n    cwd = require_cwd(ctx)\n    repo_root = require_repo_root(ctx)\n    git = require_git(ctx)\n    plan_backend = require_plan_backend(ctx)\n    time = require_time(ctx)\n\n    # Fetch plan from GitHub issue\n    result = plan_backend.get_plan(repo_root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        error_output = {\n            \"success\": False,\n            \"error\": \"plan_not_found\",\n            \"message\": f\"Could not fetch plan for issue #{issue_number}: Issue not found. \"\n            f\"Ensure issue has erk-plan label and plan content.\",\n        }\n        click.echo(json.dumps(error_output), err=True)\n        raise SystemExit(1)\n    plan = result\n\n    current_branch = _get_current_branch(git, cwd)\n    branch_manager = require_branch_manager(ctx)\n\n    # Issue-based plan: generate P{issue}-... branch name\n    # Check if already on a branch for this issue - reuse it\n    expected_prefix = f\"P{issue_number}-\"\n    if current_branch.startswith(expected_prefix):\n        # Already on correct branch (e.g., remote workflow re-running with issue arg)\n        click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)\n        branch_name = current_branch\n    else:\n        # Generate branch name from issue\n        timestamp = time.now()\n        branch_name = generate_issue_branch_name(\n            issue_number, plan.title, timestamp, objective_id=plan.objective_id\n        )\n\n        # Check if branch already exists\n        local_branches = git.branch.list_local_branches(repo_root)\n\n        if branch_name in local_branches:\n            # Branch exists - just check it out\n            click.echo(f\"Branch '{branch_name}' already exists, checking out...\", err=True)\n            branch_manager.checkout_branch(cwd, branch_name)\n        else:\n            base_branch = current_branch\n\n            # Create branch using BranchManager (handles Graphite tracking automatically)\n            create_result = branch_manager.create_branch(repo_root, branch_name, base_branch)\n            if isinstance(create_result, BranchAlreadyExists):\n                click.echo(f\"Error: {create_result.message}\", err=True)\n                raise SystemExit(1) from None\n            click.echo(f\"Created branch '{branch_name}' from '{base_branch}'\", err=True)\n\n            branch_manager.checkout_branch(cwd, branch_name)\n\n    # Create .impl/ folder with plan content (unless --no-impl)\n    impl_path_str: str | None = None\n\n    if not no_impl:\n        impl_path = cwd / \".impl\"\n        impl_path_str = str(impl_path)\n\n        create_impl_folder(\n            worktree_path=cwd,\n            plan_content=plan.body,\n            overwrite=True,\n        )\n\n        save_plan_ref(\n            impl_path,\n            provider=\"github\",\n            plan_id=str(issue_number),\n            url=plan.url,\n            labels=(),\n            objective_id=plan.objective_id,\n        )\n\n    return {\n        \"success\": True,\n        \"impl_path\": impl_path_str,\n        \"issue_number\": issue_number,\n        \"issue_url\": plan.url,\n        \"branch\": branch_name,\n        \"plan_title\": plan.title,\n        \"no_impl\": no_impl,\n    }\n\n\n@click.command(name=\"setup-impl-from-issue\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--session-id\",\n    default=None,\n    help=\"Claude session ID for marker creation\",\n)\n@click.option(\n    \"--no-impl\",\n    is_flag=True,\n    help=\"Skip .impl/ folder creation (for local execution without file overhead)\",\n)\n@click.pass_context\ndef setup_impl_from_issue(\n    ctx: click.Context,\n    issue_number: int,\n    session_id: str | None,\n    no_impl: bool,\n) -> None:\n    \"\"\"Set up .impl/ folder from GitHub issue in current worktree.\n\n    Fetches plan content from GitHub issue, creates/checks out a feature branch,\n    and creates .impl/ folder structure with plan.md, progress.md, and issue.json.\n\n    ISSUE_NUMBER: GitHub issue number containing the plan\n\n    The command:\n    1. Fetches the plan from the GitHub issue or draft PR\n    2. Creates a feature branch from current branch (stacked) or trunk\n    3. Checks out the new branch in the current worktree\n    4. Creates .impl/ folder with plan content\n    5. Saves issue reference for PR linking\n    \"\"\"\n    plan_backend = require_plan_backend(ctx)\n\n    # Dispatch based on plan backend\n    if plan_backend.get_provider_name() == \"github-draft-pr\":\n        output = _setup_draft_pr_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n    else:\n        output = _setup_issue_plan(ctx, issue_number=issue_number, no_impl=no_impl)\n\n    click.echo(json.dumps(output))\n","structuredPatch":[{"oldStart":294,"oldLines":10,"newStart":294,"newLines":12,"lines":["         click.echo(f\"Already on branch for issue #{issue_number}: {current_branch}\", err=True)","         branch_name = current_branch","     else:","-        # Generate branch name from issue","+        # Generate branch name from issue with LLM-generated slug","+        executor = require_prompt_executor(ctx)","+        slug = generate_slug_or_fallback(executor, plan.title)","         timestamp = time.now()","         branch_name = generate_issue_branch_name(","-            issue_number, plan.title, timestamp, objective_id=plan.objective_id","+            issue_number, slug, timestamp, objective_id=plan.objective_id","         )"," ","         # Check if branch already exists"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"f7cc0ab7-d046-4678-905f-cb074cbf5dcd","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_016NebgE8Ttf2e6GuAjtk9hY","type":"message","role":"assistant","content":[{"type":"text","text":"**Site 5: plan_migrate_to_draft_pr.py**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":334,"cache_read_input_tokens":95284,"cache_creation":{"ephemeral_5m_input_tokens":334,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHLM7XpLdRie8UZLrFq","type":"assistant","uuid":"ea989e59-d60a-4ce1-99dd-64104234bc40","timestamp":"2026-02-22T14:41:30.123Z"}
{"parentUuid":"ea989e59-d60a-4ce1-99dd-64104234bc40","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_016NebgE8Ttf2e6GuAjtk9hY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MUPqYvwyQiBUEaA5G3sV2t","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py","old_string":"from erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_repo_root,\n    require_time,\n)","new_string":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":334,"cache_read_input_tokens":95284,"cache_creation":{"ephemeral_5m_input_tokens":334,"ephemeral_1h_input_tokens":0},"output_tokens":6,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHLM7XpLdRie8UZLrFq","type":"assistant","uuid":"6e62c2cb-bbbf-4c12-b854-f70f1e372787","timestamp":"2026-02-22T14:41:32.027Z"}
{"parentUuid":"6e62c2cb-bbbf-4c12-b854-f70f1e372787","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MUPqYvwyQiBUEaA5G3sV2t","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py has been updated successfully."}]},"uuid":"f2474673-00b1-4cdc-87c9-5e68438173ea","timestamp":"2026-02-22T14:41:32.710Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py","oldString":"from erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_repo_root,\n    require_time,\n)","newString":"from erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)","originalFile":"\"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\nReads an existing erk-plan GitHub issue, creates a draft PR using the\ndraft_pr backend, then closes the original issue with a migration notice.\n\nUsage:\n    erk exec plan-migrate-to-draft-pr <issue_number>\n    erk exec plan-migrate-to-draft-pr <issue_number> --dry-run\n    erk exec plan-migrate-to-draft-pr <issue_number> --format display\n\nOptions:\n    --dry-run: Preview the migration without making any changes\n    --format json|display: Output format (default: json)\n\nExit Codes:\n    0: Success\n    1: Error (issue not found, not an erk-plan, etc.)\n\"\"\"\n\nimport json\n\nimport click\n\nfrom erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.github import GitHubPlanStore\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _output_error(output_format: str, message: str, error_type: str) -> None:\n    \"\"\"Emit an error in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"Error: {message}\", err=True)\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": False,\n                    \"error\": error_type,\n                    \"message\": message,\n                }\n            )\n        )\n\n\ndef _output_dry_run(\n    output_format: str,\n    *,\n    issue_number: int,\n    title: str,\n    branch_name: str,\n    trunk: str,\n) -> None:\n    \"\"\"Emit dry-run preview in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"[dry-run] Would migrate issue #{issue_number}: {title}\")\n        click.echo(f\"[dry-run] Would create branch: {branch_name} from {trunk}\")\n        click.echo(\"[dry-run] Would create draft PR from branch\")\n        click.echo(f\"[dry-run] Would close issue #{issue_number}\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"dry_run\": True,\n                    \"original_issue_number\": issue_number,\n                    \"title\": title,\n                    \"branch_name\": branch_name,\n                    \"trunk\": trunk,\n                }\n            )\n        )\n\n\n@click.command(name=\"plan-migrate-to-draft-pr\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--dry-run\",\n    is_flag=True,\n    default=False,\n    help=\"Preview the migration without making any changes\",\n)\n@click.option(\n    \"--format\",\n    \"output_format\",\n    type=click.Choice([\"json\", \"display\"]),\n    default=\"json\",\n    help=\"Output format: json (default) or display (formatted text)\",\n)\n@click.pass_context\ndef plan_migrate_to_draft_pr(\n    ctx: click.Context,\n    issue_number: int,\n    *,\n    dry_run: bool,\n    output_format: str,\n) -> None:\n    \"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\n    Reads the plan from the specified GitHub issue, creates a new draft PR\n    with the same content and metadata, then closes the original issue with\n    a migration notice pointing to the new draft PR.\n\n    Preserves: title, plan content, labels (including erk-learn), objective\n    link, and created_from_session from the original issue.\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    issues = require_issues(ctx)\n    now = require_time(ctx).now()\n\n    # Fetch the issue plan via GitHubPlanStore\n    issue_store = GitHubPlanStore(issues)\n    plan = issue_store.get_plan(repo_root, str(issue_number))\n    if isinstance(plan, PlanNotFound):\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} not found\",\n            \"issue_not_found\",\n        )\n        raise SystemExit(1)\n\n    # Validate it has the erk-plan label\n    if \"erk-plan\" not in plan.labels:\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} does not have the 'erk-plan' label\",\n            \"not_an_erk_plan\",\n        )\n        raise SystemExit(1)\n\n    # Generate draft-PR branch name from trunk\n    trunk = git.branch.detect_trunk_branch(cwd)\n    branch_name = generate_draft_pr_branch_name(\n        plan.title,\n        now,\n        objective_id=plan.objective_id,\n    )\n\n    if dry_run:\n        _output_dry_run(\n            output_format,\n            issue_number=issue_number,\n            title=plan.title,\n            branch_name=branch_name,\n            trunk=trunk,\n        )\n        return\n\n    # Save current branch so we can restore after checkout dance\n    current_branch = git.branch.get_current_branch(cwd)\n    restore_branch = current_branch or \"HEAD\"\n\n    # Create branch from trunk, commit plan file, push\n    git.branch.create_branch(cwd, branch_name, trunk, force=False)\n    git.branch.checkout_branch(cwd, branch_name)\n    try:\n        impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n        impl_context_dir.mkdir(parents=True, exist_ok=True)\n        plan_file = impl_context_dir / \"plan.md\"\n        plan_file.write_text(plan.body, encoding=\"utf-8\")\n        git.commit.stage_files(repo_root, [f\"{IMPL_CONTEXT_DIR}/plan.md\"])\n        git.commit.commit(repo_root, f\"Add plan: {plan.title}\")\n        git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n    finally:\n        git.branch.checkout_branch(cwd, restore_branch)\n\n    # Build metadata for draft PR, preserving key fields from original issue\n    created_from_session = plan.header_fields.get(\"created_from_session\")\n    metadata: dict[str, object] = {\n        k: v\n        for k, v in {\n            \"branch_name\": branch_name,\n            \"trunk_branch\": trunk,\n            \"objective_issue\": plan.objective_id,\n            \"created_from_session\": created_from_session,\n        }.items()\n        if v is not None\n    }\n\n    # Create draft PR via DraftPRPlanBackend\n    draft_backend = DraftPRPlanBackend(github, issues, time=require_time(ctx))\n    result = draft_backend.create_plan(\n        repo_root=repo_root,\n        title=plan.title,\n        content=plan.body,\n        labels=tuple(plan.labels),\n        metadata=metadata,\n    )\n    pr_number = int(result.plan_id)\n    pr_url = result.url\n\n    # Carry over operational metadata from the source issue's plan-header.\n    # create_plan sets these to None; update_metadata restores historical data.\n    _FIELDS_HANDLED_BY_CREATE = {\n        \"schema_version\",\n        \"created_at\",\n        \"created_by\",\n        \"branch_name\",\n        \"plan_comment_id\",\n        \"source_repo\",\n        \"objective_issue\",\n        \"created_from_session\",\n        \"created_from_workflow_run_url\",\n    }\n    operational_fields: dict[str, object] = {\n        k: v\n        for k, v in plan.header_fields.items()\n        if k not in _FIELDS_HANDLED_BY_CREATE and v is not None\n    }\n    if operational_fields:\n        draft_backend.update_metadata(repo_root, str(pr_number), operational_fields)\n\n    # Comment on original issue with migration notice, then close it\n    migration_comment = (\n        f\"Migrated to draft PR #{pr_number}: {pr_url}\\n\\n\"\n        \"This issue has been superseded by the draft PR above.\"\n    )\n    issues.add_comment(repo_root, issue_number, migration_comment)\n    issues.close_issue(repo_root, issue_number)\n\n    if output_format == \"display\":\n        click.echo(f\"Migrated plan #{issue_number} → draft PR #{pr_number}\")\n        click.echo(f\"Title: {plan.title}\")\n        click.echo(f\"PR URL: {pr_url}\")\n        click.echo(f\"Branch: {branch_name}\")\n        click.echo(f\"Original issue #{issue_number} closed.\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"original_issue_number\": issue_number,\n                    \"pr_number\": pr_number,\n                    \"pr_url\": pr_url,\n                    \"branch_name\": branch_name,\n                }\n            )\n        )\n","structuredPatch":[{"oldStart":21,"oldLines":11,"newStart":21,"newLines":13,"lines":[" "," import click"," ","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk_shared.context.helpers import (","     require_cwd,","     require_git,","     require_github,","     require_issues,","+    require_prompt_executor,","     require_repo_root,","     require_time,"," )"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"f2474673-00b1-4cdc-87c9-5e68438173ea","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_012kDeeBh1Nie7Hq4bMD9Y31","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GUd3H8Go8zVB5JQGNoijoX","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py","old_string":"    # Generate draft-PR branch name from trunk\n    trunk = git.branch.detect_trunk_branch(cwd)\n    branch_name = generate_draft_pr_branch_name(\n        plan.title,\n        now,\n        objective_id=plan.objective_id,\n    )","new_string":"    # Generate draft-PR branch name from trunk with LLM-generated slug\n    trunk = git.branch.detect_trunk_branch(cwd)\n    executor = require_prompt_executor(ctx)\n    slug = generate_slug_or_fallback(executor, plan.title)\n    branch_name = generate_draft_pr_branch_name(\n        slug,\n        now,\n        objective_id=plan.objective_id,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":522,"cache_read_input_tokens":95618,"cache_creation":{"ephemeral_5m_input_tokens":522,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHLiZ827RsokLqHgSkY","type":"assistant","uuid":"efc590ed-4ec2-42b1-89bd-2978312ea0d8","timestamp":"2026-02-22T14:41:37.975Z"}
{"parentUuid":"efc590ed-4ec2-42b1-89bd-2978312ea0d8","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GUd3H8Go8zVB5JQGNoijoX","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py has been updated successfully."}]},"uuid":"770a7761-eb3c-4835-aff4-74bd41f5af35","timestamp":"2026-02-22T14:41:38.648Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py","oldString":"    # Generate draft-PR branch name from trunk\n    trunk = git.branch.detect_trunk_branch(cwd)\n    branch_name = generate_draft_pr_branch_name(\n        plan.title,\n        now,\n        objective_id=plan.objective_id,\n    )","newString":"    # Generate draft-PR branch name from trunk with LLM-generated slug\n    trunk = git.branch.detect_trunk_branch(cwd)\n    executor = require_prompt_executor(ctx)\n    slug = generate_slug_or_fallback(executor, plan.title)\n    branch_name = generate_draft_pr_branch_name(\n        slug,\n        now,\n        objective_id=plan.objective_id,\n    )","originalFile":"\"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\nReads an existing erk-plan GitHub issue, creates a draft PR using the\ndraft_pr backend, then closes the original issue with a migration notice.\n\nUsage:\n    erk exec plan-migrate-to-draft-pr <issue_number>\n    erk exec plan-migrate-to-draft-pr <issue_number> --dry-run\n    erk exec plan-migrate-to-draft-pr <issue_number> --format display\n\nOptions:\n    --dry-run: Preview the migration without making any changes\n    --format json|display: Output format (default: json)\n\nExit Codes:\n    0: Success\n    1: Error (issue not found, not an erk-plan, etc.)\n\"\"\"\n\nimport json\n\nimport click\n\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.context.helpers import (\n    require_cwd,\n    require_git,\n    require_github,\n    require_issues,\n    require_prompt_executor,\n    require_repo_root,\n    require_time,\n)\nfrom erk_shared.naming import generate_draft_pr_branch_name\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom erk_shared.plan_store.draft_pr_lifecycle import IMPL_CONTEXT_DIR\nfrom erk_shared.plan_store.github import GitHubPlanStore\nfrom erk_shared.plan_store.types import PlanNotFound\n\n\ndef _output_error(output_format: str, message: str, error_type: str) -> None:\n    \"\"\"Emit an error in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"Error: {message}\", err=True)\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": False,\n                    \"error\": error_type,\n                    \"message\": message,\n                }\n            )\n        )\n\n\ndef _output_dry_run(\n    output_format: str,\n    *,\n    issue_number: int,\n    title: str,\n    branch_name: str,\n    trunk: str,\n) -> None:\n    \"\"\"Emit dry-run preview in the requested format.\"\"\"\n    if output_format == \"display\":\n        click.echo(f\"[dry-run] Would migrate issue #{issue_number}: {title}\")\n        click.echo(f\"[dry-run] Would create branch: {branch_name} from {trunk}\")\n        click.echo(\"[dry-run] Would create draft PR from branch\")\n        click.echo(f\"[dry-run] Would close issue #{issue_number}\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"dry_run\": True,\n                    \"original_issue_number\": issue_number,\n                    \"title\": title,\n                    \"branch_name\": branch_name,\n                    \"trunk\": trunk,\n                }\n            )\n        )\n\n\n@click.command(name=\"plan-migrate-to-draft-pr\")\n@click.argument(\"issue_number\", type=int)\n@click.option(\n    \"--dry-run\",\n    is_flag=True,\n    default=False,\n    help=\"Preview the migration without making any changes\",\n)\n@click.option(\n    \"--format\",\n    \"output_format\",\n    type=click.Choice([\"json\", \"display\"]),\n    default=\"json\",\n    help=\"Output format: json (default) or display (formatted text)\",\n)\n@click.pass_context\ndef plan_migrate_to_draft_pr(\n    ctx: click.Context,\n    issue_number: int,\n    *,\n    dry_run: bool,\n    output_format: str,\n) -> None:\n    \"\"\"Migrate an issue-based plan to a draft-PR-based plan.\n\n    Reads the plan from the specified GitHub issue, creates a new draft PR\n    with the same content and metadata, then closes the original issue with\n    a migration notice pointing to the new draft PR.\n\n    Preserves: title, plan content, labels (including erk-learn), objective\n    link, and created_from_session from the original issue.\n    \"\"\"\n    repo_root = require_repo_root(ctx)\n    cwd = require_cwd(ctx)\n    git = require_git(ctx)\n    github = require_github(ctx)\n    issues = require_issues(ctx)\n    now = require_time(ctx).now()\n\n    # Fetch the issue plan via GitHubPlanStore\n    issue_store = GitHubPlanStore(issues)\n    plan = issue_store.get_plan(repo_root, str(issue_number))\n    if isinstance(plan, PlanNotFound):\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} not found\",\n            \"issue_not_found\",\n        )\n        raise SystemExit(1)\n\n    # Validate it has the erk-plan label\n    if \"erk-plan\" not in plan.labels:\n        _output_error(\n            output_format,\n            f\"Issue #{issue_number} does not have the 'erk-plan' label\",\n            \"not_an_erk_plan\",\n        )\n        raise SystemExit(1)\n\n    # Generate draft-PR branch name from trunk\n    trunk = git.branch.detect_trunk_branch(cwd)\n    branch_name = generate_draft_pr_branch_name(\n        plan.title,\n        now,\n        objective_id=plan.objective_id,\n    )\n\n    if dry_run:\n        _output_dry_run(\n            output_format,\n            issue_number=issue_number,\n            title=plan.title,\n            branch_name=branch_name,\n            trunk=trunk,\n        )\n        return\n\n    # Save current branch so we can restore after checkout dance\n    current_branch = git.branch.get_current_branch(cwd)\n    restore_branch = current_branch or \"HEAD\"\n\n    # Create branch from trunk, commit plan file, push\n    git.branch.create_branch(cwd, branch_name, trunk, force=False)\n    git.branch.checkout_branch(cwd, branch_name)\n    try:\n        impl_context_dir = repo_root / IMPL_CONTEXT_DIR\n        impl_context_dir.mkdir(parents=True, exist_ok=True)\n        plan_file = impl_context_dir / \"plan.md\"\n        plan_file.write_text(plan.body, encoding=\"utf-8\")\n        git.commit.stage_files(repo_root, [f\"{IMPL_CONTEXT_DIR}/plan.md\"])\n        git.commit.commit(repo_root, f\"Add plan: {plan.title}\")\n        git.remote.push_to_remote(cwd, \"origin\", branch_name, set_upstream=True, force=False)\n    finally:\n        git.branch.checkout_branch(cwd, restore_branch)\n\n    # Build metadata for draft PR, preserving key fields from original issue\n    created_from_session = plan.header_fields.get(\"created_from_session\")\n    metadata: dict[str, object] = {\n        k: v\n        for k, v in {\n            \"branch_name\": branch_name,\n            \"trunk_branch\": trunk,\n            \"objective_issue\": plan.objective_id,\n            \"created_from_session\": created_from_session,\n        }.items()\n        if v is not None\n    }\n\n    # Create draft PR via DraftPRPlanBackend\n    draft_backend = DraftPRPlanBackend(github, issues, time=require_time(ctx))\n    result = draft_backend.create_plan(\n        repo_root=repo_root,\n        title=plan.title,\n        content=plan.body,\n        labels=tuple(plan.labels),\n        metadata=metadata,\n    )\n    pr_number = int(result.plan_id)\n    pr_url = result.url\n\n    # Carry over operational metadata from the source issue's plan-header.\n    # create_plan sets these to None; update_metadata restores historical data.\n    _FIELDS_HANDLED_BY_CREATE = {\n        \"schema_version\",\n        \"created_at\",\n        \"created_by\",\n        \"branch_name\",\n        \"plan_comment_id\",\n        \"source_repo\",\n        \"objective_issue\",\n        \"created_from_session\",\n        \"created_from_workflow_run_url\",\n    }\n    operational_fields: dict[str, object] = {\n        k: v\n        for k, v in plan.header_fields.items()\n        if k not in _FIELDS_HANDLED_BY_CREATE and v is not None\n    }\n    if operational_fields:\n        draft_backend.update_metadata(repo_root, str(pr_number), operational_fields)\n\n    # Comment on original issue with migration notice, then close it\n    migration_comment = (\n        f\"Migrated to draft PR #{pr_number}: {pr_url}\\n\\n\"\n        \"This issue has been superseded by the draft PR above.\"\n    )\n    issues.add_comment(repo_root, issue_number, migration_comment)\n    issues.close_issue(repo_root, issue_number)\n\n    if output_format == \"display\":\n        click.echo(f\"Migrated plan #{issue_number} → draft PR #{pr_number}\")\n        click.echo(f\"Title: {plan.title}\")\n        click.echo(f\"PR URL: {pr_url}\")\n        click.echo(f\"Branch: {branch_name}\")\n        click.echo(f\"Original issue #{issue_number} closed.\")\n    else:\n        click.echo(\n            json.dumps(\n                {\n                    \"success\": True,\n                    \"original_issue_number\": issue_number,\n                    \"pr_number\": pr_number,\n                    \"pr_url\": pr_url,\n                    \"branch_name\": branch_name,\n                }\n            )\n        )\n","structuredPatch":[{"oldStart":142,"oldLines":10,"newStart":142,"newLines":12,"lines":["         )","         raise SystemExit(1)"," ","-    # Generate draft-PR branch name from trunk","+    # Generate draft-PR branch name from trunk with LLM-generated slug","     trunk = git.branch.detect_trunk_branch(cwd)","+    executor = require_prompt_executor(ctx)","+    slug = generate_slug_or_fallback(executor, plan.title)","     branch_name = generate_draft_pr_branch_name(","-        plan.title,","+        slug,","         now,","         objective_id=plan.objective_id,","     )"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"770a7761-eb3c-4835-aff4-74bd41f5af35","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01GZhfXQsS6jYeqYb3shWQZH","type":"message","role":"assistant","content":[{"type":"text","text":"Now I need to verify that `require_prompt_executor` exists in the helpers module:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":352,"cache_read_input_tokens":96140,"cache_creation":{"ephemeral_5m_input_tokens":352,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHM9w79NkYteZpAnbgV","type":"assistant","uuid":"9ca10ea0-99f3-444e-893f-e11fd7198cea","timestamp":"2026-02-22T14:41:41.316Z"}
{"parentUuid":"9ca10ea0-99f3-444e-893f-e11fd7198cea","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01GZhfXQsS6jYeqYb3shWQZH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Kpr3hjJdoG4KDWEaVzkETg","name":"Grep","input":{"pattern":"require_prompt_executor","path":"/home/runner/work/erk/erk/packages/erk-shared/src/erk_shared/context/helpers.py","output_mode":"content","-A":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":352,"cache_read_input_tokens":96140,"cache_creation":{"ephemeral_5m_input_tokens":352,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHM9w79NkYteZpAnbgV","type":"assistant","uuid":"5e93929c-2b46-41d5-835d-855b5918b187","timestamp":"2026-02-22T14:41:42.485Z"}
{"parentUuid":"5e93929c-2b46-41d5-835d-855b5918b187","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Kpr3hjJdoG4KDWEaVzkETg","type":"tool_result","content":"304:def require_prompt_executor(ctx: click.Context) -> PromptExecutor:\n305-    \"\"\"Get PromptExecutor from context, exiting with error if not initialized.\n306-\n307-    Uses LBYL pattern to check context before accessing.\n308-\n309-    Args:\n310-        ctx: Click context (must have ErkContext in ctx.obj)\n311-\n312-    Returns:\n313-        PromptExecutor instance from context\n314-\n--\n322:        ...     executor = require_prompt_executor(ctx)\n323-        ...     result = executor.execute_prompt(\"Generate summary\", model=\"haiku\")\n324-    \"\"\"\n325-    if ctx.obj is None:\n326-        click.echo(\"Error: Context not initialized\", err=True)\n327-        raise SystemExit(1)\n328-\n329-    return ctx.obj.prompt_executor\n330-\n331-\n332-def require_local_config(ctx: click.Context) -> LoadedConfig:"}]},"uuid":"69f79d4d-2e43-4fa2-bfe7-d63081d0d69e","timestamp":"2026-02-22T14:41:42.915Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"304:def require_prompt_executor(ctx: click.Context) -> PromptExecutor:\n305-    \"\"\"Get PromptExecutor from context, exiting with error if not initialized.\n306-\n307-    Uses LBYL pattern to check context before accessing.\n308-\n309-    Args:\n310-        ctx: Click context (must have ErkContext in ctx.obj)\n311-\n312-    Returns:\n313-        PromptExecutor instance from context\n314-\n--\n322:        ...     executor = require_prompt_executor(ctx)\n323-        ...     result = executor.execute_prompt(\"Generate summary\", model=\"haiku\")\n324-    \"\"\"\n325-    if ctx.obj is None:\n326-        click.echo(\"Error: Context not initialized\", err=True)\n327-        raise SystemExit(1)\n328-\n329-    return ctx.obj.prompt_executor\n330-\n331-\n332-def require_local_config(ctx: click.Context) -> LoadedConfig:","numLines":23}}
{"parentUuid":"69f79d4d-2e43-4fa2-bfe7-d63081d0d69e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01RJjYhxg8FUjqgsje9sPrPZ","type":"message","role":"assistant","content":[{"type":"text","text":"`require_prompt_executor` exists. Now let me also check if there are any callers of `generate_branch_name` that I need to update:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":607,"cache_read_input_tokens":96492,"cache_creation":{"ephemeral_5m_input_tokens":607,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHMUBTkViyGHtifdHPh","type":"assistant","uuid":"4b213e63-0f41-4afa-ab9e-c438de48fed4","timestamp":"2026-02-22T14:41:46.494Z"}
{"parentUuid":"4b213e63-0f41-4afa-ab9e-c438de48fed4","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01RJjYhxg8FUjqgsje9sPrPZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HPk9spZJ7FTdfCXPL2yGUK","name":"Grep","input":{"pattern":"generate_branch_name\\(","path":"/home/runner/work/erk/erk/src","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":607,"cache_read_input_tokens":96492,"cache_creation":{"ephemeral_5m_input_tokens":607,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHMUBTkViyGHtifdHPh","type":"assistant","uuid":"f6422052-98a4-452b-a636-62c5305aecf4","timestamp":"2026-02-22T14:41:47.088Z"}
{"parentUuid":"f6422052-98a4-452b-a636-62c5305aecf4","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HPk9spZJ7FTdfCXPL2yGUK","type":"tool_result","content":"src/erk/cli/commands/one_shot_dispatch.py:61:def generate_branch_name(\nsrc/erk/cli/commands/one_shot_dispatch.py:151:        branch_name = generate_branch_name(\nsrc/erk/cli/commands/one_shot_dispatch.py:215:        branch_name = generate_branch_name("}]},"uuid":"ec2d4d84-a377-4657-bd09-657d35d1bd67","timestamp":"2026-02-22T14:41:47.594Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"src/erk/cli/commands/one_shot_dispatch.py:61:def generate_branch_name(\nsrc/erk/cli/commands/one_shot_dispatch.py:151:        branch_name = generate_branch_name(\nsrc/erk/cli/commands/one_shot_dispatch.py:215:        branch_name = generate_branch_name(","numLines":3}}
{"parentUuid":"ec2d4d84-a377-4657-bd09-657d35d1bd67","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01CKB52ue9o8DfpsQ5Ze3iMh","type":"message","role":"assistant","content":[{"type":"text","text":"Good, only the two call sites I already updated. Let me also check for callers in tests:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":242,"cache_read_input_tokens":97099,"cache_creation":{"ephemeral_5m_input_tokens":242,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHMpBjVLzjusqVWMkT6","type":"assistant","uuid":"dd4c8a59-6154-49e4-aa57-2263785cd780","timestamp":"2026-02-22T14:41:50.721Z"}
{"parentUuid":"dd4c8a59-6154-49e4-aa57-2263785cd780","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01CKB52ue9o8DfpsQ5Ze3iMh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MCKwi1TT72SXcL1bcv7Abe","name":"Grep","input":{"pattern":"from erk.cli.commands.one_shot_dispatch import generate_branch_name","path":"/home/runner/work/erk/erk/tests","output_mode":"files_with_matches"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":242,"cache_read_input_tokens":97099,"cache_creation":{"ephemeral_5m_input_tokens":242,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHMpBjVLzjusqVWMkT6","type":"assistant","uuid":"c2597736-6c54-41b0-89d3-71fb34b80497","timestamp":"2026-02-22T14:41:51.247Z"}
{"parentUuid":"c2597736-6c54-41b0-89d3-71fb34b80497","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MCKwi1TT72SXcL1bcv7Abe","type":"tool_result","content":"Found 1 file\ntests/commands/one_shot/test_branch_name.py"}]},"uuid":"53dcdf1b-a7e3-41a9-929b-a20e907a8a95","timestamp":"2026-02-22T14:41:51.692Z","toolUseResult":{"mode":"files_with_matches","filenames":["tests/commands/one_shot/test_branch_name.py"],"numFiles":1}}
{"parentUuid":"53dcdf1b-a7e3-41a9-929b-a20e907a8a95","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01VizeDzfEFP2fWNBE6ddsno","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018di8756xxXswHnSnFtq2wC","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":370,"cache_read_input_tokens":97341,"cache_creation":{"ephemeral_5m_input_tokens":370,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHN7hgwnZFmiHx287uX","type":"assistant","uuid":"79b1dafc-599a-4c07-a1ff-2fed1e42471e","timestamp":"2026-02-22T14:41:54.261Z"}
{"parentUuid":"79b1dafc-599a-4c07-a1ff-2fed1e42471e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018di8756xxXswHnSnFtq2wC","type":"tool_result","content":"     1→\"\"\"Tests for one-shot branch name generation.\"\"\"\n     2→\n     3→import re\n     4→\n     5→from erk.cli.commands.one_shot_dispatch import generate_branch_name\n     6→from erk_shared.gateway.time.fake import FakeTime\n     7→\n     8→\n     9→def test_generate_branch_name_basic() -> None:\n    10→    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    11→    name = generate_branch_name(\n    12→        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    13→    )\n    14→    assert name.startswith(\"oneshot-fix-the-import-\")\n    15→    # Should end with timestamp pattern -MM-DD-HHMM\n    16→    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n    17→\n    18→\n    19→def test_generate_branch_name_sanitizes_special_chars() -> None:\n    20→    \"\"\"Test that special characters are sanitized.\"\"\"\n    21→    name = generate_branch_name(\n    22→        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    23→    )\n    24→    assert name.startswith(\"oneshot-\")\n    25→    # No special characters in the branch name (except hyphens and digits)\n    26→    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n    27→\n    28→\n    29→def test_generate_branch_name_truncates_long_prompt() -> None:\n    30→    \"\"\"Test that long prompts are truncated.\"\"\"\n    31→    long_prompt = \"a\" * 100\n    32→    name = generate_branch_name(\n    33→        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    34→    )\n    35→    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    36→    assert len(name) <= 50\n    37→\n    38→\n    39→def test_generate_branch_name_with_plan_issue_number() -> None:\n    40→    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    41→    name = generate_branch_name(\n    42→        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    43→    )\n    44→    assert name.startswith(\"P42-fix-the-import-\")\n    45→    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n    46→\n    47→\n    48→def test_generate_branch_name_with_large_plan_issue_number() -> None:\n    49→    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    50→    name = generate_branch_name(\n    51→        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    52→    )\n    53→    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    54→    assert name.startswith(\"P12345-\")\n    55→    assert len(name) <= 50\n    56→\n    57→\n    58→def test_generate_branch_name_with_objective_id() -> None:\n    59→    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    60→    name = generate_branch_name(\n    61→        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    62→    )\n    63→    assert name.startswith(\"P42-O100-\")\n    64→    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n    65→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"f2b206b3-e980-4666-8acf-9792200ab758","timestamp":"2026-02-22T14:41:54.276Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","content":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","numLines":65,"startLine":1,"totalLines":65}}}
{"parentUuid":"f2b206b3-e980-4666-8acf-9792200ab758","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014hHZQAPWsrBGfmF2vkirCo","type":"message","role":"assistant","content":[{"type":"text","text":"These tests need to be updated to pass the new `prompt_executor` parameter. Since these tests test the raw slugification (not LLM), they should pass `None`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1243,"cache_read_input_tokens":97711,"cache_creation":{"ephemeral_5m_input_tokens":1243,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHNJkhaQwFxwZT4P38W","type":"assistant","uuid":"4251ade3-5b85-434b-964b-3192a1e9448c","timestamp":"2026-02-22T14:41:57.887Z"}
{"parentUuid":"4251ade3-5b85-434b-964b-3192a1e9448c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014hHZQAPWsrBGfmF2vkirCo","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CKdig1RxyvK2bufBdn8qAr","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","new_string":"def test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1243,"cache_read_input_tokens":97711,"cache_creation":{"ephemeral_5m_input_tokens":1243,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHNJkhaQwFxwZT4P38W","type":"assistant","uuid":"51ccbe86-78aa-478c-bcca-1044c1d9b21d","timestamp":"2026-02-22T14:41:59.918Z"}
{"parentUuid":"51ccbe86-78aa-478c-bcca-1044c1d9b21d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CKdig1RxyvK2bufBdn8qAr","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"e8b797c9-f7a6-4e23-8545-a1011b4f65e2","timestamp":"2026-02-22T14:42:00.585Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","newString":"def test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":9,"oldLines":7,"newStart":9,"newLines":11,"lines":[" def test_generate_branch_name_basic() -> None:","     \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"","     name = generate_branch_name(","-        \"fix the import\", time=FakeTime(), plan_issue_number=None, objective_id=None","+        \"fix the import\",","+        time=FakeTime(),","+        plan_issue_number=None,","+        objective_id=None,","+        prompt_executor=None,","     )","     assert name.startswith(\"oneshot-fix-the-import-\")","     # Should end with timestamp pattern -MM-DD-HHMM"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"e8b797c9-f7a6-4e23-8545-a1011b4f65e2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01S1CqVExTCQXitxvTTGQAGz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017j5mwm8aP3az4QbSBjztou","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","new_string":"def test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":552,"cache_read_input_tokens":98954,"cache_creation":{"ephemeral_5m_input_tokens":552,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHNmjBLBHsa2Gsrj6fV","type":"assistant","uuid":"17da5c1a-6376-461a-8938-56d67d30925a","timestamp":"2026-02-22T14:42:04.917Z"}
{"parentUuid":"17da5c1a-6376-461a-8938-56d67d30925a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017j5mwm8aP3az4QbSBjztou","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"7c18adbe-f8c1-4bdc-9ffb-9061ef47f569","timestamp":"2026-02-22T14:42:05.591Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","newString":"def test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":23,"oldLines":7,"newStart":23,"newLines":11,"lines":[" def test_generate_branch_name_sanitizes_special_chars() -> None:","     \"\"\"Test that special characters are sanitized.\"\"\"","     name = generate_branch_name(","-        \"Fix: Bug #123!\", time=FakeTime(), plan_issue_number=None, objective_id=None","+        \"Fix: Bug #123!\",","+        time=FakeTime(),","+        plan_issue_number=None,","+        objective_id=None,","+        prompt_executor=None,","     )","     assert name.startswith(\"oneshot-\")","     # No special characters in the branch name (except hyphens and digits)"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"7c18adbe-f8c1-4bdc-9ffb-9061ef47f569","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01VMCwEXtnaRcjBoWbbqTW3s","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01TpS4sKbT1ppWuJ5CSPr7Sy","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","new_string":"def test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt,\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":320,"cache_read_input_tokens":99506,"cache_creation":{"ephemeral_5m_input_tokens":320,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHP9A2Lqzq9ezD9dhTW","type":"assistant","uuid":"d5b61804-3dfb-44cf-8740-14ba0ecf2130","timestamp":"2026-02-22T14:42:09.955Z"}
{"parentUuid":"d5b61804-3dfb-44cf-8740-14ba0ecf2130","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01TpS4sKbT1ppWuJ5CSPr7Sy","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"34922f55-3e62-4894-a016-61f11e06ba90","timestamp":"2026-02-22T14:42:10.616Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )","newString":"def test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt,\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":38,"oldLines":7,"newStart":38,"newLines":11,"lines":["     \"\"\"Test that long prompts are truncated.\"\"\"","     long_prompt = \"a\" * 100","     name = generate_branch_name(","-        long_prompt, time=FakeTime(), plan_issue_number=None, objective_id=None","+        long_prompt,","+        time=FakeTime(),","+        plan_issue_number=None,","+        objective_id=None,","+        prompt_executor=None,","     )","     # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)","     assert len(name) <= 50"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"34922f55-3e62-4894-a016-61f11e06ba90","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01RTicyYhainxcRuHLNuvXHy","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017Evg98YNKSgaJNnQdQQy4i","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )","new_string":"def test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=None,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":339,"cache_read_input_tokens":99826,"cache_creation":{"ephemeral_5m_input_tokens":339,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHPWbctRU6HyG2gRvXg","type":"assistant","uuid":"d03c6728-c58a-47d4-a392-60c1ffb1ee80","timestamp":"2026-02-22T14:42:15.044Z"}
{"parentUuid":"d03c6728-c58a-47d4-a392-60c1ffb1ee80","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017Evg98YNKSgaJNnQdQQy4i","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"2e3706d1-5603-4cd1-806b-ebe8854142d7","timestamp":"2026-02-22T14:42:15.722Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )","newString":"def test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=None,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt,\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":51,"oldLines":7,"newStart":51,"newLines":11,"lines":[" def test_generate_branch_name_with_plan_issue_number() -> None:","     \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"","     name = generate_branch_name(","-        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=None","+        \"fix the import\",","+        time=FakeTime(),","+        plan_issue_number=42,","+        objective_id=None,","+        prompt_executor=None,","     )","     assert name.startswith(\"P42-fix-the-import-\")","     assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"2e3706d1-5603-4cd1-806b-ebe8854142d7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01McN63Ae3q2qSEMAAXKstDw","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017G7aXGTmsFScAUkHqcrdR2","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )","new_string":"def test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100,\n        time=FakeTime(),\n        plan_issue_number=12345,\n        objective_id=None,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":532,"cache_read_input_tokens":100165,"cache_creation":{"ephemeral_5m_input_tokens":532,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHPtUkfvzmJNctmxfF3","type":"assistant","uuid":"82ba2e48-e6fa-4729-9c4e-e192663600b1","timestamp":"2026-02-22T14:42:20.093Z"}
{"parentUuid":"82ba2e48-e6fa-4729-9c4e-e192663600b1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017G7aXGTmsFScAUkHqcrdR2","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"aade48cf-7c7f-40a1-8a74-a8cd31cf2cb2","timestamp":"2026-02-22T14:42:20.759Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )","newString":"def test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100,\n        time=FakeTime(),\n        plan_issue_number=12345,\n        objective_id=None,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt,\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":64,"oldLines":7,"newStart":64,"newLines":11,"lines":[" def test_generate_branch_name_with_large_plan_issue_number() -> None:","     \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"","     name = generate_branch_name(","-        \"a\" * 100, time=FakeTime(), plan_issue_number=12345, objective_id=None","+        \"a\" * 100,","+        time=FakeTime(),","+        plan_issue_number=12345,","+        objective_id=None,","+        prompt_executor=None,","     )","     # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24","     assert name.startswith(\"P12345-\")"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"aade48cf-7c7f-40a1-8a74-a8cd31cf2cb2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_017ebUzR91UXBobMWvKxEid9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QtxQX9PqpFPEsSFZCKb6Qx","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","old_string":"def test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )","new_string":"def test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=100,\n        prompt_executor=None,\n    )"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":341,"cache_read_input_tokens":100697,"cache_creation":{"ephemeral_5m_input_tokens":341,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHQFzZn9iYByfLtfpk5","type":"assistant","uuid":"c7c648c3-8504-4fa2-902e-70842a87e759","timestamp":"2026-02-22T14:42:25.106Z"}
{"parentUuid":"c7c648c3-8504-4fa2-902e-70842a87e759","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QtxQX9PqpFPEsSFZCKb6Qx","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py has been updated successfully."}]},"uuid":"5cafe5d1-dc4e-433d-9b3e-8a74ee8efe44","timestamp":"2026-02-22T14:42:25.785Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_branch_name.py","oldString":"def test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )","newString":"def test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=100,\n        prompt_executor=None,\n    )","originalFile":"\"\"\"Tests for one-shot branch name generation.\"\"\"\n\nimport re\n\nfrom erk.cli.commands.one_shot_dispatch import generate_branch_name\nfrom erk_shared.gateway.time.fake import FakeTime\n\n\ndef test_generate_branch_name_basic() -> None:\n    \"\"\"Test basic branch name generation with no plan issue (oneshot- prefix).\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-fix-the-import-\")\n    # Should end with timestamp pattern -MM-DD-HHMM\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_sanitizes_special_chars() -> None:\n    \"\"\"Test that special characters are sanitized.\"\"\"\n    name = generate_branch_name(\n        \"Fix: Bug #123!\",\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"oneshot-\")\n    # No special characters in the branch name (except hyphens and digits)\n    assert re.match(r\"^oneshot-[a-z0-9-]+-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_truncates_long_prompt() -> None:\n    \"\"\"Test that long prompts are truncated.\"\"\"\n    long_prompt = \"a\" * 100\n    name = generate_branch_name(\n        long_prompt,\n        time=FakeTime(),\n        plan_issue_number=None,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    # Should be bounded in length: oneshot- (8) + slug (max ~23) + timestamp (-MM-DD-HHMM, 10)\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_plan_issue_number() -> None:\n    \"\"\"Test branch name uses P<N>- prefix when plan_issue_number is provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\",\n        time=FakeTime(),\n        plan_issue_number=42,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    assert name.startswith(\"P42-fix-the-import-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n\n\ndef test_generate_branch_name_with_large_plan_issue_number() -> None:\n    \"\"\"Test branch name with a large plan issue number truncates slug appropriately.\"\"\"\n    name = generate_branch_name(\n        \"a\" * 100,\n        time=FakeTime(),\n        plan_issue_number=12345,\n        objective_id=None,\n        prompt_executor=None,\n    )\n    # P12345- is 7 chars, timestamp is 10 chars, total slug space is 31-7=24\n    assert name.startswith(\"P12345-\")\n    assert len(name) <= 50\n\n\ndef test_generate_branch_name_with_objective_id() -> None:\n    \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"\n    name = generate_branch_name(\n        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100\n    )\n    assert name.startswith(\"P42-O100-\")\n    assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None\n","structuredPatch":[{"oldStart":78,"oldLines":7,"newStart":78,"newLines":11,"lines":[" def test_generate_branch_name_with_objective_id() -> None:","     \"\"\"Test branch name encodes O{N} when both plan_issue_number and objective_id are provided.\"\"\"","     name = generate_branch_name(","-        \"fix the import\", time=FakeTime(), plan_issue_number=42, objective_id=100","+        \"fix the import\",","+        time=FakeTime(),","+        plan_issue_number=42,","+        objective_id=100,","+        prompt_executor=None,","     )","     assert name.startswith(\"P42-O100-\")","     assert re.search(r\"-\\d{2}-\\d{2}-\\d{4}$\", name) is not None"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"5cafe5d1-dc4e-433d-9b3e-8a74ee8efe44","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01BTR9fAKRU6oSd7ivdTD7Zm","type":"message","role":"assistant","content":[{"type":"text","text":"All 5 integration sites are done, plus the existing tests are updated. Let me run the full CI check:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":343,"cache_read_input_tokens":101038,"cache_creation":{"ephemeral_5m_input_tokens":343,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHQdTQ1hGzND4v1dVws","type":"assistant","uuid":"44604419-25d5-4b3f-b1d1-85ae6cd17441","timestamp":"2026-02-22T14:42:28.878Z"}
{"parentUuid":"44604419-25d5-4b3f-b1d1-85ae6cd17441","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01BTR9fAKRU6oSd7ivdTD7Zm","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QLPxpz1vLxL46KvDqkc9p1","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"in_progress","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":343,"cache_read_input_tokens":101038,"cache_creation":{"ephemeral_5m_input_tokens":343,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHQdTQ1hGzND4v1dVws","type":"assistant","uuid":"5ffafedd-f623-49eb-b53e-f5f3b943c037","timestamp":"2026-02-22T14:42:30.751Z"}
{"parentUuid":"5ffafedd-f623-49eb-b53e-f5f3b943c037","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QLPxpz1vLxL46KvDqkc9p1","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"c9ce6633-d225-4fe3-acf5-ad54009bde82","timestamp":"2026-02-22T14:42:30.766Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"in_progress","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"pending","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"in_progress","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}]}}
{"parentUuid":"c9ce6633-d225-4fe3-acf5-ad54009bde82","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01MS8KU48Xd8D3y6yeWXJT13","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01KYb1GTJdiwHgfycNgPX4bG","name":"Task","input":{"description":"Run fast CI checks","prompt":"Run the following CI checks and report all results. Do NOT fix any errors - just report them.\n\n1. Run ruff check on the changed files:\n   - src/erk/core/branch_slug_generator.py\n   - tests/core/test_branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n   - tests/commands/one_shot/test_branch_name.py\n\n2. Run ruff format --check on the same files\n\n3. Run ty check on the changed source files (not tests):\n   - src/erk/core/branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n\n4. Run pytest on the new and modified test files:\n   - tests/core/test_branch_slug_generator.py\n   - tests/commands/one_shot/test_branch_name.py\n\nReport ALL results verbatim.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":282,"cache_read_input_tokens":101381,"cache_creation":{"ephemeral_5m_input_tokens":282,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHQzjpeRbMrPUAXAK4B","type":"assistant","uuid":"dbbf47c4-fec1-4c75-a2e6-77bef00ec767","timestamp":"2026-02-22T14:42:38.784Z"}
{"parentUuid":"dbbf47c4-fec1-4c75-a2e6-77bef00ec767","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01KYb1GTJdiwHgfycNgPX4bG","type":"tool_result","content":[{"type":"text","text":"## CI Check Results\n\n### 1. Ruff Check - FAILED\n\n**4 fixable errors found:**\n\n1. **src/erk/cli/commands/one_shot_dispatch.py:8:1** - I001: Import block is un-sorted or un-formatted\n   - Lines 8-36: Import block needs to be reorganized\n\n2. **src/erk/cli/commands/submit.py:3:1** - I001: Import block is un-sorted or un-formatted\n   - Lines 3-52: Import block needs to be reorganized\n\n3. **src/erk/core/branch_slug_generator.py:14:61** - F401: `PromptResult` imported but unused\n   - Remove `PromptResult` from the import: `from erk_shared.core.prompt_executor import PromptExecutor`\n\n4. **tests/core/test_branch_slug_generator.py:5:5** - F401: `BranchSlugResult` imported but unused\n   - Remove `BranchSlugResult` from the import statement\n\nAll 4 errors are fixable with `ruff check --fix`.\n\n### 2. Ruff Format Check - PASSED\n\n8 files already formatted correctly.\n\n### 3. Type Check (ty) - PASSED\n\nAll checks passed on source files.\n\n### 4. Pytest - PASSED\n\n18 tests passed in 0.58s:\n- tests/core/test_branch_slug_generator.py: 12 tests passed\n- tests/commands/one_shot/test_branch_name.py: 6 tests passed\n\n**Summary:** Ruff linting has 4 fixable issues (import sorting and unused imports), but formatting and type checking are clean. All tests pass."},{"type":"text","text":"agentId: a4ceea4 (for resuming to continue this agent's work if needed)"}]}]},"uuid":"4d08f682-d2bb-4821-9e6f-6d9fb939cd5f","timestamp":"2026-02-22T14:43:09.195Z","toolUseResult":{"status":"completed","prompt":"Run the following CI checks and report all results. Do NOT fix any errors - just report them.\n\n1. Run ruff check on the changed files:\n   - src/erk/core/branch_slug_generator.py\n   - tests/core/test_branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n   - tests/commands/one_shot/test_branch_name.py\n\n2. Run ruff format --check on the same files\n\n3. Run ty check on the changed source files (not tests):\n   - src/erk/core/branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n\n4. Run pytest on the new and modified test files:\n   - tests/core/test_branch_slug_generator.py\n   - tests/commands/one_shot/test_branch_name.py\n\nReport ALL results verbatim.","agentId":"a4ceea4","content":[{"type":"text","text":"## CI Check Results\n\n### 1. Ruff Check - FAILED\n\n**4 fixable errors found:**\n\n1. **src/erk/cli/commands/one_shot_dispatch.py:8:1** - I001: Import block is un-sorted or un-formatted\n   - Lines 8-36: Import block needs to be reorganized\n\n2. **src/erk/cli/commands/submit.py:3:1** - I001: Import block is un-sorted or un-formatted\n   - Lines 3-52: Import block needs to be reorganized\n\n3. **src/erk/core/branch_slug_generator.py:14:61** - F401: `PromptResult` imported but unused\n   - Remove `PromptResult` from the import: `from erk_shared.core.prompt_executor import PromptExecutor`\n\n4. **tests/core/test_branch_slug_generator.py:5:5** - F401: `BranchSlugResult` imported but unused\n   - Remove `BranchSlugResult` from the import statement\n\nAll 4 errors are fixable with `ruff check --fix`.\n\n### 2. Ruff Format Check - PASSED\n\n8 files already formatted correctly.\n\n### 3. Type Check (ty) - PASSED\n\nAll checks passed on source files.\n\n### 4. Pytest - PASSED\n\n18 tests passed in 0.58s:\n- tests/core/test_branch_slug_generator.py: 12 tests passed\n- tests/commands/one_shot/test_branch_name.py: 6 tests passed\n\n**Summary:** Ruff linting has 4 fixable issues (import sorting and unused imports), but formatting and type checking are clean. All tests pass."}],"totalDurationMs":30347,"totalTokens":16241,"totalToolUseCount":4,"usage":{"input_tokens":7,"cache_creation_input_tokens":3150,"cache_read_input_tokens":12668,"cache_creation":{"ephemeral_5m_input_tokens":3150,"ephemeral_1h_input_tokens":0},"output_tokens":416,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"4d08f682-d2bb-4821-9e6f-6d9fb939cd5f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HRdpzcFCMd9JtHapNUEzdD","type":"message","role":"assistant","content":[{"type":"text","text":"4 fixable ruff issues. Let me fix them:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":935,"cache_read_input_tokens":101663,"cache_creation":{"ephemeral_5m_input_tokens":935,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHTq3zL8GeCkqzDnrEz","type":"assistant","uuid":"dd4c252c-9fc5-4f06-adae-7f137f633921","timestamp":"2026-02-22T14:43:11.584Z"}
{"parentUuid":"dd4c252c-9fc5-4f06-adae-7f137f633921","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HRdpzcFCMd9JtHapNUEzdD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HDSUp1uaH6dopxUHoQke2k","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","old_string":"from erk_shared.core.prompt_executor import PromptExecutor, PromptResult","new_string":"from erk_shared.core.prompt_executor import PromptExecutor"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":935,"cache_read_input_tokens":101663,"cache_creation":{"ephemeral_5m_input_tokens":935,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHTq3zL8GeCkqzDnrEz","type":"assistant","uuid":"ff07252b-eb97-44ce-8a74-380dd9388ab3","timestamp":"2026-02-22T14:43:13.217Z"}
{"parentUuid":"ff07252b-eb97-44ce-8a74-380dd9388ab3","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HDSUp1uaH6dopxUHoQke2k","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py has been updated successfully."}]},"uuid":"6d6aff8c-be5c-41e3-84ab-1bc069159b99","timestamp":"2026-02-22T14:43:14.067Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/core/branch_slug_generator.py","oldString":"from erk_shared.core.prompt_executor import PromptExecutor, PromptResult","newString":"from erk_shared.core.prompt_executor import PromptExecutor","originalFile":"\"\"\"Branch slug generation via LLM inference.\n\nThis module provides branch name slug generation using a fast LLM call\nto distill plan/issue titles into meaningful 2-4 word slugs before they\nenter the branch naming pipeline.\n\nFollows the CommitMessageGenerator pattern from src/erk/core/commit_message_generator.py.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom erk_shared.core.prompt_executor import PromptExecutor, PromptResult\nfrom erk_shared.naming import sanitize_worktree_name\n\nBRANCH_SLUG_SYSTEM_PROMPT = \"\"\"\\\nYou are a branch name slug generator. Given a title, return ONLY a concise\n2-4 word slug using lowercase letters and hyphens. No explanation.\n\nRules:\n- Use 2-4 hyphenated words (e.g., \"fix-auth-session\", \"add-plan-validation\")\n- Capture the distinctive essence, not generic words\n- Drop filler words: \"the\", \"a\", \"for\", \"and\", \"implementation\", \"plan\"\n- Prefer verbs: add, fix, refactor, update, consolidate, extract, migrate\n- Never exceed 30 characters total\n- Output ONLY the slug, nothing else\"\"\"\n\n\n@dataclass(frozen=True)\nclass BranchSlugResult:\n    \"\"\"Result of branch slug generation.\n\n    Attributes:\n        success: Whether generation succeeded\n        slug: The generated slug if successful\n        error_message: Error description if generation failed\n    \"\"\"\n\n    success: bool\n    slug: str | None\n    error_message: str | None\n\n\nclass BranchSlugGenerator:\n    \"\"\"Generates branch name slugs via LLM inference.\n\n    This is a concrete class (not ABC) that uses PromptExecutor for\n    testability. In tests, inject FakePromptExecutor with simulated prompt output.\n    \"\"\"\n\n    def __init__(self, executor: PromptExecutor) -> None:\n        self._executor = executor\n\n    def generate(self, title: str) -> BranchSlugResult:\n        \"\"\"Generate a branch slug from a title.\n\n        Sends the title to an LLM with the branch slug system prompt,\n        then validates the output meets slug requirements.\n\n        Args:\n            title: Plan or issue title to distill into a slug\n\n        Returns:\n            BranchSlugResult with success status and slug or error\n        \"\"\"\n        result = self._executor.execute_prompt(\n            title,\n            model=\"haiku\",\n            tools=None,\n            cwd=None,\n            system_prompt=BRANCH_SLUG_SYSTEM_PROMPT,\n            dangerous=False,\n        )\n\n        if not result.success:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=result.error or \"LLM execution failed\",\n            )\n\n        slug = _postprocess_slug(result.output)\n        if slug is None:\n            return BranchSlugResult(\n                success=False,\n                slug=None,\n                error_message=f\"Invalid LLM output: {result.output!r}\",\n            )\n\n        return BranchSlugResult(\n            success=True,\n            slug=slug,\n            error_message=None,\n        )\n\n\ndef _postprocess_slug(raw_output: str) -> str | None:\n    \"\"\"Clean and validate LLM slug output.\n\n    Post-processing steps:\n    1. Strip whitespace\n    2. Strip surrounding quotes and backticks\n    3. Run through sanitize_worktree_name as safety net\n    4. Validate: must have 2+ hyphenated words\n    5. Validate: max 30 characters\n\n    Args:\n        raw_output: Raw LLM output string\n\n    Returns:\n        Validated slug string, or None if invalid\n    \"\"\"\n    stripped = raw_output.strip()\n\n    # Strip surrounding quotes and backticks\n    stripped = stripped.strip(\"\\\"'`\")\n\n    # Run through sanitize_worktree_name as safety net\n    sanitized = sanitize_worktree_name(stripped)\n\n    # Validate: must have 2+ hyphenated words\n    words = sanitized.split(\"-\")\n    if len(words) < 2:\n        return None\n\n    # Validate: max 30 characters\n    if len(sanitized) > 30:\n        return None\n\n    return sanitized\n\n\ndef generate_slug_or_fallback(executor: PromptExecutor, title: str) -> str:\n    \"\"\"Generate a slug from title, falling back to raw title on failure.\n\n    Convenience function that returns the LLM slug on success,\n    or the raw title on failure (so sanitize_worktree_name handles it downstream).\n\n    Args:\n        executor: PromptExecutor for LLM inference\n        title: Plan or issue title\n\n    Returns:\n        LLM-generated slug on success, raw title on failure\n    \"\"\"\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(title)\n    if result.success and result.slug is not None:\n        return result.slug\n    return title\n","structuredPatch":[{"oldStart":11,"oldLines":7,"newStart":11,"newLines":7,"lines":[" "," from dataclasses import dataclass"," ","-from erk_shared.core.prompt_executor import PromptExecutor, PromptResult","+from erk_shared.core.prompt_executor import PromptExecutor"," from erk_shared.naming import sanitize_worktree_name"," "," BRANCH_SLUG_SYSTEM_PROMPT = \"\"\"\\"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"6d6aff8c-be5c-41e3-84ab-1bc069159b99","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01JXrjm6EUNMdppzNr34jscx","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LrtUSxQViktYYy42kt7Cnz","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","old_string":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)","new_string":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    generate_slug_or_fallback,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":213,"cache_read_input_tokens":102598,"cache_creation":{"ephemeral_5m_input_tokens":213,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHUBssxNtvwtKup4tzv","type":"assistant","uuid":"a549b315-7831-4d2a-bbd5-605b2cb52cf0","timestamp":"2026-02-22T14:43:17.687Z"}
{"parentUuid":"a549b315-7831-4d2a-bbd5-605b2cb52cf0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"<tool_use_error>File has not been read yet. Read it first before writing to it.</tool_use_error>","is_error":true,"tool_use_id":"toolu_01LrtUSxQViktYYy42kt7Cnz"}]},"uuid":"19d4ceee-a839-4081-9f25-3fc176cd61f5","timestamp":"2026-02-22T14:43:17.698Z","toolUseResult":"Error: File has not been read yet. Read it first before writing to it."}
{"parentUuid":"19d4ceee-a839-4081-9f25-3fc176cd61f5","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Jjs1Q8rxG3zKCKtqLMWRWZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JSyBhkp5gaG9jxAiXZpjGN","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","limit":10},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":237,"cache_read_input_tokens":102811,"cache_creation":{"ephemeral_5m_input_tokens":237,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHUTTkSF2YvLCGaL3p4","type":"assistant","uuid":"f698d9f6-7f06-498e-ae33-04d796c3b37e","timestamp":"2026-02-22T14:43:20.529Z"}
{"parentUuid":"f698d9f6-7f06-498e-ae33-04d796c3b37e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JSyBhkp5gaG9jxAiXZpjGN","type":"tool_result","content":"     1→\"\"\"Tests for BranchSlugGenerator.\"\"\"\n     2→\n     3→from erk.core.branch_slug_generator import (\n     4→    BranchSlugGenerator,\n     5→    BranchSlugResult,\n     6→    generate_slug_or_fallback,\n     7→)\n     8→from tests.fakes.prompt_executor import FakePromptExecutor\n     9→\n    10→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b24e8088-f11b-46a7-8e00-64a37a25ea7f","timestamp":"2026-02-22T14:43:20.571Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","content":"\"\"\"Tests for BranchSlugGenerator.\"\"\"\n\nfrom erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)\nfrom tests.fakes.prompt_executor import FakePromptExecutor\n\n","numLines":10,"startLine":1,"totalLines":168}}}
{"parentUuid":"b24e8088-f11b-46a7-8e00-64a37a25ea7f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01RZF5gkX4MKPXjnWLJEJCvJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CSYbZwKPRr5mEoJ7fNrz7K","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","old_string":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)","new_string":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    generate_slug_or_fallback,\n)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":292,"cache_read_input_tokens":103048,"cache_creation":{"ephemeral_5m_input_tokens":292,"ephemeral_1h_input_tokens":0},"output_tokens":24,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHUfnfG7mfKsXJkGdvV","type":"assistant","uuid":"1f87b574-e4a5-4632-aaa7-0ff4df5bc653","timestamp":"2026-02-22T14:43:24.816Z"}
{"parentUuid":"1f87b574-e4a5-4632-aaa7-0ff4df5bc653","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CSYbZwKPRr5mEoJ7fNrz7K","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py has been updated successfully."}]},"uuid":"068b2bdc-3e4f-473d-9364-f70f9e7ac48a","timestamp":"2026-02-22T14:43:25.487Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/core/test_branch_slug_generator.py","oldString":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)","newString":"from erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    generate_slug_or_fallback,\n)","originalFile":"\"\"\"Tests for BranchSlugGenerator.\"\"\"\n\nfrom erk.core.branch_slug_generator import (\n    BranchSlugGenerator,\n    BranchSlugResult,\n    generate_slug_or_fallback,\n)\nfrom tests.fakes.prompt_executor import FakePromptExecutor\n\n\ndef test_successful_slug_generation() -> None:\n    \"\"\"Test successful slug generation from a plan title.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"objective-marker-fallback\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Objective Context Marker Fallback\")\n\n    assert result.success is True\n    assert result.slug == \"objective-marker-fallback\"\n    assert result.error_message is None\n\n\ndef test_strips_quotes_from_output() -> None:\n    \"\"\"Test that surrounding quotes are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output='\"fix-auth-session\"',\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Authentication Session Handling\")\n\n    assert result.success is True\n    assert result.slug == \"fix-auth-session\"\n\n\ndef test_strips_backticks_from_output() -> None:\n    \"\"\"Test that surrounding backticks are stripped from LLM output.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"`add-plan-validation`\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Add Plan Validation Gate\")\n\n    assert result.success is True\n    assert result.slug == \"add-plan-validation\"\n\n\ndef test_falls_back_on_executor_failure() -> None:\n    \"\"\"Test that executor failure returns error result.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"Claude CLI not available\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert result.error_message is not None\n\n\ndef test_rejects_single_word_output() -> None:\n    \"\"\"Test that single-word output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"refactor\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Refactor the Gateway Layer\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_rejects_too_long_output() -> None:\n    \"\"\"Test that output exceeding 30 characters is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"this-is-a-very-long-branch-name-that-exceeds-limit\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Very Long Title\")\n\n    assert result.success is False\n    assert result.slug is None\n    assert \"Invalid LLM output\" in (result.error_message or \"\")\n\n\ndef test_generate_slug_or_fallback_returns_slug_on_success() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns slug on success.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug in Login\")\n\n    assert result == \"fix-auth-bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_failure() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title on failure.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"LLM unavailable\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_generate_slug_or_fallback_returns_raw_title_on_invalid_output() -> None:\n    \"\"\"Test that generate_slug_or_fallback returns raw title when LLM output is invalid.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"singleword\",\n    )\n    result = generate_slug_or_fallback(executor, \"Fix Authentication Bug\")\n\n    assert result == \"Fix Authentication Bug\"\n\n\ndef test_uses_haiku_model() -> None:\n    \"\"\"Test that the generator uses the haiku model.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix-auth-bug\",\n    )\n    generator = BranchSlugGenerator(executor)\n    generator.generate(\"Fix Auth Bug\")\n\n    assert len(executor.prompt_calls) == 1\n    # prompt_calls records (prompt, system_prompt, dangerous)\n    prompt, system_prompt, dangerous = executor.prompt_calls[0]\n    assert prompt == \"Fix Auth Bug\"\n    assert system_prompt is not None\n    assert dangerous is False\n\n\ndef test_sanitizes_special_characters() -> None:\n    \"\"\"Test that special characters in LLM output are sanitized.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"fix auth-bug!\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Fix Auth Bug!\")\n\n    assert result.success is True\n    # sanitize_worktree_name handles the special chars\n    assert result.slug == \"fix-auth-bug\"\n\n\ndef test_empty_output_rejected() -> None:\n    \"\"\"Test that empty LLM output is rejected.\"\"\"\n    executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_output=\"\",\n    )\n    generator = BranchSlugGenerator(executor)\n    result = generator.generate(\"Some Title\")\n\n    assert result.success is False\n    assert result.slug is None\n","structuredPatch":[{"oldStart":2,"oldLines":7,"newStart":2,"newLines":6,"lines":[" "," from erk.core.branch_slug_generator import (","     BranchSlugGenerator,","-    BranchSlugResult,","     generate_slug_or_fallback,"," )"," from tests.fakes.prompt_executor import FakePromptExecutor"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"068b2bdc-3e4f-473d-9364-f70f9e7ac48a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Rh3qdMjN1p2JSRoNTadKZd","type":"message","role":"assistant","content":[{"type":"text","text":"Now fix the import sorting issues. Let me read the affected import blocks:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":428,"cache_read_input_tokens":103340,"cache_creation":{"ephemeral_5m_input_tokens":428,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHV5hpxXRDfaW8xuuoE","type":"assistant","uuid":"d30975c3-e790-4db3-9167-69ece073f922","timestamp":"2026-02-22T14:43:31.261Z"}
{"parentUuid":"d30975c3-e790-4db3-9167-69ece073f922","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Rh3qdMjN1p2JSRoNTadKZd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0121FNeskkMTv7V4kCNTVJeY","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","offset":7,"limit":30},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":428,"cache_read_input_tokens":103340,"cache_creation":{"ephemeral_5m_input_tokens":428,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHV5hpxXRDfaW8xuuoE","type":"assistant","uuid":"176f594f-c96d-49e2-ad39-86a89e1b2099","timestamp":"2026-02-22T14:43:32.399Z"}
{"parentUuid":"176f594f-c96d-49e2-ad39-86a89e1b2099","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0121FNeskkMTv7V4kCNTVJeY","type":"tool_result","content":"     7→\n     8→import logging\n     9→from dataclasses import dataclass\n    10→from datetime import UTC\n    11→\n    12→import click\n    13→\n    14→from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\n    15→from erk.cli.ensure import Ensure\n    16→from erk.core.branch_slug_generator import generate_slug_or_fallback\n    17→from erk.core.context import ErkContext, NoRepoSentinel, RepoContext\n    18→from erk_shared.gateway.git.remote_ops.types import PushError\n    19→from erk_shared.gateway.github.metadata.core import (\n    20→    create_submission_queued_block,\n    21→    render_erk_issue_event,\n    22→)\n    23→from erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\n    24→from erk_shared.gateway.github.parsing import construct_workflow_run_url\n    25→from erk_shared.gateway.github.plan_issues import create_plan_issue\n    26→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    27→from erk_shared.gateway.time.abc import Time\n    28→from erk_shared.core.prompt_executor import PromptExecutor\n    29→from erk_shared.naming import (\n    30→    format_branch_timestamp_suffix,\n    31→    generate_draft_pr_branch_name,\n    32→    generate_issue_branch_name,\n    33→    sanitize_worktree_name,\n    34→)\n    35→from erk_shared.output.output import user_output\n    36→from erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"28df518f-fd7b-4994-9f35-f8d17d9eba14","timestamp":"2026-02-22T14:43:32.603Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","content":"\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body","numLines":30,"startLine":7,"totalLines":447}}}
{"parentUuid":"28df518f-fd7b-4994-9f35-f8d17d9eba14","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HY4C8CAMneLpEfgURZkbV3","type":"message","role":"assistant","content":[{"type":"text","text":"The `erk_shared.core.prompt_executor` import is out of order (should be before `erk_shared.gateway`):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":680,"cache_read_input_tokens":103768,"cache_creation":{"ephemeral_5m_input_tokens":680,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHVZC4FahrzeLMw6ih2","type":"assistant","uuid":"141d6732-ded1-430f-b07a-c8e3e8529f91","timestamp":"2026-02-22T14:43:35.448Z"}
{"parentUuid":"141d6732-ded1-430f-b07a-c8e3e8529f91","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HY4C8CAMneLpEfgURZkbV3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012JyuhSwnXoM4jfX4CFUv4M","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","old_string":"from erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (","new_string":"from erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import ("},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":680,"cache_read_input_tokens":103768,"cache_creation":{"ephemeral_5m_input_tokens":680,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHVZC4FahrzeLMw6ih2","type":"assistant","uuid":"6088aecb-4237-4e30-859f-010a5760cfce","timestamp":"2026-02-22T14:43:38.934Z"}
{"parentUuid":"6088aecb-4237-4e30-859f-010a5760cfce","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012JyuhSwnXoM4jfX4CFUv4M","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py has been updated successfully."}]},"uuid":"c1015cad-6832-48c0-a24f-a88f20486e0c","timestamp":"2026-02-22T14:43:39.612Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/one_shot_dispatch.py","oldString":"from erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (","newString":"from erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.naming import (","originalFile":"\"\"\"Shared dispatch logic for one-shot autonomous execution.\n\nExtracts the branch-create/push/PR/workflow-trigger sequence into reusable\npieces so both `erk one-shot` and `erk objective plan --one-shot` can\ndispatch tasks through the same CI workflow.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import UTC\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.ensure import Ensure\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext, NoRepoSentinel, RepoContext\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.metadata.plan_header import format_plan_header_body\nfrom erk_shared.gateway.github.parsing import construct_workflow_run_url\nfrom erk_shared.gateway.github.plan_issues import create_plan_issue\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.time.abc import Time\nfrom erk_shared.core.prompt_executor import PromptExecutor\nfrom erk_shared.naming import (\n    format_branch_timestamp_suffix,\n    generate_draft_pr_branch_name,\n    generate_issue_branch_name,\n    sanitize_worktree_name,\n)\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.draft_pr_lifecycle import build_plan_stage_body\n\nlogger = logging.getLogger(__name__)\n\nONE_SHOT_WORKFLOW = \"one-shot.yml\"\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchParams:\n    \"\"\"Parameters for dispatching a one-shot workflow.\"\"\"\n\n    prompt: str\n    model: str | None\n    extra_workflow_inputs: dict[str, str]\n\n\n@dataclass(frozen=True)\nclass OneShotDispatchResult:\n    \"\"\"Result of a successful one-shot dispatch.\"\"\"\n\n    pr_number: int\n    run_id: str\n    branch_name: str\n\n\ndef generate_branch_name(\n    prompt: str,\n    *,\n    time: Time,\n    plan_issue_number: int | None,\n    objective_id: int | None,\n    prompt_executor: PromptExecutor | None,\n) -> str:\n    \"\"\"Generate a branch name from the prompt.\n\n    Format: P{N}-{slug}-{MM-DD-HHMM} (with optional O{M} objective encoding)\n    when plan_issue_number is provided, otherwise oneshot-{slug}-{MM-DD-HHMM}.\n\n    When prompt_executor is provided, uses LLM to generate a concise slug\n    from the prompt. When None (e.g., dry-run mode), falls back to\n    sanitize_worktree_name.\n\n    Args:\n        prompt: The task description\n        time: Time gateway for deterministic timestamps\n        plan_issue_number: If provided, delegate to generate_issue_branch_name\n        objective_id: If provided with plan_issue_number, encode O{N} in branch name\n        prompt_executor: PromptExecutor for LLM slug generation, or None to skip\n\n    Returns:\n        Branch name string\n    \"\"\"\n    title = prompt\n    if prompt_executor is not None:\n        title = generate_slug_or_fallback(prompt_executor, prompt)\n\n    if plan_issue_number is not None:\n        return generate_issue_branch_name(\n            plan_issue_number, title, time.now(), objective_id=objective_id\n        )\n    slug = sanitize_worktree_name(title)\n    prefix = \"oneshot-\"\n    max_slug_len = 31 - len(prefix)\n    if len(slug) > max_slug_len:\n        slug = slug[:max_slug_len].rstrip(\"-\")\n    timestamp = format_branch_timestamp_suffix(time.now())\n    return f\"{prefix}{slug}{timestamp}\"\n\n\ndef dispatch_one_shot(\n    ctx: ErkContext,\n    *,\n    params: OneShotDispatchParams,\n    dry_run: bool,\n) -> OneShotDispatchResult | None:\n    \"\"\"Execute the full dispatch sequence for a one-shot workflow.\n\n    Creates branch, commits prompt file directly to branch (no checkout),\n    pushes, creates draft PR, and triggers workflow. In dry-run mode,\n    prints what would happen without executing.\n\n    Args:\n        ctx: Erk context with git/github gateways\n        params: Dispatch parameters\n        dry_run: If True, print preview without executing\n\n    Returns:\n        OneShotDispatchResult with pr_number, run_id, branch_name,\n        or None in dry-run mode\n    \"\"\"\n    # Validate we're in a git repo\n    Ensure.invariant(\n        not isinstance(ctx.repo, NoRepoSentinel),\n        \"Not in a git repository\",\n    )\n    assert not isinstance(ctx.repo, NoRepoSentinel)\n    repo: RepoContext = ctx.repo\n\n    # Validate GitHub authentication\n    Ensure.gh_authenticated(ctx)\n\n    # Get GitHub username\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect trunk branch\n    trunk = ctx.git.branch.detect_trunk_branch(repo.root)\n\n    # Build PR title\n    max_title_len = 60\n    suffix = \"...\" if len(params.prompt) > max_title_len else \"\"\n    pr_title = f\"One-shot: {params.prompt[:max_title_len]}{suffix}\"\n\n    if dry_run:\n        # In dry-run, show preview without creating skeleton issue\n        branch_name = generate_branch_name(\n            params.prompt,\n            time=ctx.time,\n            plan_issue_number=None,\n            objective_id=None,\n            prompt_executor=None,\n        )\n        user_output(\n            click.style(\"Dry-run mode:\", fg=\"cyan\", bold=True) + \" No changes will be made\\n\"\n        )\n        user_output(f\"Prompt: {params.prompt}\")\n        user_output(f\"Branch: {branch_name}\")\n        user_output(f\"PR title: {pr_title}\")\n        user_output(f\"Base branch: {trunk}\")\n        user_output(f\"Submitted by: {submitted_by}\")\n        if params.model is not None:\n            user_output(f\"Model: {params.model}\")\n        user_output(f\"Workflow: {ONE_SHOT_WORKFLOW}\")\n        if params.extra_workflow_inputs:\n            for key, value in params.extra_workflow_inputs.items():\n                user_output(f\"Extra input: {key}={value}\")\n        return None\n\n    objective_issue_str = params.extra_workflow_inputs.get(\"objective_issue\")\n    objective_id = int(objective_issue_str) if objective_issue_str else None\n\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    # --- Backend-conditional entity creation ---\n    # github backend: create skeleton issue first for P<N>- branch naming\n    # draft_pr backend: skip skeleton issue, use planned/ branch naming, PR is the plan\n    plan_issue_number: int | None = None\n    if not is_draft_pr:\n        skeleton_plan_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        skeleton_result = create_plan_issue(\n            github_issues=ctx.github.issues,\n            repo_root=repo.root,\n            plan_content=skeleton_plan_content,\n            title=f\"One-shot: {params.prompt[:max_title_len]}{suffix}\",\n            extra_labels=None,\n            title_tag=None,\n            source_repo=None,\n            objective_id=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        plan_issue_number = skeleton_result.issue_number\n\n    # Generate branch name with LLM-generated slug\n    slug = generate_slug_or_fallback(ctx.prompt_executor, params.prompt)\n    if is_draft_pr:\n        # draft_pr: planned/ prefix (no issue number needed)\n        branch_name = generate_draft_pr_branch_name(\n            slug,\n            ctx.time.now(),\n            objective_id=objective_id,\n        )\n    else:\n        # github: P<N>- prefix using skeleton issue number\n        branch_name = generate_branch_name(\n            slug,\n            time=ctx.time,\n            plan_issue_number=plan_issue_number,\n            objective_id=objective_id,\n            prompt_executor=None,\n        )\n\n    # Save current branch for restoration after workflow trigger\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Create branch from trunk\n    user_output(\"Creating branch...\")\n    ctx.git.branch.create_branch(repo.root, branch_name, trunk, force=False)\n\n    # Write prompt to .worker-impl/prompt.md directly on the branch (no checkout).\n    # (.impl/ is in .gitignore; .worker-impl/ is the committable counterpart\n    # that the remote workflow copies into .impl/)\n    ctx.git.commit.commit_files_to_branch(\n        repo.root,\n        branch=branch_name,\n        files={\".worker-impl/prompt.md\": params.prompt + \"\\n\"},\n        message=f\"One-shot: {params.prompt[:60]}\",\n    )\n\n    # Push to remote\n    user_output(\"Pushing to remote...\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        Ensure.invariant(False, f\"Failed to push branch: {push_result.message}\")\n\n    # --- Create draft PR ---\n    user_output(\"Creating draft PR...\")\n    if is_draft_pr:\n        # draft_pr: create PR with plan-header metadata block\n        _, username_for_header, _ = ctx.github.check_auth_status()\n        created_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n        metadata_body = format_plan_header_body(\n            created_at=created_at,\n            created_by=username_for_header or \"unknown\",\n            worktree_name=None,\n            branch_name=branch_name,\n            plan_comment_id=None,\n            last_dispatched_run_id=None,\n            last_dispatched_node_id=None,\n            last_dispatched_at=None,\n            last_local_impl_at=None,\n            last_local_impl_event=None,\n            last_local_impl_session=None,\n            last_local_impl_user=None,\n            last_remote_impl_at=None,\n            last_remote_impl_run_id=None,\n            last_remote_impl_session_id=None,\n            source_repo=None,\n            objective_issue=objective_id,\n            created_from_session=None,\n            created_from_workflow_run_url=None,\n            last_learn_session=None,\n            last_learn_at=None,\n            learn_status=None,\n            learn_plan_issue=None,\n            learn_plan_pr=None,\n            learned_from_issue=None,\n            lifecycle_stage=\"prompted\",\n        )\n        placeholder_content = (\n            f\"_One-shot: plan content will be populated by one-shot workflow._\\n\\n\"\n            f\"**Prompt:** {params.prompt}\"\n        )\n        pr_body_initial = build_plan_stage_body(metadata_body, placeholder_content)\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            pr_body_initial,\n            trunk,\n            draft=True,\n        )\n        # Add footer now that we have the PR number.\n        # No issue_number — draft PR IS the plan, Closes #N would be self-referential.\n        footer = build_pr_body_footer(pr_number, issue_number=None, plans_repo=None)\n        ctx.github.update_pr_body(repo.root, pr_number, pr_body_initial + footer)\n        # Add erk-plan label\n        ctx.github.add_label_to_pr(repo.root, pr_number, \"erk-plan\")\n\n        # Key: set plan_issue_number = pr_number so downstream code\n        # (workflow inputs, metadata writing, comments) targets the PR\n        plan_issue_number = pr_number\n    else:\n        # github: create plain draft PR with closing reference\n        closing_ref = \"\"\n        if plan_issue_number is not None:\n            plans_repo = ctx.local_config.plans_repo\n            closing_ref = (\n                f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                if plans_repo\n                else f\"\\n\\nCloses #{plan_issue_number}\"\n            )\n        pr_number = ctx.github.create_pr(\n            repo.root,\n            branch_name,\n            pr_title,\n            f\"Autonomous one-shot execution.\\n\\n**Prompt:** {params.prompt}{closing_ref}\",\n            trunk,\n            draft=True,\n        )\n    user_output(f\"Created draft PR #{pr_number}\")\n\n    # Build workflow inputs\n    # Truncate prompt for workflow input (full text is in .worker-impl/prompt.md)\n    max_input_len = 500\n    truncated_prompt = params.prompt[:max_input_len]\n    if len(params.prompt) > max_input_len:\n        truncated_prompt += \"... (full prompt committed to .worker-impl/prompt.md)\"\n\n    inputs: dict[str, str] = {\n        \"prompt\": truncated_prompt,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"submitted_by\": submitted_by,\n        \"plan_backend\": \"draft_pr\" if is_draft_pr else \"github\",\n    }\n    if params.model is not None:\n        inputs[\"model_name\"] = params.model\n    if plan_issue_number is not None:\n        inputs[\"plan_issue_number\"] = str(plan_issue_number)\n\n    # Merge extra workflow inputs\n    inputs.update(params.extra_workflow_inputs)\n\n    # Trigger workflow\n    user_output(\"Triggering one-shot workflow...\")\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=ONE_SHOT_WORKFLOW,\n        inputs=inputs,\n    )\n\n    # Compute run_url and queued_at for use in PR body update, metadata, and comment\n    run_url: str | None = None\n    if repo.github is not None:\n        run_url = construct_workflow_run_url(repo.github.owner, repo.github.repo, run_id)\n    queued_at = ctx.time.now().replace(tzinfo=UTC).isoformat()\n\n    # Update PR body with workflow run link (best-effort)\n    # For github backend: rewrite with prompt + run link + closing ref\n    # For draft_pr backend: skip — metadata block body should not be overwritten\n    if not is_draft_pr and run_url is not None:\n        try:\n            closing_ref = \"\"\n            if plan_issue_number is not None:\n                plans_repo = ctx.local_config.plans_repo\n                closing_ref = (\n                    f\"\\n\\nCloses {plans_repo}#{plan_issue_number}\"\n                    if plans_repo\n                    else f\"\\n\\nCloses #{plan_issue_number}\"\n                )\n            pr_body = (\n                f\"Autonomous one-shot execution.\\n\\n\"\n                f\"**Prompt:** {params.prompt}\\n\\n\"\n                f\"**Workflow run:** {run_url}{closing_ref}\"\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body)\n        except Exception as e:\n            logger.warning(\"Failed to update stub PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata and post queued comment (best-effort)\n    if plan_issue_number is not None:\n        # Write dispatch metadata to plan entity (issue for github, PR for draft_pr)\n        try:\n            write_dispatch_metadata(\n                plan_backend=ctx.plan_backend,\n                github=ctx.github,\n                repo_root=repo.root,\n                issue_number=plan_issue_number,\n                run_id=run_id,\n                dispatched_at=queued_at,\n            )\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Dispatch metadata written\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n            )\n\n        # Post queued event comment to plan entity\n        try:\n            metadata_block = create_submission_queued_block(\n                queued_at=queued_at,\n                submitted_by=submitted_by,\n                issue_number=plan_issue_number,\n                validation_results={\"issue_is_open\": True, \"has_erk_plan_label\": True},\n                expected_workflow=\"one-shot\",\n            )\n            comment_body = render_erk_issue_event(\n                title=\"\\U0001f504 One-Shot Dispatched\",\n                metadata=metadata_block,\n                description=(\n                    f\"One-shot submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                    f\"**Workflow run:** {run_url or 'N/A'}\\n\\n\"\n                    f\"**Prompt:** {params.prompt}\"\n                ),\n            )\n            ctx.issues.add_comment(repo.root, plan_issue_number, comment_body)\n            user_output(click.style(\"\\u2713\", fg=\"green\") + \" Queued event comment posted\")\n        except Exception as e:\n            user_output(\n                click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to post queued comment: {e}\"\n            )\n\n    # Display results\n    user_output(\"\")\n    user_output(click.style(\"Done!\", fg=\"green\", bold=True))\n    if repo.github is not None and run_url is not None:\n        pr_url = f\"https://github.com/{repo.github.owner}/{repo.github.repo}/pull/{pr_number}\"\n        user_output(f\"PR: {click.style(pr_url, fg='cyan')}\")\n        user_output(f\"Run: {click.style(run_url, fg='cyan')}\")\n    else:\n        user_output(f\"PR #{pr_number} created, workflow run {run_id} triggered\")\n\n    return OneShotDispatchResult(\n        pr_number=pr_number,\n        run_id=run_id,\n        branch_name=branch_name,\n    )\n","structuredPatch":[{"oldStart":15,"oldLines":6,"newStart":15,"newLines":7,"lines":[" from erk.cli.ensure import Ensure"," from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk.core.context import ErkContext, NoRepoSentinel, RepoContext","+from erk_shared.core.prompt_executor import PromptExecutor"," from erk_shared.gateway.git.remote_ops.types import PushError"," from erk_shared.gateway.github.metadata.core import (","     create_submission_queued_block,"]},{"oldStart":25,"oldLines":7,"newStart":26,"newLines":6,"lines":[" from erk_shared.gateway.github.plan_issues import create_plan_issue"," from erk_shared.gateway.github.pr_footer import build_pr_body_footer"," from erk_shared.gateway.time.abc import Time","-from erk_shared.core.prompt_executor import PromptExecutor"," from erk_shared.naming import (","     format_branch_timestamp_suffix,","     generate_draft_pr_branch_name,"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"c1015cad-6832-48c0-a24f-a88f20486e0c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01FrFyM4yfhdT2pg9Hp3hg9o","type":"message","role":"assistant","content":[{"type":"text","text":"Now fix submit.py import sorting:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":763,"cache_read_input_tokens":104448,"cache_creation":{"ephemeral_5m_input_tokens":763,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHW57PHCqSZ3YYYZHBp","type":"assistant","uuid":"da4aa77c-f08f-4bf3-977e-90ec4e0d800a","timestamp":"2026-02-22T14:43:42.805Z"}
{"parentUuid":"da4aa77c-f08f-4bf3-977e-90ec4e0d800a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01FrFyM4yfhdT2pg9Hp3hg9o","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PBFWa7Uh8LBuKWX7JchfGz","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","offset":1,"limit":55},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":763,"cache_read_input_tokens":104448,"cache_creation":{"ephemeral_5m_input_tokens":763,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHW57PHCqSZ3YYYZHBp","type":"assistant","uuid":"a544886a-4d5d-4918-ac50-1c34648e930f","timestamp":"2026-02-22T14:43:43.469Z"}
{"parentUuid":"a544886a-4d5d-4918-ac50-1c34648e930f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PBFWa7Uh8LBuKWX7JchfGz","type":"tool_result","content":"     1→\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n     2→\n     3→import logging\n     4→import tomllib\n     5→from collections.abc import Iterator\n     6→from contextlib import contextmanager\n     7→from dataclasses import dataclass\n     8→from datetime import UTC, datetime\n     9→from pathlib import Path\n    10→\n    11→import click\n    12→\n    13→from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\n    14→from erk.cli.commands.slot.common import is_placeholder_branch\n    15→from erk.cli.commands.submit_helpers import ensure_trunk_synced\n    16→from erk.cli.constants import (\n    17→    DISPATCH_WORKFLOW_METADATA_NAME,\n    18→    DISPATCH_WORKFLOW_NAME,\n    19→    ERK_PLAN_LABEL,\n    20→    ERK_PLAN_TITLE_PREFIX,\n    21→    PLAN_HEADING_PREFIX,\n    22→    PLANNED_PR_TITLE_PREFIX,\n    23→)\n    24→from erk.cli.core import discover_repo_context\n    25→from erk.cli.ensure import Ensure, UserFacingCliError\n    26→from erk.core.context import ErkContext\n    27→from erk.core.repo_discovery import RepoContext\n    28→from erk_shared.gateway.branch_manager.types import SubmitBranchError\n    29→from erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\n    30→from erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\n    31→from erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\n    32→from erk_shared.gateway.github.metadata.core import (\n    33→    create_submission_queued_block,\n    34→    render_erk_issue_event,\n    35→)\n    36→from erk_shared.gateway.github.parsing import (\n    37→    construct_pr_url,\n    38→    construct_workflow_run_url,\n    39→    extract_owner_repo_from_github_url,\n    40→)\n    41→from erk_shared.gateway.github.pr_footer import build_pr_body_footer\n    42→from erk_shared.gateway.github.types import PRNotFound\n    43→from erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\n    44→from erk.core.branch_slug_generator import generate_slug_or_fallback\n    45→from erk_shared.naming import generate_issue_branch_name\n    46→from erk_shared.output.output import user_output\n    47→from erk_shared.plan_store.types import PlanNotFound\n    48→from erk_shared.worker_impl_folder import (\n    49→    create_worker_impl_folder,\n    50→    remove_worker_impl_folder,\n    51→    worker_impl_folder_exists,\n    52→)\n    53→\n    54→logger = logging.getLogger(__name__)\n    55→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"4d96aeb2-01ac-46a3-bb2f-cecac1e1aad1","timestamp":"2026-02-22T14:43:43.510Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","content":"\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n\nimport logging\nimport tomllib\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,\n    worker_impl_folder_exists,\n)\n\nlogger = logging.getLogger(__name__)\n","numLines":55,"startLine":1,"totalLines":1341}}}
{"parentUuid":"4d96aeb2-01ac-46a3-bb2f-cecac1e1aad1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_017rRPWPvsv5CrQtPaVJkar9","type":"message","role":"assistant","content":[{"type":"text","text":"The `erk.core.branch_slug_generator` import on line 44 should be grouped with the other `erk.` imports (lines 13-27):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1009,"cache_read_input_tokens":105211,"cache_creation":{"ephemeral_5m_input_tokens":1009,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHWMmFenb7uHzvQ52t3","type":"assistant","uuid":"238b1395-7ffd-41ce-9ec8-bf1eb96878e0","timestamp":"2026-02-22T14:43:47.079Z"}
{"parentUuid":"238b1395-7ffd-41ce-9ec8-bf1eb96878e0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_017rRPWPvsv5CrQtPaVJkar9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01XquAUrzXv93fJxwHoLRU61","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","old_string":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name","new_string":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk_shared.naming import generate_issue_branch_name"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1009,"cache_read_input_tokens":105211,"cache_creation":{"ephemeral_5m_input_tokens":1009,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHWMmFenb7uHzvQ52t3","type":"assistant","uuid":"1549af4a-6f61-49a6-bd8c-f35283df018d","timestamp":"2026-02-22T14:43:56.320Z"}
{"parentUuid":"1549af4a-6f61-49a6-bd8c-f35283df018d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01XquAUrzXv93fJxwHoLRU61","type":"tool_result","content":"The file /home/runner/work/erk/erk/src/erk/cli/commands/submit.py has been updated successfully."}]},"uuid":"2f9f9cd6-7f6a-4817-aeb5-bee5c64e6890","timestamp":"2026-02-22T14:43:57.005Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/src/erk/cli/commands/submit.py","oldString":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name","newString":"from erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk_shared.naming import generate_issue_branch_name","originalFile":"\"\"\"Submit issue for remote AI implementation via GitHub Actions.\"\"\"\n\nimport logging\nimport tomllib\nfrom collections.abc import Iterator\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nimport click\n\nfrom erk.cli.commands.pr.metadata_helpers import write_dispatch_metadata\nfrom erk.cli.commands.slot.common import is_placeholder_branch\nfrom erk.cli.commands.submit_helpers import ensure_trunk_synced\nfrom erk.cli.constants import (\n    DISPATCH_WORKFLOW_METADATA_NAME,\n    DISPATCH_WORKFLOW_NAME,\n    ERK_PLAN_LABEL,\n    ERK_PLAN_TITLE_PREFIX,\n    PLAN_HEADING_PREFIX,\n    PLANNED_PR_TITLE_PREFIX,\n)\nfrom erk.cli.core import discover_repo_context\nfrom erk.cli.ensure import Ensure, UserFacingCliError\nfrom erk.core.context import ErkContext\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.branch_manager.types import SubmitBranchError\nfrom erk_shared.gateway.git.branch_ops.types import BranchAlreadyExists\nfrom erk_shared.gateway.git.remote_ops.types import PullRebaseError, PushError\nfrom erk_shared.gateway.github.issues.types import IssueInfo, IssueNotFound\nfrom erk_shared.gateway.github.metadata.core import (\n    create_submission_queued_block,\n    render_erk_issue_event,\n)\nfrom erk_shared.gateway.github.parsing import (\n    construct_pr_url,\n    construct_workflow_run_url,\n    extract_owner_repo_from_github_url,\n)\nfrom erk_shared.gateway.github.pr_footer import build_pr_body_footer\nfrom erk_shared.gateway.github.types import PRNotFound\nfrom erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL\nfrom erk.core.branch_slug_generator import generate_slug_or_fallback\nfrom erk_shared.naming import generate_issue_branch_name\nfrom erk_shared.output.output import user_output\nfrom erk_shared.plan_store.types import PlanNotFound\nfrom erk_shared.worker_impl_folder import (\n    create_worker_impl_folder,\n    remove_worker_impl_folder,\n    worker_impl_folder_exists,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef _format_issue_ref(issue_number: int, plans_repo: str | None) -> str:\n    \"\"\"Format issue reference for PR body.\n\n    Args:\n        issue_number: The issue number\n        plans_repo: Target repo in \"owner/repo\" format, or None for same repo\n\n    Returns:\n        \"#N\" for same-repo, \"owner/repo#N\" for cross-repo\n    \"\"\"\n    if plans_repo is None:\n        return f\"#{issue_number}\"\n    return f\"{plans_repo}#{issue_number}\"\n\n\n@contextmanager\ndef branch_rollback(ctx: ErkContext, repo_root: Path, original_branch: str) -> Iterator[None]:\n    \"\"\"Context manager that restores original branch on exception.\n\n    On success, does nothing (caller handles cleanup).\n    On exception, checks out original_branch and re-raises.\n    \"\"\"\n    try:\n        yield\n    except Exception:\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + \"Operation failed, restoring original branch...\"\n        )\n        ctx.branch_manager.checkout_branch(repo_root, original_branch)\n        raise\n\n\ndef is_issue_learn_plan(labels: list[str]) -> bool:\n    \"\"\"Check if an issue is a learn plan by checking for erk-learn label.\n\n    Args:\n        labels: The issue's labels\n\n    Returns:\n        True if the issue has the erk-learn label, False otherwise\n    \"\"\"\n    return \"erk-learn\" in labels\n\n\ndef _find_existing_branches_for_issue(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n) -> list[str]:\n    \"\"\"Find local branches matching P{issue_number}-* pattern.\"\"\"\n    local_branches = ctx.git.branch.list_local_branches(repo_root)\n    prefix = f\"P{issue_number}-\"\n    return sorted([b for b in local_branches if b.startswith(prefix)])\n\n\ndef _prompt_existing_branch_action(\n    ctx: ErkContext,\n    repo_root: Path,\n    existing_branches: list[str],\n    new_branch_name: str,\n    *,\n    force: bool,\n) -> str | None:\n    \"\"\"Prompt user to decide what to do with existing branch(es).\n\n    Args:\n        ctx: ErkContext with git operations\n        repo_root: Repository root path\n        existing_branches: List of existing branch names matching the issue pattern\n        new_branch_name: Name for new branch if creating fresh\n        force: If True, delete existing branches without prompting\n\n    Returns:\n        - Branch name to use (existing branch)\n        - None to signal \"create new\" (after deleting existing)\n    \"\"\"\n    if force:\n        user_output(f\"\\nDeleting {len(existing_branches)} existing branch(es) (--force mode):\")\n        for branch in existing_branches:\n            ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n            user_output(f\"  Deleted: {branch}\")\n        return None  # Signal \"create new branch\"\n\n    user_output(\"\\nFound existing local branch(es) for this issue:\")\n    for branch in existing_branches:\n        user_output(f\"  • {branch}\")\n    user_output(f\"\\nNew branch would be: {click.style(new_branch_name, fg='cyan')}\")\n    user_output(\"\")\n\n    # Use newest branch (latest timestamp = last alphabetically)\n    branch_to_use = existing_branches[-1]\n\n    # Single binary prompt\n    reuse = ctx.console.confirm(\n        f\"Reuse existing branch '{branch_to_use}'? \"\n        \"If not, a new branch and PR will be created (old draft PR will be closed)\",\n        default=True,\n    )\n\n    if reuse:\n        return branch_to_use\n\n    # Delete existing branches and signal \"create new\"\n    for branch in existing_branches:\n        ctx.branch_manager.delete_branch(repo_root, branch, force=True)\n        user_output(f\"Deleted branch: {branch}\")\n    return None\n\n\ndef get_learn_plan_parent_branch(ctx: ErkContext, repo_root: Path, plan_id: str) -> str | None:\n    \"\"\"Get the parent branch for a learn plan.\n\n    Learn plans should stack on their parent plan's branch.\n    Extracts learned_from_issue via plan_backend, fetches parent's branch_name.\n\n    Args:\n        ctx: ErkContext with plan_backend\n        repo_root: Repository root path\n        plan_id: Plan identifier\n\n    Returns:\n        Parent plan's branch_name if found, None otherwise\n    \"\"\"\n    learned_from = ctx.plan_backend.get_metadata_field(repo_root, plan_id, \"learned_from_issue\")\n    if isinstance(learned_from, PlanNotFound) or learned_from is None:\n        return None\n\n    branch_name = ctx.plan_backend.get_metadata_field(repo_root, str(learned_from), \"branch_name\")\n    if isinstance(branch_name, PlanNotFound) or branch_name is None:\n        return None\n    return str(branch_name)\n\n\ndef load_workflow_config(repo_root: Path, workflow_name: str) -> dict[str, str]:\n    \"\"\"Load workflow config from .erk/config.toml [workflows.<name>] section.\n\n    Args:\n        repo_root: Repository root path\n        workflow_name: Workflow filename (with or without .yml/.yaml extension).\n            Only the basename is used for config lookup.\n\n    Returns:\n        Dict of string key-value pairs for workflow inputs.\n        Returns empty dict if config file or section doesn't exist.\n\n    Example:\n        For workflow_name=\"plan-implement.yml\", reads from:\n        .erk/config.toml -> [workflows.plan-implement] section\n    \"\"\"\n    config_path = repo_root / \".erk\" / \"config.toml\"\n\n    if not config_path.exists():\n        return {}\n\n    with open(config_path, \"rb\") as f:\n        data = tomllib.load(f)\n\n    # Extract basename and strip .yml/.yaml extension\n    basename = Path(workflow_name).name\n    config_name = basename.removesuffix(\".yml\").removesuffix(\".yaml\")\n\n    # Get [workflows.<name>] section\n    workflows_section = data.get(\"workflows\", {})\n    workflow_config = workflows_section.get(config_name, {})\n\n    # Convert all values to strings (workflow inputs are always strings)\n    return {k: str(v) for k, v in workflow_config.items()}\n\n\n@dataclass(frozen=True)\nclass ValidatedIssue:\n    \"\"\"Issue that passed all validation checks.\"\"\"\n\n    number: int\n    issue: IssueInfo\n    branch_name: str\n    branch_exists: bool\n    pr_number: int | None\n    is_learn_origin: bool\n\n\n@dataclass(frozen=True)\nclass SubmitResult:\n    \"\"\"Result of submitting a single issue.\"\"\"\n\n    issue_number: int\n    issue_title: str\n    issue_url: str\n    pr_number: int | None\n    pr_url: str | None\n    workflow_run_id: str\n    workflow_url: str\n\n\ndef _build_workflow_run_url(issue_url: str, run_id: str) -> str:\n    \"\"\"Construct GitHub Actions workflow run URL from issue URL and run ID.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        run_id: Workflow run ID\n\n    Returns:\n        Workflow run URL (e.g., https://github.com/owner/repo/actions/runs/1234567890)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_workflow_run_url(owner, repo, run_id)\n    return f\"https://github.com/actions/runs/{run_id}\"\n\n\ndef _strip_plan_markers(title: str) -> str:\n    \"\"\"Strip '[erk-plan]' prefix and 'Plan:' prefix from issue title for use as PR title.\"\"\"\n    result = title\n    # Strip \"[erk-plan] \" prefix if present\n    if result.startswith(ERK_PLAN_TITLE_PREFIX):\n        result = result[len(ERK_PLAN_TITLE_PREFIX) :]\n    # Strip \"Plan: \" prefix if present\n    if result.startswith(PLAN_HEADING_PREFIX):\n        result = result[len(PLAN_HEADING_PREFIX) :]\n    return result\n\n\ndef _add_planned_prefix(title: str) -> str:\n    \"\"\"Prepend 'planned/' prefix to PR title (idempotent).\n\n    Args:\n        title: The PR title to prefix\n\n    Returns:\n        The title with 'planned/' prefix, skipping if already prefixed\n    \"\"\"\n    if title.startswith(PLANNED_PR_TITLE_PREFIX):\n        return title\n    return f\"{PLANNED_PR_TITLE_PREFIX}{title}\"\n\n\ndef _build_pr_url(issue_url: str, pr_number: int) -> str:\n    \"\"\"Construct GitHub PR URL from issue URL and PR number.\n\n    Args:\n        issue_url: GitHub issue URL (e.g., https://github.com/owner/repo/issues/123)\n        pr_number: PR number\n\n    Returns:\n        PR URL (e.g., https://github.com/owner/repo/pull/456)\n    \"\"\"\n    owner_repo = extract_owner_repo_from_github_url(issue_url)\n    if owner_repo is not None:\n        owner, repo = owner_repo\n        return construct_pr_url(owner, repo, pr_number)\n    return f\"https://github.com/pull/{pr_number}\"\n\n\ndef _close_orphaned_draft_prs(\n    ctx: ErkContext,\n    repo_root: Path,\n    issue_number: int,\n    keep_pr_number: int,\n) -> list[int]:\n    \"\"\"Close old draft PRs linked to an issue, keeping the specified one.\n\n    Returns list of PR numbers that were closed.\n    \"\"\"\n    linked_prs = ctx.issues.get_prs_referencing_issue(repo_root, issue_number)\n\n    closed_prs: list[int] = []\n    for pr in linked_prs:\n        # Close orphaned drafts: draft PRs that are OPEN and not the one we just created\n        # Any draft PR linked to an erk-plan issue is fair game to close\n        if pr.is_draft and pr.state == \"OPEN\" and pr.number != keep_pr_number:\n            ctx.github.close_pr(repo_root, pr.number)\n            closed_prs.append(pr.number)\n\n    return closed_prs\n\n\n@dataclass(frozen=True)\nclass ValidatedDraftPR:\n    \"\"\"Draft PR that passed all validation checks.\"\"\"\n\n    number: int\n    title: str\n    url: str\n    branch_name: str\n\n\ndef _validate_draft_pr_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    plan_number: int,\n) -> ValidatedDraftPR:\n    \"\"\"Validate a draft PR plan for submission.\n\n    Fetches the PR, validates it has the erk-plan label and is OPEN.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        plan_number: PR number to validate\n\n    Raises:\n        SystemExit: If PR doesn't exist, missing label, or not OPEN.\n    \"\"\"\n    pr_result = ctx.github.get_pr(repo.root, plan_number)\n    if isinstance(pr_result, PRNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in pr_result.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"PR #{plan_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if pr_result.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number} is {pr_result.state}\\n\\n\"\n            \"Cannot submit closed PRs for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    return ValidatedDraftPR(\n        number=plan_number,\n        title=pr_result.title,\n        url=pr_result.url,\n        branch_name=pr_result.head_ref_name,\n    )\n\n\ndef _submit_draft_pr_plan(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedDraftPR,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a validated draft-PR plan for implementation.\n\n    For draft-PR plans, the branch and PR already exist. This function:\n    - Fetches and checks out the existing plan branch\n    - Creates .worker-impl/ with provider=\"github-draft-pr\"\n    - Commits and pushes .worker-impl/ to existing branch\n    - Triggers the workflow with plan_backend=\"draft_pr\"\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated draft PR information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    plan_number = validated.number\n    branch_name = validated.branch_name\n\n    # Fetch plan content via PlanBackend\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(plan_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"PR #{plan_number}: plan content not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Fetch and checkout the existing plan branch\n    user_output(f\"Checking out existing plan branch: {click.style(branch_name, fg='cyan')}\")\n    ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n    local_branches = ctx.git.branch.list_local_branches(repo.root)\n    if branch_name not in local_branches:\n        remote_ref = f\"origin/{branch_name}\"\n        ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Sync local branch with remote (may be behind from prior submission or CI)\n    pull_result = ctx.git.remote.pull_rebase(repo.root, \"origin\", branch_name)\n    if isinstance(pull_result, PullRebaseError):\n        raise UserFacingCliError(\n            f\"Failed to sync branch '{branch_name}' with remote: {pull_result.message}\"\n        )\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    # Create .worker-impl/ with draft-PR provider\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(plan_number),\n        url=validated.url,\n        repo_root=repo.root,\n        provider=\"github-draft-pr\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for PR #{plan_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=False, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Switch back to original branch\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Build inputs dict with plan_backend=\"draft_pr\"\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n\n    inputs = {\n        \"plan_id\": str(plan_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": validated.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(plan_number),\n        \"base_branch\": base_branch,\n        \"plan_backend\": \"draft_pr\",\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL\n    workflow_url = _build_workflow_run_url(validated.url, run_id)\n\n    # Write dispatch metadata FIRST (before any PR body modification)\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=plan_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    # Update PR body with workflow run link (best-effort)\n    # Guard: only append if body is non-empty to avoid overwriting metadata block\n    try:\n        pr_details = ctx.github.get_pr(repo.root, plan_number)\n        if not isinstance(pr_details, PRNotFound) and pr_details.body:\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, plan_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Post queued event comment via PlanBackend\n    try:\n        validation_results = {\n            \"pr_is_open\": True,\n            \"has_erk_plan_label\": True,\n        }\n\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=plan_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Plan Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Plan submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.plan_backend.add_comment(repo.root, str(plan_number), comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(validated.url, plan_number)\n\n    return SubmitResult(\n        issue_number=plan_number,\n        issue_title=validated.title,\n        issue_url=validated.url,\n        pr_number=plan_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\ndef _validate_issue_for_submit(\n    ctx: ErkContext,\n    repo: RepoContext,\n    issue_number: int,\n    base_branch: str,\n    *,\n    force: bool,\n) -> ValidatedIssue:\n    \"\"\"Validate a single issue for submission.\n\n    Fetches the issue, validates constraints, derives branch name, and checks\n    if branch/PR already exist.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        issue_number: GitHub issue number to validate\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Raises:\n        SystemExit: If issue doesn't exist, missing label, or closed.\n    \"\"\"\n    # Fetch issue from GitHub\n    issue = ctx.issues.get_issue(repo.root, issue_number)\n    if isinstance(issue, IssueNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue.issue_number} not found\")\n        raise SystemExit(1)\n\n    # Validate: must have erk-plan label\n    if ERK_PLAN_LABEL not in issue.labels:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + f\"Issue #{issue_number} does not have {ERK_PLAN_LABEL} label\\n\\n\"\n            \"Cannot submit non-plan issues for automated implementation.\\n\"\n            \"To create a plan, use Plan Mode then /erk:plan-save\"\n        )\n        raise SystemExit(1)\n\n    # Validate: must be OPEN\n    if issue.state != \"OPEN\":\n        user_output(\n            click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} is {issue.state}\\n\\n\"\n            \"Cannot submit closed issues for automated implementation.\"\n        )\n        raise SystemExit(1)\n\n    # Use provided base_branch instead of detecting trunk\n    logger.debug(\"base_branch=%s\", base_branch)\n\n    # Check for existing local branches BEFORE computing new name\n    existing_branches = _find_existing_branches_for_issue(ctx, repo.root, issue_number)\n\n    # Compute branch name using canonical naming function\n    objective_id_raw = ctx.plan_backend.get_metadata_field(\n        repo.root, str(issue_number), \"objective_issue\"\n    )\n    objective_id: int | None = None\n    if isinstance(objective_id_raw, int):\n        objective_id = objective_id_raw\n    elif isinstance(objective_id_raw, str) and objective_id_raw.isdigit():\n        objective_id = int(objective_id_raw)\n    slug = generate_slug_or_fallback(ctx.prompt_executor, issue.title)\n    new_branch_name = generate_issue_branch_name(\n        issue_number, slug, ctx.time.now(), objective_id=objective_id\n    )\n\n    if existing_branches:\n        chosen = _prompt_existing_branch_action(\n            ctx, repo.root, existing_branches, new_branch_name, force=force\n        )\n        branch_name = chosen if chosen is not None else new_branch_name\n    else:\n        branch_name = new_branch_name\n\n    logger.debug(\"branch_name=%s\", branch_name)\n    user_output(f\"Computed branch: {click.style(branch_name, fg='cyan')}\")\n\n    # Check if branch already exists on remote and has a PR\n    branch_exists = ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", branch_name)\n    logger.debug(\"branch_exists_on_remote(%s)=%s\", branch_name, branch_exists)\n\n    pr_number: int | None = None\n    if branch_exists:\n        pr_details = ctx.github.get_pr_for_branch(repo.root, branch_name)\n        if not isinstance(pr_details, PRNotFound):\n            pr_number = pr_details.number\n\n    # Check if this issue is a learn plan\n    is_learn_origin = is_issue_learn_plan(issue.labels)\n\n    return ValidatedIssue(\n        number=issue_number,\n        issue=issue,\n        branch_name=branch_name,\n        branch_exists=branch_exists,\n        pr_number=pr_number,\n        is_learn_origin=is_learn_origin,\n    )\n\n\ndef _create_branch_and_pr(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    branch_name: str,\n    base_branch: str,\n    submitted_by: str,\n    original_branch: str,\n) -> int:\n    \"\"\"Create branch, commit, push, and create draft PR.\n\n    This function is called within the branch_rollback context manager.\n    On any exception, the context manager will restore the original branch.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        branch_name: Name of branch to create\n        base_branch: Base branch for PR\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (for cleanup on success)\n\n    Returns:\n        PR number of the created draft PR.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n\n    ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n    # Get plan content and create .worker-impl/ folder\n    user_output(\"Fetching plan content...\")\n    result = ctx.plan_store.get_plan(repo.root, str(issue_number))\n    if isinstance(result, PlanNotFound):\n        user_output(click.style(\"Error: \", fg=\"red\") + f\"Issue #{issue_number} not found\")\n        raise SystemExit(1)\n    plan = result\n\n    # Clean up previous .worker-impl/ if it exists (e.g., from a prior failed submission)\n    if worker_impl_folder_exists(repo.root):\n        user_output(\"Cleaning up previous .worker-impl/ folder...\")\n        remove_worker_impl_folder(repo.root)\n\n    user_output(\"Creating .worker-impl/ folder...\")\n    create_worker_impl_folder(\n        plan_content=plan.body,\n        plan_id=str(issue_number),\n        url=issue.url,\n        repo_root=repo.root,\n        provider=\"github\",\n        objective_id=plan.objective_id,\n    )\n\n    # Stage, commit, and push\n    ctx.git.commit.stage_files(repo.root, [\".worker-impl\"])\n    ctx.git.commit.commit(repo.root, f\"Add plan for issue #{issue_number}\")\n    push_result = ctx.git.remote.push_to_remote(\n        repo.root, \"origin\", branch_name, set_upstream=True, force=False\n    )\n    if isinstance(push_result, PushError):\n        raise UserFacingCliError(push_result.message)\n    user_output(click.style(\"✓\", fg=\"green\") + \" Branch pushed to remote\")\n\n    # Create draft PR\n    # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n    # MUST be in the initial body passed to create_pr(), NOT added via update.\n    # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n    # updated when the body is edited afterward.\n    user_output(\"Creating draft PR...\")\n    plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n    issue_ref = _format_issue_ref(issue_number, plans_repo)\n    pr_body = (\n        f\"**Author:** @{submitted_by}\\n\"\n        f\"**Plan:** {issue_ref}\\n\\n\"\n        f\"**Status:** Queued for implementation\\n\\n\"\n        f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n        f\"## Implementation Plan\\n\\n\"\n        f\"<details>\\n\"\n        f\"<summary><strong>Implementation Plan</strong> (Issue #{issue_number})</summary>\\n\\n\"\n        f\"{plan.body}\\n\\n\"\n        f\"</details>\\n\\n\"\n        f\"---\\n\\n\"\n        f\"Closes {issue_ref}\"\n    )\n    pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n    pr_number = ctx.github.create_pr(\n        repo_root=repo.root,\n        branch=branch_name,\n        title=pr_title,\n        body=pr_body,\n        base=base_branch,\n        draft=True,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n    # Update PR body with checkout command footer\n    footer = build_pr_body_footer(\n        pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n    )\n    ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n    # Add extraction skip label if this is a learn plan\n    if validated.is_learn_origin:\n        ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n        # FUTURE ENHANCEMENT: When a learn plan issue gets a PR, update the parent\n        # plan's learn_status from \"completed_with_plan\" to track the PR number.\n        # Currently, the parent only gets updated when the learn plan's PR lands\n        # (in land_cmd._update_parent_learn_status_if_learn_plan). Adding an\n        # intermediate state here would let the TUI show the PR number (e.g.,\n        # \"🚧 #5514\") instead of the learn plan issue number (e.g., \"#5508\")\n        # while the PR is still in review.\n        # See: LearnStatusValue in erk_shared/github/metadata/schemas.py\n\n    # Link PR with Graphite (if enabled)\n    if ctx.branch_manager.is_graphite_managed():\n        user_output(\"Linking PR with Graphite...\")\n        submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n        if isinstance(submit_result, SubmitBranchError):\n            user_output(\n                click.style(\"✗\", fg=\"red\")\n                + f\" Failed to link PR with Graphite: {submit_result.message}\"\n            )\n        else:\n            user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n    # Close any orphaned draft PRs for this issue\n    closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n    if closed_prs:\n        user_output(\n            click.style(\"✓\", fg=\"green\")\n            + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n            + \", \".join(f\"#{n}\" for n in closed_prs)\n        )\n\n    # Switch back to original branch (keep the new branch for Graphite lineage)\n    ctx.branch_manager.checkout_branch(repo.root, original_branch)\n\n    return pr_number\n\n\ndef _submit_single_issue(\n    ctx: ErkContext,\n    *,\n    repo: RepoContext,\n    validated: ValidatedIssue,\n    submitted_by: str,\n    original_branch: str,\n    base_branch: str,\n) -> SubmitResult:\n    \"\"\"Submit a single validated issue for implementation.\n\n    Creates branch/PR if needed and triggers workflow.\n\n    Args:\n        ctx: ErkContext with git operations\n        repo: Repository context\n        validated: Validated issue information\n        submitted_by: GitHub username of submitter\n        original_branch: Original branch name (to restore after)\n        base_branch: Base branch for PR (trunk or custom feature branch)\n\n    Returns:\n        SubmitResult with URLs and identifiers.\n    \"\"\"\n    issue = validated.issue\n    issue_number = validated.number\n    branch_name = validated.branch_name\n    branch_exists = validated.branch_exists\n    pr_number = validated.pr_number\n\n    if branch_exists:\n        if pr_number is not None:\n            user_output(\n                f\"PR #{pr_number} already exists for branch '{branch_name}' (state: existing)\"\n            )\n            user_output(\"Skipping branch/PR creation, triggering workflow...\")\n        else:\n            # Branch exists but no PR - need to add a commit for PR creation\n            user_output(f\"Branch '{branch_name}' exists but no PR. Adding placeholder commit...\")\n\n            # Fetch and checkout the remote branch locally\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", branch_name)\n\n            # Only create tracking branch if it doesn't exist locally (LBYL)\n            local_branches = ctx.git.branch.list_local_branches(repo.root)\n            if branch_name not in local_branches:\n                remote_ref = f\"origin/{branch_name}\"\n                ctx.branch_manager.create_tracking_branch(repo.root, branch_name, remote_ref)\n\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Create empty commit as placeholder for PR creation\n            ctx.git.commit.commit(\n                repo.root,\n                f\"[erk-plan] Initialize implementation for issue #{issue_number}\",\n            )\n            push_result = ctx.git.remote.push_to_remote(\n                repo.root, \"origin\", branch_name, set_upstream=False, force=False\n            )\n            if isinstance(push_result, PushError):\n                raise UserFacingCliError(push_result.message)\n            user_output(click.style(\"✓\", fg=\"green\") + \" Placeholder commit pushed\")\n\n            # Now create the PR\n            # IMPORTANT: \"Closes owner/repo#N\" (cross-repo) or \"Closes #N\" (same-repo)\n            # MUST be in the initial body passed to create_pr(), NOT added via update.\n            # GitHub's willCloseTarget API field is set at PR creation time and is NOT\n            # updated when the body is edited afterward.\n            plans_repo = ctx.local_config.plans_repo if ctx.local_config else None\n            issue_ref = _format_issue_ref(issue_number, plans_repo)\n            pr_body = (\n                f\"**Author:** @{submitted_by}\\n\"\n                f\"**Plan:** {issue_ref}\\n\\n\"\n                f\"**Status:** Queued for implementation\\n\\n\"\n                f\"This PR will be marked ready for review after implementation completes.\\n\\n\"\n                f\"---\\n\\n\"\n                f\"Closes {issue_ref}\"\n            )\n            pr_title = _add_planned_prefix(_strip_plan_markers(issue.title))\n            pr_number = ctx.github.create_pr(\n                repo_root=repo.root,\n                branch=branch_name,\n                title=pr_title,\n                body=pr_body,\n                base=base_branch,\n                draft=True,\n            )\n            user_output(click.style(\"✓\", fg=\"green\") + f\" Draft PR #{pr_number} created\")\n\n            # Update PR body with checkout command footer\n            footer = build_pr_body_footer(\n                pr_number=pr_number, issue_number=issue_number, plans_repo=plans_repo\n            )\n            ctx.github.update_pr_body(repo.root, pr_number, pr_body + footer)\n\n            # Add extraction skip label if this is a learn plan\n            if validated.is_learn_origin:\n                ctx.github.add_label_to_pr(repo.root, pr_number, ERK_SKIP_LEARN_LABEL)\n                # FUTURE ENHANCEMENT: See comment in _create_branch_and_pr for\n                # updating parent plan's learn_status when learn plan gets a PR.\n\n            # Link PR with Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                user_output(\"Linking PR with Graphite...\")\n                submit_result = ctx.branch_manager.submit_branch(repo.root, branch_name)\n                if isinstance(submit_result, SubmitBranchError):\n                    user_output(\n                        click.style(\"✗\", fg=\"red\")\n                        + f\" Failed to link PR with Graphite: {submit_result.message}\"\n                    )\n                else:\n                    user_output(click.style(\"✓\", fg=\"green\") + \" PR linked with Graphite\")\n\n            # Close any orphaned draft PRs\n            closed_prs = _close_orphaned_draft_prs(ctx, repo.root, issue_number, pr_number)\n            if closed_prs:\n                user_output(\n                    click.style(\"✓\", fg=\"green\")\n                    + f\" Closed {len(closed_prs)} orphaned draft PR(s): \"\n                    + \", \".join(f\"#{n}\" for n in closed_prs)\n                )\n\n            # Switch back to original branch (keep the new branch for Graphite lineage)\n            ctx.branch_manager.checkout_branch(repo.root, original_branch)\n    else:\n        # Check if branch exists locally (user chose to reuse existing)\n        local_branches = ctx.git.branch.list_local_branches(repo.root)\n        branch_exists_locally = branch_name in local_branches\n\n        if branch_exists_locally:\n            # Reuse existing local branch\n            user_output(f\"Using existing local branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Track in Graphite if not already tracked\n            if ctx.branch_manager.is_graphite_managed():\n                if not ctx.graphite.is_branch_tracked(repo.root, branch_name):\n                    ctx.branch_manager.track_branch(repo.root, branch_name, base_branch)\n                    user_output(click.style(\"✓\", fg=\"green\") + \" Branch tracked in Graphite\")\n\n            # Checkout existing branch\n            ctx.branch_manager.checkout_branch(repo.root, branch_name)\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n        else:\n            # Create new branch\n            user_output(f\"Creating branch from origin/{base_branch}...\")\n            ctx.git.remote.fetch_branch(repo.root, \"origin\", base_branch)\n\n            # Verify parent is tracked by Graphite (if enabled)\n            if ctx.branch_manager.is_graphite_managed():\n                parent_branch = base_branch.removeprefix(\"origin/\")\n                if not ctx.graphite.is_branch_tracked(repo.root, parent_branch):\n                    msg = (\n                        f\"Cannot stack on branch '{parent_branch}' - \"\n                        f\"it's not tracked by Graphite.\\n\\n\"\n                        f\"To fix this:\\n\"\n                        f\"  1. gt checkout {parent_branch}\\n\"\n                        f\"  2. gt track --parent <parent-branch>\\n\\n\"\n                        f\"Then retry your command.\"\n                    )\n                    user_output(click.style(\"Error: \", fg=\"red\") + msg)\n                    raise SystemExit(1)\n\n            create_result = ctx.branch_manager.create_branch(\n                repo.root, branch_name, f\"origin/{base_branch}\"\n            )\n            if isinstance(create_result, BranchAlreadyExists):\n                user_output(click.style(\"Error: \", fg=\"red\") + create_result.message)\n                raise SystemExit(1) from None\n            user_output(f\"Created branch: {click.style(branch_name, fg='cyan')}\")\n\n            # Use context manager to restore original branch on failure\n            with branch_rollback(ctx, repo.root, original_branch):\n                pr_number = _create_branch_and_pr(\n                    ctx=ctx,\n                    repo=repo,\n                    validated=validated,\n                    branch_name=branch_name,\n                    base_branch=base_branch,\n                    submitted_by=submitted_by,\n                    original_branch=original_branch,\n                )\n\n    # Gather submission metadata\n    queued_at = datetime.now(UTC).isoformat()\n\n    # Validate pr_number is set before workflow dispatch\n    if pr_number is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Failed to create or find PR. Cannot trigger workflow.\"\n        )\n        raise SystemExit(1)\n\n    # Load workflow-specific config\n    workflow_config = load_workflow_config(repo.root, DISPATCH_WORKFLOW_NAME)\n\n    # Trigger workflow via direct dispatch\n    user_output(\"\")\n    user_output(f\"Triggering workflow: {click.style(DISPATCH_WORKFLOW_NAME, fg='cyan')}\")\n    user_output(f\"  Display name: {DISPATCH_WORKFLOW_METADATA_NAME}\")\n\n    # Build inputs dict, merging workflow config\n    inputs = {\n        # Required inputs (always passed)\n        \"plan_id\": str(issue_number),\n        \"submitted_by\": submitted_by,\n        \"plan_title\": issue.title,\n        \"branch_name\": branch_name,\n        \"pr_number\": str(pr_number),\n        \"base_branch\": base_branch,\n        # Config-based inputs (from .erk/workflows/)\n        **workflow_config,\n    }\n\n    run_id = ctx.github.trigger_workflow(\n        repo_root=repo.root,\n        workflow=DISPATCH_WORKFLOW_NAME,\n        inputs=inputs,\n    )\n    user_output(click.style(\"✓\", fg=\"green\") + \" Workflow triggered.\")\n\n    # Compute workflow URL once (used for PR body update, queued comment, and result)\n    workflow_url = _build_workflow_run_url(issue.url, run_id)\n\n    # Update PR body with workflow run link (best-effort)\n    try:\n        pr_details = ctx.github.get_pr(repo.root, pr_number)\n        if not isinstance(pr_details, PRNotFound):\n            updated_body = pr_details.body + f\"\\n\\n**Workflow run:** {workflow_url}\"\n            ctx.github.update_pr_body(repo.root, pr_number, updated_body)\n    except Exception as e:\n        logger.warning(\"Failed to update PR body with workflow run link: %s\", e)\n\n    # Write dispatch metadata synchronously to fix race condition with erk dash\n    # This ensures the issue body has the run info before we return to the user\n    try:\n        write_dispatch_metadata(\n            plan_backend=ctx.plan_backend,\n            github=ctx.github,\n            repo_root=repo.root,\n            issue_number=issue_number,\n            run_id=run_id,\n            dispatched_at=queued_at,\n        )\n        user_output(click.style(\"✓\", fg=\"green\") + \" Dispatch metadata written to issue\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\") + f\"Failed to update dispatch metadata: {e}\"\n        )\n\n    validation_results = {\n        \"issue_is_open\": True,\n        \"has_erk_plan_label\": True,\n    }\n\n    # Create and post queued event comment\n    try:\n        metadata_block = create_submission_queued_block(\n            queued_at=queued_at,\n            submitted_by=submitted_by,\n            issue_number=issue_number,\n            validation_results=validation_results,\n            expected_workflow=DISPATCH_WORKFLOW_METADATA_NAME,\n        )\n\n        comment_body = render_erk_issue_event(\n            title=\"🔄 Issue Queued for Implementation\",\n            metadata=metadata_block,\n            description=(\n                f\"Issue submitted by **{submitted_by}** at {queued_at}.\\n\\n\"\n                f\"The `{DISPATCH_WORKFLOW_METADATA_NAME}` workflow has been \"\n                f\"triggered via direct dispatch.\\n\\n\"\n                f\"**Workflow run:** {workflow_url}\\n\\n\"\n                f\"Branch and draft PR were created locally for correct commit attribution.\"\n            ),\n        )\n\n        user_output(\"Posting queued event comment...\")\n        ctx.issues.add_comment(repo.root, issue_number, comment_body)\n        user_output(click.style(\"✓\", fg=\"green\") + \" Queued event comment posted\")\n    except Exception as e:\n        # Log warning but don't block - workflow is already triggered\n        user_output(\n            click.style(\"Warning: \", fg=\"yellow\")\n            + f\"Failed to post queued comment: {e}\\n\"\n            + \"Workflow is already running.\"\n        )\n\n    pr_url = _build_pr_url(issue.url, pr_number) if pr_number else None\n\n    return SubmitResult(\n        issue_number=issue_number,\n        issue_title=issue.title,\n        issue_url=issue.url,\n        pr_number=pr_number,\n        pr_url=pr_url,\n        workflow_run_id=run_id,\n        workflow_url=workflow_url,\n    )\n\n\n@click.command(\"submit\")\n@click.argument(\"issue_numbers\", type=int, nargs=-1, required=True)\n@click.option(\n    \"--base\",\n    type=str,\n    default=None,\n    help=\"Base branch for PR (defaults to current branch).\",\n)\n@click.option(\n    \"-f\",\n    \"--force\",\n    is_flag=True,\n    help=\"Delete existing branches and create fresh without prompting.\",\n)\n@click.pass_obj\ndef submit_cmd(\n    ctx: ErkContext, issue_numbers: tuple[int, ...], base: str | None, force: bool\n) -> None:\n    \"\"\"Submit issues for remote AI implementation via GitHub Actions.\n\n    Creates branch and draft PR locally (for correct commit attribution),\n    then triggers the dispatch-erk-queue.yml GitHub Actions workflow.\n\n    Arguments:\n        ISSUE_NUMBERS: One or more GitHub issue numbers to submit\n\n    Example:\n        erk plan submit 123\n        erk plan submit 123 456 789\n        erk plan submit 123 --base master\n\n    Requires:\n        - All issues must have erk-plan label\n        - All issues must be OPEN\n        - Working directory must be clean (no uncommitted changes)\n    \"\"\"\n    # Validate GitHub CLI prerequisites upfront (LBYL)\n    Ensure.gh_authenticated(ctx)\n\n    # Get repository context\n    if isinstance(ctx.repo, RepoContext):\n        repo = ctx.repo\n    else:\n        repo = discover_repo_context(ctx, ctx.cwd)\n\n    # Ensure trunk is synced before any operations\n    ensure_trunk_synced(ctx, repo)\n\n    # Save current state (needed for both default base and restoration)\n    original_branch = ctx.git.branch.get_current_branch(repo.root)\n    if original_branch is None:\n        user_output(\n            click.style(\"Error: \", fg=\"red\")\n            + \"Not on a branch (detached HEAD state). Cannot submit from here.\"\n        )\n        raise SystemExit(1)\n\n    # Validate base branch if provided, otherwise default to current branch (LBYL)\n    if base is not None:\n        if not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", base):\n            user_output(\n                click.style(\"Error: \", fg=\"red\") + f\"Base branch '{base}' does not exist on remote\"\n            )\n            raise SystemExit(1)\n        target_branch = base\n    else:\n        # If on a placeholder branch (local-only), use trunk as base\n        if is_placeholder_branch(original_branch):\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        elif not ctx.git.branch.branch_exists_on_remote(repo.root, \"origin\", original_branch):\n            # Current branch not pushed to remote - fall back to trunk\n            target_branch = ctx.git.branch.detect_trunk_branch(repo.root)\n        else:\n            target_branch = original_branch\n\n    # For single-issue learn plan submissions, auto-detect parent branch\n    issue_number = issue_numbers[0] if len(issue_numbers) == 1 else None\n    if (\n        issue_number is not None\n        and base is None\n        and ctx.issues.issue_exists(repo.root, issue_number)\n    ):\n        issue = ctx.issues.get_issue(repo.root, issue_number)\n        # issue_exists check above ensures this won't be IssueNotFound\n        if not isinstance(issue, IssueNotFound) and is_issue_learn_plan(issue.labels):\n            parent_branch = get_learn_plan_parent_branch(ctx, repo.root, str(issue_number))\n            if parent_branch is not None and ctx.git.branch.branch_exists_on_remote(\n                repo.root, \"origin\", parent_branch\n            ):\n                target_branch = parent_branch\n                user_output(\n                    f\"Learn plan detected, stacking on parent branch: \"\n                    f\"{click.style(parent_branch, fg='cyan')}\"\n                )\n            elif parent_branch is not None:\n                user_output(\n                    click.style(\"Warning: \", fg=\"yellow\")\n                    + f\"Parent branch '{parent_branch}' not on remote, using trunk\"\n                )\n\n    # Get GitHub username (authentication already validated)\n    _, username, _ = ctx.github.check_auth_status()\n    submitted_by = username or \"unknown\"\n\n    # Detect draft-PR backend\n    is_draft_pr = ctx.plan_backend.get_provider_name() == \"github-draft-pr\"\n\n    if is_draft_pr:\n        # Draft-PR path: branch and PR already exist, just validate and trigger workflow\n        user_output(f\"Validating {len(issue_numbers)} draft-PR plan(s)...\")\n        user_output(\"\")\n\n        validated_draft_prs: list[ValidatedDraftPR] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating PR #{issue_number}...\")\n            validated_pr = _validate_draft_pr_for_submit(ctx, repo, issue_number)\n            validated_draft_prs.append(validated_pr)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_draft_prs)} plan(s) validated\"\n        )\n        user_output(\"\")\n\n        for v in validated_draft_prs:\n            user_output(f\"  #{v.number}: {click.style(v.title, fg='yellow')}\")\n        user_output(\"\")\n\n        results: list[SubmitResult] = []\n        for i, v in enumerate(validated_draft_prs):\n            if len(validated_draft_prs) > 1:\n                count = len(validated_draft_prs)\n                user_output(f\"--- Submitting PR {i + 1}/{count}: #{v.number} ---\")\n            else:\n                user_output(f\"Submitting PR #{v.number}...\")\n            user_output(\"\")\n            result = _submit_draft_pr_plan(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n    else:\n        # Issue-based path: existing flow\n        # Phase 1: Validate ALL issues upfront (atomic - fail fast before any side effects)\n        user_output(f\"Validating {len(issue_numbers)} issue(s)...\")\n        user_output(\"\")\n\n        validated_issues: list[ValidatedIssue] = []\n        for issue_number in issue_numbers:\n            user_output(f\"Validating issue #{issue_number}...\")\n            validated_issue = _validate_issue_for_submit(\n                ctx, repo, issue_number, target_branch, force=force\n            )\n            validated_issues.append(validated_issue)\n\n        user_output(\"\")\n        user_output(\n            click.style(\"✓\", fg=\"green\") + f\" All {len(validated_issues)} issue(s) validated\"\n        )\n        user_output(\"\")\n\n        # Display validated issues\n        for v in validated_issues:\n            user_output(f\"  #{v.number}: {click.style(v.issue.title, fg='yellow')}\")\n        user_output(\"\")\n\n        # Phase 2: Submit all validated issues\n        results = []\n        for i, v in enumerate(validated_issues):\n            if len(validated_issues) > 1:\n                user_output(\n                    f\"--- Submitting issue {i + 1}/{len(validated_issues)}: #{v.number} ---\"\n                )\n            else:\n                user_output(f\"Submitting issue #{v.number}...\")\n            user_output(\"\")\n            result = _submit_single_issue(\n                ctx,\n                repo=repo,\n                validated=v,\n                submitted_by=submitted_by,\n                original_branch=original_branch,\n                base_branch=target_branch,\n            )\n            results.append(result)\n            user_output(\"\")\n\n    # Success output\n    user_output(\"\")\n    user_output(click.style(\"✓\", fg=\"green\") + f\" {len(results)} issue(s) submitted successfully!\")\n    user_output(\"\")\n    user_output(\"Submitted issues:\")\n    for r in results:\n        user_output(f\"  • #{r.issue_number}: {r.issue_title}\")\n        user_output(f\"    Issue: {r.issue_url}\")\n        if r.pr_url:\n            user_output(f\"    PR: {r.pr_url}\")\n        user_output(f\"    Workflow: {r.workflow_url}\")\n","structuredPatch":[{"oldStart":23,"oldLines":6,"newStart":23,"newLines":7,"lines":[" )"," from erk.cli.core import discover_repo_context"," from erk.cli.ensure import Ensure, UserFacingCliError","+from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk.core.context import ErkContext"," from erk.core.repo_discovery import RepoContext"," from erk_shared.gateway.branch_manager.types import SubmitBranchError"]},{"oldStart":41,"oldLines":7,"newStart":42,"newLines":6,"lines":[" from erk_shared.gateway.github.pr_footer import build_pr_body_footer"," from erk_shared.gateway.github.types import PRNotFound"," from erk_shared.gateway.gt.operations.finalize import ERK_SKIP_LEARN_LABEL","-from erk.core.branch_slug_generator import generate_slug_or_fallback"," from erk_shared.naming import generate_issue_branch_name"," from erk_shared.output.output import user_output"," from erk_shared.plan_store.types import PlanNotFound"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"2f9f9cd6-7f6a-4817-aeb5-bee5c64e6890","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01J3fZJVFX9PSDfKzicxDueg","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me re-run CI to verify all fixes:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1352,"cache_read_input_tokens":106220,"cache_creation":{"ephemeral_5m_input_tokens":1352,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHXMXeHEyERe5tqQy3e","type":"assistant","uuid":"b0cf7235-f89a-4de4-a356-6608e1bc23b2","timestamp":"2026-02-22T14:43:59.439Z"}
{"parentUuid":"b0cf7235-f89a-4de4-a356-6608e1bc23b2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01J3fZJVFX9PSDfKzicxDueg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018hrM6kfLQf5FprxkEEj25i","name":"Task","input":{"description":"Re-run CI checks after fixes","prompt":"Run the following CI checks and report all results. Do NOT fix any errors - just report them.\n\n1. ruff check on these files:\n   - src/erk/core/branch_slug_generator.py\n   - tests/core/test_branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n   - tests/commands/one_shot/test_branch_name.py\n\n2. pytest on the affected test files:\n   - tests/core/test_branch_slug_generator.py\n   - tests/commands/one_shot/test_branch_name.py\n\nReport ALL results verbatim.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1352,"cache_read_input_tokens":106220,"cache_creation":{"ephemeral_5m_input_tokens":1352,"ephemeral_1h_input_tokens":0},"output_tokens":3,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHXMXeHEyERe5tqQy3e","type":"assistant","uuid":"b96a137b-c91d-4879-aaa2-b79a065b559f","timestamp":"2026-02-22T14:44:04.614Z"}
{"parentUuid":"b96a137b-c91d-4879-aaa2-b79a065b559f","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018hrM6kfLQf5FprxkEEj25i","type":"tool_result","content":[{"type":"text","text":"## CI Check Results\n\n**ruff check**: passed\n- All checks passed on all 8 specified files\n\n**pytest**: passed\n- tests/core/test_branch_slug_generator.py: 12 passed\n- tests/commands/one_shot/test_branch_name.py: 6 passed\n- **Total: 18 passed in 0.59s**\n\nAll CI checks passed successfully. No errors to report."},{"type":"text","text":"agentId: aec860e (for resuming to continue this agent's work if needed)"}]}]},"uuid":"9bbba557-8a15-4617-8e11-428f73a58a1a","timestamp":"2026-02-22T14:44:37.789Z","toolUseResult":{"status":"completed","prompt":"Run the following CI checks and report all results. Do NOT fix any errors - just report them.\n\n1. ruff check on these files:\n   - src/erk/core/branch_slug_generator.py\n   - tests/core/test_branch_slug_generator.py\n   - src/erk/cli/commands/exec/scripts/plan_save.py\n   - src/erk/cli/commands/submit.py\n   - src/erk/cli/commands/one_shot_dispatch.py\n   - src/erk/cli/commands/exec/scripts/setup_impl_from_issue.py\n   - src/erk/cli/commands/exec/scripts/plan_migrate_to_draft_pr.py\n   - tests/commands/one_shot/test_branch_name.py\n\n2. pytest on the affected test files:\n   - tests/core/test_branch_slug_generator.py\n   - tests/commands/one_shot/test_branch_name.py\n\nReport ALL results verbatim.","agentId":"aec860e","content":[{"type":"text","text":"## CI Check Results\n\n**ruff check**: passed\n- All checks passed on all 8 specified files\n\n**pytest**: passed\n- tests/core/test_branch_slug_generator.py: 12 passed\n- tests/commands/one_shot/test_branch_name.py: 6 passed\n- **Total: 18 passed in 0.59s**\n\nAll CI checks passed successfully. No errors to report."}],"totalDurationMs":33094,"totalTokens":13212,"totalToolUseCount":2,"usage":{"input_tokens":5,"cache_creation_input_tokens":338,"cache_read_input_tokens":12768,"cache_creation":{"ephemeral_5m_input_tokens":338,"ephemeral_1h_input_tokens":0},"output_tokens":101,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"9bbba557-8a15-4617-8e11-428f73a58a1a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_018QVDFgMsHYwkBo5Sk4sY9x","type":"message","role":"assistant","content":[{"type":"text","text":"All CI checks pass. Now let me also run the broader test suite to ensure no existing tests are broken:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":477,"cache_read_input_tokens":107572,"cache_creation":{"ephemeral_5m_input_tokens":477,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHaMvnVqMRkzvd2hUZY","type":"assistant","uuid":"4b942f3d-035b-425a-b17a-88e2fa7ee3bf","timestamp":"2026-02-22T14:44:40.470Z"}
{"parentUuid":"4b942f3d-035b-425a-b17a-88e2fa7ee3bf","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_018QVDFgMsHYwkBo5Sk4sY9x","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SYvFiSbhJVbe5xsw9UYomu","name":"Task","input":{"description":"Run full unit test suite","prompt":"Run `make test-unit` and report the summary results (pass/fail counts). Do NOT fix any errors - just report them. If there are failures, report which test files and test names failed.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":477,"cache_read_input_tokens":107572,"cache_creation":{"ephemeral_5m_input_tokens":477,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHaMvnVqMRkzvd2hUZY","type":"assistant","uuid":"6d9e33c1-aa1a-45ed-ad35-d004cb4d6d7a","timestamp":"2026-02-22T14:44:42.315Z"}
{"parentUuid":"6d9e33c1-aa1a-45ed-ad35-d004cb4d6d7a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SYvFiSbhJVbe5xsw9UYomu","type":"tool_result","content":[{"type":"text","text":"## Test Summary\n\n**make test-unit-erk: FAILED**\n\n**Results:**\n- **8 failed, 5385 passed in 20.96s**\n\n**Failed Tests:**\n\n1. **tests/commands/submit/test_basic_submission.py**\n   - `test_submit_creates_branch_and_draft_pr` - Branch name mismatch (expected `P123-implement-feature-x-01-15-1430` but got `P123-test-title-test-body-01-15-1430`)\n   - `test_submit_tracks_branch_with_graphite` - Branch name mismatch (expected `P123-implement-feature-x-01-15-1430` but got `P123-test-title-test-body-01-15-1430`)\n\n2. **tests/commands/submit/test_existing_branch_detection.py**\n   - `test_submit_deletes_existing_and_creates_new_when_user_declines_reuse` - Branch name mismatch\n   - `test_submit_proceeds_normally_when_no_existing_branches` - Branch name mismatch\n   - `test_submit_force_deletes_existing_branches_and_creates_new` - Branch name mismatch\n   - `test_submit_force_creates_new_branch_when_none_exist` - Branch name mismatch\n\n3. **tests/commands/submit/test_graphite_linking.py**\n   - `test_plan_submit_existing_branch_links_with_graphite` - Error: \"Cannot stack on branch 'main' - it's not tracked by Graphite\"\n   - `test_plan_submit_existing_branch_shows_error_when_graphite_submit_fails` - Error: \"Cannot stack on branch 'main' - it's not tracked by Graphite\"\n\n**Root Issues:**\n- **Branch naming logic** appears to have changed - tests expect branch names based on \"implement-feature-x\" but the code is generating names based on \"test-title-test-body\"\n- **Graphite tracking** - tests are failing because the fake Graphite implementation isn't properly tracking the base branch as a Graphite-tracked branch"},{"type":"text","text":"agentId: adaf364 (for resuming to continue this agent's work if needed)"}]}]},"uuid":"ca9e979b-099c-4f6c-8541-33c7edd4977c","timestamp":"2026-02-22T14:45:16.951Z","toolUseResult":{"status":"completed","prompt":"Run `make test-unit` and report the summary results (pass/fail counts). Do NOT fix any errors - just report them. If there are failures, report which test files and test names failed.","agentId":"adaf364","content":[{"type":"text","text":"## Test Summary\n\n**make test-unit-erk: FAILED**\n\n**Results:**\n- **8 failed, 5385 passed in 20.96s**\n\n**Failed Tests:**\n\n1. **tests/commands/submit/test_basic_submission.py**\n   - `test_submit_creates_branch_and_draft_pr` - Branch name mismatch (expected `P123-implement-feature-x-01-15-1430` but got `P123-test-title-test-body-01-15-1430`)\n   - `test_submit_tracks_branch_with_graphite` - Branch name mismatch (expected `P123-implement-feature-x-01-15-1430` but got `P123-test-title-test-body-01-15-1430`)\n\n2. **tests/commands/submit/test_existing_branch_detection.py**\n   - `test_submit_deletes_existing_and_creates_new_when_user_declines_reuse` - Branch name mismatch\n   - `test_submit_proceeds_normally_when_no_existing_branches` - Branch name mismatch\n   - `test_submit_force_deletes_existing_branches_and_creates_new` - Branch name mismatch\n   - `test_submit_force_creates_new_branch_when_none_exist` - Branch name mismatch\n\n3. **tests/commands/submit/test_graphite_linking.py**\n   - `test_plan_submit_existing_branch_links_with_graphite` - Error: \"Cannot stack on branch 'main' - it's not tracked by Graphite\"\n   - `test_plan_submit_existing_branch_shows_error_when_graphite_submit_fails` - Error: \"Cannot stack on branch 'main' - it's not tracked by Graphite\"\n\n**Root Issues:**\n- **Branch naming logic** appears to have changed - tests expect branch names based on \"implement-feature-x\" but the code is generating names based on \"test-title-test-body\"\n- **Graphite tracking** - tests are failing because the fake Graphite implementation isn't properly tracking the base branch as a Graphite-tracked branch"}],"totalDurationMs":34618,"totalTokens":18492,"totalToolUseCount":3,"usage":{"input_tokens":7,"cache_creation_input_tokens":2480,"cache_read_input_tokens":15483,"cache_creation":{"ephemeral_5m_input_tokens":2480,"ephemeral_1h_input_tokens":0},"output_tokens":522,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"ca9e979b-099c-4f6c-8541-33c7edd4977c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HrDBWrMagsV4Lx1pjWTwc9","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nThe test failures make sense. The `FakePromptExecutor` in those tests returns `\"Test Title\\n\\nTest body\"` by default, so `generate_slug_or_fallback` is using that instead of the original title. The submit tests create `FakePromptExecutor` without specifying `simulated_prompt_output`, so it defaults to `\"Test Title\\n\\nTest body\"` which gets slugified to `test-title-test-body`.\n\nI need to update the submit tests to configure the `FakePromptExecutor` with appropriate simulated output, or configure it to fail so it falls back to the raw title. Let me look at these test files:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":904,"cache_read_input_tokens":108049,"cache_creation":{"ephemeral_5m_input_tokens":904,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdFRhGvUrM1g5JoTpk","type":"assistant","uuid":"38799922-6738-477c-a1f7-664b68fad04a","timestamp":"2026-02-22T14:45:22.663Z"}
{"parentUuid":"38799922-6738-477c-a1f7-664b68fad04a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HrDBWrMagsV4Lx1pjWTwc9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01J3NzJ2bfMxXWNkxqSgJMNc","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/test_basic_submission.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":904,"cache_read_input_tokens":108049,"cache_creation":{"ephemeral_5m_input_tokens":904,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdFRhGvUrM1g5JoTpk","type":"assistant","uuid":"34f6ded3-1afb-49be-bf17-a5e92f0342f7","timestamp":"2026-02-22T14:45:23.189Z"}
{"parentUuid":"34f6ded3-1afb-49be-bf17-a5e92f0342f7","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HrDBWrMagsV4Lx1pjWTwc9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01P3wcR6EkCV4UGb92F7K75r","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/test_existing_branch_detection.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":904,"cache_read_input_tokens":108049,"cache_creation":{"ephemeral_5m_input_tokens":904,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdFRhGvUrM1g5JoTpk","type":"assistant","uuid":"797c3681-26e2-4e37-ba62-e8885a5f3deb","timestamp":"2026-02-22T14:45:23.667Z"}
{"parentUuid":"797c3681-26e2-4e37-ba62-e8885a5f3deb","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HrDBWrMagsV4Lx1pjWTwc9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011Wt15gvG141tUvK1z1buG3","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/test_graphite_linking.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":904,"cache_read_input_tokens":108049,"cache_creation":{"ephemeral_5m_input_tokens":904,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdFRhGvUrM1g5JoTpk","type":"assistant","uuid":"7fefd6b2-5b3d-4862-89b9-6c8643f3568a","timestamp":"2026-02-22T14:45:24.088Z"}
{"parentUuid":"7fefd6b2-5b3d-4862-89b9-6c8643f3568a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01J3NzJ2bfMxXWNkxqSgJMNc","type":"tool_result","content":"     1→\"\"\"Tests for basic submit command functionality.\"\"\"\n     2→\n     3→from pathlib import Path\n     4→\n     5→from click.testing import CliRunner\n     6→\n     7→from erk.cli.commands.submit import submit_cmd\n     8→from erk_shared.gateway.graphite.types import BranchMetadata\n     9→from tests.commands.submit.conftest import create_plan, setup_submit_context\n    10→\n    11→\n    12→def test_submit_creates_branch_and_draft_pr(tmp_path: Path) -> None:\n    13→    \"\"\"Test submit creates linked branch, pushes, creates draft PR, triggers workflow.\"\"\"\n    14→    plan = create_plan(\"123\", \"Implement feature X\")\n    15→    repo_root = tmp_path / \"repo\"\n    16→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n    17→        tmp_path,\n    18→        {\"123\": plan},\n    19→        git_kwargs={\n    20→            \"current_branches\": {repo_root: \"main\"},\n    21→            \"trunk_branches\": {repo_root: \"master\"},\n    22→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n    23→        },\n    24→    )\n    25→\n    26→    runner = CliRunner()\n    27→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n    28→\n    29→    assert result.exit_code == 0, result.output\n    30→    assert \"issue(s) submitted successfully!\" in result.output\n    31→    assert \"Workflow:\" in result.output\n    32→\n    33→    # Branch name is sanitize_worktree_name(...) + timestamp suffix \"-01-15-1430\"\n    34→    expected_branch = \"P123-implement-feature-x-01-15-1430\"\n    35→\n    36→    # Verify branch was created via git (from origin/<current_branch>)\n    37→    # Note: submit defaults to current branch as base, not trunk_branch\n    38→    # (tuple is cwd, branch_name, start_point, force)\n    39→    assert len(fake_git.created_branches) == 1\n    40→    created_repo, created_branch, created_base, created_force = fake_git.created_branches[0]\n    41→    assert created_repo == repo_root\n    42→    assert created_branch == expected_branch\n    43→    assert created_base == \"origin/main\"  # Uses current branch as base\n    44→    assert created_force is False\n    45→\n    46→    # Verify branch was pushed\n    47→    assert len(fake_git.pushed_branches) == 1\n    48→    remote, branch, set_upstream, force = fake_git.pushed_branches[0]\n    49→    assert remote == \"origin\"\n    50→    assert branch == expected_branch\n    51→    assert set_upstream is True\n    52→    assert force is False\n    53→\n    54→    # Verify draft PR was created\n    55→    assert len(fake_github.created_prs) == 1\n    56→    branch_name, title, body, base, draft = fake_github.created_prs[0]\n    57→    assert branch_name == expected_branch\n    58→    assert title == \"planned/Implement feature X\"\n    59→    assert draft is True\n    60→    # PR body contains plan reference\n    61→    assert \"**Plan:** #123\" in body\n    62→\n    63→    # Verify workflow was triggered\n    64→    assert len(fake_github.triggered_workflows) == 1\n    65→    workflow, inputs = fake_github.triggered_workflows[0]\n    66→    assert workflow == \"plan-implement.yml\"\n    67→    assert inputs[\"plan_id\"] == \"123\"\n    68→\n    69→    # Verify local branch is preserved (for Graphite lineage tracking)\n    70→    assert len(fake_git._deleted_branches) == 0\n    71→\n    72→\n    73→def test_submit_tracks_branch_with_graphite(tmp_path: Path) -> None:\n    74→    \"\"\"Test submit tracks the created branch with Graphite for proper PR stacking.\n    75→\n    76→    When branches are created via submit, they must be tracked with Graphite\n    77→    so that `erk land` can find child PRs and update their base branches before\n    78→    merging. Without tracking, child PRs get auto-closed by GitHub when their\n    79→    base branch is deleted.\n    80→    \"\"\"\n    81→    plan = create_plan(\"123\", \"Implement feature X\")\n    82→    repo_root = tmp_path / \"repo\"\n    83→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n    84→        tmp_path,\n    85→        {\"123\": plan},\n    86→        git_kwargs={\n    87→            \"current_branches\": {repo_root: \"main\"},\n    88→            \"trunk_branches\": {repo_root: \"master\"},\n    89→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n    90→        },\n    91→        graphite_kwargs={\n    92→            # main must be tracked for stacking to work\n    93→            \"branches\": {\n    94→                \"main\": BranchMetadata.trunk(\"main\"),\n    95→            },\n    96→        },\n    97→        use_graphite=True,\n    98→    )\n    99→\n   100→    runner = CliRunner()\n   101→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   102→\n   103→    assert result.exit_code == 0, result.output\n   104→\n   105→    # Branch name is sanitize_worktree_name(...) + timestamp suffix \"-01-15-1430\"\n   106→    expected_branch = \"P123-implement-feature-x-01-15-1430\"\n   107→\n   108→    # Verify branch was tracked with Graphite (critical for child PR detection)\n   109→    # BranchManager.create_branch() strips the origin/ prefix for Graphite tracking\n   110→    # because gt track doesn't accept remote refs - it uses local branch names\n   111→    assert len(fake_graphite.track_branch_calls) == 1\n   112→    tracked_repo, tracked_branch, parent_branch = fake_graphite.track_branch_calls[0]\n   113→    assert tracked_repo == repo_root\n   114→    assert tracked_branch == expected_branch\n   115→    assert parent_branch == \"main\"  # Local branch name (origin/ stripped by BranchManager)\n   116→\n   117→\n   118→def test_submit_displays_workflow_run_url(tmp_path: Path) -> None:\n   119→    \"\"\"Test submit displays workflow run URL from trigger_workflow response.\"\"\"\n   120→    plan = create_plan(\"123\", \"Add workflow run URL to erk submit output\")\n   121→    ctx, fake_git, fake_github, _, _, _ = setup_submit_context(tmp_path, {\"123\": plan})\n   122→\n   123→    runner = CliRunner()\n   124→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   125→\n   126→    assert result.exit_code == 0, result.output\n   127→    assert \"issue(s) submitted successfully!\" in result.output\n   128→    # Verify workflow run URL is displayed (uses run_id returned by trigger_workflow)\n   129→    expected_url = \"https://github.com/test-owner/test-repo/actions/runs/1234567890\"\n   130→    assert expected_url in result.output\n   131→\n   132→\n   133→def test_submit_single_issue_still_works(tmp_path: Path) -> None:\n   134→    \"\"\"Test backwards compatibility: single issue argument still works.\"\"\"\n   135→    plan = create_plan(\"123\", \"Implement feature X\")\n   136→    ctx, fake_git, fake_github, _, _, _ = setup_submit_context(tmp_path, {\"123\": plan})\n   137→\n   138→    runner = CliRunner()\n   139→    # Single argument - backwards compatibility\n   140→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   141→\n   142→    assert result.exit_code == 0, result.output\n   143→    assert \"1 issue(s) submitted successfully!\" in result.output\n   144→    assert \"Workflow:\" in result.output\n   145→\n   146→    # Verify branch was created via git\n   147→    assert len(fake_git.created_branches) == 1\n   148→\n   149→    # Verify workflow was triggered\n   150→    assert len(fake_github.triggered_workflows) == 1\n   151→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"367edf28-8fe2-4aa3-b931-d2b5b97675aa","timestamp":"2026-02-22T14:45:24.106Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/test_basic_submission.py","content":"\"\"\"Tests for basic submit command functionality.\"\"\"\n\nfrom pathlib import Path\n\nfrom click.testing import CliRunner\n\nfrom erk.cli.commands.submit import submit_cmd\nfrom erk_shared.gateway.graphite.types import BranchMetadata\nfrom tests.commands.submit.conftest import create_plan, setup_submit_context\n\n\ndef test_submit_creates_branch_and_draft_pr(tmp_path: Path) -> None:\n    \"\"\"Test submit creates linked branch, pushes, creates draft PR, triggers workflow.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n        },\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"issue(s) submitted successfully!\" in result.output\n    assert \"Workflow:\" in result.output\n\n    # Branch name is sanitize_worktree_name(...) + timestamp suffix \"-01-15-1430\"\n    expected_branch = \"P123-implement-feature-x-01-15-1430\"\n\n    # Verify branch was created via git (from origin/<current_branch>)\n    # Note: submit defaults to current branch as base, not trunk_branch\n    # (tuple is cwd, branch_name, start_point, force)\n    assert len(fake_git.created_branches) == 1\n    created_repo, created_branch, created_base, created_force = fake_git.created_branches[0]\n    assert created_repo == repo_root\n    assert created_branch == expected_branch\n    assert created_base == \"origin/main\"  # Uses current branch as base\n    assert created_force is False\n\n    # Verify branch was pushed\n    assert len(fake_git.pushed_branches) == 1\n    remote, branch, set_upstream, force = fake_git.pushed_branches[0]\n    assert remote == \"origin\"\n    assert branch == expected_branch\n    assert set_upstream is True\n    assert force is False\n\n    # Verify draft PR was created\n    assert len(fake_github.created_prs) == 1\n    branch_name, title, body, base, draft = fake_github.created_prs[0]\n    assert branch_name == expected_branch\n    assert title == \"planned/Implement feature X\"\n    assert draft is True\n    # PR body contains plan reference\n    assert \"**Plan:** #123\" in body\n\n    # Verify workflow was triggered\n    assert len(fake_github.triggered_workflows) == 1\n    workflow, inputs = fake_github.triggered_workflows[0]\n    assert workflow == \"plan-implement.yml\"\n    assert inputs[\"plan_id\"] == \"123\"\n\n    # Verify local branch is preserved (for Graphite lineage tracking)\n    assert len(fake_git._deleted_branches) == 0\n\n\ndef test_submit_tracks_branch_with_graphite(tmp_path: Path) -> None:\n    \"\"\"Test submit tracks the created branch with Graphite for proper PR stacking.\n\n    When branches are created via submit, they must be tracked with Graphite\n    so that `erk land` can find child PRs and update their base branches before\n    merging. Without tracking, child PRs get auto-closed by GitHub when their\n    base branch is deleted.\n    \"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n        },\n        graphite_kwargs={\n            # main must be tracked for stacking to work\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n        },\n        use_graphite=True,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n\n    # Branch name is sanitize_worktree_name(...) + timestamp suffix \"-01-15-1430\"\n    expected_branch = \"P123-implement-feature-x-01-15-1430\"\n\n    # Verify branch was tracked with Graphite (critical for child PR detection)\n    # BranchManager.create_branch() strips the origin/ prefix for Graphite tracking\n    # because gt track doesn't accept remote refs - it uses local branch names\n    assert len(fake_graphite.track_branch_calls) == 1\n    tracked_repo, tracked_branch, parent_branch = fake_graphite.track_branch_calls[0]\n    assert tracked_repo == repo_root\n    assert tracked_branch == expected_branch\n    assert parent_branch == \"main\"  # Local branch name (origin/ stripped by BranchManager)\n\n\ndef test_submit_displays_workflow_run_url(tmp_path: Path) -> None:\n    \"\"\"Test submit displays workflow run URL from trigger_workflow response.\"\"\"\n    plan = create_plan(\"123\", \"Add workflow run URL to erk submit output\")\n    ctx, fake_git, fake_github, _, _, _ = setup_submit_context(tmp_path, {\"123\": plan})\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"issue(s) submitted successfully!\" in result.output\n    # Verify workflow run URL is displayed (uses run_id returned by trigger_workflow)\n    expected_url = \"https://github.com/test-owner/test-repo/actions/runs/1234567890\"\n    assert expected_url in result.output\n\n\ndef test_submit_single_issue_still_works(tmp_path: Path) -> None:\n    \"\"\"Test backwards compatibility: single issue argument still works.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    ctx, fake_git, fake_github, _, _, _ = setup_submit_context(tmp_path, {\"123\": plan})\n\n    runner = CliRunner()\n    # Single argument - backwards compatibility\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"1 issue(s) submitted successfully!\" in result.output\n    assert \"Workflow:\" in result.output\n\n    # Verify branch was created via git\n    assert len(fake_git.created_branches) == 1\n\n    # Verify workflow was triggered\n    assert len(fake_github.triggered_workflows) == 1\n","numLines":151,"startLine":1,"totalLines":151}}}
{"parentUuid":"367edf28-8fe2-4aa3-b931-d2b5b97675aa","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01P3wcR6EkCV4UGb92F7K75r","type":"tool_result","content":"     1→\"\"\"Tests for existing branch detection and reuse in submit command.\"\"\"\n     2→\n     3→from pathlib import Path\n     4→\n     5→from click.testing import CliRunner\n     6→\n     7→from erk.cli.commands.submit import (\n     8→    _find_existing_branches_for_issue,\n     9→    submit_cmd,\n    10→)\n    11→from erk.core.context import context_for_test\n    12→from erk_shared.gateway.graphite.types import BranchMetadata\n    13→from tests.commands.submit.conftest import create_plan, setup_submit_context\n    14→\n    15→\n    16→def test_find_existing_branches_detects_matching_pattern(tmp_path: Path) -> None:\n    17→    \"\"\"Test _find_existing_branches_for_issue finds P{issue}-* branches.\"\"\"\n    18→    from erk_shared.gateway.git.fake import FakeGit\n    19→\n    20→    repo_root = tmp_path / \"repo\"\n    21→    repo_root.mkdir()\n    22→\n    23→    fake_git = FakeGit(\n    24→        current_branches={repo_root: \"main\"},\n    25→        local_branches={\n    26→            repo_root: [\n    27→                \"main\",\n    28→                \"P123-feature-01-23-0909\",\n    29→                \"P123-feature-01-23-0910\",\n    30→                \"P456-other-01-23-0909\",\n    31→                \"unrelated-branch\",\n    32→            ]\n    33→        },\n    34→    )\n    35→\n    36→    ctx = context_for_test(cwd=repo_root, git=fake_git)\n    37→\n    38→    result = _find_existing_branches_for_issue(ctx, repo_root, 123)\n    39→\n    40→    assert result == [\"P123-feature-01-23-0909\", \"P123-feature-01-23-0910\"]\n    41→\n    42→\n    43→def test_find_existing_branches_returns_empty_when_none_exist(tmp_path: Path) -> None:\n    44→    \"\"\"Test _find_existing_branches_for_issue returns empty list when no matches.\"\"\"\n    45→    from erk_shared.gateway.git.fake import FakeGit\n    46→\n    47→    repo_root = tmp_path / \"repo\"\n    48→    repo_root.mkdir()\n    49→\n    50→    fake_git = FakeGit(\n    51→        current_branches={repo_root: \"main\"},\n    52→        local_branches={repo_root: [\"main\", \"other-branch\"]},\n    53→    )\n    54→\n    55→    ctx = context_for_test(cwd=repo_root, git=fake_git)\n    56→\n    57→    result = _find_existing_branches_for_issue(ctx, repo_root, 123)\n    58→\n    59→    assert result == []\n    60→\n    61→\n    62→def test_submit_uses_existing_branch_when_user_confirms(tmp_path: Path) -> None:\n    63→    \"\"\"Test submit reuses existing local branch when user confirms.\"\"\"\n    64→    plan = create_plan(\"123\", \"Implement feature X\")\n    65→    repo_root = tmp_path / \"repo\"\n    66→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n    67→        tmp_path,\n    68→        {\"123\": plan},\n    69→        git_kwargs={\n    70→            \"current_branches\": {repo_root: \"main\"},\n    71→            \"trunk_branches\": {repo_root: \"master\"},\n    72→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n    73→            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n    74→        },\n    75→        graphite_kwargs={\n    76→            \"branches\": {\n    77→                \"main\": BranchMetadata.trunk(\"main\"),\n    78→            },\n    79→        },\n    80→        use_graphite=True,\n    81→        # User confirms \"use existing branch\"\n    82→        confirm_responses=[True],\n    83→    )\n    84→\n    85→    runner = CliRunner()\n    86→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n    87→\n    88→    assert result.exit_code == 0, result.output\n    89→    assert \"Found existing local branch(es) for this issue\" in result.output\n    90→    assert \"P123-implement-feature-x-01-23-0909\" in result.output\n    91→    assert \"Using existing local branch\" in result.output\n    92→\n    93→    # Verify NO new branch was created (should reuse existing)\n    94→    assert len(fake_git.created_branches) == 0\n    95→\n    96→    # Verify existing branch was tracked in Graphite\n    97→    assert len(fake_graphite.track_branch_calls) == 1\n    98→    tracked_repo, tracked_branch, parent = fake_graphite.track_branch_calls[0]\n    99→    assert tracked_branch == \"P123-implement-feature-x-01-23-0909\"\n   100→    assert parent == \"main\"\n   101→\n   102→\n   103→def test_submit_deletes_existing_and_creates_new_when_user_declines_reuse(\n   104→    tmp_path: Path,\n   105→) -> None:\n   106→    \"\"\"Test submit deletes existing branches and creates new when user declines reuse.\"\"\"\n   107→    plan = create_plan(\"123\", \"Implement feature X\")\n   108→    repo_root = tmp_path / \"repo\"\n   109→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n   110→        tmp_path,\n   111→        {\"123\": plan},\n   112→        git_kwargs={\n   113→            \"current_branches\": {repo_root: \"main\"},\n   114→            \"trunk_branches\": {repo_root: \"master\"},\n   115→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   116→            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n   117→        },\n   118→        graphite_kwargs={\n   119→            \"branches\": {\n   120→                \"main\": BranchMetadata.trunk(\"main\"),\n   121→            },\n   122→        },\n   123→        use_graphite=True,\n   124→        # User declines \"reuse existing\" in single binary prompt\n   125→        confirm_responses=[False],\n   126→    )\n   127→\n   128→    runner = CliRunner()\n   129→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   130→\n   131→    assert result.exit_code == 0, result.output\n   132→    assert \"Found existing local branch(es) for this issue\" in result.output\n   133→    assert \"Deleted branch: P123-implement-feature-x-01-23-0909\" in result.output\n   134→\n   135→    # Verify old branch was deleted\n   136→    assert len(fake_git._deleted_branches) == 1\n   137→    assert fake_git._deleted_branches[0] == \"P123-implement-feature-x-01-23-0909\"\n   138→\n   139→    # Verify new branch was created with current timestamp\n   140→    # (tuple is cwd, branch_name, start_point, force)\n   141→    assert len(fake_git.created_branches) == 1\n   142→    _, created_branch, _, _ = fake_git.created_branches[0]\n   143→    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n   144→\n   145→\n   146→def test_submit_deletes_and_creates_when_user_declines_reuse(tmp_path: Path) -> None:\n   147→    \"\"\"Test submit deletes existing and creates new when user declines reuse in single prompt.\"\"\"\n   148→    plan = create_plan(\"123\", \"Implement feature X\")\n   149→    repo_root = tmp_path / \"repo\"\n   150→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n   151→        tmp_path,\n   152→        {\"123\": plan},\n   153→        git_kwargs={\n   154→            \"current_branches\": {repo_root: \"main\"},\n   155→            \"trunk_branches\": {repo_root: \"master\"},\n   156→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   157→            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n   158→        },\n   159→        # User declines \"reuse existing\" in single binary prompt\n   160→        confirm_responses=[False],\n   161→    )\n   162→\n   163→    runner = CliRunner()\n   164→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   165→\n   166→    assert result.exit_code == 0, result.output\n   167→    assert \"Deleted branch: P123-implement-feature-x-01-23-0909\" in result.output\n   168→\n   169→    # Verify old branch was deleted\n   170→    assert len(fake_git._deleted_branches) == 1\n   171→    assert fake_git._deleted_branches[0] == \"P123-implement-feature-x-01-23-0909\"\n   172→\n   173→    # Verify new branch was created\n   174→    assert len(fake_git.created_branches) == 1\n   175→\n   176→\n   177→def test_submit_uses_newest_existing_branch_when_multiple_exist(tmp_path: Path) -> None:\n   178→    \"\"\"Test submit offers newest existing branch when multiple exist.\"\"\"\n   179→    plan = create_plan(\"123\", \"Implement feature X\")\n   180→    repo_root = tmp_path / \"repo\"\n   181→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n   182→        tmp_path,\n   183→        {\"123\": plan},\n   184→        git_kwargs={\n   185→            \"current_branches\": {repo_root: \"main\"},\n   186→            \"trunk_branches\": {repo_root: \"master\"},\n   187→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   188→            \"local_branches\": {\n   189→                repo_root: [\n   190→                    \"main\",\n   191→                    \"P123-implement-feature-x-01-23-0900\",  # Older\n   192→                    \"P123-implement-feature-x-01-23-0905\",  # Middle\n   193→                    \"P123-implement-feature-x-01-23-0910\",  # Newest\n   194→                ]\n   195→            },\n   196→        },\n   197→        graphite_kwargs={\n   198→            \"branches\": {\n   199→                \"main\": BranchMetadata.trunk(\"main\"),\n   200→            },\n   201→        },\n   202→        use_graphite=True,\n   203→        # User confirms \"use existing branch\" (which will be the newest)\n   204→        confirm_responses=[True],\n   205→    )\n   206→\n   207→    runner = CliRunner()\n   208→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   209→\n   210→    assert result.exit_code == 0, result.output\n   211→\n   212→    # Verify all three branches are shown\n   213→    assert \"P123-implement-feature-x-01-23-0900\" in result.output\n   214→    assert \"P123-implement-feature-x-01-23-0905\" in result.output\n   215→    assert \"P123-implement-feature-x-01-23-0910\" in result.output\n   216→\n   217→    # Verify the newest branch is used (shown in confirmation prompt)\n   218→    # The prompt mentions the newest branch which is 0910\n   219→    assert \"Using existing local branch\" in result.output\n   220→\n   221→    # Verify existing branch was tracked\n   222→    assert len(fake_graphite.track_branch_calls) == 1\n   223→    _, tracked_branch, _ = fake_graphite.track_branch_calls[0]\n   224→    assert tracked_branch == \"P123-implement-feature-x-01-23-0910\"\n   225→\n   226→\n   227→def test_submit_proceeds_normally_when_no_existing_branches(tmp_path: Path) -> None:\n   228→    \"\"\"Test submit creates new branch when no existing branches match.\"\"\"\n   229→    plan = create_plan(\"123\", \"Implement feature X\")\n   230→    repo_root = tmp_path / \"repo\"\n   231→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n   232→        tmp_path,\n   233→        {\"123\": plan},\n   234→        git_kwargs={\n   235→            \"current_branches\": {repo_root: \"main\"},\n   236→            \"trunk_branches\": {repo_root: \"master\"},\n   237→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   238→            \"local_branches\": {repo_root: [\"main\"]},  # No P123-* branches\n   239→        },\n   240→    )\n   241→\n   242→    runner = CliRunner()\n   243→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   244→\n   245→    assert result.exit_code == 0, result.output\n   246→    # No existing branch prompt should appear\n   247→    assert \"Found existing local branch(es)\" not in result.output\n   248→    assert \"issue(s) submitted successfully!\" in result.output\n   249→\n   250→    # Verify new branch was created\n   251→    # (tuple is cwd, branch_name, start_point, force)\n   252→    assert len(fake_git.created_branches) == 1\n   253→    _, created_branch, _, _ = fake_git.created_branches[0]\n   254→    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n   255→\n   256→\n   257→def test_submit_deletes_multiple_existing_branches(tmp_path: Path) -> None:\n   258→    \"\"\"Test submit deletes all existing branches when user declines reuse.\"\"\"\n   259→    plan = create_plan(\"123\", \"Implement feature X\")\n   260→    repo_root = tmp_path / \"repo\"\n   261→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n   262→        tmp_path,\n   263→        {\"123\": plan},\n   264→        git_kwargs={\n   265→            \"current_branches\": {repo_root: \"main\"},\n   266→            \"trunk_branches\": {repo_root: \"master\"},\n   267→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   268→            \"local_branches\": {\n   269→                repo_root: [\n   270→                    \"main\",\n   271→                    \"P123-implement-feature-x-01-23-0900\",\n   272→                    \"P123-implement-feature-x-01-23-0905\",\n   273→                ]\n   274→            },\n   275→        },\n   276→        # User declines \"reuse existing\" in single binary prompt\n   277→        confirm_responses=[False],\n   278→    )\n   279→\n   280→    runner = CliRunner()\n   281→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n   282→\n   283→    assert result.exit_code == 0, result.output\n   284→    assert \"Deleted branch: P123-implement-feature-x-01-23-0900\" in result.output\n   285→    assert \"Deleted branch: P123-implement-feature-x-01-23-0905\" in result.output\n   286→\n   287→    # Verify both old branches were deleted\n   288→    assert len(fake_git._deleted_branches) == 2\n   289→    assert \"P123-implement-feature-x-01-23-0900\" in fake_git._deleted_branches\n   290→    assert \"P123-implement-feature-x-01-23-0905\" in fake_git._deleted_branches\n   291→\n   292→    # Verify new branch was created\n   293→    assert len(fake_git.created_branches) == 1\n   294→\n   295→\n   296→def test_submit_force_deletes_existing_branches_and_creates_new(tmp_path: Path) -> None:\n   297→    \"\"\"Test --force deletes existing branches without prompting.\"\"\"\n   298→    plan = create_plan(\"123\", \"Implement feature X\")\n   299→    repo_root = tmp_path / \"repo\"\n   300→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n   301→        tmp_path,\n   302→        {\"123\": plan},\n   303→        git_kwargs={\n   304→            \"current_branches\": {repo_root: \"main\"},\n   305→            \"trunk_branches\": {repo_root: \"master\"},\n   306→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   307→            \"local_branches\": {\n   308→                repo_root: [\n   309→                    \"main\",\n   310→                    \"P123-implement-feature-x-01-23-0900\",\n   311→                    \"P123-implement-feature-x-01-23-0905\",\n   312→                ]\n   313→            },\n   314→        },\n   315→        # NO confirm_responses - force mode should NOT prompt\n   316→    )\n   317→\n   318→    runner = CliRunner()\n   319→    result = runner.invoke(submit_cmd, [\"123\", \"-f\"], obj=ctx)\n   320→\n   321→    assert result.exit_code == 0, result.output\n   322→    # Should show force mode message\n   323→    assert \"Deleting 2 existing branch(es) (--force mode)\" in result.output\n   324→    # Should not show the interactive prompt message\n   325→    assert \"Use existing branch\" not in result.output\n   326→\n   327→    # Verify both old branches were deleted\n   328→    assert len(fake_git._deleted_branches) == 2\n   329→    assert \"P123-implement-feature-x-01-23-0900\" in fake_git._deleted_branches\n   330→    assert \"P123-implement-feature-x-01-23-0905\" in fake_git._deleted_branches\n   331→\n   332→    # Verify new branch was created\n   333→    assert len(fake_git.created_branches) == 1\n   334→    _, created_branch, _, _ = fake_git.created_branches[0]\n   335→    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n   336→\n   337→\n   338→def test_submit_force_creates_new_branch_when_none_exist(tmp_path: Path) -> None:\n   339→    \"\"\"Test --force creates new branch normally when no existing branches.\"\"\"\n   340→    plan = create_plan(\"123\", \"Implement feature X\")\n   341→    repo_root = tmp_path / \"repo\"\n   342→    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n   343→        tmp_path,\n   344→        {\"123\": plan},\n   345→        git_kwargs={\n   346→            \"current_branches\": {repo_root: \"main\"},\n   347→            \"trunk_branches\": {repo_root: \"master\"},\n   348→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   349→            \"local_branches\": {repo_root: [\"main\"]},  # No P123-* branches\n   350→        },\n   351→    )\n   352→\n   353→    runner = CliRunner()\n   354→    result = runner.invoke(submit_cmd, [\"123\", \"-f\"], obj=ctx)\n   355→\n   356→    assert result.exit_code == 0, result.output\n   357→    # Should not show existing branch prompts\n   358→    assert \"Found existing local branch(es)\" not in result.output\n   359→    assert \"Deleting\" not in result.output\n   360→    assert \"issue(s) submitted successfully!\" in result.output\n   361→\n   362→    # Verify new branch was created normally\n   363→    assert len(fake_git.created_branches) == 1\n   364→    _, created_branch, _, _ = fake_git.created_branches[0]\n   365→    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n   366→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"eb7da392-bc12-42c9-83f6-e8f827d0bd85","timestamp":"2026-02-22T14:45:24.106Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/test_existing_branch_detection.py","content":"\"\"\"Tests for existing branch detection and reuse in submit command.\"\"\"\n\nfrom pathlib import Path\n\nfrom click.testing import CliRunner\n\nfrom erk.cli.commands.submit import (\n    _find_existing_branches_for_issue,\n    submit_cmd,\n)\nfrom erk.core.context import context_for_test\nfrom erk_shared.gateway.graphite.types import BranchMetadata\nfrom tests.commands.submit.conftest import create_plan, setup_submit_context\n\n\ndef test_find_existing_branches_detects_matching_pattern(tmp_path: Path) -> None:\n    \"\"\"Test _find_existing_branches_for_issue finds P{issue}-* branches.\"\"\"\n    from erk_shared.gateway.git.fake import FakeGit\n\n    repo_root = tmp_path / \"repo\"\n    repo_root.mkdir()\n\n    fake_git = FakeGit(\n        current_branches={repo_root: \"main\"},\n        local_branches={\n            repo_root: [\n                \"main\",\n                \"P123-feature-01-23-0909\",\n                \"P123-feature-01-23-0910\",\n                \"P456-other-01-23-0909\",\n                \"unrelated-branch\",\n            ]\n        },\n    )\n\n    ctx = context_for_test(cwd=repo_root, git=fake_git)\n\n    result = _find_existing_branches_for_issue(ctx, repo_root, 123)\n\n    assert result == [\"P123-feature-01-23-0909\", \"P123-feature-01-23-0910\"]\n\n\ndef test_find_existing_branches_returns_empty_when_none_exist(tmp_path: Path) -> None:\n    \"\"\"Test _find_existing_branches_for_issue returns empty list when no matches.\"\"\"\n    from erk_shared.gateway.git.fake import FakeGit\n\n    repo_root = tmp_path / \"repo\"\n    repo_root.mkdir()\n\n    fake_git = FakeGit(\n        current_branches={repo_root: \"main\"},\n        local_branches={repo_root: [\"main\", \"other-branch\"]},\n    )\n\n    ctx = context_for_test(cwd=repo_root, git=fake_git)\n\n    result = _find_existing_branches_for_issue(ctx, repo_root, 123)\n\n    assert result == []\n\n\ndef test_submit_uses_existing_branch_when_user_confirms(tmp_path: Path) -> None:\n    \"\"\"Test submit reuses existing local branch when user confirms.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n        },\n        graphite_kwargs={\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n        },\n        use_graphite=True,\n        # User confirms \"use existing branch\"\n        confirm_responses=[True],\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Found existing local branch(es) for this issue\" in result.output\n    assert \"P123-implement-feature-x-01-23-0909\" in result.output\n    assert \"Using existing local branch\" in result.output\n\n    # Verify NO new branch was created (should reuse existing)\n    assert len(fake_git.created_branches) == 0\n\n    # Verify existing branch was tracked in Graphite\n    assert len(fake_graphite.track_branch_calls) == 1\n    tracked_repo, tracked_branch, parent = fake_graphite.track_branch_calls[0]\n    assert tracked_branch == \"P123-implement-feature-x-01-23-0909\"\n    assert parent == \"main\"\n\n\ndef test_submit_deletes_existing_and_creates_new_when_user_declines_reuse(\n    tmp_path: Path,\n) -> None:\n    \"\"\"Test submit deletes existing branches and creates new when user declines reuse.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n        },\n        graphite_kwargs={\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n        },\n        use_graphite=True,\n        # User declines \"reuse existing\" in single binary prompt\n        confirm_responses=[False],\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Found existing local branch(es) for this issue\" in result.output\n    assert \"Deleted branch: P123-implement-feature-x-01-23-0909\" in result.output\n\n    # Verify old branch was deleted\n    assert len(fake_git._deleted_branches) == 1\n    assert fake_git._deleted_branches[0] == \"P123-implement-feature-x-01-23-0909\"\n\n    # Verify new branch was created with current timestamp\n    # (tuple is cwd, branch_name, start_point, force)\n    assert len(fake_git.created_branches) == 1\n    _, created_branch, _, _ = fake_git.created_branches[0]\n    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n\n\ndef test_submit_deletes_and_creates_when_user_declines_reuse(tmp_path: Path) -> None:\n    \"\"\"Test submit deletes existing and creates new when user declines reuse in single prompt.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {repo_root: [\"main\", \"P123-implement-feature-x-01-23-0909\"]},\n        },\n        # User declines \"reuse existing\" in single binary prompt\n        confirm_responses=[False],\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Deleted branch: P123-implement-feature-x-01-23-0909\" in result.output\n\n    # Verify old branch was deleted\n    assert len(fake_git._deleted_branches) == 1\n    assert fake_git._deleted_branches[0] == \"P123-implement-feature-x-01-23-0909\"\n\n    # Verify new branch was created\n    assert len(fake_git.created_branches) == 1\n\n\ndef test_submit_uses_newest_existing_branch_when_multiple_exist(tmp_path: Path) -> None:\n    \"\"\"Test submit offers newest existing branch when multiple exist.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {\n                repo_root: [\n                    \"main\",\n                    \"P123-implement-feature-x-01-23-0900\",  # Older\n                    \"P123-implement-feature-x-01-23-0905\",  # Middle\n                    \"P123-implement-feature-x-01-23-0910\",  # Newest\n                ]\n            },\n        },\n        graphite_kwargs={\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n        },\n        use_graphite=True,\n        # User confirms \"use existing branch\" (which will be the newest)\n        confirm_responses=[True],\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n\n    # Verify all three branches are shown\n    assert \"P123-implement-feature-x-01-23-0900\" in result.output\n    assert \"P123-implement-feature-x-01-23-0905\" in result.output\n    assert \"P123-implement-feature-x-01-23-0910\" in result.output\n\n    # Verify the newest branch is used (shown in confirmation prompt)\n    # The prompt mentions the newest branch which is 0910\n    assert \"Using existing local branch\" in result.output\n\n    # Verify existing branch was tracked\n    assert len(fake_graphite.track_branch_calls) == 1\n    _, tracked_branch, _ = fake_graphite.track_branch_calls[0]\n    assert tracked_branch == \"P123-implement-feature-x-01-23-0910\"\n\n\ndef test_submit_proceeds_normally_when_no_existing_branches(tmp_path: Path) -> None:\n    \"\"\"Test submit creates new branch when no existing branches match.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {repo_root: [\"main\"]},  # No P123-* branches\n        },\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    # No existing branch prompt should appear\n    assert \"Found existing local branch(es)\" not in result.output\n    assert \"issue(s) submitted successfully!\" in result.output\n\n    # Verify new branch was created\n    # (tuple is cwd, branch_name, start_point, force)\n    assert len(fake_git.created_branches) == 1\n    _, created_branch, _, _ = fake_git.created_branches[0]\n    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n\n\ndef test_submit_deletes_multiple_existing_branches(tmp_path: Path) -> None:\n    \"\"\"Test submit deletes all existing branches when user declines reuse.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {\n                repo_root: [\n                    \"main\",\n                    \"P123-implement-feature-x-01-23-0900\",\n                    \"P123-implement-feature-x-01-23-0905\",\n                ]\n            },\n        },\n        # User declines \"reuse existing\" in single binary prompt\n        confirm_responses=[False],\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Deleted branch: P123-implement-feature-x-01-23-0900\" in result.output\n    assert \"Deleted branch: P123-implement-feature-x-01-23-0905\" in result.output\n\n    # Verify both old branches were deleted\n    assert len(fake_git._deleted_branches) == 2\n    assert \"P123-implement-feature-x-01-23-0900\" in fake_git._deleted_branches\n    assert \"P123-implement-feature-x-01-23-0905\" in fake_git._deleted_branches\n\n    # Verify new branch was created\n    assert len(fake_git.created_branches) == 1\n\n\ndef test_submit_force_deletes_existing_branches_and_creates_new(tmp_path: Path) -> None:\n    \"\"\"Test --force deletes existing branches without prompting.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {\n                repo_root: [\n                    \"main\",\n                    \"P123-implement-feature-x-01-23-0900\",\n                    \"P123-implement-feature-x-01-23-0905\",\n                ]\n            },\n        },\n        # NO confirm_responses - force mode should NOT prompt\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\", \"-f\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    # Should show force mode message\n    assert \"Deleting 2 existing branch(es) (--force mode)\" in result.output\n    # Should not show the interactive prompt message\n    assert \"Use existing branch\" not in result.output\n\n    # Verify both old branches were deleted\n    assert len(fake_git._deleted_branches) == 2\n    assert \"P123-implement-feature-x-01-23-0900\" in fake_git._deleted_branches\n    assert \"P123-implement-feature-x-01-23-0905\" in fake_git._deleted_branches\n\n    # Verify new branch was created\n    assert len(fake_git.created_branches) == 1\n    _, created_branch, _, _ = fake_git.created_branches[0]\n    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n\n\ndef test_submit_force_creates_new_branch_when_none_exist(tmp_path: Path) -> None:\n    \"\"\"Test --force creates new branch normally when no existing branches.\"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, _, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n            \"local_branches\": {repo_root: [\"main\"]},  # No P123-* branches\n        },\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\", \"-f\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    # Should not show existing branch prompts\n    assert \"Found existing local branch(es)\" not in result.output\n    assert \"Deleting\" not in result.output\n    assert \"issue(s) submitted successfully!\" in result.output\n\n    # Verify new branch was created normally\n    assert len(fake_git.created_branches) == 1\n    _, created_branch, _, _ = fake_git.created_branches[0]\n    assert created_branch == \"P123-implement-feature-x-01-15-1430\"\n","numLines":366,"startLine":1,"totalLines":366}}}
{"parentUuid":"eb7da392-bc12-42c9-83f6-e8f827d0bd85","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011Wt15gvG141tUvK1z1buG3","type":"tool_result","content":"     1→\"\"\"Tests for Graphite PR linking in submit command.\n     2→\n     3→These tests verify that submit properly links PRs with Graphite\n     4→by calling submit_branch after PR creation, which establishes\n     5→Graphite's remote stack metadata.\n     6→\"\"\"\n     7→\n     8→from pathlib import Path\n     9→\n    10→from click.testing import CliRunner\n    11→\n    12→from erk.cli.commands.submit import submit_cmd\n    13→from erk_shared.gateway.graphite.types import BranchMetadata\n    14→from tests.commands.submit.conftest import create_plan, setup_submit_context\n    15→\n    16→\n    17→def test_plan_submit_links_pr_with_graphite_when_enabled(tmp_path: Path) -> None:\n    18→    \"\"\"Test submit calls submit_branch to link PR with Graphite after PR creation.\n    19→\n    20→    When Graphite is enabled, after creating a PR via gh pr create, submit should\n    21→    call submit_branch to establish Graphite's remote stack metadata. This allows\n    22→    `gt log` to show the PR in Graphite's tracking.\n    23→    \"\"\"\n    24→    plan = create_plan(\"123\", \"Implement feature X\")\n    25→    repo_root = tmp_path / \"repo\"\n    26→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n    27→        tmp_path,\n    28→        {\"123\": plan},\n    29→        git_kwargs={\n    30→            \"current_branches\": {repo_root: \"main\"},\n    31→            \"trunk_branches\": {repo_root: \"master\"},\n    32→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n    33→        },\n    34→        graphite_kwargs={\n    35→            # main must be tracked for stacking to work\n    36→            \"branches\": {\n    37→                \"main\": BranchMetadata.trunk(\"main\"),\n    38→            },\n    39→        },\n    40→        use_graphite=True,\n    41→    )\n    42→\n    43→    runner = CliRunner()\n    44→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n    45→\n    46→    assert result.exit_code == 0, result.output\n    47→    assert \"Linking PR with Graphite\" in result.output\n    48→    assert \"PR linked with Graphite\" in result.output\n    49→\n    50→    # Verify submit_stack was called (GraphiteBranchManager.submit_branch calls submit_stack)\n    51→    assert len(fake_graphite.submit_stack_calls) == 1\n    52→\n    53→\n    54→def test_plan_submit_skips_graphite_linking_when_disabled(tmp_path: Path) -> None:\n    55→    \"\"\"Test submit does NOT call submit_branch when Graphite is disabled.\n    56→\n    57→    When Graphite is disabled (use_graphite=False), the submit command should\n    58→    skip the Graphite linking step entirely.\n    59→    \"\"\"\n    60→    plan = create_plan(\"123\", \"Implement feature X\")\n    61→    repo_root = tmp_path / \"repo\"\n    62→    # Note: use_graphite=False is the default\n    63→    ctx, fake_git, fake_github, _, graphite, repo_root = setup_submit_context(\n    64→        tmp_path,\n    65→        {\"123\": plan},\n    66→        git_kwargs={\n    67→            \"current_branches\": {repo_root: \"main\"},\n    68→            \"trunk_branches\": {repo_root: \"master\"},\n    69→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n    70→        },\n    71→        use_graphite=False,\n    72→    )\n    73→\n    74→    runner = CliRunner()\n    75→    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n    76→\n    77→    assert result.exit_code == 0, result.output\n    78→    # Should NOT have Graphite linking messages\n    79→    assert \"Linking PR with Graphite\" not in result.output\n    80→    # When Graphite is disabled, graphite is GraphiteDisabled (not FakeGraphite)\n    81→    # The fact that there are no Graphite messages in output confirms it was skipped\n    82→\n    83→\n    84→def test_plan_submit_existing_branch_links_with_graphite(tmp_path: Path) -> None:\n    85→    \"\"\"Test submit links PR with Graphite when using existing branch path.\n    86→\n    87→    When a branch already exists on remote but has no PR (Path 2 in submit),\n    88→    after creating the PR, submit should still call submit_branch to\n    89→    establish Graphite's remote stack metadata.\n    90→    \"\"\"\n    91→    plan = create_plan(\"456\", \"Fix bug in feature\")\n    92→    repo_root = tmp_path / \"repo\"\n    93→    # Pre-compute the expected branch name: P<issue>-<sanitized-title>-<timestamp>\n    94→    expected_branch = \"P456-fix-bug-in-feature-01-15-1430\"\n    95→\n    96→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n    97→        tmp_path,\n    98→        {\"456\": plan},\n    99→        git_kwargs={\n   100→            \"current_branches\": {repo_root: \"main\"},\n   101→            \"trunk_branches\": {repo_root: \"master\"},\n   102→            # Branch already exists on remote (FakeGit checks this list for branch_exists_on_remote)\n   103→            \"remote_branches\": {repo_root: [\"origin/main\", f\"origin/{expected_branch}\"]},\n   104→        },\n   105→        use_graphite=True,\n   106→    )\n   107→\n   108→    runner = CliRunner()\n   109→    result = runner.invoke(submit_cmd, [\"456\"], obj=ctx)\n   110→\n   111→    assert result.exit_code == 0, result.output\n   112→    assert \"Linking PR with Graphite\" in result.output\n   113→    assert \"PR linked with Graphite\" in result.output\n   114→\n   115→    # Verify submit_stack was called for the existing branch path\n   116→    assert len(fake_graphite.submit_stack_calls) == 1\n   117→\n   118→\n   119→def test_plan_submit_shows_error_when_graphite_submit_fails(tmp_path: Path) -> None:\n   120→    \"\"\"Test submit shows error message when Graphite submit_branch fails.\n   121→\n   122→    When Graphite submit fails during PR creation, the command should still\n   123→    succeed (PR already created) but display an error about the failure.\n   124→    \"\"\"\n   125→    plan = create_plan(\"789\", \"Implement feature Y\")\n   126→    repo_root = tmp_path / \"repo\"\n   127→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n   128→        tmp_path,\n   129→        {\"789\": plan},\n   130→        git_kwargs={\n   131→            \"current_branches\": {repo_root: \"main\"},\n   132→            \"trunk_branches\": {repo_root: \"master\"},\n   133→            \"remote_branches\": {repo_root: [\"origin/main\"]},\n   134→        },\n   135→        graphite_kwargs={\n   136→            \"branches\": {\n   137→                \"main\": BranchMetadata.trunk(\"main\"),\n   138→            },\n   139→            \"submit_stack_raises\": RuntimeError(\"network error\"),\n   140→        },\n   141→        use_graphite=True,\n   142→    )\n   143→\n   144→    runner = CliRunner()\n   145→    result = runner.invoke(submit_cmd, [\"789\"], obj=ctx)\n   146→\n   147→    assert result.exit_code == 0, result.output\n   148→    assert \"Linking PR with Graphite\" in result.output\n   149→    assert \"Failed to link PR with Graphite\" in result.output\n   150→    assert \"network error\" in result.output\n   151→\n   152→\n   153→def test_plan_submit_existing_branch_shows_error_when_graphite_submit_fails(\n   154→    tmp_path: Path,\n   155→) -> None:\n   156→    \"\"\"Test submit shows error when Graphite submit_branch fails on existing branch path.\n   157→\n   158→    When a branch already exists on remote but has no PR, and Graphite submit fails\n   159→    after creating the PR, the command should still succeed but show an error.\n   160→    \"\"\"\n   161→    plan = create_plan(\"456\", \"Fix bug in feature\")\n   162→    repo_root = tmp_path / \"repo\"\n   163→    expected_branch = \"P456-fix-bug-in-feature-01-15-1430\"\n   164→\n   165→    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n   166→        tmp_path,\n   167→        {\"456\": plan},\n   168→        git_kwargs={\n   169→            \"current_branches\": {repo_root: \"main\"},\n   170→            \"trunk_branches\": {repo_root: \"master\"},\n   171→            \"remote_branches\": {repo_root: [\"origin/main\", f\"origin/{expected_branch}\"]},\n   172→        },\n   173→        graphite_kwargs={\n   174→            \"submit_stack_raises\": RuntimeError(\"timeout error\"),\n   175→        },\n   176→        use_graphite=True,\n   177→    )\n   178→\n   179→    runner = CliRunner()\n   180→    result = runner.invoke(submit_cmd, [\"456\"], obj=ctx)\n   181→\n   182→    assert result.exit_code == 0, result.output\n   183→    assert \"Linking PR with Graphite\" in result.output\n   184→    assert \"Failed to link PR with Graphite\" in result.output\n   185→    assert \"timeout error\" in result.output\n   186→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"9a7e07e3-7075-42c1-b6e1-ebf1e783f87d","timestamp":"2026-02-22T14:45:24.106Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/test_graphite_linking.py","content":"\"\"\"Tests for Graphite PR linking in submit command.\n\nThese tests verify that submit properly links PRs with Graphite\nby calling submit_branch after PR creation, which establishes\nGraphite's remote stack metadata.\n\"\"\"\n\nfrom pathlib import Path\n\nfrom click.testing import CliRunner\n\nfrom erk.cli.commands.submit import submit_cmd\nfrom erk_shared.gateway.graphite.types import BranchMetadata\nfrom tests.commands.submit.conftest import create_plan, setup_submit_context\n\n\ndef test_plan_submit_links_pr_with_graphite_when_enabled(tmp_path: Path) -> None:\n    \"\"\"Test submit calls submit_branch to link PR with Graphite after PR creation.\n\n    When Graphite is enabled, after creating a PR via gh pr create, submit should\n    call submit_branch to establish Graphite's remote stack metadata. This allows\n    `gt log` to show the PR in Graphite's tracking.\n    \"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n        },\n        graphite_kwargs={\n            # main must be tracked for stacking to work\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n        },\n        use_graphite=True,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Linking PR with Graphite\" in result.output\n    assert \"PR linked with Graphite\" in result.output\n\n    # Verify submit_stack was called (GraphiteBranchManager.submit_branch calls submit_stack)\n    assert len(fake_graphite.submit_stack_calls) == 1\n\n\ndef test_plan_submit_skips_graphite_linking_when_disabled(tmp_path: Path) -> None:\n    \"\"\"Test submit does NOT call submit_branch when Graphite is disabled.\n\n    When Graphite is disabled (use_graphite=False), the submit command should\n    skip the Graphite linking step entirely.\n    \"\"\"\n    plan = create_plan(\"123\", \"Implement feature X\")\n    repo_root = tmp_path / \"repo\"\n    # Note: use_graphite=False is the default\n    ctx, fake_git, fake_github, _, graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"123\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n        },\n        use_graphite=False,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"123\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    # Should NOT have Graphite linking messages\n    assert \"Linking PR with Graphite\" not in result.output\n    # When Graphite is disabled, graphite is GraphiteDisabled (not FakeGraphite)\n    # The fact that there are no Graphite messages in output confirms it was skipped\n\n\ndef test_plan_submit_existing_branch_links_with_graphite(tmp_path: Path) -> None:\n    \"\"\"Test submit links PR with Graphite when using existing branch path.\n\n    When a branch already exists on remote but has no PR (Path 2 in submit),\n    after creating the PR, submit should still call submit_branch to\n    establish Graphite's remote stack metadata.\n    \"\"\"\n    plan = create_plan(\"456\", \"Fix bug in feature\")\n    repo_root = tmp_path / \"repo\"\n    # Pre-compute the expected branch name: P<issue>-<sanitized-title>-<timestamp>\n    expected_branch = \"P456-fix-bug-in-feature-01-15-1430\"\n\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"456\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            # Branch already exists on remote (FakeGit checks this list for branch_exists_on_remote)\n            \"remote_branches\": {repo_root: [\"origin/main\", f\"origin/{expected_branch}\"]},\n        },\n        use_graphite=True,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"456\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Linking PR with Graphite\" in result.output\n    assert \"PR linked with Graphite\" in result.output\n\n    # Verify submit_stack was called for the existing branch path\n    assert len(fake_graphite.submit_stack_calls) == 1\n\n\ndef test_plan_submit_shows_error_when_graphite_submit_fails(tmp_path: Path) -> None:\n    \"\"\"Test submit shows error message when Graphite submit_branch fails.\n\n    When Graphite submit fails during PR creation, the command should still\n    succeed (PR already created) but display an error about the failure.\n    \"\"\"\n    plan = create_plan(\"789\", \"Implement feature Y\")\n    repo_root = tmp_path / \"repo\"\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"789\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\"]},\n        },\n        graphite_kwargs={\n            \"branches\": {\n                \"main\": BranchMetadata.trunk(\"main\"),\n            },\n            \"submit_stack_raises\": RuntimeError(\"network error\"),\n        },\n        use_graphite=True,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"789\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Linking PR with Graphite\" in result.output\n    assert \"Failed to link PR with Graphite\" in result.output\n    assert \"network error\" in result.output\n\n\ndef test_plan_submit_existing_branch_shows_error_when_graphite_submit_fails(\n    tmp_path: Path,\n) -> None:\n    \"\"\"Test submit shows error when Graphite submit_branch fails on existing branch path.\n\n    When a branch already exists on remote but has no PR, and Graphite submit fails\n    after creating the PR, the command should still succeed but show an error.\n    \"\"\"\n    plan = create_plan(\"456\", \"Fix bug in feature\")\n    repo_root = tmp_path / \"repo\"\n    expected_branch = \"P456-fix-bug-in-feature-01-15-1430\"\n\n    ctx, fake_git, fake_github, _, fake_graphite, repo_root = setup_submit_context(\n        tmp_path,\n        {\"456\": plan},\n        git_kwargs={\n            \"current_branches\": {repo_root: \"main\"},\n            \"trunk_branches\": {repo_root: \"master\"},\n            \"remote_branches\": {repo_root: [\"origin/main\", f\"origin/{expected_branch}\"]},\n        },\n        graphite_kwargs={\n            \"submit_stack_raises\": RuntimeError(\"timeout error\"),\n        },\n        use_graphite=True,\n    )\n\n    runner = CliRunner()\n    result = runner.invoke(submit_cmd, [\"456\"], obj=ctx)\n\n    assert result.exit_code == 0, result.output\n    assert \"Linking PR with Graphite\" in result.output\n    assert \"Failed to link PR with Graphite\" in result.output\n    assert \"timeout error\" in result.output\n","numLines":186,"startLine":1,"totalLines":186}}}
{"parentUuid":"9a7e07e3-7075-42c1-b6e1-ebf1e783f87d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01271QJ9q9tnHPhttvWFUJbk","type":"message","role":"assistant","content":[{"type":"text","text":"The issue is clear: the `setup_submit_context` creates an `ErkContext` with a default `FakePromptExecutor` that returns `\"Test Title\\n\\nTest body\"`. I need to check the conftest to see how the context is being created:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11122,"cache_read_input_tokens":108953,"cache_creation":{"ephemeral_5m_input_tokens":11122,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdmyE6yAqr5j3yB9DY","type":"assistant","uuid":"0ebad5e3-605f-48ab-b833-805aaa1b20e8","timestamp":"2026-02-22T14:45:27.799Z"}
{"parentUuid":"0ebad5e3-605f-48ab-b833-805aaa1b20e8","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01271QJ9q9tnHPhttvWFUJbk","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01JugEaTkd31LvenJioShj2A","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":11122,"cache_read_input_tokens":108953,"cache_creation":{"ephemeral_5m_input_tokens":11122,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHdmyE6yAqr5j3yB9DY","type":"assistant","uuid":"0d0caee7-fabd-4a6f-ad1f-21f368f957cd","timestamp":"2026-02-22T14:45:28.317Z"}
{"parentUuid":"0d0caee7-fabd-4a6f-ad1f-21f368f957cd","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01JugEaTkd31LvenJioShj2A","type":"tool_result","content":"     1→\"\"\"Shared fixtures and helpers for submit command tests.\"\"\"\n     2→\n     3→from datetime import UTC, datetime\n     4→from pathlib import Path\n     5→\n     6→from erk.cli.commands.submit import ERK_PLAN_LABEL\n     7→from erk.core.context import context_for_test\n     8→from erk.core.repo_discovery import RepoContext\n     9→from erk_shared.gateway.github.metadata.core import render_metadata_block\n    10→from erk_shared.gateway.github.metadata.types import MetadataBlock\n    11→from erk_shared.plan_store.types import Plan, PlanState\n    12→from tests.test_utils.plan_helpers import create_plan_store\n    13→\n    14→\n    15→def make_plan_body(content: str = \"Implementation details...\") -> str:\n    16→    \"\"\"Create a valid issue body with plan-header metadata block.\n    17→\n    18→    The plan-header block is required for `update_plan_header_dispatch` to work.\n    19→    \"\"\"\n    20→    plan_header_data = {\n    21→        \"schema_version\": \"2\",\n    22→        \"created_at\": \"2024-01-01T00:00:00Z\",\n    23→        \"created_by\": \"test-user\",\n    24→    }\n    25→    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    26→    return f\"{header_block}\\n\\n# Plan\\n\\n{content}\"\n    27→\n    28→\n    29→def make_learn_plan_body(content: str = \"Documentation learning...\") -> str:\n    30→    \"\"\"Create a valid learn plan issue body with plan-header metadata block.\n    31→\n    32→    Note: Learn plans are identified by the erk-learn label, not by metadata fields.\n    33→    \"\"\"\n    34→    plan_header_data = {\n    35→        \"schema_version\": \"2\",\n    36→        \"created_at\": \"2024-01-01T00:00:00Z\",\n    37→        \"created_by\": \"test-user\",\n    38→    }\n    39→    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    40→    return f\"{header_block}\\n\\n# Learn Plan\\n\\n{content}\"\n    41→\n    42→\n    43→def create_plan(\n    44→    plan_identifier: str,\n    45→    title: str,\n    46→    body: str | None = None,\n    47→    state: PlanState = PlanState.OPEN,\n    48→    labels: list[str] | None = None,\n    49→) -> Plan:\n    50→    \"\"\"Create a Plan with common defaults for testing.\"\"\"\n    51→    now = datetime.now(UTC)\n    52→    return Plan(\n    53→        plan_identifier=plan_identifier,\n    54→        title=title,\n    55→        body=body if body is not None else make_plan_body(),\n    56→        state=state,\n    57→        url=f\"https://github.com/test-owner/test-repo/issues/{plan_identifier}\",\n    58→        labels=labels if labels is not None else [ERK_PLAN_LABEL],\n    59→        assignees=[],\n    60→        created_at=now,\n    61→        updated_at=now,\n    62→        metadata={},\n    63→        objective_id=None,\n    64→    )\n    65→\n    66→\n    67→def setup_submit_context(\n    68→    tmp_path: Path,\n    69→    plans: dict[str, Plan],\n    70→    git_kwargs: dict | None = None,\n    71→    github_kwargs: dict | None = None,\n    72→    issues_kwargs: dict | None = None,\n    73→    graphite_kwargs: dict | None = None,\n    74→    *,\n    75→    use_graphite: bool = False,\n    76→    confirm_responses: list[bool] | None = None,\n    77→    remote_branch_refs: list[str] | None = None,\n    78→    backend: str = \"github\",\n    79→):\n    80→    \"\"\"Setup common context for submit tests.\n    81→\n    82→    Args:\n    83→        use_graphite: If True, enable Graphite integration (allows track_branch calls).\n    84→                     Default False for backwards compatibility with existing tests.\n    85→        confirm_responses: List of boolean responses for ctx.console.confirm() calls.\n    86→                          If None, uses default FakeConsole with no responses configured.\n    87→        remote_branch_refs: List of remote branch refs (e.g., [\"origin/branch\", \"origin/master\"]).\n    88→                           These are passed to FakeGit's remote_branches keyed by repo_root.\n    89→        backend: Plan store backend type - \"github\" or \"draft_pr\".\n    90→\n    91→    Returns (ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root)\n    92→        where fake_backing is FakeGitHubIssues (github) or FakeGitHub (draft_pr).\n    93→    \"\"\"\n    94→    from erk_shared.context.types import GlobalConfig\n    95→    from erk_shared.gateway.console.fake import FakeConsole\n    96→    from erk_shared.gateway.git.fake import FakeGit\n    97→    from erk_shared.gateway.github.fake import FakeGitHub\n    98→    from erk_shared.gateway.github.issues.fake import FakeGitHubIssues\n    99→    from erk_shared.gateway.graphite.fake import FakeGraphite\n   100→\n   101→    repo_root = tmp_path / \"repo\"\n   102→    repo_root.mkdir()\n   103→\n   104→    fake_plan_store, fake_backing = create_plan_store(plans, backend=backend)\n   105→\n   106→    git_kwargs = git_kwargs or {}\n   107→    if \"current_branches\" not in git_kwargs:\n   108→        git_kwargs[\"current_branches\"] = {repo_root: \"main\"}\n   109→    if \"trunk_branches\" not in git_kwargs:\n   110→        git_kwargs[\"trunk_branches\"] = {repo_root: \"master\"}\n   111→    if remote_branch_refs is not None:\n   112→        git_kwargs[\"remote_branches\"] = {repo_root: remote_branch_refs}\n   113→\n   114→    fake_git = FakeGit(**git_kwargs)\n   115→    fake_github = FakeGitHub(**(github_kwargs or {}))\n   116→    # When use_graphite=False, use GraphiteDisabled sentinel to match production behavior\n   117→    if use_graphite:\n   118→        fake_graphite = FakeGraphite(**(graphite_kwargs or {}))\n   119→    else:\n   120→        from erk_shared.gateway.graphite.disabled import (\n   121→            GraphiteDisabled,\n   122→            GraphiteDisabledReason,\n   123→        )\n   124→\n   125→        fake_graphite = GraphiteDisabled(GraphiteDisabledReason.CONFIG_DISABLED)\n   126→\n   127→    # Update issues kwargs if provided (only applicable to github backend)\n   128→    if issues_kwargs and isinstance(fake_backing, FakeGitHubIssues):\n   129→        for key, value in issues_kwargs.items():\n   130→            setattr(fake_backing, f\"_{key}\", value)\n   131→\n   132→    repo_dir = tmp_path / \".erk\" / \"repos\" / \"test-repo\"\n   133→    repo = RepoContext(\n   134→        root=repo_root,\n   135→        repo_name=\"test-repo\",\n   136→        repo_dir=repo_dir,\n   137→        worktrees_dir=repo_dir / \"worktrees\",\n   138→        pool_json_path=repo_dir / \"pool.json\",\n   139→    )\n   140→\n   141→    # Create GlobalConfig with use_graphite setting\n   142→    global_config = GlobalConfig.test(erk_root=repo_dir, use_graphite=use_graphite)\n   143→\n   144→    # Create FakeConsole with confirm responses if provided\n   145→    fake_console = FakeConsole(\n   146→        is_interactive=True,\n   147→        is_stdout_tty=None,\n   148→        is_stderr_tty=None,\n   149→        confirm_responses=confirm_responses,\n   150→    )\n   151→\n   152→    # Wire up issues gateway: for github backend, use the fake backing;\n   153→    # for draft_pr backend, let context_for_test create a default FakeGitHubIssues\n   154→    fake_issues = fake_backing if isinstance(fake_backing, FakeGitHubIssues) else None\n   155→\n   156→    ctx = context_for_test(\n   157→        cwd=repo_root,\n   158→        git=fake_git,\n   159→        github=fake_github,\n   160→        issues=fake_issues,\n   161→        plan_store=fake_plan_store,\n   162→        graphite=fake_graphite,\n   163→        repo=repo,\n   164→        global_config=global_config,\n   165→        console=fake_console,\n   166→    )\n   167→\n   168→    return ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root\n   169→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"a7c1e68e-a2a2-460a-bea6-72a999226902","timestamp":"2026-02-22T14:45:28.335Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py","content":"\"\"\"Shared fixtures and helpers for submit command tests.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nfrom erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.github.metadata.core import render_metadata_block\nfrom erk_shared.gateway.github.metadata.types import MetadataBlock\nfrom erk_shared.plan_store.types import Plan, PlanState\nfrom tests.test_utils.plan_helpers import create_plan_store\n\n\ndef make_plan_body(content: str = \"Implementation details...\") -> str:\n    \"\"\"Create a valid issue body with plan-header metadata block.\n\n    The plan-header block is required for `update_plan_header_dispatch` to work.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Plan\\n\\n{content}\"\n\n\ndef make_learn_plan_body(content: str = \"Documentation learning...\") -> str:\n    \"\"\"Create a valid learn plan issue body with plan-header metadata block.\n\n    Note: Learn plans are identified by the erk-learn label, not by metadata fields.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Learn Plan\\n\\n{content}\"\n\n\ndef create_plan(\n    plan_identifier: str,\n    title: str,\n    body: str | None = None,\n    state: PlanState = PlanState.OPEN,\n    labels: list[str] | None = None,\n) -> Plan:\n    \"\"\"Create a Plan with common defaults for testing.\"\"\"\n    now = datetime.now(UTC)\n    return Plan(\n        plan_identifier=plan_identifier,\n        title=title,\n        body=body if body is not None else make_plan_body(),\n        state=state,\n        url=f\"https://github.com/test-owner/test-repo/issues/{plan_identifier}\",\n        labels=labels if labels is not None else [ERK_PLAN_LABEL],\n        assignees=[],\n        created_at=now,\n        updated_at=now,\n        metadata={},\n        objective_id=None,\n    )\n\n\ndef setup_submit_context(\n    tmp_path: Path,\n    plans: dict[str, Plan],\n    git_kwargs: dict | None = None,\n    github_kwargs: dict | None = None,\n    issues_kwargs: dict | None = None,\n    graphite_kwargs: dict | None = None,\n    *,\n    use_graphite: bool = False,\n    confirm_responses: list[bool] | None = None,\n    remote_branch_refs: list[str] | None = None,\n    backend: str = \"github\",\n):\n    \"\"\"Setup common context for submit tests.\n\n    Args:\n        use_graphite: If True, enable Graphite integration (allows track_branch calls).\n                     Default False for backwards compatibility with existing tests.\n        confirm_responses: List of boolean responses for ctx.console.confirm() calls.\n                          If None, uses default FakeConsole with no responses configured.\n        remote_branch_refs: List of remote branch refs (e.g., [\"origin/branch\", \"origin/master\"]).\n                           These are passed to FakeGit's remote_branches keyed by repo_root.\n        backend: Plan store backend type - \"github\" or \"draft_pr\".\n\n    Returns (ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root)\n        where fake_backing is FakeGitHubIssues (github) or FakeGitHub (draft_pr).\n    \"\"\"\n    from erk_shared.context.types import GlobalConfig\n    from erk_shared.gateway.console.fake import FakeConsole\n    from erk_shared.gateway.git.fake import FakeGit\n    from erk_shared.gateway.github.fake import FakeGitHub\n    from erk_shared.gateway.github.issues.fake import FakeGitHubIssues\n    from erk_shared.gateway.graphite.fake import FakeGraphite\n\n    repo_root = tmp_path / \"repo\"\n    repo_root.mkdir()\n\n    fake_plan_store, fake_backing = create_plan_store(plans, backend=backend)\n\n    git_kwargs = git_kwargs or {}\n    if \"current_branches\" not in git_kwargs:\n        git_kwargs[\"current_branches\"] = {repo_root: \"main\"}\n    if \"trunk_branches\" not in git_kwargs:\n        git_kwargs[\"trunk_branches\"] = {repo_root: \"master\"}\n    if remote_branch_refs is not None:\n        git_kwargs[\"remote_branches\"] = {repo_root: remote_branch_refs}\n\n    fake_git = FakeGit(**git_kwargs)\n    fake_github = FakeGitHub(**(github_kwargs or {}))\n    # When use_graphite=False, use GraphiteDisabled sentinel to match production behavior\n    if use_graphite:\n        fake_graphite = FakeGraphite(**(graphite_kwargs or {}))\n    else:\n        from erk_shared.gateway.graphite.disabled import (\n            GraphiteDisabled,\n            GraphiteDisabledReason,\n        )\n\n        fake_graphite = GraphiteDisabled(GraphiteDisabledReason.CONFIG_DISABLED)\n\n    # Update issues kwargs if provided (only applicable to github backend)\n    if issues_kwargs and isinstance(fake_backing, FakeGitHubIssues):\n        for key, value in issues_kwargs.items():\n            setattr(fake_backing, f\"_{key}\", value)\n\n    repo_dir = tmp_path / \".erk\" / \"repos\" / \"test-repo\"\n    repo = RepoContext(\n        root=repo_root,\n        repo_name=\"test-repo\",\n        repo_dir=repo_dir,\n        worktrees_dir=repo_dir / \"worktrees\",\n        pool_json_path=repo_dir / \"pool.json\",\n    )\n\n    # Create GlobalConfig with use_graphite setting\n    global_config = GlobalConfig.test(erk_root=repo_dir, use_graphite=use_graphite)\n\n    # Create FakeConsole with confirm responses if provided\n    fake_console = FakeConsole(\n        is_interactive=True,\n        is_stdout_tty=None,\n        is_stderr_tty=None,\n        confirm_responses=confirm_responses,\n    )\n\n    # Wire up issues gateway: for github backend, use the fake backing;\n    # for draft_pr backend, let context_for_test create a default FakeGitHubIssues\n    fake_issues = fake_backing if isinstance(fake_backing, FakeGitHubIssues) else None\n\n    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n    )\n\n    return ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root\n","numLines":169,"startLine":1,"totalLines":169}}}
{"parentUuid":"a7c1e68e-a2a2-460a-bea6-72a999226902","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01H6HY2dYEQkkoiGmU3KCQnu","type":"message","role":"assistant","content":[{"type":"text","text":"The `context_for_test` creates a default `FakePromptExecutor` which has `simulated_prompt_output=None`, defaulting to `\"Test Title\\n\\nTest body\"`. The fix is to configure the `FakePromptExecutor` in the submit test context to simulate failure (so the slug generator falls back to the raw title). Let me check `context_for_test` to see if it takes a `prompt_executor` parameter:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2680,"cache_read_input_tokens":120075,"cache_creation":{"ephemeral_5m_input_tokens":2680,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHe6798UitD1mnJndd4","type":"assistant","uuid":"52fbc9d6-1bb7-4887-93c7-d98a5b8909a2","timestamp":"2026-02-22T14:45:32.995Z"}
{"parentUuid":"52fbc9d6-1bb7-4887-93c7-d98a5b8909a2","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01H6HY2dYEQkkoiGmU3KCQnu","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EoK4yHVABCvByz8gY2NrX6","name":"Grep","input":{"pattern":"def context_for_test","path":"/home/runner/work/erk/erk/src/erk/core/context.py","output_mode":"content","-A":50},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2680,"cache_read_input_tokens":120075,"cache_creation":{"ephemeral_5m_input_tokens":2680,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHe6798UitD1mnJndd4","type":"assistant","uuid":"c3735749-97eb-447c-a47a-2fddf5de2021","timestamp":"2026-02-22T14:45:34.098Z"}
{"parentUuid":"c3735749-97eb-447c-a47a-2fddf5de2021","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EoK4yHVABCvByz8gY2NrX6","type":"tool_result","content":"192:def context_for_test(\n193-    *,\n194-    git: Git | None = None,\n195-    github: GitHub | None = None,\n196-    github_admin: GitHubAdmin | None = None,\n197-    issues: GitHubIssues | None = None,\n198-    plan_store: PlanStore | None = None,\n199-    graphite: Graphite | None = None,\n200-    console: Console | None = None,\n201-    shell: Shell | None = None,\n202-    codespace: Codespace | None = None,\n203-    agent_launcher: AgentLauncher | None = None,\n204-    agent_docs: AgentDocs | None = None,\n205-    completion: Completion | None = None,\n206-    time: Time | None = None,\n207-    erk_installation: ErkInstallation | None = None,\n208-    script_writer: ScriptWriter | None = None,\n209-    plan_list_service: PlanListService | None = None,\n210-    objective_list_service: ObjectiveListService | None = None,\n211-    codespace_registry: CodespaceRegistry | None = None,\n212-    claude_installation: ClaudeInstallation | None = None,\n213-    prompt_executor: PromptExecutor | None = None,\n214-    cwd: Path | None = None,\n215-    global_config: GlobalConfig | None = None,\n216-    local_config: LoadedConfig | None = None,\n217-    repo: RepoContext | NoRepoSentinel | None = None,\n218-    repo_info: RepoInfo | None = None,\n219-    package_info: ErkPackageInfo | None = None,\n220-    dry_run: bool = False,\n221-    debug: bool = False,\n222-) -> ErkContext:\n223-    \"\"\"Create test context with optional pre-configured integration classes.\n224-\n225-    Provides full control over all context parameters with sensible test defaults\n226-    for any unspecified values. Use this for complex test scenarios that need\n227-    specific configurations for multiple integration classes.\n228-\n229-    Args:\n230-        git: Optional Git implementation. If None, creates empty FakeGit.\n231-        github: Optional GitHub implementation. If None, creates empty FakeGitHub.\n232-        issues: Optional GitHubIssues implementation.\n233-                   If None, creates empty FakeGitHubIssues.\n234-        graphite: Optional Graphite implementation.\n235-                     If None, creates empty FakeGraphite.\n236-        console: Optional Console implementation. If None, creates FakeConsole.\n237-        shell: Optional Shell implementation. If None, creates empty FakeShell.\n238-        completion: Optional Completion implementation.\n239-                       If None, creates empty FakeCompletion.\n240-        erk_installation: Optional ErkInstallation implementation.\n241-                          If None, creates FakeErkInstallation with test config.\n242-        script_writer: Optional ScriptWriter implementation."}]},"uuid":"1d082d13-10b6-452f-a139-5bb5dad30c66","timestamp":"2026-02-22T14:45:34.552Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"192:def context_for_test(\n193-    *,\n194-    git: Git | None = None,\n195-    github: GitHub | None = None,\n196-    github_admin: GitHubAdmin | None = None,\n197-    issues: GitHubIssues | None = None,\n198-    plan_store: PlanStore | None = None,\n199-    graphite: Graphite | None = None,\n200-    console: Console | None = None,\n201-    shell: Shell | None = None,\n202-    codespace: Codespace | None = None,\n203-    agent_launcher: AgentLauncher | None = None,\n204-    agent_docs: AgentDocs | None = None,\n205-    completion: Completion | None = None,\n206-    time: Time | None = None,\n207-    erk_installation: ErkInstallation | None = None,\n208-    script_writer: ScriptWriter | None = None,\n209-    plan_list_service: PlanListService | None = None,\n210-    objective_list_service: ObjectiveListService | None = None,\n211-    codespace_registry: CodespaceRegistry | None = None,\n212-    claude_installation: ClaudeInstallation | None = None,\n213-    prompt_executor: PromptExecutor | None = None,\n214-    cwd: Path | None = None,\n215-    global_config: GlobalConfig | None = None,\n216-    local_config: LoadedConfig | None = None,\n217-    repo: RepoContext | NoRepoSentinel | None = None,\n218-    repo_info: RepoInfo | None = None,\n219-    package_info: ErkPackageInfo | None = None,\n220-    dry_run: bool = False,\n221-    debug: bool = False,\n222-) -> ErkContext:\n223-    \"\"\"Create test context with optional pre-configured integration classes.\n224-\n225-    Provides full control over all context parameters with sensible test defaults\n226-    for any unspecified values. Use this for complex test scenarios that need\n227-    specific configurations for multiple integration classes.\n228-\n229-    Args:\n230-        git: Optional Git implementation. If None, creates empty FakeGit.\n231-        github: Optional GitHub implementation. If None, creates empty FakeGitHub.\n232-        issues: Optional GitHubIssues implementation.\n233-                   If None, creates empty FakeGitHubIssues.\n234-        graphite: Optional Graphite implementation.\n235-                     If None, creates empty FakeGraphite.\n236-        console: Optional Console implementation. If None, creates FakeConsole.\n237-        shell: Optional Shell implementation. If None, creates empty FakeShell.\n238-        completion: Optional Completion implementation.\n239-                       If None, creates empty FakeCompletion.\n240-        erk_installation: Optional ErkInstallation implementation.\n241-                          If None, creates FakeErkInstallation with test config.\n242-        script_writer: Optional ScriptWriter implementation.","numLines":51}}
{"parentUuid":"1d082d13-10b6-452f-a139-5bb5dad30c66","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01PgVZjA4CqACfFPZEBUzBQV","type":"message","role":"assistant","content":[{"type":"text","text":"`context_for_test` accepts `prompt_executor`. The cleanest fix is to pass a `FakePromptExecutor` configured to error (simulating \"LLM unavailable\") in the submit test conftest, so it falls back to the raw title. This way, the tests keep their existing assertions about branch names."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1198,"cache_read_input_tokens":122755,"cache_creation":{"ephemeral_5m_input_tokens":1198,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHeYYctv6zMRxJxs1Nc","type":"assistant","uuid":"70a05a3d-6ccb-453a-9d31-980f11b9f08e","timestamp":"2026-02-22T14:45:38.879Z"}
{"parentUuid":"70a05a3d-6ccb-453a-9d31-980f11b9f08e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01PgVZjA4CqACfFPZEBUzBQV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0178cGttLPgo4rmZhmiaLb9L","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py","old_string":"from erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext","new_string":"from erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext\nfrom tests.fakes.prompt_executor import FakePromptExecutor"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1198,"cache_read_input_tokens":122755,"cache_creation":{"ephemeral_5m_input_tokens":1198,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHeYYctv6zMRxJxs1Nc","type":"assistant","uuid":"fd245ba9-fa17-4b79-ba6b-51b6c1b32bf0","timestamp":"2026-02-22T14:45:40.676Z"}
{"parentUuid":"fd245ba9-fa17-4b79-ba6b-51b6c1b32bf0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0178cGttLPgo4rmZhmiaLb9L","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/submit/conftest.py has been updated successfully."}]},"uuid":"ca5501a5-ded2-4e02-90eb-99b8a4dce6d1","timestamp":"2026-02-22T14:45:41.356Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py","oldString":"from erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext","newString":"from erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext\nfrom tests.fakes.prompt_executor import FakePromptExecutor","originalFile":"\"\"\"Shared fixtures and helpers for submit command tests.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nfrom erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext\nfrom erk_shared.gateway.github.metadata.core import render_metadata_block\nfrom erk_shared.gateway.github.metadata.types import MetadataBlock\nfrom erk_shared.plan_store.types import Plan, PlanState\nfrom tests.test_utils.plan_helpers import create_plan_store\n\n\ndef make_plan_body(content: str = \"Implementation details...\") -> str:\n    \"\"\"Create a valid issue body with plan-header metadata block.\n\n    The plan-header block is required for `update_plan_header_dispatch` to work.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Plan\\n\\n{content}\"\n\n\ndef make_learn_plan_body(content: str = \"Documentation learning...\") -> str:\n    \"\"\"Create a valid learn plan issue body with plan-header metadata block.\n\n    Note: Learn plans are identified by the erk-learn label, not by metadata fields.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Learn Plan\\n\\n{content}\"\n\n\ndef create_plan(\n    plan_identifier: str,\n    title: str,\n    body: str | None = None,\n    state: PlanState = PlanState.OPEN,\n    labels: list[str] | None = None,\n) -> Plan:\n    \"\"\"Create a Plan with common defaults for testing.\"\"\"\n    now = datetime.now(UTC)\n    return Plan(\n        plan_identifier=plan_identifier,\n        title=title,\n        body=body if body is not None else make_plan_body(),\n        state=state,\n        url=f\"https://github.com/test-owner/test-repo/issues/{plan_identifier}\",\n        labels=labels if labels is not None else [ERK_PLAN_LABEL],\n        assignees=[],\n        created_at=now,\n        updated_at=now,\n        metadata={},\n        objective_id=None,\n    )\n\n\ndef setup_submit_context(\n    tmp_path: Path,\n    plans: dict[str, Plan],\n    git_kwargs: dict | None = None,\n    github_kwargs: dict | None = None,\n    issues_kwargs: dict | None = None,\n    graphite_kwargs: dict | None = None,\n    *,\n    use_graphite: bool = False,\n    confirm_responses: list[bool] | None = None,\n    remote_branch_refs: list[str] | None = None,\n    backend: str = \"github\",\n):\n    \"\"\"Setup common context for submit tests.\n\n    Args:\n        use_graphite: If True, enable Graphite integration (allows track_branch calls).\n                     Default False for backwards compatibility with existing tests.\n        confirm_responses: List of boolean responses for ctx.console.confirm() calls.\n                          If None, uses default FakeConsole with no responses configured.\n        remote_branch_refs: List of remote branch refs (e.g., [\"origin/branch\", \"origin/master\"]).\n                           These are passed to FakeGit's remote_branches keyed by repo_root.\n        backend: Plan store backend type - \"github\" or \"draft_pr\".\n\n    Returns (ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root)\n        where fake_backing is FakeGitHubIssues (github) or FakeGitHub (draft_pr).\n    \"\"\"\n    from erk_shared.context.types import GlobalConfig\n    from erk_shared.gateway.console.fake import FakeConsole\n    from erk_shared.gateway.git.fake import FakeGit\n    from erk_shared.gateway.github.fake import FakeGitHub\n    from erk_shared.gateway.github.issues.fake import FakeGitHubIssues\n    from erk_shared.gateway.graphite.fake import FakeGraphite\n\n    repo_root = tmp_path / \"repo\"\n    repo_root.mkdir()\n\n    fake_plan_store, fake_backing = create_plan_store(plans, backend=backend)\n\n    git_kwargs = git_kwargs or {}\n    if \"current_branches\" not in git_kwargs:\n        git_kwargs[\"current_branches\"] = {repo_root: \"main\"}\n    if \"trunk_branches\" not in git_kwargs:\n        git_kwargs[\"trunk_branches\"] = {repo_root: \"master\"}\n    if remote_branch_refs is not None:\n        git_kwargs[\"remote_branches\"] = {repo_root: remote_branch_refs}\n\n    fake_git = FakeGit(**git_kwargs)\n    fake_github = FakeGitHub(**(github_kwargs or {}))\n    # When use_graphite=False, use GraphiteDisabled sentinel to match production behavior\n    if use_graphite:\n        fake_graphite = FakeGraphite(**(graphite_kwargs or {}))\n    else:\n        from erk_shared.gateway.graphite.disabled import (\n            GraphiteDisabled,\n            GraphiteDisabledReason,\n        )\n\n        fake_graphite = GraphiteDisabled(GraphiteDisabledReason.CONFIG_DISABLED)\n\n    # Update issues kwargs if provided (only applicable to github backend)\n    if issues_kwargs and isinstance(fake_backing, FakeGitHubIssues):\n        for key, value in issues_kwargs.items():\n            setattr(fake_backing, f\"_{key}\", value)\n\n    repo_dir = tmp_path / \".erk\" / \"repos\" / \"test-repo\"\n    repo = RepoContext(\n        root=repo_root,\n        repo_name=\"test-repo\",\n        repo_dir=repo_dir,\n        worktrees_dir=repo_dir / \"worktrees\",\n        pool_json_path=repo_dir / \"pool.json\",\n    )\n\n    # Create GlobalConfig with use_graphite setting\n    global_config = GlobalConfig.test(erk_root=repo_dir, use_graphite=use_graphite)\n\n    # Create FakeConsole with confirm responses if provided\n    fake_console = FakeConsole(\n        is_interactive=True,\n        is_stdout_tty=None,\n        is_stderr_tty=None,\n        confirm_responses=confirm_responses,\n    )\n\n    # Wire up issues gateway: for github backend, use the fake backing;\n    # for draft_pr backend, let context_for_test create a default FakeGitHubIssues\n    fake_issues = fake_backing if isinstance(fake_backing, FakeGitHubIssues) else None\n\n    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n    )\n\n    return ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root\n","structuredPatch":[{"oldStart":6,"oldLines":6,"newStart":6,"newLines":7,"lines":[" from erk.cli.commands.submit import ERK_PLAN_LABEL"," from erk.core.context import context_for_test"," from erk.core.repo_discovery import RepoContext","+from tests.fakes.prompt_executor import FakePromptExecutor"," from erk_shared.gateway.github.metadata.core import render_metadata_block"," from erk_shared.gateway.github.metadata.types import MetadataBlock"," from erk_shared.plan_store.types import Plan, PlanState"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"ca5501a5-ded2-4e02-90eb-99b8a4dce6d1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01UP1GsdVf8WfXNxSjVQmRtr","type":"message","role":"assistant","content":[{"type":"text","text":"Now I need to pass the `prompt_executor` into `context_for_test`. The best approach is to configure the `FakePromptExecutor` to simulate failure so that `generate_slug_or_fallback` returns the raw title (matching existing test expectations):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":333,"cache_read_input_tokens":123953,"cache_creation":{"ephemeral_5m_input_tokens":333,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHf3hZBaidsrbVq1Haw","type":"assistant","uuid":"999648a1-b474-438c-a96d-46b5532b8c3b","timestamp":"2026-02-22T14:45:45.756Z"}
{"parentUuid":"999648a1-b474-438c-a96d-46b5532b8c3b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01UP1GsdVf8WfXNxSjVQmRtr","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013CCKx8pZnZkjegFdWv8P4V","name":"Edit","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py","old_string":"    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n    )","new_string":"    # Configure FakePromptExecutor to simulate failure so that\n    # generate_slug_or_fallback falls back to the raw title.\n    # This keeps branch name assertions stable in tests.\n    fake_prompt_executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"LLM unavailable in test\",\n    )\n\n    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n        prompt_executor=fake_prompt_executor,\n    )"},"caller":{"type":"direct"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":333,"cache_read_input_tokens":123953,"cache_creation":{"ephemeral_5m_input_tokens":333,"ephemeral_1h_input_tokens":0},"output_tokens":451,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHf3hZBaidsrbVq1Haw","type":"assistant","uuid":"0284fc4d-4ac4-42a2-ac18-22f6345c36ce","timestamp":"2026-02-22T14:45:49.453Z"}
{"parentUuid":"0284fc4d-4ac4-42a2-ac18-22f6345c36ce","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013CCKx8pZnZkjegFdWv8P4V","type":"tool_result","content":"The file /home/runner/work/erk/erk/tests/commands/submit/conftest.py has been updated successfully."}]},"uuid":"ea93534e-0f3e-4356-8429-bbafcf67d744","timestamp":"2026-02-22T14:45:50.145Z","toolUseResult":{"filePath":"/home/runner/work/erk/erk/tests/commands/submit/conftest.py","oldString":"    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n    )","newString":"    # Configure FakePromptExecutor to simulate failure so that\n    # generate_slug_or_fallback falls back to the raw title.\n    # This keeps branch name assertions stable in tests.\n    fake_prompt_executor = FakePromptExecutor(\n        available=True,\n        simulated_prompt_error=\"LLM unavailable in test\",\n    )\n\n    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n        prompt_executor=fake_prompt_executor,\n    )","originalFile":"\"\"\"Shared fixtures and helpers for submit command tests.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom pathlib import Path\n\nfrom erk.cli.commands.submit import ERK_PLAN_LABEL\nfrom erk.core.context import context_for_test\nfrom erk.core.repo_discovery import RepoContext\nfrom tests.fakes.prompt_executor import FakePromptExecutor\nfrom erk_shared.gateway.github.metadata.core import render_metadata_block\nfrom erk_shared.gateway.github.metadata.types import MetadataBlock\nfrom erk_shared.plan_store.types import Plan, PlanState\nfrom tests.test_utils.plan_helpers import create_plan_store\n\n\ndef make_plan_body(content: str = \"Implementation details...\") -> str:\n    \"\"\"Create a valid issue body with plan-header metadata block.\n\n    The plan-header block is required for `update_plan_header_dispatch` to work.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Plan\\n\\n{content}\"\n\n\ndef make_learn_plan_body(content: str = \"Documentation learning...\") -> str:\n    \"\"\"Create a valid learn plan issue body with plan-header metadata block.\n\n    Note: Learn plans are identified by the erk-learn label, not by metadata fields.\n    \"\"\"\n    plan_header_data = {\n        \"schema_version\": \"2\",\n        \"created_at\": \"2024-01-01T00:00:00Z\",\n        \"created_by\": \"test-user\",\n    }\n    header_block = render_metadata_block(MetadataBlock(\"plan-header\", plan_header_data))\n    return f\"{header_block}\\n\\n# Learn Plan\\n\\n{content}\"\n\n\ndef create_plan(\n    plan_identifier: str,\n    title: str,\n    body: str | None = None,\n    state: PlanState = PlanState.OPEN,\n    labels: list[str] | None = None,\n) -> Plan:\n    \"\"\"Create a Plan with common defaults for testing.\"\"\"\n    now = datetime.now(UTC)\n    return Plan(\n        plan_identifier=plan_identifier,\n        title=title,\n        body=body if body is not None else make_plan_body(),\n        state=state,\n        url=f\"https://github.com/test-owner/test-repo/issues/{plan_identifier}\",\n        labels=labels if labels is not None else [ERK_PLAN_LABEL],\n        assignees=[],\n        created_at=now,\n        updated_at=now,\n        metadata={},\n        objective_id=None,\n    )\n\n\ndef setup_submit_context(\n    tmp_path: Path,\n    plans: dict[str, Plan],\n    git_kwargs: dict | None = None,\n    github_kwargs: dict | None = None,\n    issues_kwargs: dict | None = None,\n    graphite_kwargs: dict | None = None,\n    *,\n    use_graphite: bool = False,\n    confirm_responses: list[bool] | None = None,\n    remote_branch_refs: list[str] | None = None,\n    backend: str = \"github\",\n):\n    \"\"\"Setup common context for submit tests.\n\n    Args:\n        use_graphite: If True, enable Graphite integration (allows track_branch calls).\n                     Default False for backwards compatibility with existing tests.\n        confirm_responses: List of boolean responses for ctx.console.confirm() calls.\n                          If None, uses default FakeConsole with no responses configured.\n        remote_branch_refs: List of remote branch refs (e.g., [\"origin/branch\", \"origin/master\"]).\n                           These are passed to FakeGit's remote_branches keyed by repo_root.\n        backend: Plan store backend type - \"github\" or \"draft_pr\".\n\n    Returns (ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root)\n        where fake_backing is FakeGitHubIssues (github) or FakeGitHub (draft_pr).\n    \"\"\"\n    from erk_shared.context.types import GlobalConfig\n    from erk_shared.gateway.console.fake import FakeConsole\n    from erk_shared.gateway.git.fake import FakeGit\n    from erk_shared.gateway.github.fake import FakeGitHub\n    from erk_shared.gateway.github.issues.fake import FakeGitHubIssues\n    from erk_shared.gateway.graphite.fake import FakeGraphite\n\n    repo_root = tmp_path / \"repo\"\n    repo_root.mkdir()\n\n    fake_plan_store, fake_backing = create_plan_store(plans, backend=backend)\n\n    git_kwargs = git_kwargs or {}\n    if \"current_branches\" not in git_kwargs:\n        git_kwargs[\"current_branches\"] = {repo_root: \"main\"}\n    if \"trunk_branches\" not in git_kwargs:\n        git_kwargs[\"trunk_branches\"] = {repo_root: \"master\"}\n    if remote_branch_refs is not None:\n        git_kwargs[\"remote_branches\"] = {repo_root: remote_branch_refs}\n\n    fake_git = FakeGit(**git_kwargs)\n    fake_github = FakeGitHub(**(github_kwargs or {}))\n    # When use_graphite=False, use GraphiteDisabled sentinel to match production behavior\n    if use_graphite:\n        fake_graphite = FakeGraphite(**(graphite_kwargs or {}))\n    else:\n        from erk_shared.gateway.graphite.disabled import (\n            GraphiteDisabled,\n            GraphiteDisabledReason,\n        )\n\n        fake_graphite = GraphiteDisabled(GraphiteDisabledReason.CONFIG_DISABLED)\n\n    # Update issues kwargs if provided (only applicable to github backend)\n    if issues_kwargs and isinstance(fake_backing, FakeGitHubIssues):\n        for key, value in issues_kwargs.items():\n            setattr(fake_backing, f\"_{key}\", value)\n\n    repo_dir = tmp_path / \".erk\" / \"repos\" / \"test-repo\"\n    repo = RepoContext(\n        root=repo_root,\n        repo_name=\"test-repo\",\n        repo_dir=repo_dir,\n        worktrees_dir=repo_dir / \"worktrees\",\n        pool_json_path=repo_dir / \"pool.json\",\n    )\n\n    # Create GlobalConfig with use_graphite setting\n    global_config = GlobalConfig.test(erk_root=repo_dir, use_graphite=use_graphite)\n\n    # Create FakeConsole with confirm responses if provided\n    fake_console = FakeConsole(\n        is_interactive=True,\n        is_stdout_tty=None,\n        is_stderr_tty=None,\n        confirm_responses=confirm_responses,\n    )\n\n    # Wire up issues gateway: for github backend, use the fake backing;\n    # for draft_pr backend, let context_for_test create a default FakeGitHubIssues\n    fake_issues = fake_backing if isinstance(fake_backing, FakeGitHubIssues) else None\n\n    ctx = context_for_test(\n        cwd=repo_root,\n        git=fake_git,\n        github=fake_github,\n        issues=fake_issues,\n        plan_store=fake_plan_store,\n        graphite=fake_graphite,\n        repo=repo,\n        global_config=global_config,\n        console=fake_console,\n    )\n\n    return ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root\n","structuredPatch":[{"oldStart":154,"oldLines":6,"newStart":154,"newLines":14,"lines":["     # for draft_pr backend, let context_for_test create a default FakeGitHubIssues","     fake_issues = fake_backing if isinstance(fake_backing, FakeGitHubIssues) else None"," ","+    # Configure FakePromptExecutor to simulate failure so that","+    # generate_slug_or_fallback falls back to the raw title.","+    # This keeps branch name assertions stable in tests.","+    fake_prompt_executor = FakePromptExecutor(","+        available=True,","+        simulated_prompt_error=\"LLM unavailable in test\",","+    )","+","     ctx = context_for_test(","         cwd=repo_root,","         git=fake_git,"]},{"oldStart":164,"oldLines":6,"newStart":172,"newLines":7,"lines":["         repo=repo,","         global_config=global_config,","         console=fake_console,","+        prompt_executor=fake_prompt_executor,","     )"," ","     return ctx, fake_git, fake_github, fake_backing, fake_graphite, repo_root"]}],"userModified":false,"replaceAll":false}}
{"parentUuid":"ea93534e-0f3e-4356-8429-bbafcf67d744","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01J5kDvZyaC7qm1hs82d5wTY","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me also check what tests use `generate_branch_name` from `one_shot_dispatch` to see if those tests also need fixing:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":685,"cache_read_input_tokens":124286,"cache_creation":{"ephemeral_5m_input_tokens":685,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHfhCnmupYCxhCUEA4Q","type":"assistant","uuid":"d4e4086c-fada-4ff2-bfea-893cc26687a6","timestamp":"2026-02-22T14:45:53.762Z"}
{"parentUuid":"d4e4086c-fada-4ff2-bfea-893cc26687a6","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01J5kDvZyaC7qm1hs82d5wTY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019ErZoMbqBsLJnCknDwhNwU","name":"Grep","input":{"pattern":"from erk.cli.commands.one_shot_dispatch import","path":"/home/runner/work/erk/erk/tests","output_mode":"content"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":685,"cache_read_input_tokens":124286,"cache_creation":{"ephemeral_5m_input_tokens":685,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHfhCnmupYCxhCUEA4Q","type":"assistant","uuid":"9458e5eb-b59c-4a60-885f-3f531caa986b","timestamp":"2026-02-22T14:45:54.477Z"}
{"parentUuid":"9458e5eb-b59c-4a60-885f-3f531caa986b","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019ErZoMbqBsLJnCknDwhNwU","type":"tool_result","content":"tests/commands/one_shot/test_branch_name.py:5:from erk.cli.commands.one_shot_dispatch import generate_branch_name\ntests/commands/one_shot/test_one_shot_dispatch.py:6:from erk.cli.commands.one_shot_dispatch import ("}]},"uuid":"bff84c9f-914f-472b-95b3-3e4aefcff402","timestamp":"2026-02-22T14:45:54.937Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"tests/commands/one_shot/test_branch_name.py:5:from erk.cli.commands.one_shot_dispatch import generate_branch_name\ntests/commands/one_shot/test_one_shot_dispatch.py:6:from erk.cli.commands.one_shot_dispatch import (","numLines":2}}
{"parentUuid":"bff84c9f-914f-472b-95b3-3e4aefcff402","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KytwwficunXzzYsmBG1xEc","type":"message","role":"assistant","content":[{"type":"text","text":"Let me check the one_shot_dispatch test to see if it will also break:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":232,"cache_read_input_tokens":124971,"cache_creation":{"ephemeral_5m_input_tokens":232,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHg3gLpL4KDfJQHgMoZ","type":"assistant","uuid":"a0e0415e-aa8f-4a24-8ac7-4bd0873db2e3","timestamp":"2026-02-22T14:45:57.501Z"}
{"parentUuid":"a0e0415e-aa8f-4a24-8ac7-4bd0873db2e3","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KytwwficunXzzYsmBG1xEc","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014KgNgNC7GaKavJqHKqMBxa","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/commands/one_shot/test_one_shot_dispatch.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":232,"cache_read_input_tokens":124971,"cache_creation":{"ephemeral_5m_input_tokens":232,"ephemeral_1h_input_tokens":0},"output_tokens":8,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHg3gLpL4KDfJQHgMoZ","type":"assistant","uuid":"c99f4522-6fc1-4415-9775-8399c241b012","timestamp":"2026-02-22T14:45:58.031Z"}
{"parentUuid":"c99f4522-6fc1-4415-9775-8399c241b012","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014KgNgNC7GaKavJqHKqMBxa","type":"tool_result","content":"     1→\"\"\"Tests for one-shot dispatch shared logic.\"\"\"\n     2→\n     3→from click.testing import CliRunner\n     4→\n     5→from erk.cli.cli import cli\n     6→from erk.cli.commands.one_shot_dispatch import (\n     7→    OneShotDispatchParams,\n     8→    dispatch_one_shot,\n     9→)\n    10→from erk_shared.gateway.git.fake import FakeGit\n    11→from erk_shared.gateway.git.remote_ops.types import PushError\n    12→from erk_shared.gateway.github.fake import FakeGitHub\n    13→from erk_shared.gateway.github.issues.fake import FakeGitHubIssues\n    14→from erk_shared.gateway.github.issues.types import IssueNotFound\n    15→from erk_shared.gateway.time.fake import FakeTime\n    16→from erk_shared.plan_store.draft_pr import DraftPRPlanBackend\n    17→from tests.test_utils.context_builders import build_workspace_test_context\n    18→from tests.test_utils.env_helpers import erk_isolated_fs_env\n    19→\n    20→\n    21→def test_dispatch_happy_path() -> None:\n    22→    \"\"\"Test dispatch creates skeleton issue, branch with P<N>- prefix, PR, and triggers workflow.\"\"\"\n    23→    runner = CliRunner()\n    24→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n    25→        env.setup_repo_structure()\n    26→\n    27→        git = FakeGit(\n    28→            git_common_dirs={env.cwd: env.git_dir},\n    29→            default_branches={env.cwd: \"main\"},\n    30→            trunk_branches={env.cwd: \"main\"},\n    31→            current_branches={env.cwd: \"main\"},\n    32→        )\n    33→        issues = FakeGitHubIssues()\n    34→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n    35→\n    36→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n    37→\n    38→        params = OneShotDispatchParams(\n    39→            prompt=\"fix the import in config.py\",\n    40→            model=None,\n    41→            extra_workflow_inputs={},\n    42→        )\n    43→\n    44→        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n    45→\n    46→        assert result is not None\n    47→        # Branch should have P<N>- prefix (skeleton issue created first)\n    48→        assert result.branch_name.startswith(\"P1-\")\n    49→\n    50→        # Verify skeleton plan issue was created\n    51→        assert len(issues.created_issues) == 1\n    52→        title, _body, labels = issues.created_issues[0]\n    53→        assert \"[erk-plan]\" in title\n    54→        assert \"erk-plan\" in labels\n    55→\n    56→        # Verify branch was created\n    57→        assert len(git.created_branches) == 1\n    58→        assert git.created_branches[0][2] == \"main\"  # start_point is trunk\n    59→\n    60→        # Verify .worker-impl/prompt.md was committed directly to branch (no checkout)\n    61→        assert len(git.branch_commits) == 1\n    62→        assert git.branch_commits[0].files == {\n    63→            \".worker-impl/prompt.md\": \"fix the import in config.py\\n\",\n    64→        }\n    65→        assert git.branch_commits[0].branch.startswith(\"P1-\")\n    66→\n    67→        # Verify push to remote\n    68→        assert len(git.pushed_branches) == 1\n    69→\n    70→        # Verify PR was created with closing reference\n    71→        assert len(github.created_prs) == 1\n    72→        _branch, _title, pr_body, base, draft = github.created_prs[0]\n    73→        assert draft is True\n    74→        assert base == \"main\"\n    75→        assert \"Closes #1\" in pr_body\n    76→\n    77→        # Verify workflow was triggered with plan_issue_number and plan_backend\n    78→        assert len(github.triggered_workflows) == 1\n    79→        workflow, inputs = github.triggered_workflows[0]\n    80→        assert workflow == \"one-shot.yml\"\n    81→        assert inputs[\"prompt\"] == \"fix the import in config.py\"\n    82→        assert inputs[\"plan_issue_number\"] == \"1\"\n    83→        assert inputs[\"plan_backend\"] == \"github\"\n    84→\n    85→        # Verify PR body was updated with workflow run link and closing reference\n    86→        assert len(github.updated_pr_bodies) == 1\n    87→        _pr_num, updated_body = github.updated_pr_bodies[0]\n    88→        assert \"**Workflow run:**\" in updated_body\n    89→        assert \"https://github.com/owner/repo/actions/runs/\" in updated_body\n    90→        assert \"Closes #1\" in updated_body\n    91→\n    92→        # Verify dispatch metadata was written to plan issue\n    93→        issue_info = issues.get_issue(env.cwd, 1)\n    94→        assert not isinstance(issue_info, IssueNotFound)\n    95→        assert \"last_dispatched_run_id\" in issue_info.body\n    96→        assert \"last_dispatched_node_id\" in issue_info.body\n    97→        assert \"last_dispatched_at\" in issue_info.body\n    98→\n    99→        # Verify we're back on original branch\n   100→        assert git.branch.get_current_branch(env.cwd) == \"main\"\n   101→\n   102→\n   103→def test_dispatch_with_extra_inputs() -> None:\n   104→    \"\"\"Test extra_workflow_inputs in workflow trigger and skeleton links to objective.\"\"\"\n   105→    runner = CliRunner()\n   106→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n   107→        env.setup_repo_structure()\n   108→\n   109→        git = FakeGit(\n   110→            git_common_dirs={env.cwd: env.git_dir},\n   111→            default_branches={env.cwd: \"main\"},\n   112→            trunk_branches={env.cwd: \"main\"},\n   113→            current_branches={env.cwd: \"main\"},\n   114→        )\n   115→        issues = FakeGitHubIssues()\n   116→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   117→\n   118→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n   119→\n   120→        params = OneShotDispatchParams(\n   121→            prompt=\"implement step 1.1\",\n   122→            model=None,\n   123→            extra_workflow_inputs={\n   124→                \"objective_issue\": \"42\",\n   125→                \"node_id\": \"1.1\",\n   126→            },\n   127→        )\n   128→\n   129→        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n   130→\n   131→        assert result is not None\n   132→        # Branch should have P<N>- prefix\n   133→        assert result.branch_name.startswith(\"P1-\")\n   134→\n   135→        # Verify extra inputs are in workflow trigger\n   136→        _workflow, inputs = github.triggered_workflows[0]\n   137→        assert inputs[\"objective_issue\"] == \"42\"\n   138→        assert inputs[\"node_id\"] == \"1.1\"\n   139→        assert inputs[\"prompt\"] == \"implement step 1.1\"\n   140→        assert inputs[\"plan_issue_number\"] == \"1\"\n   141→\n   142→\n   143→def test_dispatch_dry_run() -> None:\n   144→    \"\"\"Test dispatch_one_shot dry_run outputs info without mutations.\"\"\"\n   145→    runner = CliRunner()\n   146→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n   147→        env.setup_repo_structure()\n   148→\n   149→        git = FakeGit(\n   150→            git_common_dirs={env.cwd: env.git_dir},\n   151→            default_branches={env.cwd: \"main\"},\n   152→            trunk_branches={env.cwd: \"main\"},\n   153→            current_branches={env.cwd: \"main\"},\n   154→        )\n   155→        github = FakeGitHub(authenticated=True)\n   156→\n   157→        ctx = build_workspace_test_context(env, git=git, github=github)\n   158→\n   159→        # Invoke via CLI to capture user_output via CliRunner\n   160→        result = runner.invoke(\n   161→            cli,\n   162→            [\"one-shot\", \"add type hints\", \"--dry-run\", \"-m\", \"opus\"],\n   163→            obj=ctx,\n   164→            catch_exceptions=False,\n   165→        )\n   166→\n   167→        assert result.exit_code == 0\n   168→        assert \"Dry-run mode:\" in result.output\n   169→        assert \"add type hints\" in result.output\n   170→\n   171→        # Verify no mutations occurred (skeleton issue NOT created in dry-run)\n   172→        assert len(git.created_branches) == 0\n   173→        assert len(git.pushed_branches) == 0\n   174→        assert len(github.created_prs) == 0\n   175→        assert len(github.triggered_workflows) == 0\n   176→\n   177→\n   178→def test_dispatch_stays_on_original_branch_on_error() -> None:\n   179→    \"\"\"Test that we stay on original branch when push fails (no checkout = nothing to restore).\"\"\"\n   180→    runner = CliRunner()\n   181→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n   182→        env.setup_repo_structure()\n   183→\n   184→        git = FakeGit(\n   185→            git_common_dirs={env.cwd: env.git_dir},\n   186→            default_branches={env.cwd: \"main\"},\n   187→            trunk_branches={env.cwd: \"main\"},\n   188→            current_branches={env.cwd: \"main\"},\n   189→            push_to_remote_error=PushError(message=\"network error\"),\n   190→        )\n   191→        github = FakeGitHub(authenticated=True)\n   192→\n   193→        ctx = build_workspace_test_context(env, git=git, github=github)\n   194→\n   195→        result = runner.invoke(\n   196→            cli,\n   197→            [\"one-shot\", \"fix the import in config.py\"],\n   198→            obj=ctx,\n   199→        )\n   200→\n   201→        # Verify command failed\n   202→        assert result.exit_code != 0\n   203→\n   204→        # Verify we're still on original branch (no checkout occurred)\n   205→        assert git.branch.get_current_branch(env.cwd) == \"main\"\n   206→\n   207→\n   208→def test_dispatch_creates_skeleton_plan_issue() -> None:\n   209→    \"\"\"Test that skeleton plan issue is created with correct content and metadata.\"\"\"\n   210→    runner = CliRunner()\n   211→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n   212→        env.setup_repo_structure()\n   213→\n   214→        git = FakeGit(\n   215→            git_common_dirs={env.cwd: env.git_dir},\n   216→            default_branches={env.cwd: \"main\"},\n   217→            trunk_branches={env.cwd: \"main\"},\n   218→            current_branches={env.cwd: \"main\"},\n   219→        )\n   220→        issues = FakeGitHubIssues()\n   221→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   222→\n   223→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n   224→\n   225→        params = OneShotDispatchParams(\n   226→            prompt=\"add user authentication\",\n   227→            model=None,\n   228→            extra_workflow_inputs={},\n   229→        )\n   230→\n   231→        dispatch_one_shot(ctx, params=params, dry_run=False)\n   232→\n   233→        # Verify skeleton issue was created with expected content\n   234→        assert len(issues.created_issues) == 1\n   235→        title, _body, labels = issues.created_issues[0]\n   236→        assert \"[erk-plan]\" in title\n   237→        assert \"erk-plan\" in labels\n   238→\n   239→        # Verify plan comment was added (create_plan_issue adds plan as comment)\n   240→        # Plus queued event comment from dispatch\n   241→        assert len(issues.added_comments) == 2\n   242→        issue_number, comment_body, _comment_id = issues.added_comments[0]\n   243→        assert issue_number == 1\n   244→        assert \"One-shot\" in comment_body\n   245→        assert \"add user authentication\" in comment_body\n   246→\n   247→        # Verify queued event comment\n   248→        issue_number, queued_body, _comment_id = issues.added_comments[1]\n   249→        assert issue_number == 1\n   250→        assert \"One-Shot Dispatched\" in queued_body\n   251→        assert \"add user authentication\" in queued_body\n   252→\n   253→\n   254→def test_dispatch_posts_queued_event_comment() -> None:\n   255→    \"\"\"Test dispatch posts a queued event comment with workflow run URL and prompt.\"\"\"\n   256→    runner = CliRunner()\n   257→    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n   258→        env.setup_repo_structure()\n   259→\n   260→        git = FakeGit(\n   261→            git_common_dirs={env.cwd: env.git_dir},\n   262→            default_branches={env.cwd: \"main\"},\n   263→            trunk_branches={env.cwd: \"main\"},\n   264→            current_branches={env.cwd: \"main\"},\n   265→        )\n   266→        issues = FakeGitHubIssues()\n   267→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   268→\n   269→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n   270→\n   271→        params = OneShotDispatchParams(\n   272→            prompt=\"refactor the auth module\",\n   273→            model=None,\n   274→            extra_workflow_inputs={},\n   275→        )\n   276→\n   277→        dispatch_one_shot(ctx, params=params, dry_run=False)\n   278→\n   279→        # create_plan_issue adds 1 comment, dispatch adds queued event comment\n   280→        assert len(issues.added_comments) == 2\n   281→\n   282→        # The queued event comment is the last one\n   283→        issue_number, comment_body, _comment_id = issues.added_comments[-1]\n   284→        assert issue_number == 1\n   285→        assert \"One-Shot Dispatched\" in comment_body\n   286→        assert \"refactor the auth module\" in comment_body\n   287→        assert \"**Workflow run:**\" in comment_body\n   288→        assert \"https://github.com/owner/repo/actions/runs/\" in comment_body\n   289→\n   290→\n   291→def test_dispatch_writes_metadata_to_plan_issue() -> None:\n   292→    \"\"\"Test that dispatch writes run_id, node_id, and timestamp metadata to the plan issue.\"\"\"\n   293→    runner = CliRunner()\n   294→    with erk_isolated_fs_env(runner, env_overrides={\"ERK_PLAN_BACKEND\": \"github\"}) as env:\n   295→        env.setup_repo_structure()\n   296→\n   297→        git = FakeGit(\n   298→            git_common_dirs={env.cwd: env.git_dir},\n   299→            default_branches={env.cwd: \"main\"},\n   300→            trunk_branches={env.cwd: \"main\"},\n   301→            current_branches={env.cwd: \"main\"},\n   302→        )\n   303→        issues = FakeGitHubIssues()\n   304→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   305→\n   306→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n   307→\n   308→        params = OneShotDispatchParams(\n   309→            prompt=\"add logging to api routes\",\n   310→            model=None,\n   311→            extra_workflow_inputs={},\n   312→        )\n   313→\n   314→        dispatch_one_shot(ctx, params=params, dry_run=False)\n   315→\n   316→        # Read the plan issue and verify dispatch metadata was written\n   317→        issue_info = issues.get_issue(env.cwd, 1)\n   318→        assert not isinstance(issue_info, IssueNotFound)\n   319→        assert \"last_dispatched_run_id: '1234567890'\" in issue_info.body\n   320→        assert \"last_dispatched_node_id: WFR_fake_node_id_1234567890\" in issue_info.body\n   321→        assert \"last_dispatched_at:\" in issue_info.body\n   322→\n   323→\n   324→def test_dispatch_draft_pr_lifecycle() -> None:\n   325→    \"\"\"Test full draft_pr dispatch: no skeleton issue, planned/ branch, PR with metadata block.\n   326→\n   327→    In draft_pr mode, the draft PR IS the plan entity. The dispatch should:\n   328→    - NOT create a skeleton issue\n   329→    - Use planned/ branch naming\n   330→    - Create a draft PR with plan-header metadata block\n   331→    - Set plan_issue_number = pr_number for downstream code\n   332→    - Write dispatch metadata to the PR (the plan entity)\n   333→    - Post queued event comment to the PR\n   334→    \"\"\"\n   335→    runner = CliRunner()\n   336→    with erk_isolated_fs_env(runner) as env:\n   337→        env.setup_repo_structure()\n   338→\n   339→        git = FakeGit(\n   340→            git_common_dirs={env.cwd: env.git_dir},\n   341→            default_branches={env.cwd: \"main\"},\n   342→            trunk_branches={env.cwd: \"main\"},\n   343→            current_branches={env.cwd: \"main\"},\n   344→        )\n   345→        issues = FakeGitHubIssues()\n   346→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   347→\n   348→        # Explicitly use DraftPRPlanBackend so ctx.plan_backend.get_provider_name()\n   349→        # returns \"github-draft-pr\" and dispatch takes the draft_pr path.\n   350→        plan_store = DraftPRPlanBackend(github, issues, time=FakeTime())\n   351→\n   352→        ctx = build_workspace_test_context(\n   353→            env, git=git, github=github, issues=issues, plan_store=plan_store\n   354→        )\n   355→\n   356→        params = OneShotDispatchParams(\n   357→            prompt=\"fix the import in config.py\",\n   358→            model=None,\n   359→            extra_workflow_inputs={},\n   360→        )\n   361→\n   362→        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n   363→\n   364→        assert result is not None\n   365→\n   366→        # No skeleton issue created — draft_pr skips issue creation\n   367→        assert len(issues.created_issues) == 0\n   368→\n   369→        # Branch uses planned/ prefix (not P<N>-)\n   370→        assert result.branch_name.startswith(\"planned/\")\n   371→        assert not result.branch_name.startswith(\"P\")\n   372→\n   373→        # PR created with plan-header metadata block\n   374→        assert len(github.created_prs) == 1\n   375→        _branch, _title, pr_body, base, draft = github.created_prs[0]\n   376→        assert draft is True\n   377→        assert base == \"main\"\n   378→        assert \"plan-header\" in pr_body\n   379→        assert \"lifecycle_stage: prompted\" in pr_body\n   380→        assert \"fix the import in config.py\" in pr_body\n   381→\n   382→        # No Closes #N in PR body (self-referential for draft_pr)\n   383→        assert \"Closes #\" not in pr_body\n   384→\n   385→        # erk-plan label added to PR\n   386→        pr_number = result.pr_number\n   387→        assert (pr_number, \"erk-plan\") in github.added_labels\n   388→\n   389→        # Workflow inputs include plan_issue_number = pr_number and plan_backend\n   390→        assert len(github.triggered_workflows) == 1\n   391→        _workflow, inputs = github.triggered_workflows[0]\n   392→        assert inputs[\"plan_issue_number\"] == str(pr_number)\n   393→        assert inputs[\"plan_backend\"] == \"draft_pr\"\n   394→\n   395→        # Dispatch metadata written to the PR (the plan entity).\n   396→        # The PR body is updated with footer, then dispatch metadata written\n   397→        # via plan_backend.update_metadata targeting the PR number.\n   398→        # updated_pr_bodies includes: (1) footer update, (2) dispatch metadata update\n   399→        assert len(github.updated_pr_bodies) >= 2\n   400→        # The dispatch metadata update should contain last_dispatched_run_id\n   401→        last_body = github.updated_pr_bodies[-1][1]\n   402→        assert \"last_dispatched_run_id\" in last_body\n   403→\n   404→        # Queued event comment is best-effort. In real GitHub, PRs are issues\n   405→        # and add_comment works on PR numbers. In the fake, PRs and issues are\n   406→        # separate, so the comment may fail. This is acceptable — dispatch\n   407→        # metadata is the critical operation.\n   408→\n   409→\n   410→def test_dispatch_long_prompt_truncates_workflow_input() -> None:\n   411→    \"\"\"Test that long prompts are truncated in workflow input but committed in full.\"\"\"\n   412→    runner = CliRunner()\n   413→    with erk_isolated_fs_env(runner) as env:\n   414→        env.setup_repo_structure()\n   415→\n   416→        git = FakeGit(\n   417→            git_common_dirs={env.cwd: env.git_dir},\n   418→            default_branches={env.cwd: \"main\"},\n   419→            trunk_branches={env.cwd: \"main\"},\n   420→            current_branches={env.cwd: \"main\"},\n   421→        )\n   422→        issues = FakeGitHubIssues()\n   423→        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n   424→\n   425→        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n   426→\n   427→        long_prompt = \"x\" * 1000\n   428→\n   429→        params = OneShotDispatchParams(\n   430→            prompt=long_prompt,\n   431→            model=None,\n   432→            extra_workflow_inputs={},\n   433→        )\n   434→\n   435→        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n   436→\n   437→        assert result is not None\n   438→\n   439→        # Verify workflow input was truncated\n   440→        _workflow, inputs = github.triggered_workflows[0]\n   441→        assert len(inputs[\"prompt\"]) < len(long_prompt)\n   442→        assert inputs[\"prompt\"].endswith(\"... (full prompt committed to .worker-impl/prompt.md)\")\n   443→\n   444→        # Verify full prompt was committed directly to branch via branch_commits\n   445→        assert len(git.branch_commits) == 1\n   446→        assert git.branch_commits[0].files == {\".worker-impl/prompt.md\": long_prompt + \"\\n\"}\n   447→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"410d3781-a18f-4435-aa7f-100889de1719","timestamp":"2026-02-22T14:45:58.062Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/commands/one_shot/test_one_shot_dispatch.py","content":"\"\"\"Tests for one-shot dispatch shared logic.\"\"\"\n\nfrom click.testing import CliRunner\n\nfrom erk.cli.cli import cli\nfrom erk.cli.commands.one_shot_dispatch import (\n    OneShotDispatchParams,\n    dispatch_one_shot,\n)\nfrom erk_shared.gateway.git.fake import FakeGit\nfrom erk_shared.gateway.git.remote_ops.types import PushError\nfrom erk_shared.gateway.github.fake import FakeGitHub\nfrom erk_shared.gateway.github.issues.fake import FakeGitHubIssues\nfrom erk_shared.gateway.github.issues.types import IssueNotFound\nfrom erk_shared.gateway.time.fake import FakeTime\nfrom erk_shared.plan_store.draft_pr import DraftPRPlanBackend\nfrom tests.test_utils.context_builders import build_workspace_test_context\nfrom tests.test_utils.env_helpers import erk_isolated_fs_env\n\n\ndef test_dispatch_happy_path() -> None:\n    \"\"\"Test dispatch creates skeleton issue, branch with P<N>- prefix, PR, and triggers workflow.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        params = OneShotDispatchParams(\n            prompt=\"fix the import in config.py\",\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        assert result is not None\n        # Branch should have P<N>- prefix (skeleton issue created first)\n        assert result.branch_name.startswith(\"P1-\")\n\n        # Verify skeleton plan issue was created\n        assert len(issues.created_issues) == 1\n        title, _body, labels = issues.created_issues[0]\n        assert \"[erk-plan]\" in title\n        assert \"erk-plan\" in labels\n\n        # Verify branch was created\n        assert len(git.created_branches) == 1\n        assert git.created_branches[0][2] == \"main\"  # start_point is trunk\n\n        # Verify .worker-impl/prompt.md was committed directly to branch (no checkout)\n        assert len(git.branch_commits) == 1\n        assert git.branch_commits[0].files == {\n            \".worker-impl/prompt.md\": \"fix the import in config.py\\n\",\n        }\n        assert git.branch_commits[0].branch.startswith(\"P1-\")\n\n        # Verify push to remote\n        assert len(git.pushed_branches) == 1\n\n        # Verify PR was created with closing reference\n        assert len(github.created_prs) == 1\n        _branch, _title, pr_body, base, draft = github.created_prs[0]\n        assert draft is True\n        assert base == \"main\"\n        assert \"Closes #1\" in pr_body\n\n        # Verify workflow was triggered with plan_issue_number and plan_backend\n        assert len(github.triggered_workflows) == 1\n        workflow, inputs = github.triggered_workflows[0]\n        assert workflow == \"one-shot.yml\"\n        assert inputs[\"prompt\"] == \"fix the import in config.py\"\n        assert inputs[\"plan_issue_number\"] == \"1\"\n        assert inputs[\"plan_backend\"] == \"github\"\n\n        # Verify PR body was updated with workflow run link and closing reference\n        assert len(github.updated_pr_bodies) == 1\n        _pr_num, updated_body = github.updated_pr_bodies[0]\n        assert \"**Workflow run:**\" in updated_body\n        assert \"https://github.com/owner/repo/actions/runs/\" in updated_body\n        assert \"Closes #1\" in updated_body\n\n        # Verify dispatch metadata was written to plan issue\n        issue_info = issues.get_issue(env.cwd, 1)\n        assert not isinstance(issue_info, IssueNotFound)\n        assert \"last_dispatched_run_id\" in issue_info.body\n        assert \"last_dispatched_node_id\" in issue_info.body\n        assert \"last_dispatched_at\" in issue_info.body\n\n        # Verify we're back on original branch\n        assert git.branch.get_current_branch(env.cwd) == \"main\"\n\n\ndef test_dispatch_with_extra_inputs() -> None:\n    \"\"\"Test extra_workflow_inputs in workflow trigger and skeleton links to objective.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        params = OneShotDispatchParams(\n            prompt=\"implement step 1.1\",\n            model=None,\n            extra_workflow_inputs={\n                \"objective_issue\": \"42\",\n                \"node_id\": \"1.1\",\n            },\n        )\n\n        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        assert result is not None\n        # Branch should have P<N>- prefix\n        assert result.branch_name.startswith(\"P1-\")\n\n        # Verify extra inputs are in workflow trigger\n        _workflow, inputs = github.triggered_workflows[0]\n        assert inputs[\"objective_issue\"] == \"42\"\n        assert inputs[\"node_id\"] == \"1.1\"\n        assert inputs[\"prompt\"] == \"implement step 1.1\"\n        assert inputs[\"plan_issue_number\"] == \"1\"\n\n\ndef test_dispatch_dry_run() -> None:\n    \"\"\"Test dispatch_one_shot dry_run outputs info without mutations.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        github = FakeGitHub(authenticated=True)\n\n        ctx = build_workspace_test_context(env, git=git, github=github)\n\n        # Invoke via CLI to capture user_output via CliRunner\n        result = runner.invoke(\n            cli,\n            [\"one-shot\", \"add type hints\", \"--dry-run\", \"-m\", \"opus\"],\n            obj=ctx,\n            catch_exceptions=False,\n        )\n\n        assert result.exit_code == 0\n        assert \"Dry-run mode:\" in result.output\n        assert \"add type hints\" in result.output\n\n        # Verify no mutations occurred (skeleton issue NOT created in dry-run)\n        assert len(git.created_branches) == 0\n        assert len(git.pushed_branches) == 0\n        assert len(github.created_prs) == 0\n        assert len(github.triggered_workflows) == 0\n\n\ndef test_dispatch_stays_on_original_branch_on_error() -> None:\n    \"\"\"Test that we stay on original branch when push fails (no checkout = nothing to restore).\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n            push_to_remote_error=PushError(message=\"network error\"),\n        )\n        github = FakeGitHub(authenticated=True)\n\n        ctx = build_workspace_test_context(env, git=git, github=github)\n\n        result = runner.invoke(\n            cli,\n            [\"one-shot\", \"fix the import in config.py\"],\n            obj=ctx,\n        )\n\n        # Verify command failed\n        assert result.exit_code != 0\n\n        # Verify we're still on original branch (no checkout occurred)\n        assert git.branch.get_current_branch(env.cwd) == \"main\"\n\n\ndef test_dispatch_creates_skeleton_plan_issue() -> None:\n    \"\"\"Test that skeleton plan issue is created with correct content and metadata.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        params = OneShotDispatchParams(\n            prompt=\"add user authentication\",\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        # Verify skeleton issue was created with expected content\n        assert len(issues.created_issues) == 1\n        title, _body, labels = issues.created_issues[0]\n        assert \"[erk-plan]\" in title\n        assert \"erk-plan\" in labels\n\n        # Verify plan comment was added (create_plan_issue adds plan as comment)\n        # Plus queued event comment from dispatch\n        assert len(issues.added_comments) == 2\n        issue_number, comment_body, _comment_id = issues.added_comments[0]\n        assert issue_number == 1\n        assert \"One-shot\" in comment_body\n        assert \"add user authentication\" in comment_body\n\n        # Verify queued event comment\n        issue_number, queued_body, _comment_id = issues.added_comments[1]\n        assert issue_number == 1\n        assert \"One-Shot Dispatched\" in queued_body\n        assert \"add user authentication\" in queued_body\n\n\ndef test_dispatch_posts_queued_event_comment() -> None:\n    \"\"\"Test dispatch posts a queued event comment with workflow run URL and prompt.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides=None) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        params = OneShotDispatchParams(\n            prompt=\"refactor the auth module\",\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        # create_plan_issue adds 1 comment, dispatch adds queued event comment\n        assert len(issues.added_comments) == 2\n\n        # The queued event comment is the last one\n        issue_number, comment_body, _comment_id = issues.added_comments[-1]\n        assert issue_number == 1\n        assert \"One-Shot Dispatched\" in comment_body\n        assert \"refactor the auth module\" in comment_body\n        assert \"**Workflow run:**\" in comment_body\n        assert \"https://github.com/owner/repo/actions/runs/\" in comment_body\n\n\ndef test_dispatch_writes_metadata_to_plan_issue() -> None:\n    \"\"\"Test that dispatch writes run_id, node_id, and timestamp metadata to the plan issue.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner, env_overrides={\"ERK_PLAN_BACKEND\": \"github\"}) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        params = OneShotDispatchParams(\n            prompt=\"add logging to api routes\",\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        # Read the plan issue and verify dispatch metadata was written\n        issue_info = issues.get_issue(env.cwd, 1)\n        assert not isinstance(issue_info, IssueNotFound)\n        assert \"last_dispatched_run_id: '1234567890'\" in issue_info.body\n        assert \"last_dispatched_node_id: WFR_fake_node_id_1234567890\" in issue_info.body\n        assert \"last_dispatched_at:\" in issue_info.body\n\n\ndef test_dispatch_draft_pr_lifecycle() -> None:\n    \"\"\"Test full draft_pr dispatch: no skeleton issue, planned/ branch, PR with metadata block.\n\n    In draft_pr mode, the draft PR IS the plan entity. The dispatch should:\n    - NOT create a skeleton issue\n    - Use planned/ branch naming\n    - Create a draft PR with plan-header metadata block\n    - Set plan_issue_number = pr_number for downstream code\n    - Write dispatch metadata to the PR (the plan entity)\n    - Post queued event comment to the PR\n    \"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        # Explicitly use DraftPRPlanBackend so ctx.plan_backend.get_provider_name()\n        # returns \"github-draft-pr\" and dispatch takes the draft_pr path.\n        plan_store = DraftPRPlanBackend(github, issues, time=FakeTime())\n\n        ctx = build_workspace_test_context(\n            env, git=git, github=github, issues=issues, plan_store=plan_store\n        )\n\n        params = OneShotDispatchParams(\n            prompt=\"fix the import in config.py\",\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        assert result is not None\n\n        # No skeleton issue created — draft_pr skips issue creation\n        assert len(issues.created_issues) == 0\n\n        # Branch uses planned/ prefix (not P<N>-)\n        assert result.branch_name.startswith(\"planned/\")\n        assert not result.branch_name.startswith(\"P\")\n\n        # PR created with plan-header metadata block\n        assert len(github.created_prs) == 1\n        _branch, _title, pr_body, base, draft = github.created_prs[0]\n        assert draft is True\n        assert base == \"main\"\n        assert \"plan-header\" in pr_body\n        assert \"lifecycle_stage: prompted\" in pr_body\n        assert \"fix the import in config.py\" in pr_body\n\n        # No Closes #N in PR body (self-referential for draft_pr)\n        assert \"Closes #\" not in pr_body\n\n        # erk-plan label added to PR\n        pr_number = result.pr_number\n        assert (pr_number, \"erk-plan\") in github.added_labels\n\n        # Workflow inputs include plan_issue_number = pr_number and plan_backend\n        assert len(github.triggered_workflows) == 1\n        _workflow, inputs = github.triggered_workflows[0]\n        assert inputs[\"plan_issue_number\"] == str(pr_number)\n        assert inputs[\"plan_backend\"] == \"draft_pr\"\n\n        # Dispatch metadata written to the PR (the plan entity).\n        # The PR body is updated with footer, then dispatch metadata written\n        # via plan_backend.update_metadata targeting the PR number.\n        # updated_pr_bodies includes: (1) footer update, (2) dispatch metadata update\n        assert len(github.updated_pr_bodies) >= 2\n        # The dispatch metadata update should contain last_dispatched_run_id\n        last_body = github.updated_pr_bodies[-1][1]\n        assert \"last_dispatched_run_id\" in last_body\n\n        # Queued event comment is best-effort. In real GitHub, PRs are issues\n        # and add_comment works on PR numbers. In the fake, PRs and issues are\n        # separate, so the comment may fail. This is acceptable — dispatch\n        # metadata is the critical operation.\n\n\ndef test_dispatch_long_prompt_truncates_workflow_input() -> None:\n    \"\"\"Test that long prompts are truncated in workflow input but committed in full.\"\"\"\n    runner = CliRunner()\n    with erk_isolated_fs_env(runner) as env:\n        env.setup_repo_structure()\n\n        git = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            default_branches={env.cwd: \"main\"},\n            trunk_branches={env.cwd: \"main\"},\n            current_branches={env.cwd: \"main\"},\n        )\n        issues = FakeGitHubIssues()\n        github = FakeGitHub(authenticated=True, issues_gateway=issues)\n\n        ctx = build_workspace_test_context(env, git=git, github=github, issues=issues)\n\n        long_prompt = \"x\" * 1000\n\n        params = OneShotDispatchParams(\n            prompt=long_prompt,\n            model=None,\n            extra_workflow_inputs={},\n        )\n\n        result = dispatch_one_shot(ctx, params=params, dry_run=False)\n\n        assert result is not None\n\n        # Verify workflow input was truncated\n        _workflow, inputs = github.triggered_workflows[0]\n        assert len(inputs[\"prompt\"]) < len(long_prompt)\n        assert inputs[\"prompt\"].endswith(\"... (full prompt committed to .worker-impl/prompt.md)\")\n\n        # Verify full prompt was committed directly to branch via branch_commits\n        assert len(git.branch_commits) == 1\n        assert git.branch_commits[0].files == {\".worker-impl/prompt.md\": long_prompt + \"\\n\"}\n","numLines":447,"startLine":1,"totalLines":447}}}
{"parentUuid":"410d3781-a18f-4435-aa7f-100889de1719","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SCLyjFGQYuWmFAh8dhkdxB","type":"message","role":"assistant","content":[{"type":"text","text":"These tests use `build_workspace_test_context`. Let me check if that also creates a default `FakePromptExecutor`:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6836,"cache_read_input_tokens":125203,"cache_creation":{"ephemeral_5m_input_tokens":6836,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHgH5zXVrgrhcgyNb2V","type":"assistant","uuid":"1682b40e-eccf-4c0b-994c-5a902b6dc96e","timestamp":"2026-02-22T14:46:01.365Z"}
{"parentUuid":"1682b40e-eccf-4c0b-994c-5a902b6dc96e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SCLyjFGQYuWmFAh8dhkdxB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012Re3SM44eTGAiY2bmT9Vgx","name":"Read","input":{"file_path":"/home/runner/work/erk/erk/tests/test_utils/context_builders.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6836,"cache_read_input_tokens":125203,"cache_creation":{"ephemeral_5m_input_tokens":6836,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHgH5zXVrgrhcgyNb2V","type":"assistant","uuid":"a898f586-9b01-424f-8a2e-3b49e4c27f48","timestamp":"2026-02-22T14:46:02.093Z"}
{"parentUuid":"a898f586-9b01-424f-8a2e-3b49e4c27f48","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012Re3SM44eTGAiY2bmT9Vgx","type":"tool_result","content":"     1→\"\"\"Shared context builders for test scenarios.\n     2→\n     3→This module provides reusable context builder functions to eliminate duplication\n     4→across test files. These builders encapsulate common patterns for setting up\n     5→ErkContext with appropriate fake implementations.\n     6→\"\"\"\n     7→\n     8→from erk.core.context import ErkContext\n     9→from erk_shared.gateway.git.dry_run import DryRunGit\n    10→from erk_shared.gateway.git.fake import FakeGit\n    11→from erk_shared.gateway.github.fake import FakeGitHub\n    12→from tests.fakes.shell import FakeShell\n    13→from tests.test_utils.env_helpers import ErkInMemEnv, ErkIsolatedFsEnv\n    14→\n    15→\n    16→def build_workspace_test_context(\n    17→    env: ErkInMemEnv | ErkIsolatedFsEnv,\n    18→    *,\n    19→    dry_run: bool = False,\n    20→    use_graphite: bool = False,\n    21→    current_branch: str | None = None,\n    22→    **kwargs,\n    23→) -> ErkContext:\n    24→    \"\"\"Build ErkContext for workspace command tests (create, split, consolidate, delete).\n    25→\n    26→    This builder provides a standard context configuration for workspace manipulation\n    27→    commands with sensible defaults and support for common testing scenarios.\n    28→\n    29→    Args:\n    30→        env: Pure or isolated erk environment fixture\n    31→        dry_run: Whether to wrap git operations with DryRunGit (default: False)\n    32→        use_graphite: Whether to enable Graphite integration (default: False)\n    33→        current_branch: Current branch name for FakeGit configuration (default: None)\n    34→        **kwargs: Additional arguments passed to env.build_context()\n    35→                  (can include custom git, github, graphite, shell instances)\n    36→\n    37→    Returns:\n    38→        ErkContext configured for workspace command testing\n    39→\n    40→    Example:\n    41→        >>> with erk_inmem_env(runner) as env:\n    42→        ...     ctx = build_workspace_test_context(env, dry_run=True)\n    43→        ...     result = runner.invoke(cli, [\"delete\", \"branch\"], obj=ctx)\n    44→    \"\"\"\n    45→    # Only create default git if not provided in kwargs\n    46→    if \"git\" not in kwargs:\n    47→        current_branches_dict = {env.cwd: current_branch} if current_branch else None\n    48→        git_ops = FakeGit(\n    49→            git_common_dirs={env.cwd: env.git_dir},\n    50→            remote_urls={(env.cwd, \"origin\"): \"https://github.com/owner/repo.git\"},\n    51→            current_branches=current_branches_dict,\n    52→        )\n    53→        if dry_run:\n    54→            git_ops = DryRunGit(git_ops)\n    55→        kwargs[\"git\"] = git_ops\n    56→    else:\n    57→        # Ensure custom git has remote_urls configured for repo discovery\n    58→        git_ops = kwargs[\"git\"]\n    59→        unwrapped = git_ops._wrapped if isinstance(git_ops, DryRunGit) else git_ops\n    60→        if hasattr(unwrapped, \"_remote_urls\"):\n    61→            # Add default remote URL if not already set for env.cwd\n    62→            if (env.cwd, \"origin\") not in unwrapped._remote_urls:\n    63→                unwrapped._remote_urls[(env.cwd, \"origin\")] = \"https://github.com/owner/repo.git\"\n    64→\n    65→    # Provide defaults for other integrations if not in kwargs\n    66→    if \"github\" not in kwargs:\n    67→        kwargs[\"github\"] = FakeGitHub()\n    68→    # Note: Don't set graphite here - let env.build_context handle it\n    69→    # based on use_graphite flag (uses GraphiteDisabled when disabled)\n    70→    if \"shell\" not in kwargs:\n    71→        kwargs[\"shell\"] = FakeShell()\n    72→\n    73→    return env.build_context(\n    74→        use_graphite=use_graphite,\n    75→        dry_run=dry_run,\n    76→        **kwargs,\n    77→    )\n    78→\n    79→\n    80→def build_graphite_test_context(\n    81→    env: ErkInMemEnv | ErkIsolatedFsEnv, *, dry_run: bool = False, **kwargs\n    82→) -> ErkContext:\n    83→    \"\"\"Build ErkContext for Graphite-enabled command tests.\n    84→\n    85→    Convenience wrapper around build_workspace_test_context() that enables\n    86→    Graphite integration by default.\n    87→\n    88→    Args:\n    89→        env: Pure or isolated erk environment fixture\n    90→        dry_run: Whether to wrap git operations with DryRunGit (default: False)\n    91→        **kwargs: Additional arguments passed to env.build_context()\n    92→\n    93→    Returns:\n    94→        ErkContext configured for Graphite command testing\n    95→\n    96→    Example:\n    97→        >>> with erk_inmem_env(runner) as env:\n    98→        ...     ctx = build_graphite_test_context(env)\n    99→        ...     result = runner.invoke(cli, [\"land-stack\"], obj=ctx)\n   100→    \"\"\"\n   101→    return build_workspace_test_context(env, dry_run=dry_run, use_graphite=True, **kwargs)\n   102→\n   103→\n   104→def build_navigation_test_context(\n   105→    env: ErkInMemEnv | ErkIsolatedFsEnv, *, current_branch: str | None = None, **kwargs\n   106→) -> ErkContext:\n   107→    \"\"\"Build ErkContext for navigation command tests (up, down, wt co).\n   108→\n   109→    Convenience wrapper around build_workspace_test_context() for navigation\n   110→    commands that typically need to specify the current branch.\n   111→\n   112→    Args:\n   113→        env: Pure or isolated erk environment fixture\n   114→        current_branch: Current branch name for FakeGit configuration (default: None)\n   115→        **kwargs: Additional arguments passed to env.build_context()\n   116→\n   117→    Returns:\n   118→        ErkContext configured for navigation command testing\n   119→\n   120→    Example:\n   121→        >>> with erk_inmem_env(runner) as env:\n   122→        ...     ctx = build_navigation_test_context(env, current_branch=\"feat-1\")\n   123→        ...     result = runner.invoke(cli, [\"up\"], obj=ctx)\n   124→    \"\"\"\n   125→    return build_workspace_test_context(env, current_branch=current_branch, **kwargs)\n   126→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"465ee19d-89e4-4a1d-9a11-eb0ea94ed7ce","timestamp":"2026-02-22T14:46:02.110Z","toolUseResult":{"type":"text","file":{"filePath":"/home/runner/work/erk/erk/tests/test_utils/context_builders.py","content":"\"\"\"Shared context builders for test scenarios.\n\nThis module provides reusable context builder functions to eliminate duplication\nacross test files. These builders encapsulate common patterns for setting up\nErkContext with appropriate fake implementations.\n\"\"\"\n\nfrom erk.core.context import ErkContext\nfrom erk_shared.gateway.git.dry_run import DryRunGit\nfrom erk_shared.gateway.git.fake import FakeGit\nfrom erk_shared.gateway.github.fake import FakeGitHub\nfrom tests.fakes.shell import FakeShell\nfrom tests.test_utils.env_helpers import ErkInMemEnv, ErkIsolatedFsEnv\n\n\ndef build_workspace_test_context(\n    env: ErkInMemEnv | ErkIsolatedFsEnv,\n    *,\n    dry_run: bool = False,\n    use_graphite: bool = False,\n    current_branch: str | None = None,\n    **kwargs,\n) -> ErkContext:\n    \"\"\"Build ErkContext for workspace command tests (create, split, consolidate, delete).\n\n    This builder provides a standard context configuration for workspace manipulation\n    commands with sensible defaults and support for common testing scenarios.\n\n    Args:\n        env: Pure or isolated erk environment fixture\n        dry_run: Whether to wrap git operations with DryRunGit (default: False)\n        use_graphite: Whether to enable Graphite integration (default: False)\n        current_branch: Current branch name for FakeGit configuration (default: None)\n        **kwargs: Additional arguments passed to env.build_context()\n                  (can include custom git, github, graphite, shell instances)\n\n    Returns:\n        ErkContext configured for workspace command testing\n\n    Example:\n        >>> with erk_inmem_env(runner) as env:\n        ...     ctx = build_workspace_test_context(env, dry_run=True)\n        ...     result = runner.invoke(cli, [\"delete\", \"branch\"], obj=ctx)\n    \"\"\"\n    # Only create default git if not provided in kwargs\n    if \"git\" not in kwargs:\n        current_branches_dict = {env.cwd: current_branch} if current_branch else None\n        git_ops = FakeGit(\n            git_common_dirs={env.cwd: env.git_dir},\n            remote_urls={(env.cwd, \"origin\"): \"https://github.com/owner/repo.git\"},\n            current_branches=current_branches_dict,\n        )\n        if dry_run:\n            git_ops = DryRunGit(git_ops)\n        kwargs[\"git\"] = git_ops\n    else:\n        # Ensure custom git has remote_urls configured for repo discovery\n        git_ops = kwargs[\"git\"]\n        unwrapped = git_ops._wrapped if isinstance(git_ops, DryRunGit) else git_ops\n        if hasattr(unwrapped, \"_remote_urls\"):\n            # Add default remote URL if not already set for env.cwd\n            if (env.cwd, \"origin\") not in unwrapped._remote_urls:\n                unwrapped._remote_urls[(env.cwd, \"origin\")] = \"https://github.com/owner/repo.git\"\n\n    # Provide defaults for other integrations if not in kwargs\n    if \"github\" not in kwargs:\n        kwargs[\"github\"] = FakeGitHub()\n    # Note: Don't set graphite here - let env.build_context handle it\n    # based on use_graphite flag (uses GraphiteDisabled when disabled)\n    if \"shell\" not in kwargs:\n        kwargs[\"shell\"] = FakeShell()\n\n    return env.build_context(\n        use_graphite=use_graphite,\n        dry_run=dry_run,\n        **kwargs,\n    )\n\n\ndef build_graphite_test_context(\n    env: ErkInMemEnv | ErkIsolatedFsEnv, *, dry_run: bool = False, **kwargs\n) -> ErkContext:\n    \"\"\"Build ErkContext for Graphite-enabled command tests.\n\n    Convenience wrapper around build_workspace_test_context() that enables\n    Graphite integration by default.\n\n    Args:\n        env: Pure or isolated erk environment fixture\n        dry_run: Whether to wrap git operations with DryRunGit (default: False)\n        **kwargs: Additional arguments passed to env.build_context()\n\n    Returns:\n        ErkContext configured for Graphite command testing\n\n    Example:\n        >>> with erk_inmem_env(runner) as env:\n        ...     ctx = build_graphite_test_context(env)\n        ...     result = runner.invoke(cli, [\"land-stack\"], obj=ctx)\n    \"\"\"\n    return build_workspace_test_context(env, dry_run=dry_run, use_graphite=True, **kwargs)\n\n\ndef build_navigation_test_context(\n    env: ErkInMemEnv | ErkIsolatedFsEnv, *, current_branch: str | None = None, **kwargs\n) -> ErkContext:\n    \"\"\"Build ErkContext for navigation command tests (up, down, wt co).\n\n    Convenience wrapper around build_workspace_test_context() for navigation\n    commands that typically need to specify the current branch.\n\n    Args:\n        env: Pure or isolated erk environment fixture\n        current_branch: Current branch name for FakeGit configuration (default: None)\n        **kwargs: Additional arguments passed to env.build_context()\n\n    Returns:\n        ErkContext configured for navigation command testing\n\n    Example:\n        >>> with erk_inmem_env(runner) as env:\n        ...     ctx = build_navigation_test_context(env, current_branch=\"feat-1\")\n        ...     result = runner.invoke(cli, [\"up\"], obj=ctx)\n    \"\"\"\n    return build_workspace_test_context(env, current_branch=current_branch, **kwargs)\n","numLines":126,"startLine":1,"totalLines":126}}}
{"parentUuid":"465ee19d-89e4-4a1d-9a11-eb0ea94ed7ce","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SxpCZ7UU4x1J6XJjGFgM2t","type":"message","role":"assistant","content":[{"type":"text","text":"This uses `env.build_context()` which ultimately calls `context_for_test`. The `one_shot_dispatch` tests also use the default `FakePromptExecutor`, so they'll also get `\"Test Title\\n\\nTest body\"` as the slug. But those tests only check `result.branch_name.startswith(\"P1-\")` and `result.branch_name.startswith(\"planned/\")`, which are prefix-based checks that should still pass regardless of the slug content.\n\nLet me verify by running the full one-shot test file:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2013,"cache_read_input_tokens":132039,"cache_creation":{"ephemeral_5m_input_tokens":2013,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHgaU1jjMGeBT9ZdT71","type":"assistant","uuid":"a5b4e1ca-e43d-4f17-a157-bf78022d0868","timestamp":"2026-02-22T14:46:07.642Z"}
{"parentUuid":"a5b4e1ca-e43d-4f17-a157-bf78022d0868","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SxpCZ7UU4x1J6XJjGFgM2t","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MstVJ1jLRmKxjygfodX7U4","name":"Task","input":{"description":"Run one-shot and submit tests","prompt":"Run these test files and report results. Do NOT fix errors - just report:\n1. pytest tests/commands/one_shot/ -v\n2. pytest tests/commands/submit/ -v\n\nReport pass/fail counts and any failure details.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":2013,"cache_read_input_tokens":132039,"cache_creation":{"ephemeral_5m_input_tokens":2013,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHgaU1jjMGeBT9ZdT71","type":"assistant","uuid":"3569e018-298e-4371-a05b-8af0436f34d4","timestamp":"2026-02-22T14:46:10.132Z"}
{"parentUuid":"3569e018-298e-4371-a05b-8af0436f34d4","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MstVJ1jLRmKxjygfodX7U4","type":"tool_result","content":[{"type":"text","text":"## Test Results\n\n**pytest tests/commands/one_shot/ -v**\n- Status: PASSED\n- Summary: 26 passed in 0.67s\n\n**pytest tests/commands/submit/ -v**\n- Status: PASSED\n- Summary: 71 passed in 0.23s\n\n**Total: 97 passed, 0 failed**\n\nAll tests in both suites passed successfully."},{"type":"text","text":"agentId: a93fcb5 (for resuming to continue this agent's work if needed)"}]}]},"uuid":"81d09804-281a-4bdb-b1f7-d4d12ba3531d","timestamp":"2026-02-22T14:46:18.488Z","toolUseResult":{"status":"completed","prompt":"Run these test files and report results. Do NOT fix errors - just report:\n1. pytest tests/commands/one_shot/ -v\n2. pytest tests/commands/submit/ -v\n\nReport pass/fail counts and any failure details.","agentId":"a93fcb5","content":[{"type":"text","text":"## Test Results\n\n**pytest tests/commands/one_shot/ -v**\n- Status: PASSED\n- Summary: 26 passed in 0.67s\n\n**pytest tests/commands/submit/ -v**\n- Status: PASSED\n- Summary: 71 passed in 0.23s\n\n**Total: 97 passed, 0 failed**\n\nAll tests in both suites passed successfully."}],"totalDurationMs":8308,"totalTokens":13398,"totalToolUseCount":2,"usage":{"input_tokens":7,"cache_creation_input_tokens":971,"cache_read_input_tokens":12324,"cache_creation":{"ephemeral_5m_input_tokens":971,"ephemeral_1h_input_tokens":0},"output_tokens":96,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"81d09804-281a-4bdb-b1f7-d4d12ba3531d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Pv8z3xhuc74QnvpDtkqFd4","type":"message","role":"assistant","content":[{"type":"text","text":"All 97 tests pass. Now let me run the full unit test suite to confirm everything is clean:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":597,"cache_read_input_tokens":134052,"cache_creation":{"ephemeral_5m_input_tokens":597,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHhnVqZRXjKz4f8GXip","type":"assistant","uuid":"f98079f5-8db1-47be-a9b9-955537584ced","timestamp":"2026-02-22T14:46:22.330Z"}
{"parentUuid":"f98079f5-8db1-47be-a9b9-955537584ced","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01Pv8z3xhuc74QnvpDtkqFd4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014nqAAieM2Hen1m5NZCM34h","name":"Task","input":{"description":"Run full unit test suite","prompt":"Run `make test-unit` and report the summary results (pass/fail counts). Do NOT fix any errors - just report them. If there are failures, report which test files and test names failed.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":597,"cache_read_input_tokens":134052,"cache_creation":{"ephemeral_5m_input_tokens":597,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHhnVqZRXjKz4f8GXip","type":"assistant","uuid":"1647a7b2-dcff-4c03-b3f9-591918e6e418","timestamp":"2026-02-22T14:46:23.989Z"}
{"parentUuid":"1647a7b2-dcff-4c03-b3f9-591918e6e418","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014nqAAieM2Hen1m5NZCM34h","type":"tool_result","content":[{"type":"text","text":"Perfect! The unit tests all passed. Here's the summary:\n\n**Test Results Summary:**\n\n- **Total tests passed: 5,529**\n  - erk unit tests: 5,393 passed in 10.95s\n  - erk-dev tests: 136 passed in 3.90s\n\n- **Failures: 0**\n- **Status: All tests passed**\n\nThe test suite executed successfully with no failures."},{"type":"text","text":"agentId: ad6b205 (for resuming to continue this agent's work if needed)"}]}]},"uuid":"47847260-6d3b-472b-8dc1-fb6d6ed4ed1e","timestamp":"2026-02-22T14:46:48.230Z","toolUseResult":{"status":"completed","prompt":"Run `make test-unit` and report the summary results (pass/fail counts). Do NOT fix any errors - just report them. If there are failures, report which test files and test names failed.","agentId":"ad6b205","content":[{"type":"text","text":"Perfect! The unit tests all passed. Here's the summary:\n\n**Test Results Summary:**\n\n- **Total tests passed: 5,529**\n  - erk unit tests: 5,393 passed in 10.95s\n  - erk-dev tests: 136 passed in 3.90s\n\n- **Failures: 0**\n- **Status: All tests passed**\n\nThe test suite executed successfully with no failures."}],"totalDurationMs":24205,"totalTokens":16485,"totalToolUseCount":3,"usage":{"input_tokens":6,"cache_creation_input_tokens":895,"cache_read_input_tokens":15483,"cache_creation":{"ephemeral_5m_input_tokens":895,"ephemeral_1h_input_tokens":0},"output_tokens":101,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"47847260-6d3b-472b-8dc1-fb6d6ed4ed1e","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014fdy3m65GuKihpWxsEvJyh","type":"message","role":"assistant","content":[{"type":"text","text":"All 5,529 tests pass. Let me also run type checking:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":290,"cache_read_input_tokens":134649,"cache_creation":{"ephemeral_5m_input_tokens":290,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHjyaQBucTnEN5hFtTW","type":"assistant","uuid":"30b92216-12bc-4ae7-8da5-b8e2b55cf33c","timestamp":"2026-02-22T14:46:51.218Z"}
{"parentUuid":"30b92216-12bc-4ae7-8da5-b8e2b55cf33c","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_014fdy3m65GuKihpWxsEvJyh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CiCG6dWXe8JVw7Qwj8bp9s","name":"Task","input":{"description":"Run type checks","prompt":"Run `make ty` and report results. Do NOT fix any errors - just report them.","subagent_type":"devrun"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":290,"cache_read_input_tokens":134649,"cache_creation":{"ephemeral_5m_input_tokens":290,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHjyaQBucTnEN5hFtTW","type":"assistant","uuid":"34509892-9de7-4c04-a564-979e4a07e5ea","timestamp":"2026-02-22T14:46:51.744Z"}
{"parentUuid":"34509892-9de7-4c04-a564-979e4a07e5ea","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CiCG6dWXe8JVw7Qwj8bp9s","type":"tool_result","content":[{"type":"text","text":"ty passed: All checks passed!\n\nThe type checking completed successfully with no errors or warnings."},{"type":"text","text":"agentId: af48745 (for resuming to continue this agent's work if needed)"}]}]},"uuid":"dcb8ba06-5026-4188-a5b1-30fcf6593db0","timestamp":"2026-02-22T14:47:02.867Z","toolUseResult":{"status":"completed","prompt":"Run `make ty` and report results. Do NOT fix any errors - just report them.","agentId":"af48745","content":[{"type":"text","text":"ty passed: All checks passed!\n\nThe type checking completed successfully with no errors or warnings."}],"totalDurationMs":11090,"totalTokens":12426,"totalToolUseCount":1,"usage":{"input_tokens":5,"cache_creation_input_tokens":109,"cache_read_input_tokens":12290,"cache_creation":{"ephemeral_5m_input_tokens":109,"ephemeral_1h_input_tokens":0},"output_tokens":22,"service_tier":"standard","inference_geo":"not_available"}}}
{"parentUuid":"dcb8ba06-5026-4188-a5b1-30fcf6593db0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KoohG7UzRj9TP8LvDJbkku","type":"message","role":"assistant","content":[{"type":"text","text":"All CI checks pass. Let me verify `.impl/` is preserved and then submit the PR."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":88131,"cache_read_input_tokens":19598,"cache_creation":{"ephemeral_5m_input_tokens":88131,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHm47XTpHMokj8QMP5k","type":"assistant","uuid":"dea604cd-92d4-4031-bc18-c66fe81fe025","timestamp":"2026-02-22T14:47:09.177Z"}
{"parentUuid":"dea604cd-92d4-4031-bc18-c66fe81fe025","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01KoohG7UzRj9TP8LvDJbkku","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Hv8haaxVNSbTNZw7qaBGhN","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"completed","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"in_progress","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":88131,"cache_read_input_tokens":19598,"cache_creation":{"ephemeral_5m_input_tokens":88131,"ephemeral_1h_input_tokens":0},"output_tokens":2,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHm47XTpHMokj8QMP5k","type":"assistant","uuid":"31140c39-93a1-46ba-a90d-863f356f7242","timestamp":"2026-02-22T14:47:11.140Z"}
{"parentUuid":"31140c39-93a1-46ba-a90d-863f356f7242","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Hv8haaxVNSbTNZw7qaBGhN","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"f19575dd-db55-4c5b-98ed-c2661010d717","timestamp":"2026-02-22T14:47:11.158Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"in_progress","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"pending","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"completed","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"in_progress","activeForm":"Submitting PR"}]}}
{"parentUuid":"f19575dd-db55-4c5b-98ed-c2661010d717","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SCesvQoVnx2MK4jLxrjV18","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EVXitJVmcumuEk51rH4h1R","name":"Bash","input":{"command":"erk exec impl-verify 2>&1","description":"Verify .impl/ folder preserved"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":107729,"cache_creation":{"ephemeral_5m_input_tokens":280,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHmfeCetGW1b69R5mAa","type":"assistant","uuid":"9b10df42-aeac-42ec-8ff6-995aa7e1bc92","timestamp":"2026-02-22T14:47:14.809Z"}
{"parentUuid":"9b10df42-aeac-42ec-8ff6-995aa7e1bc92","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01SCesvQoVnx2MK4jLxrjV18","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Q2LFoP6gBi1uWCHtzrtwnH","name":"Bash","input":{"command":"erk exec impl-signal ended --session-id \"${CLAUDE_SESSION_ID}\" 2>/dev/null || true","description":"Signal implementation ended"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":107729,"cache_creation":{"ephemeral_5m_input_tokens":280,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHmfeCetGW1b69R5mAa","type":"assistant","uuid":"a7083695-da04-4abd-a720-684488a572cf","timestamp":"2026-02-22T14:47:15.715Z"}
{"parentUuid":"a7083695-da04-4abd-a720-684488a572cf","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EVXitJVmcumuEk51rH4h1R","type":"tool_result","content":"{\"valid\": true, \"impl_dir\": \"/home/runner/work/erk/erk/.impl\"}","is_error":false}]},"uuid":"aaf178d7-d7d2-484c-a81e-aa660fea9405","timestamp":"2026-02-22T14:47:16.714Z","toolUseResult":{"stdout":"{\"valid\": true, \"impl_dir\": \"/home/runner/work/erk/erk/.impl\"}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"aaf178d7-d7d2-484c-a81e-aa660fea9405","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Q2LFoP6gBi1uWCHtzrtwnH","type":"tool_result","content":"{\n  \"success\": true,\n  \"event\": \"ended\",\n  \"issue_number\": 7853\n}","is_error":false}]},"uuid":"5740421f-0d04-4557-a28a-44917ef0724d","timestamp":"2026-02-22T14:47:19.011Z","toolUseResult":{"stdout":"{\n  \"success\": true,\n  \"event\": \"ended\",\n  \"issue_number\": 7853\n}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"5740421f-0d04-4557-a28a-44917ef0724d","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_015xYomgDUw1ZCXkvF6XfTT8","type":"message","role":"assistant","content":[{"type":"text","text":"Good. Now upload the session and submit the PR:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":276,"cache_read_input_tokens":108009,"cache_creation":{"ephemeral_5m_input_tokens":276,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHnF9pxqvkr29qiXUhK","type":"assistant","uuid":"3ea64691-712d-4479-8944-7b742d355447","timestamp":"2026-02-22T14:47:21.651Z"}
{"parentUuid":"3ea64691-712d-4479-8944-7b742d355447","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_015xYomgDUw1ZCXkvF6XfTT8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019f7SiXDboSA6giW1H6zAkd","name":"Bash","input":{"command":"eval \"$(erk exec capture-session-info)\" && ISSUE_NUMBER=$(python3 -c \"import json; print(json.load(open('.impl/issue.json'))['issue_number'])\" 2>/dev/null || echo \"\") && if [ -n \"$SESSION_ID\" ] && [ -n \"$SESSION_FILE\" ] && [ -n \"$ISSUE_NUMBER\" ]; then erk exec upload-session --session-file \"$SESSION_FILE\" --session-id \"$SESSION_ID\" --source local --issue-number \"$ISSUE_NUMBER\" || true; fi","description":"Upload session for async learn"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":276,"cache_read_input_tokens":108009,"cache_creation":{"ephemeral_5m_input_tokens":276,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHnF9pxqvkr29qiXUhK","type":"assistant","uuid":"d8ff1d4b-aee8-4600-b685-70fa27dbeeb0","timestamp":"2026-02-22T14:47:23.935Z"}
{"parentUuid":"d8ff1d4b-aee8-4600-b685-70fa27dbeeb0","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019f7SiXDboSA6giW1H6zAkd","type":"tool_result","content":"","is_error":false}]},"uuid":"ee82267c-6d45-49b4-92ae-33c64c6132bc","timestamp":"2026-02-22T14:47:24.969Z","toolUseResult":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"ee82267c-6d45-49b4-92ae-33c64c6132bc","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HjLeNi1qZNMQrfSh212bwz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BrkSwykwF54kG8RbQypmSz","name":"Bash","input":{"command":"erk pr submit 2>&1","description":"Submit PR via erk","timeout":120000},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":241,"cache_read_input_tokens":108285,"cache_creation":{"ephemeral_5m_input_tokens":241,"ephemeral_1h_input_tokens":0},"output_tokens":19,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHngbmiMdYVHVjbvfve","type":"assistant","uuid":"37478e3c-5c4e-4697-87f5-d9fc2129d059","timestamp":"2026-02-22T14:47:29.042Z"}
{"parentUuid":"37478e3c-5c4e-4697-87f5-d9fc2129d059","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BrkSwykwF54kG8RbQypmSz","type":"tool_result","content":"🚀 Submitting PR...\n\n   Committing uncommitted changes...\nPhase 1: Creating or Updating PR\n   PR #7853 found (already exists)\n\nPhase 2: Getting diff\n\nPhase 3: Fetching plan context\n   Incorporating plan from issue #7853\n\nPhase 4: Generating PR description\n   Reading diff file...\n   Diff loaded (24,453 chars)\n   Analyzing changes with Claude...\n   PR description generated\n\nPhase 5: Graphite enhancement\n\nPhase 6: Updating PR metadata\n   Publishing draft PR...\n   PR metadata updated\n\n✅ \u001b]8;;https://github.com/dagster-io/erk/pull/7853\u001b\\https://github.com/dagster-io/erk/pull/7853\u001b]8;;\u001b\\","is_error":false}]},"uuid":"02356978-ee4c-47c8-92ef-229508a9b5c1","timestamp":"2026-02-22T14:47:45.275Z","toolUseResult":{"stdout":"🚀 Submitting PR...\n\n   Committing uncommitted changes...\nPhase 1: Creating or Updating PR\n   PR #7853 found (already exists)\n\nPhase 2: Getting diff\n\nPhase 3: Fetching plan context\n   Incorporating plan from issue #7853\n\nPhase 4: Generating PR description\n   Reading diff file...\n   Diff loaded (24,453 chars)\n   Analyzing changes with Claude...\n   PR description generated\n\nPhase 5: Graphite enhancement\n\nPhase 6: Updating PR metadata\n   Publishing draft PR...\n   PR metadata updated\n\n✅ \u001b]8;;https://github.com/dagster-io/erk/pull/7853\u001b\\https://github.com/dagster-io/erk/pull/7853\u001b]8;;\u001b\\","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"02356978-ee4c-47c8-92ef-229508a9b5c1","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01PBAMUJxNVVRjGGAMacAx1u","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Kn9QaM2kbdrjJeaH6GupKn","name":"Bash","input":{"command":"erk pr check 2>&1","description":"Validate PR rules"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":294,"cache_read_input_tokens":108526,"cache_creation":{"ephemeral_5m_input_tokens":294,"ephemeral_1h_input_tokens":0},"output_tokens":19,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHpBa5TzuPKdm9jqg7d","type":"assistant","uuid":"522c9f40-491b-4d08-9301-470c254b2378","timestamp":"2026-02-22T14:47:48.418Z"}
{"parentUuid":"522c9f40-491b-4d08-9301-470c254b2378","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Kn9QaM2kbdrjJeaH6GupKn","type":"tool_result","content":"Checking PR #7853 for branch planned/plan-llm-generated-bran-02-22-0933...\n\n[PASS] Branch name and plan reference agree (#7853)\n[PASS] Draft PR plan — no closing reference needed\n[PASS] PR body contains checkout footer\n\nAll checks passed","is_error":false}]},"uuid":"adbb2ec4-1601-4402-bd34-769372cba433","timestamp":"2026-02-22T14:47:49.953Z","toolUseResult":{"stdout":"Checking PR #7853 for branch planned/plan-llm-generated-bran-02-22-0933...\n\n[PASS] Branch name and plan reference agree (#7853)\n[PASS] Draft PR plan — no closing reference needed\n[PASS] PR body contains checkout footer\n\nAll checks passed","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"adbb2ec4-1601-4402-bd34-769372cba433","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_019sQETq9j9zdPm8AXBs7thE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011fQigURVZfdBenWLYNSbVq","name":"Bash","input":{"command":"erk exec impl-signal submitted 2>/dev/null || true","description":"Signal PR submitted"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":353,"cache_read_input_tokens":108820,"cache_creation":{"ephemeral_5m_input_tokens":353,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHpXTQkqKMomPrkg3C8","type":"assistant","uuid":"29f4844b-2b90-469b-a741-e08e21fb293a","timestamp":"2026-02-22T14:47:52.742Z"}
{"parentUuid":"29f4844b-2b90-469b-a741-e08e21fb293a","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011fQigURVZfdBenWLYNSbVq","type":"tool_result","content":"{\n  \"success\": true,\n  \"event\": \"submitted\",\n  \"issue_number\": 7853\n}","is_error":false}]},"uuid":"cfc05105-73b8-4b4d-a0e4-f544af34c888","timestamp":"2026-02-22T14:47:55.446Z","toolUseResult":{"stdout":"{\n  \"success\": true,\n  \"event\": \"submitted\",\n  \"issue_number\": 7853\n}","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"cfc05105-73b8-4b4d-a0e4-f544af34c888","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01N7vyehgRuNYmQd2Sot5em1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WoXsLZdUrgWNq1sFrkNCMA","name":"TodoWrite","input":{"todos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"completed","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"completed","activeForm":"Submitting PR"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":123,"cache_read_input_tokens":109173,"cache_creation":{"ephemeral_5m_input_tokens":123,"ephemeral_1h_input_tokens":0},"output_tokens":25,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHpvwHgCDYHmGABAWA9","type":"assistant","uuid":"fe93c231-7934-4b9a-a10a-a89787fb4263","timestamp":"2026-02-22T14:47:59.178Z"}
{"parentUuid":"fe93c231-7934-4b9a-a10a-a89787fb4263","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WoXsLZdUrgWNq1sFrkNCMA","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"uuid":"c131184d-2feb-4041-8300-ea2425a93f89","timestamp":"2026-02-22T14:47:59.235Z","toolUseResult":{"oldTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"completed","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"in_progress","activeForm":"Submitting PR"}],"newTodos":[{"content":"Create src/erk/core/branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator module"},{"content":"Create tests/core/test_branch_slug_generator.py","status":"completed","activeForm":"Creating branch slug generator tests"},{"content":"Integrate at 5 call sites","status":"completed","activeForm":"Integrating slug generator at call sites"},{"content":"Run CI and fix issues","status":"completed","activeForm":"Running CI and fixing issues"},{"content":"Submit PR","status":"completed","activeForm":"Submitting PR"}]}}
{"parentUuid":"c131184d-2feb-4041-8300-ea2425a93f89","isSidechain":false,"userType":"external","cwd":"/home/runner/work/erk/erk","sessionId":"f4caa9a1-b0f8-434c-8f36-26e0329648f0","version":"2.0.67","gitBranch":"planned/plan-llm-generated-bran-02-22-0933","slug":"fluffy-baking-karp","message":{"model":"claude-opus-4-6","id":"msg_01HKEpUduUCZqyBqsWt7mF39","type":"message","role":"assistant","content":[{"type":"text","text":"Plan execution complete. Here's the summary:\n\n**PR:** https://github.com/dagster-io/erk/pull/7853\n\n**Changes made:**\n\n1. **New module** `src/erk/core/branch_slug_generator.py` - `BranchSlugGenerator` class that uses `PromptExecutor` to send titles to a fast LLM (haiku) with a system prompt requesting 2-4 word slugs. Includes post-processing (strip quotes/backticks, sanitize, validate 2+ words, max 30 chars) and a `generate_slug_or_fallback()` convenience function that returns the raw title on failure.\n\n2. **New tests** `tests/core/test_branch_slug_generator.py` - 12 tests covering success, quote/backtick stripping, executor failure, single-word rejection, too-long rejection, fallback behavior, model selection, and empty output.\n\n3. **Integrated at 5 call sites:**\n   - `plan_save.py` - `planned/` branch naming for draft-PR plans\n   - `submit.py` - `P{issue}-` branch naming for plan submission\n   - `one_shot_dispatch.py` - Both `P{issue}-` and `oneshot-` branches\n   - `setup_impl_from_issue.py` - `P{issue}-` branch naming during impl setup\n   - `plan_migrate_to_draft_pr.py` - `planned/` branch naming during migration\n\n4. **Updated existing tests** - `test_branch_name.py` (added `prompt_executor=None` parameter), submit test conftest (configured `FakePromptExecutor` with error fallback)\n\n**CI:** 5,529 unit tests pass, type checking clean, ruff clean."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":255,"cache_read_input_tokens":109296,"cache_creation":{"ephemeral_5m_input_tokens":255,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard","inference_geo":"global"}},"requestId":"req_011CYPHqD8NWa7AbhUQvMcBD","type":"assistant","uuid":"5f77fbb3-618a-4e69-bb9c-6dec66a3680d","timestamp":"2026-02-22T14:48:11.476Z"}
